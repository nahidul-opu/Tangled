Project,File,CommitHash,Diff,Decision,CommitMessage
spring-boot,9232.json,ed15f742fd4eacc14b06908112ac4ca6ae4c0f90,"@@ -1,7 +1,7 @@
 	public static String template(TemplateEngine engine, String name, Map<String, ?> model)
 			throws IOException, CompilationFailedException, ClassNotFoundException {
-		Writable writable = getTemplate(name).make(model);
+		Writable writable = getTemplate(engine, name).make(model);
 		StringWriter result = new StringWriter();
 		writable.writeTo(result);
 		return result.toString();
 	}
\ No newline at end of file
",Buggy,"Fix bug in GroovyTemplate convenience

It was ignoring the engine argument in the 3 arg version
of template()."
spring-boot,9233.json,ed15f742fd4eacc14b06908112ac4ca6ae4c0f90,"@@ -1,17 +1,16 @@
-	private static Template getTemplate(String name) throws CompilationFailedException,
+	private static Template getTemplate(TemplateEngine engine, String name) throws CompilationFailedException,
 			ClassNotFoundException, IOException {
-		GStringTemplateEngine engine = new GStringTemplateEngine();
 
 		File file = new File(""templates"", name);
 		if (file.exists()) {
 			return engine.createTemplate(file);
 		}
 
 		ClassLoader classLoader = GroovyTemplate.class.getClassLoader();
 		URL resource = classLoader.getResource(""templates/"" + name);
 		if (resource != null) {
 			return engine.createTemplate(resource);
 		}
 
 		return engine.createTemplate(name);
 	}
\ No newline at end of file
",Buggy,"Fix bug in GroovyTemplate convenience

It was ignoring the engine argument in the 3 arg version
of template()."
spring-boot,510.json,99ae6dac5321a741d93ff5187fafb94c295a6928,"@@ -1,3 +1,3 @@
-		public CouchbaseEnvironment couchbaseEnvironment() throws Exception {
-			return createEnvironment(this.properties);
+		public DefaultCouchbaseEnvironment couchbaseEnvironment() throws Exception {
+			return initializeEnvironmentBuilder(this.properties).build();
 		}
\ No newline at end of file
",Buggy,"Customize Couchbase's socket connect timeout

Our Windows build is failing currently because the couchbase server does
not handle a socket connection within a second (the default). This commit
adds a property to customize this option and set it to 10 sec in the
sample.

While investigating this issue, it turns out that while
`CouchbaseConfiguration` is public, it is not really possible to extend
it in user's configuration. This commit fixes this problem and add a test
that demonstrates how it can be used.

Closes gh-5657"
spring-boot,516.json,99ae6dac5321a741d93ff5187fafb94c295a6928,"@@ -1,22 +1,23 @@
-		protected CouchbaseEnvironment createEnvironment(CouchbaseProperties properties) {
+		protected DefaultCouchbaseEnvironment.Builder initializeEnvironmentBuilder(CouchbaseProperties properties) {
 			CouchbaseProperties.Endpoints endpoints = properties.getEnv().getEndpoints();
 			CouchbaseProperties.Timeouts timeouts = properties.getEnv().getTimeouts();
 			DefaultCouchbaseEnvironment.Builder builder = DefaultCouchbaseEnvironment
 					.builder().connectTimeout(timeouts.getConnect())
 					.kvEndpoints(endpoints.getKeyValue())
 					.kvTimeout(timeouts.getKeyValue())
 					.queryEndpoints(endpoints.getQuery())
 					.queryTimeout(timeouts.getQuery()).viewEndpoints(endpoints.getView())
+					.socketConnectTimeout(timeouts.getSocketConnect())
 					.viewTimeout(timeouts.getView());
 			CouchbaseProperties.Ssl ssl = properties.getEnv().getSsl();
 			if (ssl.getEnabled()) {
 				builder.sslEnabled(true);
 				if (ssl.getKeyStore() != null) {
 					builder.sslKeystoreFile(ssl.getKeyStore());
 				}
 				if (ssl.getKeyStorePassword() != null) {
 					builder.sslKeystorePassword(ssl.getKeyStorePassword());
 				}
 			}
-			return builder.build();
+			return builder;
 		}
\ No newline at end of file
",Buggy,"Customize Couchbase's socket connect timeout

Our Windows build is failing currently because the couchbase server does
not handle a socket connection within a second (the default). This commit
adds a property to customize this option and set it to 10 sec in the
sample.

While investigating this issue, it turns out that while
`CouchbaseConfiguration` is public, it is not really possible to extend
it in user's configuration. This commit fixes this problem and add a test
that demonstrates how it can be used.

Closes gh-5657"
spring-boot,6313.json,1a2186e6efed5c53d7c50548de7b30b9a6dcd7f7,"@@ -1,6 +1,6 @@
 		private boolean startsWithArgumentClassName(String message) {
-			Predicate<Object> startsWith = (argument) -> argument != null
-					&& message.startsWith(argument.getClass().getName());
+			Predicate<Object> startsWith = (argument) -> startsWithArgumentClassName(
+					message, argument);
 			return startsWith.test(this.argument)
 					|| Stream.of(this.additionalArguments).anyMatch(startsWith);
 		}
\ No newline at end of file
",Buggy,"Attempt to fix lambda error detection on JDK 9

Update `LambdaSafe` to also detect `ClassCastException` messages that
start with ""module/name"".

See gh-11584"
spring-boot,2051.json,4b4dc28a869e2f8b988f6ac6ea8a31c274477da5,"@@ -1,9 +1,10 @@
 	private void logError(ServerRequest request, ServerResponse response, Throwable throwable) {
 		if (logger.isDebugEnabled()) {
 			logger.debug(request.exchange().getLogPrefix() + formatError(throwable, request));
 		}
-		if (response.statusCode().equals(HttpStatus.INTERNAL_SERVER_ERROR)) {
+		if (HttpStatus.resolve(response.rawStatusCode()) != null
+				&& response.statusCode().equals(HttpStatus.INTERNAL_SERVER_ERROR)) {
 			logger.error(request.exchange().getLogPrefix() + ""500 Server Error for "" + formatRequest(request),
 					throwable);
 		}
 	}
\ No newline at end of file
",Buggy,"Support non-standard error codes with AbstractErrorWebExceptionHandler

Fixes gh-16691"
guava,10860.json,81f0a77431bf90bf02543b999577400c7c13aa13,"@@ -1,13 +1,15 @@
       @Override public Iterator<T> iterator() {
         return new AbstractIterator<T>() {
+          private final Iterator<Optional<T>> iterator = checkNotNull(optionals.iterator());
+
           @Override protected T computeNext() {
             while (iterator.hasNext()) {
               Optional<T> optional = iterator.next();
               if (optional.isPresent()) {
                 return optional.get();
               }
             }
             return endOfData();
           }
         };
       };
\ No newline at end of file
",Buggy,"Fix bug in Optional#presentInstances.
-------------
Created by MOE: http://code.google.com/p/moe-java
MOE_MIGRATED_REVID=26472796"
guava,10861.json,81f0a77431bf90bf02543b999577400c7c13aa13,"@@ -1,19 +1,20 @@
-  public static <T> Iterable<T> presentInstances(Iterable<Optional<T>> optionals) {
+  public static <T> Iterable<T> presentInstances(final Iterable<Optional<T>> optionals) {
     checkNotNull(optionals);
-    final Iterator<Optional<T>> iterator = checkNotNull(optionals.iterator());
     return new Iterable<T>() {
       @Override public Iterator<T> iterator() {
         return new AbstractIterator<T>() {
+          private final Iterator<Optional<T>> iterator = checkNotNull(optionals.iterator());
+
           @Override protected T computeNext() {
             while (iterator.hasNext()) {
               Optional<T> optional = iterator.next();
               if (optional.isPresent()) {
                 return optional.get();
               }
             }
             return endOfData();
           }
         };
       };
     };
   }
\ No newline at end of file
",Buggy,"Fix bug in Optional#presentInstances.
-------------
Created by MOE: http://code.google.com/p/moe-java
MOE_MIGRATED_REVID=26472796"
guava,14951.json,803f44ac9c6a3457388394e952132fe18449cb9f,"@@ -1,4 +1,6 @@
     @Override public void clear() {
-      linkedEntries.removeAll(createEntries(delegate()));
+      for (V value : delegate) {
+        linkedEntries.remove(createEntry(value));
+      }
       delegate.clear();
     }
\ No newline at end of file
",Buggy,"Fix performance problem in LinkedHashMultimap.removeAll(key), as documented in http://code.google.com/p/guava-libraries/issues/detail?id=371&start=100

R=kak
DELTA=3  (2 added, 0 deleted, 1 changed)


Revision created by MOE tool push_codebase.
MOE_MIGRATION=177089


git-svn-id: https://guava-libraries.googlecode.com/svn/trunk@93 8138a162-5c33-11de-8abc-d1c337b90d21"
guava,9470.json,2ee7f9da69308c56d5af71267e8b797cedaf31ba,"@@ -1,3 +1,5 @@
   public boolean hasEdgeConnecting(N nodeU, N nodeV) {
-    return !edgesConnecting(nodeU, nodeV).isEmpty();
+    checkNotNull(nodeU);
+    checkNotNull(nodeV);
+    return nodes().contains(nodeU) && successors(nodeU).contains(nodeV);
   }
\ No newline at end of file
",Buggy,"AbstractNetwork: fix bug in AbstractNetwork.hasEdgeConnecting() causing it to throw if either endpoint was not in the graph.

RELNOTES=Fix bug in AbstractNetwork.hasEdgeConnecting() causing it to throw if either endpoint was not in the graph.  Originally reported as GitHub issue #3721.

-------------
Created by MOE: https://github.com/google/moe
MOE_MIGRATED_REVID=282846559"
guava,9471.json,2ee7f9da69308c56d5af71267e8b797cedaf31ba,"@@ -1,7 +1,7 @@
   public boolean hasEdgeConnecting(EndpointPair<N> endpoints) {
     checkNotNull(endpoints);
     if (!isOrderingCompatible(endpoints)) {
       return false;
     }
-    return !edgesConnecting(endpoints.nodeU(), endpoints.nodeV()).isEmpty();
+    return hasEdgeConnecting(endpoints.nodeU(), endpoints.nodeV());
   }
\ No newline at end of file
",Buggy,"AbstractNetwork: fix bug in AbstractNetwork.hasEdgeConnecting() causing it to throw if either endpoint was not in the graph.

RELNOTES=Fix bug in AbstractNetwork.hasEdgeConnecting() causing it to throw if either endpoint was not in the graph.  Originally reported as GitHub issue #3721.

-------------
Created by MOE: https://github.com/google/moe
MOE_MIGRATED_REVID=282846559"
guava,18902.json,314727b81a4f45210ab53ebd46b695150ea36f8c,"@@ -1,14 +1,11 @@
   public static long copy(Readable from, Appendable to) throws IOException {
     CharBuffer buf = CharBuffer.allocate(BUF_SIZE);
     long total = 0;
-    while (true) {
-      int r = from.read(buf);
-      if (r == -1) {
-        break;
-      }
+    while (from.read(buf) != -1) {
       buf.flip();
-      to.append(buf, 0, r);
-      total += r;
+      to.append(buf);
+      total += buf.remaining();
+      buf.clear();
     }
     return total;
   }
\ No newline at end of file
",Buggy,"Fix a bug with CharStreams.copy not clearing its buffer after reading.

Guava issue 1061: http://code.google.com/p/guava-libraries/issues/detail?id=1061
-------------
Created by MOE: http://code.google.com/p/moe-java
MOE_MIGRATED_REVID=31793143"
guava,12172.json,843f8d8fc37133e6870d5b2200838219a55eb83e,"@@ -1,3 +1,3 @@
     @Override public int size() {
-      return safeIntFactorial(inputList.size());
+      return IntMath.factorial(inputList.size());
     }
\ No newline at end of file
",Buggy,"Nuke 85 lines of code in Collections2 by adopting common.math. Which apparently fixed a size calculation bug that wasn't found due to a bad test that thought C(34,14) > MAX_VALUE.  (?)

Also snuck a call to IntMath.pow() into cartesianProduct.
-------------
Created by MOE: http://code.google.com/p/moe-java
MOE_MIGRATED_REVID=28310475"
guava,12171.json,843f8d8fc37133e6870d5b2200838219a55eb83e,"@@ -1,32 +1,25 @@
-    static <E> int calculateSize(List<E> sortedInputList,
-        Comparator<? super E> comparator) {
-      try {
-        long permutations = 1;
-        int n = 1;
-        int r = 1;
-        for (; n < sortedInputList.size(); n++, r++) {
-          int comparison = comparator.compare(sortedInputList.get(n - 1),
-              sortedInputList.get(n));
-          // The list is sorted, this is an invariant.
-          checkState(comparison <= 0);
-          if (comparison < 0) {
-            // We move to the next non-repeated element.
-            permutations *= binomialCoefficient(n, r);
-            r = 0;
-
-            // Return early if we have more than MAX_VALUE permutations.
-            if (!isPositiveInt(permutations)) {
-              return Integer.MAX_VALUE;
-            }
+    private static <E> int calculateSize(
+        List<E> sortedInputList, Comparator<? super E> comparator) {
+      long permutations = 1;
+      int n = 1;
+      int r = 1;
+      while (n < sortedInputList.size()) {
+        int comparison = comparator.compare(
+            sortedInputList.get(n - 1), sortedInputList.get(n));
+        if (comparison < 0) {
+          // We move to the next non-repeated element.
+          permutations *= binomial(n, r);
+          r = 0;
+          if (!isPositiveInt(permutations)) {
+            return Integer.MAX_VALUE;
           }
         }
-        permutations *= binomialCoefficient(n, r);
-        if (!isPositiveInt(permutations)) {
-          return Integer.MAX_VALUE;
-        }
-        return (int) permutations;
-      } catch (IllegalArgumentException e) {
-        // Overflow. Fall back to max size.
+        n++;
+        r++;
+      }
+      permutations *= binomial(n, r);
+      if (!isPositiveInt(permutations)) {
         return Integer.MAX_VALUE;
       }
+      return (int) permutations;
     }
\ No newline at end of file
",Buggy,"Nuke 85 lines of code in Collections2 by adopting common.math. Which apparently fixed a size calculation bug that wasn't found due to a bad test that thought C(34,14) > MAX_VALUE.  (?)

Also snuck a call to IntMath.pow() into cartesianProduct.
-------------
Created by MOE: http://code.google.com/p/moe-java
MOE_MIGRATED_REVID=28310475"
guava,1857.json,a0f748e78516c8c80c945f6a4c4fae752d11bff5,"@@ -1,9 +1,7 @@
   private void readObject(ObjectInputStream stream) throws IOException, ClassNotFoundException {
     stream.defaultReadObject();
     keyType = (Class<K>) stream.readObject();
     valueType = (Class<V>) stream.readObject();
-    setDelegates(
-        WellBehavedMap.wrap(new EnumMap<K, V>(keyType)),
-        WellBehavedMap.wrap(new EnumMap<V, K>(valueType)));
+    setDelegates(new EnumMap<K, V>(keyType), new EnumMap<V, K>(valueType));
     Serialization.populateMap(this, stream);
   }
\ No newline at end of file
",NotBuggy,"Delete WellBehavedMap.

The bug it worked around was fixed in Java 7:
https://bugs.java.com/bugdatabase/view_bug.do?bug_id=6312706

And I don't believe it was ever present under Android:
https://android.googlesource.com/platform/libcore/+/fdb2704414a9ed92394ada0d1395e4db86889465/luni/src/main/java/java/util/EnumMap.java#146

I haven't looked for the absolute first version ever of GWT, but the still very old GWT file doesn't have the bug, either.

Deleting this class will simplify some work I'm doing around our EnumMap usage for j2cl.

RELNOTES=n/a

-------------
Created by MOE: https://github.com/google/moe
MOE_MIGRATED_REVID=233418344"
guava,13304.json,a0f748e78516c8c80c945f6a4c4fae752d11bff5,"@@ -1,8 +1,7 @@
   private void readObject(ObjectInputStream stream) throws IOException, ClassNotFoundException {
     stream.defaultReadObject();
     keyType = (Class<K>) stream.readObject();
     setDelegates(
-        WellBehavedMap.wrap(new EnumMap<K, V>(keyType)),
-        new HashMap<V, K>(keyType.getEnumConstants().length * 3 / 2));
+        new EnumMap<K, V>(keyType), new HashMap<V, K>(keyType.getEnumConstants().length * 3 / 2));
     Serialization.populateMap(this, stream);
   }
\ No newline at end of file
",NotBuggy,"Delete WellBehavedMap.

The bug it worked around was fixed in Java 7:
https://bugs.java.com/bugdatabase/view_bug.do?bug_id=6312706

And I don't believe it was ever present under Android:
https://android.googlesource.com/platform/libcore/+/fdb2704414a9ed92394ada0d1395e4db86889465/luni/src/main/java/java/util/EnumMap.java#146

I haven't looked for the absolute first version ever of GWT, but the still very old GWT file doesn't have the bug, either.

Deleting this class will simplify some work I'm doing around our EnumMap usage for j2cl.

RELNOTES=n/a

-------------
Created by MOE: https://github.com/google/moe
MOE_MIGRATED_REVID=233418344"
guava,22245.json,c5231cfd14de78cd50099e095798fba6726cbe9e,"@@ -1,7 +1,7 @@
   public static RegularImmutableAsList<Object> instantiate(SerializationStreamReader reader)
       throws SerializationException {
-    @SuppressWarnings(""unchecked"") // serialization is necessarily type unsafe
-    ImmutableCollection<Object> delegateCollection = (ImmutableCollection) reader.readObject();
-    ImmutableList<?> delegateList = (ImmutableList<?>) reader.readObject();
-    return new RegularImmutableAsList<Object>(delegateCollection, delegateList);
+    ArrayList<Object> elements = new ArrayList<Object>();
+    Collection_CustomFieldSerializerBase.deserialize(reader, elements);
+    ImmutableList<Object> delegate = ImmutableList.copyOf(elements);
+    return new RegularImmutableAsList<Object>(delegate, delegate);
   }
\ No newline at end of file
",Buggy,"fixes serialization errors when serializing a
RegularImmutableAsList

the issue occur when ImmutableList is included in gwt's serialization
policy and ImmutableSet not and a list created by ImmutableSet.asList
needs to be serialized

Fixes #2614

-------------
Created by MOE: https://github.com/google/moe
MOE_MIGRATED_REVID=137724815"
guava,22246.json,c5231cfd14de78cd50099e095798fba6726cbe9e,"@@ -1,5 +1,4 @@
   public static void serialize(SerializationStreamWriter writer, RegularImmutableAsList<?> instance)
       throws SerializationException {
-    writer.writeObject(instance.delegateCollection());
-    writer.writeObject(instance.delegateList());
+    Collection_CustomFieldSerializerBase.serialize(writer, instance);
   }
\ No newline at end of file
",Buggy,"fixes serialization errors when serializing a
RegularImmutableAsList

the issue occur when ImmutableList is included in gwt's serialization
policy and ImmutableSet not and a list created by ImmutableSet.asList
needs to be serialized

Fixes #2614

-------------
Created by MOE: https://github.com/google/moe
MOE_MIGRATED_REVID=137724815"
guava,11944.json,946ebccece2c45cce528cdc6d2db1aa31d2cfa73,"@@ -1,20 +1,26 @@
   private Type resolveTypeArgsForSubclass(Class<?> subclass) {
-    if (runtimeType instanceof Class) {
+    // If both runtimeType and subclass are not parameterized, return subclass
+    // If runtimeType is not parameterized but subclass is, process subclass as a parameterized type
+    // If runtimeType is a raw type (i.e. is a parameterized type specified as a Class<?>), we
+    // return subclass as a raw type
+    if (runtimeType instanceof Class
+        && ((subclass.getTypeParameters().length == 0)
+            || (getRawType().getTypeParameters().length != 0))) {
       // no resolution needed
       return subclass;
     }
     // class Base<A, B> {}
     // class Sub<X, Y> extends Base<X, Y> {}
     // Base<String, Integer>.subtype(Sub.class):
 
     // Sub<X, Y>.getSupertype(Base.class) => Base<X, Y>
     // => X=String, Y=Integer
     // => Sub<X, Y>=Sub<String, Integer>
     TypeToken<?> genericSubtype = toGenericType(subclass);
     @SuppressWarnings({""rawtypes"", ""unchecked""}) // subclass isn't <? extends T>
     Type supertypeWithArgsFromSubtype =
         genericSubtype.getSupertype((Class) getRawType()).runtimeType;
     return new TypeResolver()
         .where(supertypeWithArgsFromSubtype, runtimeType)
         .resolveType(genericSubtype.runtimeType);
   }
\ No newline at end of file
",Buggy,"Currently, SomeClass<?>.getSubType(SubClass<?, OtherT>) returns SubClass<?, OtherT>.
However, if we do NotGeneric.getSubtype(SubClass<OtherT>), we get SubClass as a raw type instead of
SubClass<OtherT>.

If we fix that bug, then as it turns out we weren't generating proper owners for static classes, so fix that too
-------------
Created by MOE: https://github.com/google/moe
MOE_MIGRATED_REVID=119755147"
guava,11937.json,946ebccece2c45cce528cdc6d2db1aa31d2cfa73,"@@ -1,24 +1,26 @@
   static <T> TypeToken<? extends T> toGenericType(Class<T> cls) {
     if (cls.isArray()) {
       Type arrayOfGenericType =
           Types.newArrayType(
               // If we are passed with int[].class, don't turn it to GenericArrayType
               toGenericType(cls.getComponentType()).runtimeType);
       @SuppressWarnings(""unchecked"") // array is covariant
       TypeToken<? extends T> result = (TypeToken<? extends T>) of(arrayOfGenericType);
       return result;
     }
     TypeVariable<Class<T>>[] typeParams = cls.getTypeParameters();
     Type ownerType =
-        cls.isMemberClass() ? toGenericType(cls.getEnclosingClass()).runtimeType : null;
+        cls.isMemberClass() && !Modifier.isStatic(cls.getModifiers())
+            ? toGenericType(cls.getEnclosingClass()).runtimeType
+            : null;
 
-    if ((typeParams.length > 0) || (ownerType != cls.getEnclosingClass())) {
+    if ((typeParams.length > 0) || ((ownerType != null) && ownerType != cls.getEnclosingClass())) {
       @SuppressWarnings(""unchecked"") // Like, it's Iterable<T> for Iterable.class
       TypeToken<? extends T> type =
           (TypeToken<? extends T>)
               of(Types.newParameterizedTypeWithOwner(ownerType, cls, typeParams));
       return type;
     } else {
       return of(cls);
     }
   }
\ No newline at end of file
",Buggy,"Currently, SomeClass<?>.getSubType(SubClass<?, OtherT>) returns SubClass<?, OtherT>.
However, if we do NotGeneric.getSubtype(SubClass<OtherT>), we get SubClass as a raw type instead of
SubClass<OtherT>.

If we fix that bug, then as it turns out we weren't generating proper owners for static classes, so fix that too
-------------
Created by MOE: https://github.com/google/moe
MOE_MIGRATED_REVID=119755147"
guava,15642.json,dd96b4930181fc70bd7c90beded3a272f251db35,"@@ -1,31 +1,30 @@
     int crossOverUp(int index, E x) {
       if (index == 0) {
         queue[0] = x;
         return 0;
       }
       int parentIndex = getParentIndex(index);
       E parentElement = elementData(parentIndex);
       if (parentIndex != 0) {
-        // This is a guard for the case of the childless uncle. No checks are
-        // performed for childlessness (even if we could check it), but since
-        // it is the minimum sibling that is moved from ""max"" to ""min"" half
-        // of the heap, and only if x is larger, and this is at the bottom
-        // edge of the heap, the heap invariant is still preserved.
+        // This is a guard for the case of the childless uncle.
+        // Since the end of the array is actually the middle of the heap,
+        // a smaller childless uncle can become a child of x when we
+        // bubble up alternate levels, violating the invariant.
         int grandparentIndex = getParentIndex(parentIndex);
         int uncleIndex = getRightChildIndex(grandparentIndex);
-        if (uncleIndex != parentIndex) {
+        if (uncleIndex != parentIndex && getLeftChildIndex(uncleIndex) >= size) {
           E uncleElement = elementData(uncleIndex);
           if (ordering.compare(uncleElement, parentElement) < 0) {
             parentIndex = uncleIndex;
             parentElement = uncleElement;
           }
         }
       }
       if (ordering.compare(parentElement, x) < 0) {
         queue[index] = parentElement;
         queue[parentIndex] = x;
         return parentIndex;
       }
       queue[index] = x;
       return index;
     }
\ No newline at end of file
",Buggy,"Fix a second case of ""childless uncle"" bug causing heap corruption.

Revision created by MOE tool push_codebase.
MOE_MIGRATION=1027


git-svn-id: https://guava-libraries.googlecode.com/svn/trunk@275 8138a162-5c33-11de-8abc-d1c337b90d21"
guava,15629.json,dd96b4930181fc70bd7c90beded3a272f251db35,"@@ -1,32 +1,28 @@
   @VisibleForTesting MoveDesc<E> removeAt(int index) {
     checkPositionIndex(index, size);
     modCount++;
     size--;
     if (size == index) {
       queue[size] = null;
       return null;
     }
+    E actualLastElement = elementData(size);
+    int lastElementAt = heapForIndex(size)
+        .getCorrectLastElement(actualLastElement);
     E toTrickle = elementData(size);
     queue[size] = null;
-    Heap heap = heapForIndex(index);
-    // We consider elementData(index) a ""hole"", and we want to fill it
-    // with the last element of the heap, toTrickle.
-    // Since the last element of the heap is from the bottom level, we
-    // optimistically fill index position with elements from lower levels,
-    // moving the hole down. In most cases this reduces the number of
-    // comparisons with toTrickle, but in some cases we will need to bubble it
-    // all the way up again.
-    int vacated = heap.fillHoleAt(index);
-    // Try to see if toTrickle can be bubbled up min levels.
-    int bubbledTo = heap.bubbleUpAlternatingLevels(vacated, toTrickle);
-    if (bubbledTo == vacated) {
-      // Could not bubble toTrickle up min levels, try moving
-      // it from min level to max level (or max to min level) and bubble up
-      // there.
-      return heap.tryCrossOverAndBubbleUp(index, vacated, toTrickle);
-    } else {
-      return (bubbledTo < index)
-          ? new MoveDesc<E>(toTrickle, elementData(index))
-          : null;
+    MoveDesc<E> changes = fillHole(index, toTrickle);
+    if (lastElementAt < index) {
+      // Last element is moved to before index, swapped with trickled element.
+      if (changes == null) {
+        // The trickled element is still after index.
+        return new MoveDesc<E>(actualLastElement, toTrickle);
+      } else {
+        // The trickled element is back before index, but the replaced element
+        // has now been moved after index.
+        return new MoveDesc<E>(actualLastElement, changes.replaced);
+      }
     }
+    // Trickled element was after index to begin with, no adjustment needed.
+    return changes;
   }
\ No newline at end of file
",NotBuggy,"Fix a second case of ""childless uncle"" bug causing heap corruption.

Revision created by MOE tool push_codebase.
MOE_MIGRATION=1027


git-svn-id: https://guava-libraries.googlecode.com/svn/trunk@275 8138a162-5c33-11de-8abc-d1c337b90d21"
guava,12247.json,0007cb257b593400097f37cf5fa9c8d5fb598c62,"@@ -1,7 +1,9 @@
     SetBuilderImpl<E> review() {
       int targetTableSize = chooseTableSize(distinct);
       if (targetTableSize * 2 < hashTable.length) {
         hashTable = rebuildHashTable(targetTableSize, dedupedElements, distinct);
+        maxRunBeforeFallback = maxRunBeforeFallback(targetTableSize);
+        expandTableThreshold = (int) (DESIRED_LOAD_FACTOR * targetTableSize);
       }
       return hashFloodingDetected(hashTable) ? new JdkBackedSetBuilderImpl<E>(this) : this;
     }
\ No newline at end of file
",Buggy,"Fix #3570 by resetting expandTableThreshold and
maxRunBeforeFallback after resizing the hashTable.

Fixes #3571

[]

RELNOTES=Fixed a bug in `ImmutableSet.Builder` that could lead to infinite loops when building multiple sets from the same builder.

-------------
Created by MOE: https://github.com/google/moe
MOE_MIGRATED_REVID=264648412"
guava,11603.json,9129e5e50020f84c7a859726b42ce211d2e37e5f,"@@ -1,7 +1,6 @@
   public Stopwatch start() {
-    checkState(!isRunning,
-        ""This stopwatch is already running; it cannot be started more than once."");
+    checkState(!isRunning, ""This stopwatch is already running."");
     isRunning = true;
     startTick = ticker.read();
     return this;
   }
\ No newline at end of file
",NotBuggy,"Miscellaneous documentation fixes and internal cleanups.
- Remove potentially misleading ""it cannot be started/stopped more than once"" from Stopwatch exception messages.
- Fix TreeTraverser ASCII art.
- Remove inaccurate @GwtCompatible annotation from FeatureUtil.
- Fix mistaken duplicate words (""the the,"" etc.).
- Strip *all* of benchmark running instructions from CharMatcherBenchmark, and preemptively strip instructions from internal escapers benchmarks.
- Remove test <echo> from ant section of pom.xml.
- Add @Nullable to StandardBaseEncoding's other constructor's paddingChar parameter.
- Remove stale comment from Futures. (UninterruptibleFuture is long dead.)
- Update name of Truth GWT module.
-------------
Created by MOE: http://code.google.com/p/moe-java
MOE_MIGRATED_REVID=42036409"
guava,11604.json,9129e5e50020f84c7a859726b42ce211d2e37e5f,"@@ -1,8 +1,7 @@
   public Stopwatch stop() {
     long tick = ticker.read();
-    checkState(isRunning,
-        ""This stopwatch is already stopped; it cannot be stopped more than once."");
+    checkState(isRunning, ""This stopwatch is already stopped."");
     isRunning = false;
     elapsedNanos += tick - startTick;
     return this;
   }
\ No newline at end of file
",NotBuggy,"Miscellaneous documentation fixes and internal cleanups.
- Remove potentially misleading ""it cannot be started/stopped more than once"" from Stopwatch exception messages.
- Fix TreeTraverser ASCII art.
- Remove inaccurate @GwtCompatible annotation from FeatureUtil.
- Fix mistaken duplicate words (""the the,"" etc.).
- Strip *all* of benchmark running instructions from CharMatcherBenchmark, and preemptively strip instructions from internal escapers benchmarks.
- Remove test <echo> from ant section of pom.xml.
- Add @Nullable to StandardBaseEncoding's other constructor's paddingChar parameter.
- Remove stale comment from Futures. (UninterruptibleFuture is long dead.)
- Update name of Truth GWT module.
-------------
Created by MOE: http://code.google.com/p/moe-java
MOE_MIGRATED_REVID=42036409"
guava,81.json,0cd4e9faa1360da4a343f84cb275d6eda0c5e732,"@@ -1,19 +1,19 @@
   private static Object getJLA() {
     try {
       /*
        * We load sun.misc.* classes using reflection since Android doesn't support these classes and
        * would result in compilation failure if we directly refer to these classes.
        */
       Class<?> sharedSecrets = Class.forName(SHARED_SECRETS_CLASSNAME, false, null);
       Method langAccess = sharedSecrets.getMethod(""getJavaLangAccess"");
       return langAccess.invoke(null);
     } catch (ThreadDeath death) {
       throw death;
     } catch (Throwable t) {
       /*
-       * This is not one of AppEngine's whitelisted classes, so even in Sun JDKs, this can fail with
+       * This is not one of AppEngine's allowed classes, so even in Sun JDKs, this can fail with
        * a NoClassDefFoundError. Other apps might deny access to sun.misc packages.
        */
       return null;
     }
   }
\ No newline at end of file
",NotBuggy,"Fix nonpublic identifiers and documentation that use ""whitelist"" or ""blacklist"" to use less problematic terms.

RELNOTES=n/a

-------------
Created by MOE: https://github.com/google/moe
MOE_MIGRATED_REVID=199834981"
guava,10879.json,0cd4e9faa1360da4a343f84cb275d6eda0c5e732,"@@ -1,19 +1,19 @@
   private static @Nullable Object getJLA() {
     try {
       /*
        * We load sun.misc.* classes using reflection since Android doesn't support these classes and
        * would result in compilation failure if we directly refer to these classes.
        */
       Class<?> sharedSecrets = Class.forName(SHARED_SECRETS_CLASSNAME, false, null);
       Method langAccess = sharedSecrets.getMethod(""getJavaLangAccess"");
       return langAccess.invoke(null);
     } catch (ThreadDeath death) {
       throw death;
     } catch (Throwable t) {
       /*
-       * This is not one of AppEngine's whitelisted classes, so even in Sun JDKs, this can fail with
+       * This is not one of AppEngine's allowed classes, so even in Sun JDKs, this can fail with
        * a NoClassDefFoundError. Other apps might deny access to sun.misc packages.
        */
       return null;
     }
   }
\ No newline at end of file
",NotBuggy,"Fix nonpublic identifiers and documentation that use ""whitelist"" or ""blacklist"" to use less problematic terms.

RELNOTES=n/a

-------------
Created by MOE: https://github.com/google/moe
MOE_MIGRATED_REVID=199834981"
guava,21458.json,eb3a9f447715b05c18179bf6313dfd28851bb56e,"@@ -1,18 +1,29 @@
   public void addListener(Runnable listener, Executor executor) {
     checkNotNull(listener, ""Runnable was null."");
     checkNotNull(executor, ""Executor was null."");
-    Listener oldHead = listeners;
-    if (oldHead != Listener.TOMBSTONE) {
-      Listener newNode = new Listener(listener, executor);
-      do {
-        newNode.next = oldHead;
-        if (ATOMIC_HELPER.casListeners(this, oldHead, newNode)) {
-          return;
-        }
-        oldHead = listeners; // re-read
-      } while (oldHead != Listener.TOMBSTONE);
+    // Checking isDone and listeners != TOMBSTONE may seem redundant, but our contract for
+    // addListener says that listeners execute 'immediate' if the future isDone(). However, our
+    // protocol for completing a future is to assign the value field (which sets isDone to true) and
+    // then to release waiters, followed by executing afterDone(), followed by releasing listeners.
+    // That means that it is possible to observe that the future isDone and that your listeners
+    // don't execute 'immediately'.  By checking isDone here we avoid that.
+    // A corollary to all that is that we don't need to check isDone inside the loop because if we
+    // get into the loop we know that we weren't done when we entered and therefore we aren't under
+    // an obligation to execute 'immediately'.
+    if (!isDone()) {
+      Listener oldHead = listeners;
+      if (oldHead != Listener.TOMBSTONE) {
+        Listener newNode = new Listener(listener, executor);
+        do {
+          newNode.next = oldHead;
+          if (ATOMIC_HELPER.casListeners(this, oldHead, newNode)) {
+            return;
+          }
+          oldHead = listeners; // re-read
+        } while (oldHead != Listener.TOMBSTONE);
+      }
     }
     // If we get here then the Listener TOMBSTONE was set, which means the future is done, call
     // the listener.
     executeListener(listener, executor);
   }
\ No newline at end of file
",Buggy,"Fix a bug in AbstractFuture.addListener where we failed to follow the contract precisely.

ListenableFuture.addListener says that listeners should execute 'immediately' when the future is done.  However, because the old version of addListener only checked the listeners field, it is possible to observe that the future is done and that your listener would not execute immediately.  This cl fixes that by adding an explicit check for isDone.

RELNOTES=Close a short race where you could observe that an AbstractFuture was done, but that listeners wouldn't execute immediately.

-------------
Created by MOE: https://github.com/google/moe
MOE_MIGRATED_REVID=212281545"
guava,22829.json,0664d966535b95328b684b471ac05c481b55f297,"@@ -1,4 +1,4 @@
     public void invalidate(Object key) {
-      key = checkNotNull(key);
+      checkNotNull(key);
       localCache.remove(key);
     }
\ No newline at end of file
",NotBuggy,"Fix Error Prone errors in GWT code.
-------------
Created by MOE: https://github.com/google/moe
MOE_MIGRATED_REVID=115110183"
guava,22803.json,0664d966535b95328b684b471ac05c481b55f297,"@@ -1,19 +1,19 @@
   public V get(Object key) {
-    key = checkNotNull(key);
+    checkNotNull(key);
     Timestamped<V> value = cachingHashMap.get(key);
 
     if (value == null) {
       statsCounter.recordMisses(1);
       return null;
     } else if (!isExpired(value)) {
       statsCounter.recordHits(1);
       value.updateTimestamp();
       return value.getValue();
     } else {
       statsCounter.recordEviction();
       statsCounter.recordMisses(1);
       alertListenerIfPresent(key, value.getValue(), RemovalCause.EXPIRED);
       cachingHashMap.remove(key);
       return null;
     }
   }
\ No newline at end of file
",NotBuggy,"Fix Error Prone errors in GWT code.
-------------
Created by MOE: https://github.com/google/moe
MOE_MIGRATED_REVID=115110183"
guava,21488.json,c0c117a04ab47f2fb380311efec97a7d9851cd6e,"@@ -1,12 +1,12 @@
   private void addDoneString(StringBuilder builder) {
     try {
       V value = getDone(this);
-      builder.append(""SUCCESS, result=["").append(value).append(""]"");
+      builder.append(""SUCCESS, result=["").append(userObjectToString(value)).append(""]"");
     } catch (ExecutionException e) {
       builder.append(""FAILURE, cause=["").append(e.getCause()).append(""]"");
     } catch (CancellationException e) {
       builder.append(""CANCELLED""); // shouldn't be reachable
     } catch (RuntimeException e) {
       builder.append(""UNKNOWN, cause=["").append(e.getClass()).append("" thrown from get()]"");
     }
   }
\ No newline at end of file
",Buggy,"Fix some simple cases of stack overflow in AbstractFuture.toString()

This is a partial fix for people doing weird things and can easily be circumvented by people adding some indirection, but this is also what AbstractCollection.toString does so it seems like there is a decent precedent for a partial solution to this problem.

It doesn't appear to be possible to implement a full fix without resorting to things like threadlocals or examining the callstack, and this problem doesn't seem important enough to justify a solution like that.

RELNOTES=n/a

-------------
Created by MOE: https://github.com/google/moe
MOE_MIGRATED_REVID=181325137"
guava,10181.json,c0c117a04ab47f2fb380311efec97a7d9851cd6e,"@@ -1,12 +1,12 @@
   private void addDoneString(StringBuilder builder) {
     try {
       V value = getDone(this);
-      builder.append(""SUCCESS, result=["").append(value).append(""]"");
+      builder.append(""SUCCESS, result=["").append(userObjectToString(value)).append(""]"");
     } catch (ExecutionException e) {
       builder.append(""FAILURE, cause=["").append(e.getCause()).append(""]"");
     } catch (CancellationException e) {
       builder.append(""CANCELLED""); // shouldn't be reachable
     } catch (RuntimeException e) {
       builder.append(""UNKNOWN, cause=["").append(e.getClass()).append("" thrown from get()]"");
     }
   }
\ No newline at end of file
",Buggy,"Fix some simple cases of stack overflow in AbstractFuture.toString()

This is a partial fix for people doing weird things and can easily be circumvented by people adding some indirection, but this is also what AbstractCollection.toString does so it seems like there is a decent precedent for a partial solution to this problem.

It doesn't appear to be possible to implement a full fix without resorting to things like threadlocals or examining the callstack, and this problem doesn't seem important enough to justify a solution like that.

RELNOTES=n/a

-------------
Created by MOE: https://github.com/google/moe
MOE_MIGRATED_REVID=181325137"
guava,10179.json,c0c117a04ab47f2fb380311efec97a7d9851cd6e,"@@ -1,11 +1,11 @@
   protected String pendingToString() {
     Object localValue = value;
     if (localValue instanceof SetFuture) {
-      return ""setFuture=["" + ((SetFuture) localValue).future + ""]"";
+      return ""setFuture=["" + userObjectToString(((SetFuture) localValue).future) + ""]"";
     } else if (this instanceof ScheduledFuture) {
       return ""remaining delay=[""
           + ((ScheduledFuture) this).getDelay(TimeUnit.MILLISECONDS)
           + "" ms]"";
     }
     return null;
   }
\ No newline at end of file
",Buggy,"Fix some simple cases of stack overflow in AbstractFuture.toString()

This is a partial fix for people doing weird things and can easily be circumvented by people adding some indirection, but this is also what AbstractCollection.toString does so it seems like there is a decent precedent for a partial solution to this problem.

It doesn't appear to be possible to implement a full fix without resorting to things like threadlocals or examining the callstack, and this problem doesn't seem important enough to justify a solution like that.

RELNOTES=n/a

-------------
Created by MOE: https://github.com/google/moe
MOE_MIGRATED_REVID=181325137"
guava,21486.json,c0c117a04ab47f2fb380311efec97a7d9851cd6e,"@@ -1,11 +1,11 @@
   protected String pendingToString() {
     Object localValue = value;
     if (localValue instanceof SetFuture) {
-      return ""setFuture=["" + ((SetFuture) localValue).future + ""]"";
+      return ""setFuture=["" + userObjectToString(((SetFuture) localValue).future) + ""]"";
     } else if (this instanceof ScheduledFuture) {
       return ""remaining delay=[""
           + ((ScheduledFuture) this).getDelay(TimeUnit.MILLISECONDS)
           + "" ms]"";
     }
     return null;
   }
\ No newline at end of file
",Buggy,"Fix some simple cases of stack overflow in AbstractFuture.toString()

This is a partial fix for people doing weird things and can easily be circumvented by people adding some indirection, but this is also what AbstractCollection.toString does so it seems like there is a decent precedent for a partial solution to this problem.

It doesn't appear to be possible to implement a full fix without resorting to things like threadlocals or examining the callstack, and this problem doesn't seem important enough to justify a solution like that.

RELNOTES=n/a

-------------
Created by MOE: https://github.com/google/moe
MOE_MIGRATED_REVID=181325137"
guava,10881.json,c95fc106ff08d0652b5d661cab9a73f38697eccc,"@@ -1,3 +1,12 @@
   private static Method getSizeMethod() {
-    return getJlaMethod(""getStackTraceDepth"", Throwable.class);
+    try {
+      Method getStackTraceDepth = getJlaMethod(""getStackTraceDepth"", Throwable.class);
+      if (getStackTraceDepth == null) {
+        return null;
+      }
+      getStackTraceDepth.invoke(getJLA(), new Throwable());
+      return getStackTraceDepth;
+    } catch (UnsupportedOperationException | IllegalAccessException | InvocationTargetException e) {
+      return null;
+    }
   }
\ No newline at end of file
",Buggy,"Throwables#lazyStackTrace unsupported on IBM JDK 6

Fix addresses a problem occurred on IBM JDK 6. To ensure
that we can call underlying method, Throwables#getSizeMethod,
to get  stack size, first a smoke test  with dummy exception.
Once method executed with success, it is safe to return it for
further usage.

Fixes #2947

-------------
Created by MOE: https://github.com/google/moe
MOE_MIGRATED_REVID=169910803"
guava,11748.json,4362a4529306ea43e177fae2d0457e794dd77cd6,"@@ -1,7 +1,7 @@
-    static Object forLookup(Type t) {
+    static TypeVariableKey forLookup(Type t) {
       if (t instanceof TypeVariable) {
         return new TypeVariableKey((TypeVariable<?>) t);
       } else {
         return null;
       }
     }
\ No newline at end of file
",NotBuggy,"Fix calls to contains(Object) and get(Object) that pass a value of apparently the wrong type.
Tighten up some generics in other cases to make the type, which was correct after all, look more correct.

BUGS:

AbstractBiMapTester:
- Fix inv.entrySet().contains(...) check, which was using the forward entry instead of the reverse.
- Fix getMap().get(v) call to be an inv.get(v) call.
- Use |reversed| instead of |entry| consistently for clarity.

TypeToken:
- Call map.get(K) instead of map.get(TypeCollector).
(Presumably this was just an optimization and not necessary for correctness?)

SIMPLIFICATIONS:

TypeResolver:
- forLookup always returns a (nullable) TypeVariableKey. Declare that return type instead of plain Object.
(benyu@: I feel like we may have talked about this, with your expressing a preference for the Object type. But I can find no record of the discussion, so I could be making that up. If you do prefer Object, I won't push for the change.)
-------------
Created by MOE: https://github.com/google/moe
MOE_MIGRATED_REVID=108994208"
guava,11957.json,4362a4529306ea43e177fae2d0457e794dd77cd6,"@@ -1,24 +1,24 @@
     private int collectTypes(K type, Map<? super K, Integer> map) {
-      Integer existing = map.get(this);
+      Integer existing = map.get(type);
       if (existing != null) {
         // short circuit: if set contains type it already contains its supertypes
         return existing;
       }
       int aboveMe = getRawType(type).isInterface()
           ? 1 // interfaces should be listed before Object
           : 0;
       for (K interfaceType : getInterfaces(type)) {
         aboveMe = Math.max(aboveMe, collectTypes(interfaceType, map));
       }
       K superclass = getSuperclass(type);
       if (superclass != null) {
         aboveMe = Math.max(aboveMe, collectTypes(superclass, map));
       }
       /*
        * TODO(benyu): should we include Object for interface?
        * Also, CharSequence[] and Object[] for String[]?
        *
        */
       map.put(type, aboveMe + 1);
       return aboveMe + 1;
     }
\ No newline at end of file
",NotBuggy,"Fix calls to contains(Object) and get(Object) that pass a value of apparently the wrong type.
Tighten up some generics in other cases to make the type, which was correct after all, look more correct.

BUGS:

AbstractBiMapTester:
- Fix inv.entrySet().contains(...) check, which was using the forward entry instead of the reverse.
- Fix getMap().get(v) call to be an inv.get(v) call.
- Use |reversed| instead of |entry| consistently for clarity.

TypeToken:
- Call map.get(K) instead of map.get(TypeCollector).
(Presumably this was just an optimization and not necessary for correctness?)

SIMPLIFICATIONS:

TypeResolver:
- forLookup always returns a (nullable) TypeVariableKey. Declare that return type instead of plain Object.
(benyu@: I feel like we may have talked about this, with your expressing a preference for the Object type. But I can find no record of the discussion, so I could be making that up. If you do prefer Object, I won't push for the change.)
-------------
Created by MOE: https://github.com/google/moe
MOE_MIGRATED_REVID=108994208"
guava,19253.json,4c949e3399a80396525774a0ffc66b8af3155242,"@@ -1,18 +1,18 @@
   private static boolean validateSyntax(List<String> parts) {
     final int lastIndex = parts.size() - 1;
 
     // Validate the last part specially, as it has different syntax rules.
 
-    if (!validatePart(parts.get(lastIndex), FINAL_PART)) {
+    if (!validatePart(parts.get(lastIndex), true)) {
       return false;
     }
 
     for (int i = 0; i < lastIndex; i++) {
       String part = parts.get(i);
-      if (!validatePart(part, NORMAL_PART)) {
+      if (!validatePart(part, false)) {
         return false;
       }
     }
 
     return true;
   }
\ No newline at end of file
",NotBuggy,"Fix bug in InetAddresses and performance problem in InternetDomainName (changed
from regex to CharMatcher).

This is intended as the last code update before release 06.




git-svn-id: https://guava-libraries.googlecode.com/svn/trunk@58 8138a162-5c33-11de-8abc-d1c337b90d21"
guava,19284.json,4c949e3399a80396525774a0ffc66b8af3155242,"@@ -1,12 +1,12 @@
   private static String convertDottedQuadToHex(String ipString) {
     int lastColon = ipString.lastIndexOf(':');
     String initialPart = ipString.substring(0, lastColon + 1);
     String dottedQuad = ipString.substring(lastColon + 1);
     byte[] quad = textToNumericFormatV4(dottedQuad);
     if (quad == null) {
       return null;
     }
-    String penultimate = Integer.toHexString((quad[0] << 8) | (quad[1] & 0xff));
-    String ultimate = Integer.toHexString((quad[2] << 8) | (quad[3] & 0xff));
+    String penultimate = Integer.toHexString(((quad[0] & 0xff) << 8) | (quad[1] & 0xff));
+    String ultimate = Integer.toHexString(((quad[2] & 0xff) << 8) | (quad[3] & 0xff));
     return initialPart + penultimate + "":"" + ultimate;
   }
\ No newline at end of file
",Buggy,"Fix bug in InetAddresses and performance problem in InternetDomainName (changed
from regex to CharMatcher).

This is intended as the last code update before release 06.




git-svn-id: https://guava-libraries.googlecode.com/svn/trunk@58 8138a162-5c33-11de-8abc-d1c337b90d21"
guava,10943.json,3fbaf56f390db1a7c442ceaeab2c3a8bc1c8fd79,"@@ -1,29 +1,43 @@
     @Override protected String computeNext() {
       while (offset != -1) {
         int start = offset;
         int end;
 
         int separatorPosition = separatorStart(offset);
         if (separatorPosition == -1) {
           end = toSplit.length();
           offset = -1;
         } else {
           end = separatorPosition;
           offset = separatorEnd(separatorPosition);
         }
 
         while (start < end && trimmer.matches(toSplit.charAt(start))) {
           start++;
         }
         while (end > start && trimmer.matches(toSplit.charAt(end - 1))) {
           end--;
         }
 
         if (omitEmptyStrings && start == end) {
           continue;
         }
 
+        if (limit == 1) {
+          // The limit has been reached, return the rest of the string as the
+          // final item.  This is tested after empty string removal so that
+          // empty strings do not count towards the limit.
+          end = toSplit.length();
+          offset = -1;
+          // Since we may have changed the end, we need to trim it again.
+          while (end > start && trimmer.matches(toSplit.charAt(end - 1))) {
+            end--;
+          }
+        } else {
+          limit--;
+        }
+
         return toSplit.subSequence(start, end).toString();
       }
       return endOfData();
     }
\ No newline at end of file
",Buggy,"Fixed bug/532.
Add warnings to README.

These should be the last changes for Guava release 08.


Revision created by MOE tool push_codebase.
MOE_MIGRATION=


git-svn-id: https://guava-libraries.googlecode.com/svn/trunk@160 8138a162-5c33-11de-8abc-d1c337b90d21"
guava,15629.json,2ef955163b3d43e7849c1929ef4e5d714b93da96,"@@ -1,27 +1,34 @@
   MoveDesc<E> removeAt(int index) {
     checkPositionIndex(index, size);
     modCount++;
     size--;
     if (size == index) {
       queue[size] = null;
       return null;
     }
     E actualLastElement = elementData(size);
-    int lastElementAt = heapForIndex(size).getCorrectLastElement(actualLastElement);
+    int lastElementAt = heapForIndex(size).swapWithConceptuallyLastElement(actualLastElement);
+    if (lastElementAt == index) {
+      // 'actualLastElement' is now at 'lastElementAt', and the element that was at 'lastElementAt'
+      // is now at the end of queue. If that's the element we wanted to remove in the first place,
+      // don't try to (incorrectly) trickle it. Instead, just delete it and we're done.
+      queue[size] = null;
+      return null;
+    }
     E toTrickle = elementData(size);
     queue[size] = null;
     MoveDesc<E> changes = fillHole(index, toTrickle);
     if (lastElementAt < index) {
       // Last element is moved to before index, swapped with trickled element.
       if (changes == null) {
         // The trickled element is still after index.
         return new MoveDesc<E>(actualLastElement, toTrickle);
       } else {
         // The trickled element is back before index, but the replaced element
         // has now been moved after index.
         return new MoveDesc<E>(actualLastElement, changes.replaced);
       }
     }
     // Trickled element was after index to begin with, no adjustment needed.
     return changes;
   }
\ No newline at end of file
",Buggy,"Fix two bugs in MinMaxPriorityQueue (introduced in [] First is a bug in removeAt(int) that sometimes causes the wrong element to be removed. Second is a bug that sometimes causes certain elements to be iterated over more than once if elements were removed during iteration.

Reported externally at https://github.com/google/guava/issues/2658

-------------
Created by MOE: https://github.com/google/moe
MOE_MIGRATED_REVID=140382230"
guava,15643.json,2ef955163b3d43e7849c1929ef4e5d714b93da96,"@@ -1,16 +1,16 @@
-    int getCorrectLastElement(E actualLastElement) {
+    int swapWithConceptuallyLastElement(E actualLastElement) {
       int parentIndex = getParentIndex(size);
       if (parentIndex != 0) {
         int grandparentIndex = getParentIndex(parentIndex);
         int uncleIndex = getRightChildIndex(grandparentIndex);
         if (uncleIndex != parentIndex && getLeftChildIndex(uncleIndex) >= size) {
           E uncleElement = elementData(uncleIndex);
           if (ordering.compare(uncleElement, actualLastElement) < 0) {
             queue[uncleIndex] = actualLastElement;
             queue[size] = uncleElement;
             return uncleIndex;
           }
         }
       }
       return size;
     }
\ No newline at end of file
",NotBuggy,"Fix two bugs in MinMaxPriorityQueue (introduced in [] First is a bug in removeAt(int) that sometimes causes the wrong element to be removed. Second is a bug that sometimes causes certain elements to be iterated over more than once if elements were removed during iteration.

Reported externally at https://github.com/google/guava/issues/2658

-------------
Created by MOE: https://github.com/google/moe
MOE_MIGRATED_REVID=140382230"
guava,15653.json,2ef955163b3d43e7849c1929ef4e5d714b93da96,"@@ -1,21 +1,23 @@
     public void remove() {
       checkRemove(canRemove);
       checkModCount();
       canRemove = false;
       expectedModCount++;
       if (cursor < size()) {
         MoveDesc<E> moved = removeAt(cursor);
         if (moved != null) {
           if (forgetMeNot == null) {
             forgetMeNot = new ArrayDeque<E>();
             skipMe = new ArrayList<E>(3);
           }
-          forgetMeNot.add(moved.toTrickle);
+          if (!containsExact(skipMe, moved.toTrickle)) {
+            forgetMeNot.add(moved.toTrickle);
+          }
           skipMe.add(moved.replaced);
         }
         cursor--;
       } else { // we must have set lastFromForgetMeNot in next()
         checkState(removeExact(lastFromForgetMeNot));
         lastFromForgetMeNot = null;
       }
     }
\ No newline at end of file
",Buggy,"Fix two bugs in MinMaxPriorityQueue (introduced in [] First is a bug in removeAt(int) that sometimes causes the wrong element to be removed. Second is a bug that sometimes causes certain elements to be iterated over more than once if elements were removed during iteration.

Reported externally at https://github.com/google/guava/issues/2658

-------------
Created by MOE: https://github.com/google/moe
MOE_MIGRATED_REVID=140382230"
guava,11915.json,953e11352bbcb297987c81d1158f0c46f16cc054,"@@ -1,19 +1,20 @@
   final TypeToken<T> rejectTypeVariables() {
     new TypeVisitor() {
       @Override void visitTypeVariable(TypeVariable<?> type) {
         throw new IllegalArgumentException(
             runtimeType + ""contains a type variable and is not safe for the operation"");
       }
       @Override void visitWildcardType(WildcardType type) {
         visit(type.getLowerBounds());
         visit(type.getUpperBounds());
       }
       @Override void visitParameterizedType(ParameterizedType type) {
         visit(type.getActualTypeArguments());
+        visit(type.getOwnerType());
       }
       @Override void visitGenericArrayType(GenericArrayType type) {
         visit(type.getGenericComponentType());
       }
     }.visit(runtimeType);
     return this;
   }
\ No newline at end of file
",Buggy,"Fixed a bug in rejectTypeVariable() where we failed to account for the owner type's type variables. For example:

abstract class From<K> {
class To<V> {
TypeToken<To<V>> type() {
return new TypeToken<To<V>>(getClass()) {};
}
}

static <K> TypeToken<From<K>.To<?>> cheat() {
return new From<K>().new To<String>() {}.type();
}

TypeToken<From<String>.To<?>> notReallyString = TheClass.<String>cheat();
notReallyString.rejectTypeVariables(); // Should throw
-------------
Created by MOE: http://code.google.com/p/moe-java
MOE_MIGRATED_REVID=45444012"
guava,11913.json,953e11352bbcb297987c81d1158f0c46f16cc054,"@@ -1,3 +1,4 @@
       @Override void visitParameterizedType(ParameterizedType type) {
         visit(type.getActualTypeArguments());
+        visit(type.getOwnerType());
       }
\ No newline at end of file
",Buggy,"Fixed a bug in rejectTypeVariable() where we failed to account for the owner type's type variables. For example:

abstract class From<K> {
class To<V> {
TypeToken<To<V>> type() {
return new TypeToken<To<V>>(getClass()) {};
}
}

static <K> TypeToken<From<K>.To<?>> cheat() {
return new From<K>().new To<String>() {}.type();
}

TypeToken<From<String>.To<?>> notReallyString = TheClass.<String>cheat();
notReallyString.rejectTypeVariables(); // Should throw
-------------
Created by MOE: http://code.google.com/p/moe-java
MOE_MIGRATED_REVID=45444012"
guava,17172.json,0330f712f56cc53633874e95bdc1203cf881eb85,"@@ -1,10 +1,10 @@
     public V get(@Nullable Object key) {
       if (key instanceof Range) {
         Range<?> range = (Range<?>) key;
         RangeMapEntry<K, V> rangeMapEntry = entriesByLowerBound.get(range.lowerBound);
-        if (rangeMapEntry.getKey().equals(range)) {
+        if (rangeMapEntry != null && rangeMapEntry.getKey().equals(range)) {
           return rangeMapEntry.getValue();
         }
       }
       return null;
     }
\ No newline at end of file
",Buggy,"Fix bug in TreeRangeMap.asMapOfRanges().get(absentRange)
-------------
Created by MOE: http://code.google.com/p/moe-java
MOE_MIGRATED_REVID=38651843"
guava,21153.json,1a5b0b9caaa5b6aaef77c9e7ace4f8cac4025738,"@@ -1,11 +1,8 @@
     private void startTask() {
-      lock.lock();
-      try {
-        if (isShutdown()) {
+      synchronized (lock) {
+        if (shutdown) {
           throw new RejectedExecutionException(""Executor already shutdown"");
         }
         runningTasks++;
-      } finally {
-        lock.unlock();
       }
     }
\ No newline at end of file
",Buggy,"Fix a signaling bug in newDirectExecutorService()  Also switch to implicit
monitors to take advantage of biased locking.

If thread A calls awaitTermination while there are no running tasks, then
Thread B calls shutdown(). Thread A will never be woken up.
-------------
Created by MOE: http://code.google.com/p/moe-java
MOE_MIGRATED_REVID=87280837"
guava,21154.json,1a5b0b9caaa5b6aaef77c9e7ace4f8cac4025738,"@@ -1,11 +1,8 @@
     private void endTask() {
-      lock.lock();
-      try {
-        runningTasks--;
-        if (isTerminated()) {
-          termination.signalAll();
+      synchronized (lock) {
+        int numRunning = --runningTasks;
+        if (numRunning == 0) {
+          lock.notifyAll();
         }
-      } finally {
-        lock.unlock();
       }
     }
\ No newline at end of file
",Buggy,"Fix a signaling bug in newDirectExecutorService()  Also switch to implicit
monitors to take advantage of biased locking.

If thread A calls awaitTermination while there are no running tasks, then
Thread B calls shutdown(). Thread A will never be woken up.
-------------
Created by MOE: http://code.google.com/p/moe-java
MOE_MIGRATED_REVID=87280837"
guava,11437.json,b4cf74aa3a56751f25ae09eb79b68e0656d40618,"@@ -1,25 +1,21 @@
   public String collapseFrom(CharSequence sequence, char replacement) {
-    int first = indexIn(sequence);
-    if (first == -1) {
-      return sequence.toString();
-    }
-
-    // TODO(kevinb): see if this implementation can be made faster
-    StringBuilder builder = new StringBuilder(sequence.length())
-        .append(sequence.subSequence(0, first))
-        .append(replacement);
-    boolean in = true;
-    for (int i = first + 1; i < sequence.length(); i++) {
+    // This implementation avoids unnecessary allocation.
+    int len = sequence.length();
+    for (int i = 0; i < len; i++) {
       char c = sequence.charAt(i);
       if (matches(c)) {
-        if (!in) {
-          builder.append(replacement);
-          in = true;
+        if (c == replacement
+            && (i == len - 1 || !matches(sequence.charAt(i + 1)))) {
+          // a no-op replacement
+          i++;
+        } else {
+          StringBuilder builder = new StringBuilder(len)
+              .append(sequence.subSequence(0, i))
+              .append(replacement);
+          return finishCollapseFrom(sequence, i + 1, len, replacement, builder, true);
         }
-      } else {
-        builder.append(c);
-        in = false;
       }
     }
-    return builder.toString();
+    // no replacement needed
+    return sequence.toString();
   }
\ No newline at end of file
",NotBuggy,"Optimize collapseFrom and trimAndCollapseFrom so that they
only allocate if necessary.  Add a few tests.  Remove the GWT
workarounds for GWT bug 4491 since it appears to be fixed.
-------------
Created by MOE: http://code.google.com/p/moe-java
MOE_MIGRATED_REVID=39757514"
guava,11403.json,b4cf74aa3a56751f25ae09eb79b68e0656d40618,"@@ -1,21 +1,17 @@
-  public String trimAndCollapseFrom(CharSequence sequence, char replacement) {
-    int first = negate().indexIn(sequence);
-    if (first == -1) {
-      return """"; // everything matches. nothing's left.
-    }
-    StringBuilder builder = new StringBuilder(sequence.length());
-    boolean inMatchingGroup = false;
-    for (int i = first; i < sequence.length(); i++) {
+  private String finishCollapseFrom(
+      CharSequence sequence, int start, int end, char replacement,
+      StringBuilder builder, boolean inMatchingGroup) {
+    for (int i = start; i < end; i++) {
       char c = sequence.charAt(i);
       if (matches(c)) {
-        inMatchingGroup = true;
-      } else {
-        if (inMatchingGroup) {
+        if (!inMatchingGroup) {
           builder.append(replacement);
-          inMatchingGroup = false;
+          inMatchingGroup = true;
         }
+      } else {
         builder.append(c);
+        inMatchingGroup = false;
       }
     }
     return builder.toString();
   }
\ No newline at end of file
",NotBuggy,"Optimize collapseFrom and trimAndCollapseFrom so that they
only allocate if necessary.  Add a few tests.  Remove the GWT
workarounds for GWT bug 4491 since it appears to be fixed.
-------------
Created by MOE: http://code.google.com/p/moe-java
MOE_MIGRATED_REVID=39757514"
guava,22907.json,9bf42862f877a0ed8234bd484aa0089a3773ccd4,"@@ -1,11 +1,12 @@
   private void addDoneString(StringBuilder builder) {
     try {
-      builder.append(""SUCCESS, result=["").append(getDone(this)).append(""]"");
+      V value = getDone(this);
+      builder.append(""SUCCESS, result=["").append(value).append(""]"");
     } catch (ExecutionException e) {
       builder.append(""FAILURE, cause=["").append(e.getCause()).append(""]"");
     } catch (CancellationException e) {
       builder.append(""CANCELLED"");
     } catch (RuntimeException e) {
       builder.append(""UNKNOWN, cause=["").append(e.getClass()).append("" thrown from get()]"");
     }
   }
\ No newline at end of file
",Buggy,"ImmediateFuture.toString() implementation to provide the returned value or exception.
Provides for all ImmediateFutures implementation the same syntax that AbstractFuture uses.

It's especially convenient during debugging of mocked asynchronous gRPC services.

Fixes bug in AbstractFuture#toString in GWT that caused wrong representation:
""Class$S413@205[status=SUCCESS, result=[FAILURE, cause=[Class$S6]]"" due to ongoing
builder being already called when getDone() throws exception.

-------------
Created by MOE: https://github.com/google/moe
MOE_MIGRATED_REVID=165925433"
pmd,8491.json,384cd4f3d9a15a09b664c728ad42e03321428d7a,"@@ -1,17 +1,17 @@
     public Object visit(ASTMethodDeclarator node, Object data) {
         Scope scope = node.getScope();
         Map params = scope.getVariableDeclarations(true);
         for (Iterator i = params.keySet().iterator(); i.hasNext();) {
             VariableNameDeclaration decl = (VariableNameDeclaration)i.next();
             List usages = (List)params.get(decl);
             for (Iterator j = usages.iterator();j.hasNext();) {
                 NameOccurrence occ = (NameOccurrence)j.next();
-                if (occ.isOnLeftHandSide()) {
+                if (occ.isOnLeftHandSide() && (occ.getNameForWhichThisIsAQualifier() == null)) {
                     RuleContext ctx = (RuleContext)data;
                     String msg = MessageFormat.format(getMessage(), new Object[] {decl.getImage()});
                     ctx.getReport().addRuleViolation(createRuleViolation(ctx, decl.getLine(), msg));
                 }
             }
         }
         return super.visit(node, data);
     }
\ No newline at end of file
",Buggy,"Several bug fixes


git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@1376 51baf565-9d33-0410-a72c-fc3788e3496d"
pmd,8745.json,384cd4f3d9a15a09b664c728ad42e03321428d7a,"@@ -1,20 +1,20 @@
     public Object visit(ASTMethodDeclaration node, Object data) {
         if (node.isAbstract()) {
             return data;
         }
 
         List returnNodes = new ArrayList();
-        node.findChildrenOfType(ASTReturnStatement.class, returnNodes);
+        node.findChildrenOfType(ASTReturnStatement.class, returnNodes, false);
         if (returnNodes.size() > 1) {
             RuleContext ctx = (RuleContext)data;
             for (Iterator i = returnNodes.iterator(); i.hasNext();) {
                 SimpleNode problem = (SimpleNode)i.next();
                 // skip the last one, it's OK
                 if (!i.hasNext()) {
                     continue;
                 }
                 ctx.getReport().addRuleViolation(createRuleViolation(ctx, problem.getBeginLine()));
             }
         }
         return data;
     }
\ No newline at end of file
",Buggy,"Several bug fixes


git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@1376 51baf565-9d33-0410-a72c-fc3788e3496d"
pmd,1151.json,384cd4f3d9a15a09b664c728ad42e03321428d7a,"@@ -1,15 +1,18 @@
-    private void findChildrenOfType(Node node, Class targetType, List results) {
+    private void findChildrenOfType(Node node, Class targetType, List results, boolean descendIntoNestedClasses) {
         if (node.getClass().equals(targetType)) {
             results.add(node);
         }
+        if (node.getClass().equals(ASTClassBody.class) && !descendIntoNestedClasses) {
+            return;
+        }
         for (int i=0; i<node.jjtGetNumChildren(); i++) {
-            Node child = (Node)node.jjtGetChild(i);
+            Node child = node.jjtGetChild(i);
             if (child.jjtGetNumChildren()>0) {
-                findChildrenOfType(child, targetType, results);
+                findChildrenOfType(child, targetType, results, descendIntoNestedClasses);
             } else {
                 if (child.getClass().equals(targetType)) {
                     results.add(child);
                 }
             }
         }
     }
\ No newline at end of file
",Buggy,"Several bug fixes


git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@1376 51baf565-9d33-0410-a72c-fc3788e3496d"
pmd,7973.json,a405d23dfb9e574e2b2ef23f1f45d548a738ed3b,"@@ -1,10 +1,4 @@
     public boolean isOnRightHandSide() {
         SimpleNode node = (SimpleNode) location.jjtGetParent().jjtGetParent().jjtGetParent();
-        if (node instanceof ASTExpression) {
-            SimpleNode parent = (SimpleNode) node.jjtGetParent();
-            if (node.jjtGetNumChildren() == 3) {
-                return true;
-            }
-        }
-        return false;
+        return node instanceof ASTExpression && node.jjtGetNumChildren() == 3;
     }
\ No newline at end of file
",NotBuggy,"Fixed bug 1050173 - ImmutableFieldRule no longer reports false positives for static fields.  Also fixed version number in PMD.java, argh.


git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@2994 51baf565-9d33-0410-a72c-fc3788e3496d"
pmd,8886.json,a405d23dfb9e574e2b2ef23f1f45d548a738ed3b,"@@ -1,18 +1,18 @@
     public Object visit(ASTUnmodifiedClassDeclaration node, Object data) {
         Map vars = node.getScope().getVariableDeclarations();
         for (Iterator i = vars.keySet().iterator(); i.hasNext();) {
             VariableNameDeclaration decl = (VariableNameDeclaration) i.next();
-            if (!decl.getAccessNodeParent().isPrivate() || decl.getAccessNodeParent().isFinal()) {
+            if (decl.getAccessNodeParent().isStatic() || !decl.getAccessNodeParent().isPrivate() || decl.getAccessNodeParent().isFinal()) {
                 continue;
             }
+
             int result = initializedInConstructor((List)vars.get(decl));
             if (result == MUTABLE) {
             	continue;
             }
-            if ((result == IMMUTABLE) ||
-                ((result == CHECKDECL) && initializedInDeclaration(decl.getAccessNodeParent()))) {
+            if (result == IMMUTABLE || ((result == CHECKDECL) && initializedInDeclaration(decl.getAccessNodeParent()))) {
                 ((RuleContext) data).getReport().addRuleViolation(createRuleViolation((RuleContext) data, decl.getLine(), MessageFormat.format(getMessage(), new Object[]{decl.getImage()})));
             }
         }
         return super.visit(node, data);
     }
\ No newline at end of file
",Buggy,"Fixed bug 1050173 - ImmutableFieldRule no longer reports false positives for static fields.  Also fixed version number in PMD.java, argh.


git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@2994 51baf565-9d33-0410-a72c-fc3788e3496d"
pmd,8888.json,a405d23dfb9e574e2b2ef23f1f45d548a738ed3b,"@@ -1,31 +1,31 @@
     private int initializedInConstructor(List usages) {
         int rc = MUTABLE, initCount = 0;
         boolean setInConstructor = false;
 		boolean foundUsage = false;
 
         for (Iterator j = usages.iterator(); j.hasNext();) {
         	foundUsage = true;
-        	NameOccurrence occurance = (NameOccurrence)j.next();
-            if (occurance.isOnLeftHandSide()) {
-            	SimpleNode node = occurance.getLocation();
+        	NameOccurrence occ = (NameOccurrence)j.next();
+            if (occ.isOnLeftHandSide()) {
+            	SimpleNode node = occ.getLocation();
             	if (node.getFirstParentOfType(ASTConstructorDeclaration.class) != null) {
             		setInConstructor = true;
             		initCount++;
  				}
  				else {
  					if (node.getFirstParentOfType(ASTMethodDeclaration.class) != null) {
  						initCount++;
  					}
  				}
  			}
         }
         if (!foundUsage || (initCount == 0)) {
         	rc = CHECKDECL;
         }
         else {
         	if ((initCount == 1) && setInConstructor) {
         		rc = IMMUTABLE;
         	}
         }
         return rc;
     }
\ No newline at end of file
",NotBuggy,"Fixed bug 1050173 - ImmutableFieldRule no longer reports false positives for static fields.  Also fixed version number in PMD.java, argh.


git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@2994 51baf565-9d33-0410-a72c-fc3788e3496d"
pmd,8249.json,222563dc32c51c8f77a1b06ba69077463a525479,"@@ -1,4 +1,4 @@
 		public AnnotationVisitor visitAnnotation(String desc, boolean visible) {
 			parent.addType(Type.getType(desc));
-			return annotationVisitor;
+			return parent.annotationVisitor;
 		}
\ No newline at end of file
",Buggy,"bug fix: acceptType only works for fields and locals


git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@4822 51baf565-9d33-0410-a72c-fc3788e3496d"
pmd,8247.json,222563dc32c51c8f77a1b06ba69077463a525479,"@@ -1,5 +1,5 @@
 	private void extractSignature(String sig) {
 		if (sig != null) {
-			new SignatureReader(sig).acceptType(sigVisitor);
+			new SignatureReader(sig).accept(sigVisitor);
 		}
 	}
\ No newline at end of file
",Buggy,"bug fix: acceptType only works for fields and locals


git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@4822 51baf565-9d33-0410-a72c-fc3788e3496d"
pmd,6069.json,51ab4ae563f9875328e56161bff3eb97331b10cd,"@@ -1,8 +1,8 @@
     public void jjtClose() {
-        if ((children == null) || (children.length == 0)) {
+        if (beginLine == -1 && (children == null || children.length == 0)) {
             beginLine = parser.token.beginLine;
             beginColumn = parser.token.beginColumn;
         }
         endLine = parser.token.endLine;
         endColumn = parser.token.endColumn;
     }
\ No newline at end of file
",Buggy,"Fixed bug 583047 - columns were wrong on ASTName nodes


git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@2011 51baf565-9d33-0410-a72c-fc3788e3496d"
pmd,6068.json,51ab4ae563f9875328e56161bff3eb97331b10cd,"@@ -1,6 +1,6 @@
     public void jjtOpen() {
-        if (parser.token.next != null) {
+        if (beginLine == -1 && parser.token.next != null) {
             beginLine = parser.token.next.beginLine;
             beginColumn = parser.token.next.beginColumn;
         }
     }
\ No newline at end of file
",Buggy,"Fixed bug 583047 - columns were wrong on ASTName nodes


git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@2011 51baf565-9d33-0410-a72c-fc3788e3496d"
pmd,1134.json,51ab4ae563f9875328e56161bff3eb97331b10cd,"@@ -1,11 +1,3 @@
     public int getBeginLine() {
-        if (beginLine != -1) {
-            return beginLine;
-        } else {
-            if ((children != null) && (children.length > 0)) {
-                return ((SimpleNode) children[0]).getBeginLine();
-            } else {
-                throw new RuntimeException(""Unable to determine begining line of Node."");
-            }
-        }
+        return beginLine;
     }
\ No newline at end of file
",Buggy,"Fixed bug 583047 - columns were wrong on ASTName nodes


git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@2011 51baf565-9d33-0410-a72c-fc3788e3496d"
pmd,2689.json,e249deb0879da58e78f31eafbafc3992661b5142,"@@ -1,7 +1,7 @@
     public int getLineCount(Mark mark, Match match) {
         TokenEntry endTok = get(mark.getIndexIntoTokenArray() + match.getTokenCount());
         if (endTok.equals(TokenEntry.EOF)) {
             endTok = get(mark.getIndexIntoTokenArray() + match.getTokenCount() - 1);
         }
-        return endTok.getBeginLine() - mark.getBeginLine();
+        return endTok.getBeginLine() - mark.getBeginLine() - 1;
     }
\ No newline at end of file
",Buggy,"Fixed bug in the 'source code slice' logic


git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@1705 51baf565-9d33-0410-a72c-fc3788e3496d"
pmd,2580.json,e249deb0879da58e78f31eafbafc3992661b5142,"@@ -1,32 +1,32 @@
     public void findMatches(int min) {
        /*
          Assign sort codes to all the pooled code. This should speed
          up sorting them.
        */
         int count = 1;
         for (Iterator iter = pool.keySet().iterator(); iter.hasNext();) {
            TokenEntry token = (TokenEntry)iter.next();
            token.setSortCode(count++);
         }
 
         MarkComparator mc = new MarkComparator(cpdListener, code);
         Collections.sort(marks, mc);
 
         MatchCollector coll = new MatchCollector(marks, code, mc);
         matches = coll.collect(min);
         Collections.sort(matches);
 
         for (Iterator i = matches(); i.hasNext();) {
             Match match = (Match)i.next();
             for (Iterator occurrences = match.iterator(); occurrences.hasNext();) {
                 Mark mark = (Mark)occurrences.next();
-                SourceCode sourceCode = (SourceCode)source.get(mark.getTokenSrcID());
                 match.setLineCount(tokens.getLineCount(mark, match));
                 if (!occurrences.hasNext()) {
                     int start = mark.getBeginLine();
-                    int end = mark.getBeginLine()-1 + tokens.getLineCount(mark, match);
+                    int end = start + match.getLineCount() - 1;
+                    SourceCode sourceCode = (SourceCode)source.get(mark.getTokenSrcID());
                     match.setSourceCodeSlice(sourceCode.getSlice(start, end));
                 }
             }
         }
     }
\ No newline at end of file
",NotBuggy,"Fixed bug in the 'source code slice' logic


git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@1705 51baf565-9d33-0410-a72c-fc3788e3496d"
pmd,961.json,1ee8cc4e8daf001172f2a3aa1a8c2a89706e988f,"@@ -1,32 +1,32 @@
     public static MetricKey<ASTAnyTypeDeclaration> of(final Metric<ASTAnyTypeDeclaration> metric, final String name) {
         return new MetricKey<ASTAnyTypeDeclaration>() {
             @Override
             public String name() {
                 return name;
             }
 
 
             @Override
             public Metric<ASTAnyTypeDeclaration> getCalculator() {
                 return metric;
             }
 
 
             @Override
             public boolean supports(ASTAnyTypeDeclaration node) {
                 return metric.supports(node);
             }
 
 
             @Override
             public boolean equals(Object obj) {
                 return obj == this;
             }
 
 
             @Override
             public int hashCode() {
-                return metric.hashCode() * 31 + name.hashCode();
+                return (metric != null ? metric.hashCode() * 31 : 0) + (name != null ? name.hashCode() : 0);
             }
         };
     }
\ No newline at end of file
",Buggy,Fix bug in key hashcode with null names or metric
pmd,5595.json,64ca9b6f01f9b946a456f6de05eada2374906d6a,"@@ -1,3 +1,6 @@
     public EcmascriptNode getFinallyBlock() {
-	return (EcmascriptNode) jjtGetChild(jjtGetNumChildren() - 1);
+        if (!isFinally()) {
+            return null;
+        }
+        return (EcmascriptNode) jjtGetChild(jjtGetNumChildren() - 1);
     }
\ No newline at end of file
",Buggy,"pmd: fix #1141 ECMAScript: getFinallyBlock() is buggy.
fix #1142 ECMAScript: getCatchClause() is buggy."
pmd,376.json,a3d5e7e1921e2c1c10f6a1e60fdfc19983732097,"@@ -1,3 +1,3 @@
     public void setClasspathRef(Reference r) {
-        createClasspath().setRefid(r);
+        createLongClasspath().setRefid(r);
     }
\ No newline at end of file
",Buggy,"Fixed nested classpath bug


git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@1901 51baf565-9d33-0410-a72c-fc3788e3496d"
pmd,7138.json,fc511ec111d90e8f861c187a7e012652c80fcc4d,"@@ -1,7 +1,11 @@
-    private String getPackageName(String importName) {
+    public String getPackageName() {
+        String importName = getImportedName();
+        if (isImportOnDemand) {
+            return importName;
+        }
         if (importName.indexOf('.') == -1) {
             return """";
         }
         int lastDot = importName.lastIndexOf('.');
         return importName.substring(0, lastDot);
     }
\ No newline at end of file
",Buggy,"Fixed a bug in ImportFromSamePackage; now it catches the case where a class has an on-demand import for the same package it is in.


git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@3729 51baf565-9d33-0410-a72c-fc3788e3496d"
pmd,8736.json,fc511ec111d90e8f861c187a7e012652c80fcc4d,"@@ -1,19 +1,19 @@
     public Object visit(ASTImportDeclaration node, Object data) {
-        ImportWrapper wrapper = new ImportWrapper(node.getImportedNameNode().getImage(), node.getImportedNameNode().getImage(), node.getImportedNameNode());
+        ImportWrapper wrapper = new ImportWrapper(node.getImportedName(), node.getImportedName(), node.getImportedNameNode());
 
         // blahhhh... this really wants to be ASTImportDeclaration to be polymorphic...
         if (node.isImportOnDemand()) {
             if (importOnDemandImports.contains(wrapper)) {
                 addViolation(data, node.getImportedNameNode(), node.getImportedNameNode().getImage());
             } else {
                 importOnDemandImports.add(wrapper);
             }
         } else {
             if (singleTypeImports.contains(wrapper)) {
                 addViolation(data, node.getImportedNameNode(), node.getImportedNameNode().getImage());
             } else {
                 singleTypeImports.add(wrapper);
             }
         }
         return data;
     }
\ No newline at end of file
",Buggy,"Fixed a bug in ImportFromSamePackage; now it catches the case where a class has an on-demand import for the same package it is in.


git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@3729 51baf565-9d33-0410-a72c-fc3788e3496d"
pmd,8913.json,fc511ec111d90e8f861c187a7e012652c80fcc4d,"@@ -1,6 +1,6 @@
     public Object visit(ASTImportDeclaration node, Object o) {
-        if (node.getImportedNameNode().getImage().indexOf(""junit"") != -1) {
+        if (node.getImportedName().indexOf(""junit"") != -1) {
             junitImported = true;
         }
         return super.visit(node, o);
     }
\ No newline at end of file
",Buggy,"Fixed a bug in ImportFromSamePackage; now it catches the case where a class has an on-demand import for the same package it is in.


git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@3729 51baf565-9d33-0410-a72c-fc3788e3496d"
pmd,4678.json,fb25329e0d9ec5d632667df393f7c1b25a698e68,"@@ -1,42 +1,42 @@
     public Object visit(ASTUserClass node, Object data) {
 
         if (Helper.isTestMethodOrClass(node)) {
             return data;
         }
 
-        // baz = String.escapeSignleQuotes(...);
-        final List<ASTAssignmentExpression> assignmentCalls = node.findDescendantsOfType(ASTAssignmentExpression.class);
-        for (ASTAssignmentExpression a : assignmentCalls) {
-            findSanitizedVariables(a);
-            findSelectContainingVariables(a);
-        }
-
         final List<ASTFieldDeclaration> fieldExpr = node.findDescendantsOfType(ASTFieldDeclaration.class);
         for (ASTFieldDeclaration a : fieldExpr) {
             findSanitizedVariables(a);
             findSelectContainingVariables(a);
         }
 
         // String foo = String.escapeSignleQuotes(...);
         final List<ASTVariableDeclaration> variableDecl = node.findDescendantsOfType(ASTVariableDeclaration.class);
         for (ASTVariableDeclaration a : variableDecl) {
             findSanitizedVariables(a);
             findSelectContainingVariables(a);
         }
 
+        // baz = String.escapeSignleQuotes(...);
+        final List<ASTAssignmentExpression> assignmentCalls = node.findDescendantsOfType(ASTAssignmentExpression.class);
+        for (ASTAssignmentExpression a : assignmentCalls) {
+            findSanitizedVariables(a);
+            findSelectContainingVariables(a);
+        }
+
         // Database.query(...) check
         final List<ASTMethodCallExpression> potentialDbQueryCalls = node
                 .findDescendantsOfType(ASTMethodCallExpression.class);
 
         for (ASTMethodCallExpression m : potentialDbQueryCalls) {
             if (!Helper.isTestMethodOrClass(m) && Helper.isMethodName(m, DATABASE, QUERY)) {
                 reportStrings(m, data);
                 reportVariables(m, data);
             }
         }
-        
+
         safeVariables.clear();
         selectContainingVariables.clear();
 
         return data;
     }
\ No newline at end of file
",NotBuggy,Bug fix to improve detection of concatenated vars
pmd,7859.json,15ff7ca9447619240ec96fdb32f7974e1ecf5730,"@@ -1,34 +1,43 @@
-    private MethodNameDeclaration createBuiltInMethodDeclaration(final String methodName, final int parameterCount) {
+    private MethodNameDeclaration createBuiltInMethodDeclaration(final String methodName, String... parameterTypes) {
         ASTMethodDeclaration methodDeclaration = new ASTMethodDeclaration(JavaParserTreeConstants.JJTMETHODDECLARATION);
         methodDeclaration.setPublic(true);
         methodDeclaration.setScope(this);
 
         ASTMethodDeclarator methodDeclarator = new ASTMethodDeclarator(JavaParserTreeConstants.JJTMETHODDECLARATOR);
         methodDeclarator.setImage(methodName);
         methodDeclarator.setScope(this);
 
         ASTFormalParameters formalParameters = new ASTFormalParameters(JavaParserTreeConstants.JJTFORMALPARAMETERS);
         formalParameters.setScope(this);
 
         methodDeclaration.jjtAddChild(methodDeclarator, 0);
         methodDeclarator.jjtSetParent(methodDeclaration);
         methodDeclarator.jjtAddChild(formalParameters, 0);
         formalParameters.jjtSetParent(methodDeclarator);
 
+        int parameterCount = parameterTypes.length;
         for (int i = 0; i < parameterCount; i++) {
             ASTFormalParameter formalParameter = new ASTFormalParameter(JavaParserTreeConstants.JJTFORMALPARAMETER);
             formalParameters.jjtAddChild(formalParameter, i);
             formalParameter.jjtSetParent(formalParameters);
 
             ASTType type = new ASTType(JavaParserTreeConstants.JJTTYPE);
             formalParameter.jjtAddChild(type, 0);
             type.jjtSetParent(formalParameter);
+            ASTReferenceType referenceType = new ASTReferenceType(JavaParserTreeConstants.JJTREFERENCETYPE);
+            type.jjtAddChild(referenceType, 0);
+            referenceType.jjtSetParent(type);
+            ASTClassOrInterfaceType classOrInterfaceType = new ASTClassOrInterfaceType(JavaParserTreeConstants.JJTCLASSORINTERFACETYPE);
+            classOrInterfaceType.setImage(parameterTypes[i]);
+            referenceType.jjtAddChild(classOrInterfaceType, 0);
+            classOrInterfaceType.jjtSetParent(referenceType);
+
             ASTVariableDeclaratorId variableDeclaratorId = new ASTVariableDeclaratorId(JavaParserTreeConstants.JJTVARIABLEDECLARATORID);
             variableDeclaratorId.setImage(""arg"" + i);
             formalParameter.jjtAddChild(variableDeclaratorId, 1);
             variableDeclaratorId.jjtSetParent(formalParameter);
         }
 
         MethodNameDeclaration mnd = new MethodNameDeclaration(methodDeclarator);
         return mnd;
     }
\ No newline at end of file
",Buggy,Fixes #1490 [java] PMD Error while processing - NullPointerException
pmd,10015.json,8694a26cafe730add04695ec1917cd51bd4bbc4e,"@@ -1,4 +1,3 @@
     public TokenManager createTokenManager(Reader source) {
-	return new PLSQLTokenManager(source);
-
+        return new PLSQLTokenManager(IOUtil.skipBOM(source));
     }
\ No newline at end of file
",Buggy,Fix #1167 Error while processing PLSQL file with BOM
pmd,3080.json,6619e19d3558abf87dbf0b3f0047e355d593043b,"@@ -1,12 +1,12 @@
     public void publish(LogRecord logRecord) {
-        System.out.println(logRecord.getMessage());
+        System.out.println(FORMATTER.format(logRecord));
         if (logRecord.getThrown() != null) {
             // Use the same channel, to make sure that the stacktrace comes
             // after the message on the console (using printStackTrace
             // directly messes things up)
             StringWriter stringWriter = new StringWriter();
             PrintWriter printWriter = new PrintWriter(stringWriter, true);
             logRecord.getThrown().printStackTrace(printWriter);
             System.out.println(stringWriter.toString());
         }
     }
\ No newline at end of file
",NotBuggy,"Fixed formatting problems in loggers

git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@5905 51baf565-9d33-0410-a72c-fc3788e3496d"
pmd,3084.json,6619e19d3558abf87dbf0b3f0047e355d593043b,"@@ -1,25 +1,25 @@
     public void publish(LogRecord logRecord) {
         //Map the log levels from java.util.logging to Ant
         int antLevel;
         Level level = logRecord.getLevel();
         if (level == Level.FINEST)
             antLevel = Project.MSG_DEBUG;   //Shown when -debug is supplied to Ant
         else if (level == Level.FINE || level == Level.FINER || level == Level.CONFIG)
             antLevel = Project.MSG_VERBOSE; //Shown when -verbose is supplied to Ant
         else if (level == Level.INFO)
             antLevel = Project.MSG_INFO;    //Always shown
         else if (level == Level.WARNING)
             antLevel = Project.MSG_WARN;    //Always shown
         else if (level == Level.SEVERE)
             antLevel = Project.MSG_ERR;     //Always shown
         else
             throw new IllegalStateException(""Unknown logging level"");   //shouldn't get ALL or NONE
         
-        antTask.log(logRecord.getMessage(), antLevel);
+        antTask.log(FORMATTER.format(logRecord), antLevel);
         if (logRecord.getThrown() != null) {
             StringWriter stringWriter = new StringWriter();
             PrintWriter printWriter = new PrintWriter(stringWriter, true);
             logRecord.getThrown().printStackTrace(printWriter);
             antTask.log(stringWriter.toString(), antLevel);
         }
     }
\ No newline at end of file
",NotBuggy,"Fixed formatting problems in loggers

git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@5905 51baf565-9d33-0410-a72c-fc3788e3496d"
pmd,7444.json,dc453cf103787e06a70385cb4eab1917f6286446,"@@ -1,3 +1,3 @@
-    public boolean isArrayDeference() {
-        return isArrayDeference;
+    public boolean isArrayDereference() {
+        return isArrayDereference;
     }
\ No newline at end of file
",NotBuggy,"Fixed bug 1242544 - SimplifyConditional no longer flags null checks that precede an instanceof involving an array dereference.


git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@3728 51baf565-9d33-0410-a72c-fc3788e3496d"
pmd,7443.json,dc453cf103787e06a70385cb4eab1917f6286446,"@@ -1,3 +1,3 @@
     public void setIsArrayDereference() {
-        isArrayDeference = true;
+        isArrayDereference = true;
     }
\ No newline at end of file
",NotBuggy,"Fixed bug 1242544 - SimplifyConditional no longer flags null checks that precede an instanceof involving an array dereference.


git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@3728 51baf565-9d33-0410-a72c-fc3788e3496d"
pmd,9037.json,dc453cf103787e06a70385cb4eab1917f6286446,"@@ -1,43 +1,43 @@
     public Object visit(ASTStatementExpression node, Object data) {
         if (node.jjtGetNumChildren() != 3
                 || !(node.jjtGetChild(0) instanceof ASTPrimaryExpression)
                 || !(node.jjtGetChild(1) instanceof ASTAssignmentOperator)
                 || (((ASTAssignmentOperator) (node.jjtGetChild(1))).isCompound())
                 || !(node.jjtGetChild(2) instanceof ASTExpression)
                 || node.jjtGetChild(0).jjtGetChild(0).jjtGetNumChildren() == 0
                 || node.jjtGetChild(2).jjtGetChild(0).jjtGetChild(0).jjtGetNumChildren() == 0
         ) {
             return super.visit(node, data);
         }
 
         SimpleNode lhs = (SimpleNode) node.jjtGetChild(0).jjtGetChild(0).jjtGetChild(0);
         if (!(lhs instanceof ASTName)) {
             return super.visit(node, data);
         }
 
         SimpleNode rhs = (SimpleNode) node.jjtGetChild(2).jjtGetChild(0).jjtGetChild(0).jjtGetChild(0);
         if (!(rhs instanceof ASTName)) {
             return super.visit(node, data);
         }
 
         if (!lhs.getImage().equals(rhs.getImage())) {
             return super.visit(node, data);
         }
 
         if (lhs.jjtGetParent().jjtGetParent().jjtGetNumChildren() > 1) {
             Node n = lhs.jjtGetParent().jjtGetParent().jjtGetChild(1);
-            if (n instanceof ASTPrimarySuffix && ((ASTPrimarySuffix) n).isArrayDeference()) {
+            if (n instanceof ASTPrimarySuffix && ((ASTPrimarySuffix) n).isArrayDereference()) {
                 return super.visit(node, data);
             }
         }
 
         if (rhs.jjtGetParent().jjtGetParent().jjtGetNumChildren() > 1) {
             Node n = rhs.jjtGetParent().jjtGetParent().jjtGetChild(1);
-            if (n instanceof ASTPrimarySuffix && ((ASTPrimarySuffix) n).isArguments() || ((ASTPrimarySuffix) n).isArrayDeference()) {
+            if (n instanceof ASTPrimarySuffix && ((ASTPrimarySuffix) n).isArguments() || ((ASTPrimarySuffix) n).isArrayDereference()) {
                 return super.visit(node, data);
             }
         }
 
         addViolation(data, node);
         return super.visit(node, data);
     }
\ No newline at end of file
",NotBuggy,"Fixed bug 1242544 - SimplifyConditional no longer flags null checks that precede an instanceof involving an array dereference.


git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@3728 51baf565-9d33-0410-a72c-fc3788e3496d"
pmd,8010.json,87bbe9e5b34ddf7a66a3d5b462991cbb47746d80,"@@ -1,11 +1,19 @@
     public JavaTypeDefinition getGenericType(final String parameterName) {
-        final TypeVariable<?>[] typeParameters = clazz.getTypeParameters();
-        for (int i = 0; i < typeParameters.length; i++) {
-            if (typeParameters[i].getName().equals(parameterName)) {
-                return getGenericType(i);
+        for (JavaTypeDefinition currTypeDef = this; currTypeDef != null; currTypeDef = currTypeDef.enclosingClass) {
+            final TypeVariable<?>[] typeParameters = currTypeDef.clazz.getTypeParameters();
+            for (int i = 0; i < typeParameters.length; i++) {
+                if (typeParameters[i].getName().equals(parameterName)) {
+                    return currTypeDef.getGenericType(i);
+                }
             }
         }
 
-        throw new IllegalArgumentException(""No generic parameter by name "" + parameterName
-                                                   + "" on class "" + clazz.getSimpleName());
+        // throw because we could not find parameterName
+        StringBuilder builder = new StringBuilder(""No generic parameter by name "").append(parameterName);
+        for (JavaTypeDefinition currTypeDef = this; currTypeDef != null; currTypeDef = currTypeDef.enclosingClass) {
+            builder.append(""\n on class "");
+            builder.append(clazz.getSimpleName());
+        }
+
+        throw new IllegalArgumentException(builder.toString());
     }
\ No newline at end of file
",Buggy,"Java, typedef: fix a bug with nested classes if the outter class is generic"
pmd,8270.json,87bbe9e5b34ddf7a66a3d5b462991cbb47746d80,"@@ -1,3 +1,3 @@
         public void visitInnerClassType(String name) {
-            parent.parseClassName(name);
+            // parent.parseClassName(name);
         }
\ No newline at end of file
",Buggy,"Java, typedef: fix a bug with nested classes if the outter class is generic"
pmd,7974.json,0b90fd01542a5a765cbb72e0b0c90185168d2331,"@@ -1,31 +1,32 @@
     public boolean isOnLeftHandSide() {
         // I detest this method with every atom of my being
         Node primaryExpression;
         if (location.jjtGetParent() instanceof ASTPrimaryExpression) {
             primaryExpression = location.jjtGetParent().jjtGetParent();
         } else if (location.jjtGetParent().jjtGetParent() instanceof ASTPrimaryExpression) {
             primaryExpression = location.jjtGetParent().jjtGetParent().jjtGetParent();
         } else {
             throw new RuntimeException(
-                    ""Found a NameOccurrence that didn't have an ASTPrimary Expression as parent or grandparent.  Parent = ""
-                            + location.jjtGetParent() + "" and grandparent = "" + location.jjtGetParent().jjtGetParent());
+                    ""Found a NameOccurrence ("" + location + "") that didn't have an ASTPrimary Expression as parent or grandparent.  Parent = ""
+                            + location.jjtGetParent() + "" and grandparent = "" + location.jjtGetParent().jjtGetParent()
+                            + "" (location line "" + location.getBeginLine() + "" col "" + location.getBeginColumn() + "")"");
         }
 
         if (isStandAlonePostfix(primaryExpression)) {
             return true;
         }
 
         if (primaryExpression.jjtGetNumChildren() <= 1) {
             return false;
         }
 
         if (!(primaryExpression.jjtGetChild(1) instanceof ASTAssignmentOperator)) {
             return false;
         }
 
         if (isPartOfQualifiedName() /* or is an array type */) {
             return false;
         }
 
         return !isCompoundAssignment(primaryExpression);
     }
\ No newline at end of file
",Buggy,"[java] Fix processing error with Cast + MethodReference

Occurred in https://github.com/spring-projects/spring-framework/blob/master/spring-beans/src/main/java/org/springframework/beans/factory/support/DefaultListableBeanFactory.java#L746"
pmd,7846.json,9a940e0cc57577c730a54adf2582612581cb05af,"@@ -1,3 +1,3 @@
     public String toString() {
-        return ""Variable "" + node.getImage() + "":"" + node.getBeginLine();
+        return ""Variable symbol "" + node.getImage() + "" line "" + node.getBeginLine();
     }
\ No newline at end of file
",Buggy,"fixed bug 660069; thx to mcclain looney for the bug report


git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@1323 51baf565-9d33-0410-a72c-fc3788e3496d"
pmd,2946.json,4383ac357979bf353947351cac11d9586398ffbd,"@@ -1,4 +1,3 @@
         public String toString() {
-            SimpleNode n = (SimpleNode) node.jjtGetChild(1);
-            return n.getImage();
+            return node.getMethodName();
         }
\ No newline at end of file
",Buggy,"Fixed bug 1235300 - NullAssignment no longer flags assignments to final fields.


git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@3672 51baf565-9d33-0410-a72c-fc3788e3496d"
pmd,9191.json,4383ac357979bf353947351cac11d9586398ffbd,"@@ -1,15 +1,20 @@
     public Object visit(ASTNullLiteral node, Object data) {
-        if (lookUp(node) instanceof ASTStatementExpression) {
-            Node n = lookUp(node);
+        if (get5thParent(node) instanceof ASTStatementExpression) {
+            ASTStatementExpression n = (ASTStatementExpression)get5thParent(node);
+
+            if (isAssignmentToFinalField(n)) {
+                return data;
+            }
+
             if (n.jjtGetNumChildren() > 2 && n.jjtGetChild(1) instanceof ASTAssignmentOperator) {
                 RuleContext ctx = (RuleContext) data;
                 ctx.getReport().addRuleViolation(createRuleViolation(ctx, node));
             }
-        } else if (lookUp2(node) instanceof ASTConditionalExpression) {
-            checkTernary((ASTConditionalExpression)lookUp2(node), data, node);
-        } else if (lookUp(node) instanceof ASTConditionalExpression) {
-            checkTernary((ASTConditionalExpression)lookUp(node), data, node);
+        } else if (get4thParent(node) instanceof ASTConditionalExpression) {
+            checkTernary((ASTConditionalExpression)get4thParent(node), data, node);
+        } else if (get5thParent(node) instanceof ASTConditionalExpression) {
+            checkTernary((ASTConditionalExpression)get5thParent(node), data, node);
         }
 
         return data;
     }
\ No newline at end of file
",Buggy,"Fixed bug 1235300 - NullAssignment no longer flags assignments to final fields.


git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@3672 51baf565-9d33-0410-a72c-fc3788e3496d"
pmd,7976.json,78583ee897aa40fd474c85d59cccee016dfadfe0,"@@ -1,3 +1,3 @@
-    private boolean postFixWithExceptions(SimpleNode primaryExpression) {
+    private boolean isStandAlonePostfix(SimpleNode primaryExpression) {
         return primaryExpression instanceof ASTPostfixExpression && primaryExpression.jjtGetParent() instanceof ASTStatementExpression && thirdChildHasDottedName(primaryExpression);
     }
\ No newline at end of file
",NotBuggy,"Fixed a predecrement problem


git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@3005 51baf565-9d33-0410-a72c-fc3788e3496d"
pmd,7974.json,78583ee897aa40fd474c85d59cccee016dfadfe0,"@@ -1,32 +1,32 @@
     public boolean isOnLeftHandSide() {
         SimpleNode primaryExpression;
         if (location.jjtGetParent() instanceof ASTPrimaryExpression) {
             primaryExpression = (SimpleNode) location.jjtGetParent().jjtGetParent();
         } else if (location.jjtGetParent().jjtGetParent() instanceof ASTPrimaryExpression) {
             primaryExpression = (SimpleNode) location.jjtGetParent().jjtGetParent().jjtGetParent();
         } else {
             throw new RuntimeException(""Found a NameOccurrence that didn't have an ASTPrimary Expression as parent or grandparent.  Parent = "" + location.jjtGetParent() + "" and grandparent = "" + location.jjtGetParent().jjtGetParent());
         }
 
-        if (postFixWithExceptions(primaryExpression))  {
+        if (isStandAlonePostfix(primaryExpression))  {
             return true;
         }
 
         if (primaryExpression.jjtGetNumChildren() <= 1) {
             return false;
         }
 
         if (!(primaryExpression.jjtGetChild(1) instanceof ASTAssignmentOperator)) {
             return false;
         }
 
         if (isPartOfQualifiedName() /* or is an array type */) {
             return false;
         }
 
         if (isCompoundAssignment(primaryExpression)) {
             return false;
         }
 
         return true;
     }
\ No newline at end of file
",NotBuggy,"Fixed a predecrement problem


git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@3005 51baf565-9d33-0410-a72c-fc3788e3496d"
pmd,8888.json,78583ee897aa40fd474c85d59cccee016dfadfe0,"@@ -1,30 +1,30 @@
     private int initializedInConstructor(List usages, Set allConstructors) {
         int rc = MUTABLE, methodInitCount = 0;
         boolean foundUsage = false;
         Set consSet = new HashSet();
-        
+
         for (Iterator j = usages.iterator(); j.hasNext();) {
             foundUsage = true;
             NameOccurrence occ = (NameOccurrence)j.next();
-            if (occ.isOnLeftHandSide()) {
+            if (occ.isOnLeftHandSide() || occ.getLocation().jjtGetParent().jjtGetParent().jjtGetParent() instanceof ASTPreDecrementExpression || occ.getLocation().jjtGetParent().jjtGetParent().jjtGetParent() instanceof ASTPreIncrementExpression) {
                 SimpleNode node = occ.getLocation();
                 SimpleNode constructor = (SimpleNode)node.getFirstParentOfType(ASTConstructorDeclaration.class);
                 if (constructor != null) {
                     consSet.add(constructor);
                 } else {
                     if (node.getFirstParentOfType(ASTMethodDeclaration.class) != null) {
                         methodInitCount++;
                     }
                 }
             }
         }
         if (!foundUsage || ((methodInitCount == 0) && consSet.isEmpty())) {
             rc = CHECKDECL;
         } else {
             allConstructors.removeAll(consSet);
             if (allConstructors.isEmpty() && (methodInitCount == 0)) {
                 rc = IMMUTABLE;
             }
         }
         return rc;
     }
\ No newline at end of file
",Buggy,"Fixed a predecrement problem


git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@3005 51baf565-9d33-0410-a72c-fc3788e3496d"
pmd,8892.json,78583ee897aa40fd474c85d59cccee016dfadfe0,"@@ -1,6 +1,5 @@
     private Set findAllConstructors(ASTUnmodifiedClassDeclaration node) {
-        List results = node.findChildrenOfType(ASTConstructorDeclaration.class);
-        HashSet set = new HashSet();
-        set.addAll(results);
+        Set set = new HashSet();
+        set.addAll(node.findChildrenOfType(ASTConstructorDeclaration.class));
         return set;
     }
\ No newline at end of file
",NotBuggy,"Fixed a predecrement problem


git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@3005 51baf565-9d33-0410-a72c-fc3788e3496d"
pmd,6536.json,1942e94cec6b6a30532716d14da5c7cd0cd8f075,"@@ -1,15 +1,15 @@
     private boolean isUnbalanced(String image, String pattern) {
         int occurance = 0;
-        int index = image.lastIndexOf(""="");
+        int index = image.indexOf(""="");
         index = image.indexOf(pattern, index + 1);
         while (index >= 0) {
             occurance++;
             index = image.indexOf(pattern, index + 1);
         }
 
         if ((occurance % 2) != 0) {
             return true;
         }
 
         return false;
     }
\ No newline at end of file
",Buggy,Bug fix
pmd,358.json,6156ba5de5f004b96bceb0cc8e44191c6876c7c9,"@@ -1,23 +1,23 @@
     private void validate() throws BuildException {
         if (formatters.isEmpty() && !printToConsole) {
             throw new BuildException(""No formatter specified; and printToConsole was false"");
         }
 
         for (Iterator i = formatters.iterator(); i.hasNext();) {
             Formatter f = (Formatter) i.next();
-            if (f.isToFileNull()) {
+            if (f.isNoOutputSupplied()) {
                 throw new BuildException(""Formatter toFile attribute is required"");
             }
         }
 
         if (ruleSetFiles == null) {
             if (nestedRules.isEmpty()) {
                 throw new BuildException(""No rulesets specified"");
             }
             ruleSetFiles = getNestedRuleSetFiles();
         }
 
         if (!targetJDK.equals(""1.3"") && !targetJDK.equals(""1.4"") && !targetJDK.equals(""1.5"")) {
             throw new BuildException(""The targetjdk attribute, if used, must be set to either '1.3', '1.4', or '1.5'"");
         }
     }
\ No newline at end of file
",Buggy,"Applied a patch from Wouter Zelle to clean up the Ant Formatter class, fix a TextRenderer bug, and make toConsole cleaner.


git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@4292 51baf565-9d33-0410-a72c-fc3788e3496d"
pmd,412.json,604a45d941cf2042c5c548490ef4401ad54080c9,"@@ -1,12 +1,10 @@
     private void logRulesUsed(RuleSets rules) {
         log(""Using these rulesets: "" + ruleSetFiles, Project.MSG_VERBOSE);
 
         RuleSet[] ruleSets = rules.getAllRuleSets();
-        for (int j = 0; j < ruleSets.length; j++) {
-            RuleSet ruleSet = ruleSets[j];
-
+        for (RuleSet ruleSet : ruleSets) {
             for (Rule rule: ruleSet.getRules()) {
                 log(""Using rule "" + rule.getName(), Project.MSG_VERBOSE);
             }
         }
     }
\ No newline at end of file
",NotBuggy,"Fixed bug 1943204 - Ant task: <ruleset> path should be relative to Ant basedir


git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@6441 51baf565-9d33-0410-a72c-fc3788e3496d"
pmd,358.json,604a45d941cf2042c5c548490ef4401ad54080c9,"@@ -1,19 +1,31 @@
     private void validate() throws BuildException {
         // TODO - check for empty Formatters List here?
         for (Formatter f: formatters) {
             if (f.isNoOutputSupplied()) {
                 throw new BuildException(""toFile or toConsole needs to be specified in Formatter"");
             }
         }
 
         if (ruleSetFiles == null) {
             if (nestedRules.isEmpty()) {
                 throw new BuildException(""No rulesets specified"");
             }
             ruleSetFiles = getNestedRuleSetFiles();
         }
 
+        // convert relative paths and substitute env variables/properties
+        final StringBuffer sb = new StringBuffer();
+        for(String s: ruleSetFiles.split("","")) {
+            Path p = new Path(getProject());
+            p.setPath(getProject().replaceProperties(s));
+            if (sb.length() > 0) {
+                sb.append(',');
+            }
+            sb.append(p);
+        }
+        ruleSetFiles = sb.toString();
+
         if (!targetJDK.equals(""1.3"") && !targetJDK.equals(""1.4"") && !targetJDK.equals(""1.5"") && !targetJDK.equals(""1.6"") && !targetJDK.equals(""1.7"") && !targetJDK.equals(""jsp"")) {
             throw new BuildException(""The targetjdk attribute, if used, must be set to either '1.3', '1.4', '1.5', '1.6', '1.7' or 'jsp'"");
         }
     }
\ No newline at end of file
",Buggy,"Fixed bug 1943204 - Ant task: <ruleset> path should be relative to Ant basedir


git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@6441 51baf565-9d33-0410-a72c-fc3788e3496d"
pmd,6753.json,1ef5079b29401bdb0df6e773f0160fa54f779018,"@@ -1,8 +1,10 @@
     public Object visit(ASTPrimaryExpression node, Object data) {
-        if (isForeignAttributeOrMethod(node) && (isAttributeAccess(node)
-            || isMethodCall(node) && isForeignGetterSetterCall(node))) {
-
-            ((MutableInt) data).increment();
+        if (isForeignAttributeOrMethod(node)) {
+            if (isAttributeAccess(node)) {
+                ((MutableInt) data).increment();
+            } else {
+                ((MutableInt) data).add(countForeignGetterSetterCalls(node));
+            }
         }
         return super.visit(node, data);
     }
\ No newline at end of file
",Buggy,"[java] ATFD calculation problem

* Fixes #1910
* Method call chains are now considered"
pmd,6754.json,1ef5079b29401bdb0df6e773f0160fa54f779018,"@@ -1,6 +1,4 @@
     private boolean isForeignGetterSetterCall(ASTPrimaryExpression node) {
-
         String methodOrAttributeName = getMethodOrAttributeName(node);
-
-        return methodOrAttributeName != null && StringUtils.startsWithAny(methodOrAttributeName, ""get"", ""is"", ""set"");
+        return isForeignGetterSetterCall(methodOrAttributeName);
     }
\ No newline at end of file
",Buggy,"[java] ATFD calculation problem

* Fixes #1910
* Method call chains are now considered"
hbase,27505.json,d589b7238257c78dc8616e47ab5bb3e2309a5237,"@@ -1,3 +1,3 @@
-    public Throwable getCause() {
+    public synchronized Throwable getCause() {
       return cause;
     }
\ No newline at end of file
",Buggy,"HBASE-19847 Fix findbugs and error-prone warnings in hbase-thrift (branch-2)

Signed-off-by: tedyu <yuzhihong@gmail.com>"
hbase,7228.json,84a50393ee56d09abb68f54b44b64f5279bd33c9,"@@ -1,8 +1,8 @@
-  public long refill(long limit, long available) {
+  public long refill(long limit) {
     final long now = EnvironmentEdgeManager.currentTime();
     if (now < nextRefillTime) {
       return 0;
     }
     nextRefillTime = now + super.getTimeUnitInMillis();
     return limit;
   }
\ No newline at end of file
",NotBuggy,HBASE-13888 Fix refill bug from HBASE-13686 (Guanghao Zhang)
hbase,7525.json,84a50393ee56d09abb68f54b44b64f5279bd33c9,"@@ -1,16 +1,16 @@
   public synchronized boolean canExecute(final long amount) {
-    long refillAmount = refill(limit, avail);
+    long refillAmount = refill(limit);
     if (refillAmount == 0 && avail < amount) {
       return false;
     }
     // check for positive overflow
     if (avail <= Long.MAX_VALUE - refillAmount) {
       avail = Math.max(0, Math.min(avail + refillAmount, limit));
     } else {
       avail = Math.max(0, limit);
     }
     if (avail >= amount) {
       return true;
     }
     return false;
   }
\ No newline at end of file
",Buggy,HBASE-13888 Fix refill bug from HBASE-13686 (Guanghao Zhang)
hbase,7389.json,84a50393ee56d09abb68f54b44b64f5279bd33c9,"@@ -1,15 +1,15 @@
-  public long refill(long limit, long available) {
+  public long refill(long limit) {
     final long now = EnvironmentEdgeManager.currentTime();
     if (nextRefillTime == -1) {
       // Till now no resource has been consumed.
       nextRefillTime = EnvironmentEdgeManager.currentTime();
       return limit;
     }
 
     long delta = (limit * (now - nextRefillTime)) / super.getTimeUnitInMillis();
     if (delta > 0) {
       this.nextRefillTime = now;
-      return Math.min(limit, available + delta);
+      return Math.min(limit, delta);
     }
     return 0;
   }
\ No newline at end of file
",Buggy,HBASE-13888 Fix refill bug from HBASE-13686 (Guanghao Zhang)
hbase,1189.json,2beda62a10f0828eb10cec28b0ba53246cd0b671,"@@ -1,5 +1,4 @@
   public static void main(String[] args) throws Exception {
-    if (conf == null) conf = HBaseConfiguration.create();
-    int ret = ToolRunner.run(conf, new ReplicationSyncUp(), args);
+    int ret = ToolRunner.run(HBaseConfiguration.create(), new ReplicationSyncUp(), args);
     System.exit(ret);
   }
\ No newline at end of file
",Buggy,"HBASE-20083 Fix findbugs error for ReplicationSyncUp
"
hbase,1193.json,2beda62a10f0828eb10cec28b0ba53246cd0b671,"@@ -1,3 +1,3 @@
     public Configuration getConfiguration() {
-      return conf;
+      return getConf();
     }
\ No newline at end of file
",Buggy,"HBASE-20083 Fix findbugs error for ReplicationSyncUp
"
hbase,5737.json,c24cf2d55ecd479c89b0613b6ebbdaba4eb793ad,"@@ -1,7 +1,10 @@
   private void addRegion(final LinkedList<RegionInfo> regions, RegionInfo hri) {
     // If meta, move it last otherwise other unassigns fail because meta is not
     // online for them to update state in. This is dodgy. Needs to be made more
     // robust. See TODO below.
-    if (hri.isMetaRegion()) regions.addLast(hri);
-    else regions.addFirst(hri);
+    if (hri.isMetaRegion()) {
+      regions.addLast(hri);
+    } else {
+      regions.addFirst(hri);
+    }
   }
\ No newline at end of file
",NotBuggy,"HBASE-19601 Fixed Checkstyle errors in hbase-rsgroup and enabled Checkstyle to fail on violations
"
hbase,5705.json,c24cf2d55ecd479c89b0613b6ebbdaba4eb793ad,"@@ -1,8 +1,11 @@
   static Set<Address> getOnlineServers(final MasterServices master) {
     Set<Address> onlineServers = new HashSet<Address>();
-    if (master == null) return onlineServers;
+    if (master == null) {
+      return onlineServers;
+    }
+
     for(ServerName server: master.getServerManager().getOnlineServers().keySet()) {
       onlineServers.add(server.getAddress());
     }
     return onlineServers;
   }
\ No newline at end of file
",NotBuggy,"HBASE-19601 Fixed Checkstyle errors in hbase-rsgroup and enabled Checkstyle to fail on violations
"
hbase,5782.json,c24cf2d55ecd479c89b0613b6ebbdaba4eb793ad,"@@ -1,4 +1,7 @@
   public boolean isOnline() {
-    if (this.rsGroupInfoManager == null) return false;
+    if (this.rsGroupInfoManager == null) {
+      return false;
+    }
+
     return this.rsGroupInfoManager.isOnline();
   }
\ No newline at end of file
",NotBuggy,"HBASE-19601 Fixed Checkstyle errors in hbase-rsgroup and enabled Checkstyle to fail on violations
"
hbase,5736.json,c24cf2d55ecd479c89b0613b6ebbdaba4eb793ad,"@@ -1,16 +1,19 @@
   private List<RegionInfo> getRegions(final Address server) {
     LinkedList<RegionInfo> regions = new LinkedList<>();
     for (Map.Entry<RegionInfo, ServerName> el :
         master.getAssignmentManager().getRegionStates().getRegionAssignments().entrySet()) {
-      if (el.getValue() == null) continue;
+      if (el.getValue() == null) {
+        continue;
+      }
+
       if (el.getValue().getAddress().equals(server)) {
         addRegion(regions, el.getKey());
       }
     }
     for (RegionStateNode state : master.getAssignmentManager().getRegionsInTransition()) {
       if (state.getRegionLocation().getAddress().equals(server)) {
         addRegion(regions, state.getRegionInfo());
       }
     }
     return regions;
   }
\ No newline at end of file
",NotBuggy,"HBASE-19601 Fixed Checkstyle errors in hbase-rsgroup and enabled Checkstyle to fail on violations
"
hbase,5743.json,c24cf2d55ecd479c89b0613b6ebbdaba4eb793ad,"@@ -1,58 +1,61 @@
   public boolean balanceRSGroup(String groupName) throws IOException {
     ServerManager serverManager = master.getServerManager();
     AssignmentManager assignmentManager = master.getAssignmentManager();
     LoadBalancer balancer = master.getLoadBalancer();
 
     synchronized (balancer) {
       // If balance not true, don't run balancer.
-      if (!((HMaster) master).isBalancerOn()) return false;
+      if (!((HMaster) master).isBalancerOn()) {
+        return false;
+      }
+
       if (master.getMasterCoprocessorHost() != null) {
         master.getMasterCoprocessorHost().preBalanceRSGroup(groupName);
       }
       if (getRSGroupInfo(groupName) == null) {
         throw new ConstraintException(""RSGroup does not exist: ""+groupName);
       }
       // Only allow one balance run at at time.
       Map<String, RegionState> groupRIT = rsGroupGetRegionsInTransition(groupName);
       if (groupRIT.size() > 0) {
         LOG.debug(""Not running balancer because "" + groupRIT.size() + "" region(s) in transition: "" +
           StringUtils.abbreviate(
               master.getAssignmentManager().getRegionStates().getRegionsInTransition().toString(),
               256));
         return false;
       }
       if (serverManager.areDeadServersInProgress()) {
         LOG.debug(""Not running balancer because processing dead regionserver(s): "" +
             serverManager.getDeadServers());
         return false;
       }
 
       //We balance per group instead of per table
       List<RegionPlan> plans = new ArrayList<>();
       for(Map.Entry<TableName, Map<ServerName, List<RegionInfo>>> tableMap:
           getRSGroupAssignmentsByTable(groupName).entrySet()) {
         LOG.info(""Creating partial plan for table "" + tableMap.getKey() + "": ""
             + tableMap.getValue());
         List<RegionPlan> partialPlans = balancer.balanceCluster(tableMap.getValue());
         LOG.info(""Partial plan for table "" + tableMap.getKey() + "": "" + partialPlans);
         if (partialPlans != null) {
           plans.addAll(partialPlans);
         }
       }
       long startTime = System.currentTimeMillis();
       boolean balancerRan = !plans.isEmpty();
       if (balancerRan) {
         LOG.info(""RSGroup balance "" + groupName + "" starting with plan count: "" + plans.size());
         for (RegionPlan plan: plans) {
           LOG.info(""balance "" + plan);
           assignmentManager.moveAsync(plan);
         }
         LOG.info(""RSGroup balance "" + groupName + "" completed after "" +
             (System.currentTimeMillis()-startTime) + "" seconds"");
       }
       if (master.getMasterCoprocessorHost() != null) {
         master.getMasterCoprocessorHost().postBalanceRSGroup(groupName, balancerRan);
       }
       return balancerRan;
     }
   }
\ No newline at end of file
",NotBuggy,"HBASE-19601 Fixed Checkstyle errors in hbase-rsgroup and enabled Checkstyle to fail on violations
"
hbase,3328.json,d272ac908ceb4696e05431066ae02d953fa6fc9d,"@@ -1,30 +1,30 @@
   protected void chore() {
-    if (!connected) {
+    if (!isConnected()) {
       return;
     }
 
     List<ServerName> sns = generateDeadServersListToSend();
     if (sns.isEmpty()) {
       // Nothing to send. Done.
       return;
     }
 
     final long curTime = EnvironmentEdgeManager.currentTime();
     if (lastMessageTime > curTime - messagePeriod) {
       // We already sent something less than 10 second ago. Done.
       return;
     }
 
     // Ok, we're going to send something then.
     lastMessageTime = curTime;
 
     // We're reusing an existing protobuf message, but we don't send everything.
     // This could be extended in the future, for example if we want to send stuff like the
     //  hbase:meta server name.
     publisher.publish(ClusterMetricsBuilder.newBuilder()
       .setHBaseVersion(VersionInfo.getVersion())
       .setClusterId(master.getMasterFileSystem().getClusterId().toString())
       .setMasterName(master.getServerName())
       .setDeadServerNames(sns)
       .build());
   }
\ No newline at end of file
",NotBuggy,"HBASE-20069 fix existing findbugs errors in hbase-server; ADDENDUM Address review
"
hbase,36406.json,aeffca497bf36ea12f89a5f92d2f918b010741fc,"@@ -1,6 +1,6 @@
   public void writeTo(Object object, Class<?> type, Type genericType,
       Annotation[] annotations, MediaType mediaType,
       MultivaluedMap<String, Object> httpHeaders, OutputStream outStream)
       throws IOException, WebApplicationException {
-    outStream.write(object.toString().getBytes());
+    outStream.write(Bytes.toBytes(object.toString()));
   }
\ No newline at end of file
",Buggy,"HBASE-19846 Fix findbugs and error-prone warnings in hbase-rest (branch-2)

Signed-off-by: tedyu <yuzhihong@gmail.com>
"
hbase,34490.json,2413a10e6718afaf74185078f0320f2e9e47d273,"@@ -1,47 +1,48 @@
   public List<InputSplit> getSplits(JobContext context) throws IOException {
     boolean closeOnFinish = false;
 
     // Just in case a subclass is relying on JobConfigurable magic.
     if (table == null) {
       initialize(context);
       closeOnFinish = true;
     }
 
     // null check in case our child overrides getTable to not throw.
     try {
       if (getTable() == null) {
         // initialize() must not have been implemented in the subclass.
         throw new IOException(INITIALIZATION_ERROR);
       }
     } catch (IllegalStateException exception) {
       throw new IOException(INITIALIZATION_ERROR, exception);
     }
 
     try {
       List<InputSplit> splits = oneInputSplitPerRegion();
 
       // set same number of mappers for each region
       if (context.getConfiguration().get(NUM_MAPPERS_PER_REGION) != null) {
         int nSplitsPerRegion = context.getConfiguration().getInt(NUM_MAPPERS_PER_REGION, 1);
         List<InputSplit> res = new ArrayList<>();
         for (int i = 0; i < splits.size(); i++) {
           List<InputSplit> tmp = createNInputSplitsUniform(splits.get(i), nSplitsPerRegion);
           res.addAll(tmp);
         }
         return res;
       }
 
       //The default value of ""hbase.mapreduce.input.autobalance"" is false.
-      if (context.getConfiguration().getBoolean(MAPREDUCE_INPUT_AUTOBALANCE, false) != false) {
-        long maxAveRegionSize = context.getConfiguration().getInt(MAX_AVERAGE_REGION_SIZE, 8*1073741824);
+      if (context.getConfiguration().getBoolean(MAPREDUCE_INPUT_AUTOBALANCE, false)) {
+        long maxAveRegionSize = context.getConfiguration()
+            .getLong(MAX_AVERAGE_REGION_SIZE, 8L*1073741824); //8GB
         return calculateAutoBalancedSplits(splits, maxAveRegionSize);
       }
 
       // return one mapper per region
       return splits;
     } finally {
       if (closeOnFinish) {
         closeTable();
       }
     }
   }
\ No newline at end of file
",NotBuggy,"HBASE-19195 error-prone fixes for client, mr, and server
"
hbase,5669.json,9fac4877d3072c3589370c9d0446342ee2658ab6,"@@ -1,7 +1,6 @@
   public static void resetCounters() throws Exception {
     Class<?> cl = (new SplitLogCounters()).getClass();
-    Field[] flds = cl.getDeclaredFields();
-    for (Field fld : flds) {
+    for (Field fld : cl.getDeclaredFields()) {
       ((AtomicLong)fld.get(null)).set(0);
     }
   }
\ No newline at end of file
",NotBuggy,"HBASE-5598 Analyse and fix the findbugs reporting by QA and add invalid bugs into findbugs-excludeFilter file

git-svn-id: https://svn.apache.org/repos/asf/hbase/trunk@1425351 13f79535-47bb-0310-9956-ffa450edef68
"
hbase,10177.json,9fac4877d3072c3589370c9d0446342ee2658ab6,"@@ -1,6 +1,5 @@
   public void start() {
     worker = new Thread(null, this, ""SplitLogWorker-"" + serverName);
     exitWorker = false;
     worker.start();
-    return;
   }
\ No newline at end of file
",NotBuggy,"HBASE-5598 Analyse and fix the findbugs reporting by QA and add invalid bugs into findbugs-excludeFilter file

git-svn-id: https://svn.apache.org/repos/asf/hbase/trunk@1425351 13f79535-47bb-0310-9956-ffa450edef68
"
hbase,28329.json,f1ad5cb93837e8d07d9d08da7c1a48caf74bbe9f,"@@ -1,8 +1,11 @@
-  public Get setTimeStamp(long timestamp) {
+  public Get setTimeStamp(long timestamp)
+  throws IOException {
     try {
       tr = new TimeRange(timestamp, timestamp+1);
     } catch(IOException e) {
-      // Will never happen
+      // This should never happen, unless integer overflow or something extremely wrong...
+      LOG.error(""TimeRange failed, likely caused by integer overflow. "", e);
+      throw e;
     }
     return this;
   }
\ No newline at end of file
",NotBuggy,"HBASE-10452 Fix potential bugs in exception handlers (Ding Yuan)



git-svn-id: https://svn.apache.org/repos/asf/hbase/trunk@1567979 13f79535-47bb-0310-9956-ffa450edef68
"
hbase,40756.json,f1ad5cb93837e8d07d9d08da7c1a48caf74bbe9f,"@@ -1,25 +1,26 @@
   public int getNumberOfRunningProcess(){
     if (!isUnix()){
       return 0;
     }
 
     BufferedReader input = null;
     try {
       int count = 0;
       Process p = Runtime.getRuntime().exec(""ps -e"");
       input = new BufferedReader(new InputStreamReader(p.getInputStream()));
       while (input.readLine() != null) {
         count++;
       }
       return count - 1; //  -1 because there is a headline
     } catch (IOException e) {
       return -1;
     }  finally {
       if (input != null){
         try {
           input.close();
-        } catch (IOException ignored) {
+        } catch (IOException e) {
+          LOG.warn(""Not able to close the InputStream"", e);
         }
       }
     }
   }
\ No newline at end of file
",NotBuggy,"HBASE-10452 Fix potential bugs in exception handlers (Ding Yuan)



git-svn-id: https://svn.apache.org/repos/asf/hbase/trunk@1567979 13f79535-47bb-0310-9956-ffa450edef68
"
hbase,40081.json,f1ad5cb93837e8d07d9d08da7c1a48caf74bbe9f,"@@ -1,10 +1,15 @@
   public static boolean isShowConfInServlet() {
     boolean isShowConf = false;
     try {
       if (Class.forName(""org.apache.hadoop.conf.ConfServlet"") != null) {
         isShowConf = true;
       }
-    } catch (Exception e) {
+    } catch (LinkageError e) {
+       // should we handle it more aggressively in addition to log the error?
+       LOG.warn(""Error thrown: "", e);
+    } catch (ClassNotFoundException ce) {
+      LOG.debug(""ClassNotFound: ConfServlet"");
+      // ignore
     }
     return isShowConf;
   }
\ No newline at end of file
",NotBuggy,"HBASE-10452 Fix potential bugs in exception handlers (Ding Yuan)



git-svn-id: https://svn.apache.org/repos/asf/hbase/trunk@1567979 13f79535-47bb-0310-9956-ffa450edef68
"
hbase,10426.json,f1ad5cb93837e8d07d9d08da7c1a48caf74bbe9f,"@@ -1,30 +1,34 @@
   protected void configureForRegion(HRegion region) {
     super.configureForRegion(region);
     if (region != null) {
       prefixLength = 0;
 
       // read the prefix length from the table descriptor
       String prefixLengthString = region.getTableDesc().getValue(
           PREFIX_LENGTH_KEY);
       if (prefixLengthString == null) {
         //read the deprecated value
         prefixLengthString = region.getTableDesc().getValue(PREFIX_LENGTH_KEY_DEPRECATED);
         if (prefixLengthString == null) {
           LOG.error(PREFIX_LENGTH_KEY + "" not specified for table ""
               + region.getTableDesc().getTableName()
               + "". Using default RegionSplitPolicy"");
           return;
         }
       }
       try {
         prefixLength = Integer.parseInt(prefixLengthString);
       } catch (NumberFormatException nfe) {
-        // ignore
+        /* Differentiate NumberFormatException from an invalid value range reported below. */
+        LOG.error(""Number format exception when parsing "" + PREFIX_LENGTH_KEY + "" for table ""
+            + region.getTableDesc().getTableName() + "":""
+            + prefixLengthString + "". "" + nfe);
+        return;
       }
       if (prefixLength <= 0) {
         LOG.error(""Invalid value for "" + PREFIX_LENGTH_KEY + "" for table ""
             + region.getTableDesc().getTableName() + "":""
             + prefixLengthString + "". Using default RegionSplitPolicy"");
       }
     }
   }
\ No newline at end of file
",NotBuggy,"HBASE-10452 Fix potential bugs in exception handlers (Ding Yuan)



git-svn-id: https://svn.apache.org/repos/asf/hbase/trunk@1567979 13f79535-47bb-0310-9956-ffa450edef68
"
ant,5703.json,a66a2b7f86fe7f4bab938d0cb5167b27c8fa4957,"@@ -1,3 +1,8 @@
     public String getJavacExecutable() {
+        if (forkedExecutable == null && isForkedJavac()) {
+            forkedExecutable = getSystemJavac();
+        } else if (forkedExecutable != null && !isForkedJavac()) {
+            forkedExecutable = null;
+        }
         return forkedExecutable;
     }
\ No newline at end of file
",Buggy,"Add testcases for latest <javac> changes, fix some problem with some
rare combination of the fork attribute and build.compiler settings.


git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@269879 13f79535-47bb-0310-9956-ffa450edef68
"
ant,5699.json,a66a2b7f86fe7f4bab938d0cb5167b27c8fa4957,"@@ -1,15 +1,16 @@
     public void setFork(String f) {
         if (f.equalsIgnoreCase(""on"")
             || f.equalsIgnoreCase(""true"")
             || f.equalsIgnoreCase(""yes"")) {
             fork = ""true"";
             forkedExecutable = getSystemJavac();
         } else if (f.equalsIgnoreCase(""off"")
                    || f.equalsIgnoreCase(""false"")
                    || f.equalsIgnoreCase(""no"")) {
             fork = ""false"";
+            forkedExecutable = null;
         } else {
             fork = ""true"";
             forkedExecutable = f;
         }
     }
\ No newline at end of file
",Buggy,"Add testcases for latest <javac> changes, fix some problem with some
rare combination of the fork attribute and build.compiler settings.


git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@269879 13f79535-47bb-0310-9956-ffa450edef68
"
ant,9617.json,4e2a4f9c9507b19b248548ec6333698af3c1a4b8,"@@ -1,35 +1,38 @@
     public String substitute(String input, String argument, int options)
         throws BuildException {
         // translate \1 to $1 so that the Perl5Substitution will work
         StringBuffer subst = new StringBuffer();
         for (int i = 0; i < argument.length(); i++) {
             char c = argument.charAt(i);
-            if (c == '\\') {
+            if (c == '$') {
+                subst.append('\\');
+                subst.append('$');
+            } else if (c == '\\') {
                 if (++i < argument.length()) {
                     c = argument.charAt(i);
                     int value = Character.digit(c, 10);
                     if (value > -1) {
                         subst.append(""$"").append(value);
                     } else {
                         subst.append(c);
                     }
                 } else {
                     // XXX - should throw an exception instead?
                     subst.append('\\');
                 }
             } else {
                 subst.append(c);
             }
         }
         
 
         // Do the substitution
         Substitution s = 
             new Perl5Substitution(subst.toString(), 
                                   Perl5Substitution.INTERPOLATE_ALL);
         return Util.substitute(matcher,
                                getCompiledPattern(options),
                                s,
                                input,
                                getSubsOptions(options));
     }
\ No newline at end of file
",Buggy,"fix for bug 20306 - regex handling of $ in replace string


git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@274633 13f79535-47bb-0310-9956-ffa450edef68
"
ant,3632.json,94182a1dfa6d104e3b48d12a651dffd53f089e85,"@@ -1,21 +1,24 @@
     protected void scanDir(File srcDir, File dest, JspMangler mangler, String files[]) {
 
         long now = (new Date()).getTime();
 
         for (int i = 0; i < files.length; i++) {
             String filename = files[i];
             File srcFile = new File(srcDir, filename);
             File javaFile = mapToJavaFile(mangler, srcFile, srcDir, dest);
+            if(javaFile==null) {
+                continue;
+            }
 
             if (srcFile.lastModified() > now) {
                 log(""Warning: file modified in the future: "" + filename,
                         Project.MSG_WARN);
             }
             boolean shouldCompile = false;
             shouldCompile = isCompileNeeded(srcFile, javaFile);
             if (shouldCompile) {
                compileList.addElement(srcFile.getAbsolutePath());
                javaFiles.addElement(javaFile);
             }
         }
     }
\ No newline at end of file
",Buggy,"this patch does not fix the failing of jspc test, it fixes two other bugs in bugzilla -NPE on inclusion of non jsp file, and webapp attr broken.


git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@273214 13f79535-47bb-0310-9956-ffa450edef68
"
ant,4122.json,731eadf2ee7888aa3c30d70893409be7208b6746,"@@ -1,28 +1,28 @@
     private Source getSource(InputStream is, Resource resource)
         throws ParserConfigurationException, SAXException {
         // todo: is this comment still relevant ??
         // FIXME: need to use a SAXSource as the source for the transform
         // so we can plug in our own entity resolver
         Source src = null;
         if (entityResolver != null) {
             if (getFactory().getFeature(SAXSource.FEATURE)) {
                 SAXParserFactory spFactory = SAXParserFactory.newInstance();
                 spFactory.setNamespaceAware(true);
                 XMLReader reader = spFactory.newSAXParser().getXMLReader();
                 reader.setEntityResolver(entityResolver);
                 src = new SAXSource(reader, new InputSource(is));
             } else {
                 throw new IllegalStateException(""xcatalog specified, but ""
                     + ""parser doesn't support SAX"");
             }
         } else {
             // WARN: Don't use the StreamSource(File) ctor. It won't work with
             // xalan prior to 2.2 because of systemid bugs.
             src = new StreamSource(is);
         }
         // The line below is a hack: the system id must an URI, but it is not
         // cleat to get the URI of an resource, so just set the name of the
         // resource as a system id
-        src.setSystemId(resource.getName());
+        src.setSystemId(resourceToURI(resource));
         return src;
     }
\ No newline at end of file
",Buggy,"Fix for SystemId of stylesheet
Bugzilla 39407.


git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@412369 13f79535-47bb-0310-9956-ffa450edef68
"
ant,4118.json,731eadf2ee7888aa3c30d70893409be7208b6746,"@@ -1,5 +1,6 @@
     public void setStylesheet(File stylesheet) throws Exception {
         FileResource fr = new FileResource();
         fr.setProject(project);
         fr.setFile(stylesheet);
+        setStylesheet(fr);
     }
\ No newline at end of file
",Buggy,"Fix for SystemId of stylesheet
Bugzilla 39407.


git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@412369 13f79535-47bb-0310-9956-ffa450edef68
"
ant,9255.json,f4f7024234069cab8a6853720a326d12065a2d8e,"@@ -1,4 +1,12 @@
     private void resetBufferInfo() {    
         Thread current = Thread.currentThread();
-        buffers.remove(current);
+        BufferInfo bufferInfo = (BufferInfo)buffers.get(current);
+        try {
+            bufferInfo.buffer.close();
+        }
+        catch (IOException e) {
+            // Shouldn't happen
+        }
+        bufferInfo.buffer = new ByteArrayOutputStream();
+        bufferInfo.skip = false;
     }
\ No newline at end of file
",Buggy,"Fixed problem which gave (on Windows) output such as:

[java] First line of real output
[java]
[java] Second line of real output
[java]


git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@271563 13f79535-47bb-0310-9956-ffa450edef68
"
ant,9260.json,f4f7024234069cab8a6853720a326d12065a2d8e,"@@ -1,3 +1,4 @@
     public void close() throws IOException {
         flush();
+        removeBuffer();
     }
\ No newline at end of file
",Buggy,"Fixed problem which gave (on Windows) output such as:

[java] First line of real output
[java]
[java] Second line of real output
[java]


git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@271563 13f79535-47bb-0310-9956-ffa450edef68
"
ant,7847.json,588ce1fbe3c07994b03283ddeb82662bb23a2785,"@@ -1,10 +1,10 @@
     public void setClassname(String classname) {
         if (executableType == ExecutableType.MODULE) {
             javaCommand.setExecutable(createModuleClassPair(
                     parseModuleFromModuleClassPair(javaCommand.getExecutable()),
-                    classname));
+                    classname), false);
         } else {
             javaCommand.setExecutable(classname);
             executableType = ExecutableType.CLASS;
         }
     }
\ No newline at end of file
",Buggy,"avoid slash translations for module names

should fix Windows test errors introduced with #15
"
ant,7722.json,588ce1fbe3c07994b03283ddeb82662bb23a2785,"@@ -1,7 +1,3 @@
     public void setExecutable(String executable) {
-        if (executable == null || executable.length() == 0) {
-            return;
-        }
-        this.executable = executable.replace('/', File.separatorChar)
-            .replace('\\', File.separatorChar);
+        setExecutable(executable, true);
     }
\ No newline at end of file
",Buggy,"avoid slash translations for module names

should fix Windows test errors introduced with #15
"
ant,7516.json,873b850f39a26e4911d612c157622751ac9582f9,"@@ -1,3 +1,6 @@
     public void addFilelist(FileList fl) throws BuildException {
+        if (fl.getProject() == null) {
+            fl.setProject(getProject());
+        }
         add(fl);
     }
\ No newline at end of file
",Buggy,"fix for 
<javac> fails with NPE when compiling with eclipse ecj 3.1.x
Bugzilla 40839.
root cause of the problem was in org.eclipse.jdt.core.JDTCompiler
method addExtDirs. A FileSet was created without the Project attribute set,
then added to a Path.


git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@469050 13f79535-47bb-0310-9956-ffa450edef68
"
ant,7517.json,873b850f39a26e4911d612c157622751ac9582f9,"@@ -1,3 +1,6 @@
     public void addDirset(DirSet dset) throws BuildException {
+        if (dset.getProject() == null) {
+            dset.setProject(getProject());
+        }
         add(dset);
     }
\ No newline at end of file
",Buggy,"fix for 
<javac> fails with NPE when compiling with eclipse ecj 3.1.x
Bugzilla 40839.
root cause of the problem was in org.eclipse.jdt.core.JDTCompiler
method addExtDirs. A FileSet was created without the Project attribute set,
then added to a Path.


git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@469050 13f79535-47bb-0310-9956-ffa450edef68
"
ant,7515.json,873b850f39a26e4911d612c157622751ac9582f9,"@@ -1,3 +1,6 @@
     public void addFileset(FileSet fs) throws BuildException {
+        if (fs.getProject() == null) {
+            fs.setProject(getProject());
+        }
         add(fs);
     }
\ No newline at end of file
",Buggy,"fix for 
<javac> fails with NPE when compiling with eclipse ecj 3.1.x
Bugzilla 40839.
root cause of the problem was in org.eclipse.jdt.core.JDTCompiler
method addExtDirs. A FileSet was created without the Project attribute set,
then added to a Path.


git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@469050 13f79535-47bb-0310-9956-ffa450edef68
"
ant,787.json,bb2695af1464b52cacdd3d3672e428358c3142dd,"@@ -1,29 +1,22 @@
     public final int read() throws IOException {
         if (!getInitialized()) {
             initialize();
             setInitialized(true);
         }
 
         int ch = -1;
         if (unicodeBuf.length() == 0) {
             ch = in.read();
             if (ch != -1) {
                 char achar = (char) ch;
                 if (achar >= '\u0080') {
-                    unicodeBuf = new StringBuffer(""u0000"");
-                    String s = Integer.toHexString(ch);
-                    //replace the last 0s by the chars contained in s
-                    for (int i = 0; i < s.length(); i++) {
-                        unicodeBuf.setCharAt(unicodeBuf.length()
-                                             - s.length() + i,
-                                             s.charAt(i));
-                    }
+                    unicodeBuf = UnicodeUtil.EscapeUnicode(achar);
                     ch = '\\';
                 }
             }
         } else {
             ch = (int) unicodeBuf.charAt(0);
             unicodeBuf.deleteCharAt(0);
         }
         return ch;
     }
\ No newline at end of file
",Buggy,"fix for bug 50515, incorrect unicode escapes in propertyfile task

git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@1054711 13f79535-47bb-0310-9956-ffa450edef68
"
ant,9748.json,bb2695af1464b52cacdd3d3672e428358c3142dd,"@@ -1,7 +1,3 @@
     private String escapeUnicode(char ch) {
-        StringBuffer buffy = new StringBuffer(""\\u"");
-        String hex = Integer.toHexString((int)ch);
-        buffy.append(""0000"".substring(4-hex.length()));
-        buffy.append(hex);
-        return buffy.toString();
-    }
\ No newline at end of file
+        return ""\\"" + UnicodeUtil.EscapeUnicode(ch);
+        }
\ No newline at end of file
",Buggy,"fix for bug 50515, incorrect unicode escapes in propertyfile task

git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@1054711 13f79535-47bb-0310-9956-ffa450edef68
"
ant,4816.json,29fface4fb93fb33b33c86124a168c04779271c0,"@@ -1,24 +1,24 @@
     public boolean execute() throws BuildException {
         Rmic owner = getRmic();
         Commandline cmd = setupRmicCommand();
         Project project = owner.getProject();
         //rely on RMIC being on the path
-        cmd.setExecutable(JavaEnvUtils.getJdkExecutable(SunRmic.RMIC_EXECUTABLE));
+        cmd.setExecutable(JavaEnvUtils.getJdkExecutable(getExecutableName()));
 
         //set up the args
         String[] args = cmd.getCommandline();
 
         try {
             Execute exe = new Execute(new LogStreamHandler(owner,
                     Project.MSG_INFO,
                     Project.MSG_WARN));
             exe.setAntRun(project);
             exe.setWorkingDirectory(project.getBaseDir());
             exe.setCommandline(args);
             exe.execute();
             return !exe.isFailure();
         } catch (IOException exception) {
-            throw new BuildException(""Error running "" + SunRmic.RMIC_EXECUTABLE
+            throw new BuildException(""Error running "" + getExecutableName()
                     + "" -maybe it is not on the path"", exception);
         }
     }
\ No newline at end of file
",Buggy,"bug ID#38732 , rmic task doesn't work with -Xnew and JDK 6.0

Fixed by writing a new adapter, xnew, that extends the forking adapter and sets the -Xnew argument. Tests supplied, though the old test, the one that would fail on java1.6, is still there.

Also made the name matching code of rmic locale-independent.

git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@434029 13f79535-47bb-0310-9956-ffa450edef68
"
ant,10020.json,ececc5c3e332b97f962b94a475408606433ee0e6,"@@ -1,14 +1,3 @@
     public boolean tryHardToDelete(File f) {
-        if (!f.delete()) {
-            if (ON_WINDOWS) {
-                System.gc();
-            }
-            try {
-                Thread.sleep(DELETE_RETRY_SLEEP_MILLIS);
-            } catch (InterruptedException ex) {
-                // Ignore Exception
-            }
-            return f.delete();
-        }
-        return true;
+        return tryHardToDelete(f, ON_WINDOWS);
     }
\ No newline at end of file
",NotBuggy,"Add an option to <delete> to run the GC before retrying a failed build on non-Windows OSes as well.  Might fix the NFS problem described in PR 45786

git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@1177305 13f79535-47bb-0310-9956-ffa450edef68
"
ant,10021.json,ececc5c3e332b97f962b94a475408606433ee0e6,"@@ -1,14 +1,14 @@
-    public boolean tryHardToDelete(File f) {
+    public boolean tryHardToDelete(File f, boolean runGC) {
         if (!f.delete()) {
-            if (ON_WINDOWS) {
+            if (runGC) {
                 System.gc();
             }
             try {
                 Thread.sleep(DELETE_RETRY_SLEEP_MILLIS);
             } catch (InterruptedException ex) {
                 // Ignore Exception
             }
             return f.delete();
         }
         return true;
     }
\ No newline at end of file
",NotBuggy,"Add an option to <delete> to run the GC before retrying a failed build on non-Windows OSes as well.  Might fix the NFS problem described in PR 45786

git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@1177305 13f79535-47bb-0310-9956-ffa450edef68
"
ant,5445.json,ececc5c3e332b97f962b94a475408606433ee0e6,"@@ -1,14 +1,14 @@
     private boolean delete(File f) {
-        if (!FILE_UTILS.tryHardToDelete(f)) {
+        if (!FILE_UTILS.tryHardToDelete(f, performGc)) {
             if (deleteOnExit) {
                 int level = quiet ? Project.MSG_VERBOSE : Project.MSG_INFO;
                 log(""Failed to delete "" + f + "", calling deleteOnExit.""
                     + "" This attempts to delete the file when the Ant jvm""
                     + "" has exited and might not succeed."", level);
                 f.deleteOnExit();
                 return true;
             }
             return false;
         }
         return true;
     }
\ No newline at end of file
",NotBuggy,"Add an option to <delete> to run the GC before retrying a failed build on non-Windows OSes as well.  Might fix the NFS problem described in PR 45786

git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@1177305 13f79535-47bb-0310-9956-ffa450edef68
"
ant,7946.json,f83f5c68c975f31a384cc24e94be4e5ebfa2da4d,"@@ -1,9 +1,11 @@
     public boolean isSelected(File basedir, String filename, File file) {
 
         // throw BuildException on error
         validate();
 
         if (file.isDirectory()) {
             return type.equals(FileType.DIR);
-        } else return type.equals(FileType.FILE);
+        } else {
+            return type.equals(FileType.FILE);
+        }
     }
\ No newline at end of file
",NotBuggy,"First pass at fixing checkstyle issues by using IDEA to reformat code and identify problem spots


git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@274773 13f79535-47bb-0310-9956-ffa450edef68
"
ant,8194.json,f83f5c68c975f31a384cc24e94be4e5ebfa2da4d,"@@ -1,11 +1,10 @@
     public void verifySettings() {
         if (dateTime == null && millis < 0) {
             setError(""You must provide a datetime or the number of ""
-                + ""milliseconds."");
-        }
-        else if (millis < 0) {
+                    + ""milliseconds."");
+        } else if (millis < 0) {
             setError(""Date of "" + dateTime
-                + "" results in negative milliseconds""
-                + "" value relative to epoch (January 1, 1970, 00:00:00 GMT)."");
+                    + "" results in negative milliseconds value""
+                    + "" relative to epoch (January 1, 1970, 00:00:00 GMT)."");
         }
     }
\ No newline at end of file
",NotBuggy,"First pass at fixing checkstyle issues by using IDEA to reformat code and identify problem spots


git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@274773 13f79535-47bb-0310-9956-ffa450edef68
"
ant,4305.json,faedd2bc5b9fdcaa0650966bc7fef43c5c59cf9a,"@@ -1,87 +1,89 @@
         private URLConnection openConnection(final URL aSource) throws IOException {
 
             // set up the URL connection
             final URLConnection connection = aSource.openConnection();
             // modify the headers
             // NB: things like user authentication could go in here too.
             if (hasTimestamp) {
                 connection.setIfModifiedSince(timestamp);
             }
             // Set the user agent
             connection.addRequestProperty(""User-Agent"", this.userAgent);
 
             // prepare Java 1.1 style credentials
             if (uname != null || pword != null) {
                 final String up = uname + "":"" + pword;
                 String encoding;
                 // we do not use the sun impl for portability,
                 // and always use our own implementation for consistent
                 // testing
                 final Base64Converter encoder = new Base64Converter();
                 encoding = encoder.encode(up.getBytes());
                 connection.setRequestProperty(""Authorization"", ""Basic ""
                         + encoding);
             }
 
-            connection.setRequestProperty(""Accept-Encoding"", GZIP_CONTENT_ENCODING);
+            if (tryGzipEncoding) {
+                connection.setRequestProperty(""Accept-Encoding"", GZIP_CONTENT_ENCODING);
+            }
 
             if (connection instanceof HttpURLConnection) {
                 ((HttpURLConnection) connection)
                         .setInstanceFollowRedirects(false);
                 ((HttpURLConnection) connection)
                         .setUseCaches(httpUseCaches);
             }
             // connect to the remote site (may take some time)
             try {
                 connection.connect();
             } catch (final NullPointerException e) {
                 //bad URLs can trigger NPEs in some JVMs
                 throw new BuildException(""Failed to parse "" + source.toString(), e);
             }
 
             // First check on a 301 / 302 (moved) response (HTTP only)
             if (connection instanceof HttpURLConnection) {
                 final HttpURLConnection httpConnection = (HttpURLConnection) connection;
                 final int responseCode = httpConnection.getResponseCode();
                 if (isMoved(responseCode)) {
                     final String newLocation = httpConnection.getHeaderField(""Location"");
                     final String message = aSource
                             + (responseCode == HttpURLConnection.HTTP_MOVED_PERM ? "" permanently""
                                     : """") + "" moved to "" + newLocation;
                     log(message, logLevel);
                     final URL newURL = new URL(aSource, newLocation);
                     if (!redirectionAllowed(aSource, newURL)) {
                         return null;
                     }
                     return openConnection(newURL);
                 }
                 // next test for a 304 result (HTTP only)
                 final long lastModified = httpConnection.getLastModified();
                 if (responseCode == HttpURLConnection.HTTP_NOT_MODIFIED
                         || (lastModified != 0 && hasTimestamp && timestamp >= lastModified)) {
                     // not modified so no file download. just return
                     // instead and trace out something so the user
                     // doesn't think that the download happened when it
                     // didn't
                     log(""Not modified - so not downloaded"", logLevel);
                     return null;
                 }
                 // test for 401 result (HTTP only)
                 if (responseCode == HttpURLConnection.HTTP_UNAUTHORIZED) {
                     final String message = ""HTTP Authorization failure"";
                     if (ignoreErrors) {
                         log(message, logLevel);
                         return null;
                     } else {
                         throw new BuildException(message);
                     }
                 }
             }
 
             //REVISIT: at this point even non HTTP connections may
             //support the if-modified-since behaviour -we just check
             //the date of the content and skip the write if it is not
             //newer. Some protocols (FTP) don't include dates, of
             //course.
             return connection;
         }
\ No newline at end of file
",Buggy,"only enable transparent gzip encoding when explicitly specified
fixes bugzilla issue 57048
"
ant,4307.json,faedd2bc5b9fdcaa0650966bc7fef43c5c59cf9a,"@@ -1,51 +1,52 @@
         private boolean downloadFile()
                 throws FileNotFoundException, IOException {
             for (int i = 0; i < numberRetries; i++) {
                 // this three attempt trick is to get round quirks in different
                 // Java implementations. Some of them take a few goes to bind
                 // properly; we ignore the first couple of such failures.
                 try {
                     is = connection.getInputStream();
                     break;
                 } catch (final IOException ex) {
                     log(""Error opening connection "" + ex, logLevel);
                 }
             }
             if (is == null) {
                 log(""Can't get "" + source + "" to "" + dest, logLevel);
                 if (ignoreErrors) {
                     return false;
                 }
                 throw new BuildException(""Can't get "" + source + "" to "" + dest,
                         getLocation());
             }
 
-            if (GZIP_CONTENT_ENCODING.equals(connection.getContentEncoding())) {
+            if (tryGzipEncoding
+                && GZIP_CONTENT_ENCODING.equals(connection.getContentEncoding())) {
                 is = new GZIPInputStream(is);
             }
 
             os = new FileOutputStream(dest);
             progress.beginDownload();
             boolean finished = false;
             try {
                 final byte[] buffer = new byte[BIG_BUFFER_SIZE];
                 int length;
                 while (!isInterrupted() && (length = is.read(buffer)) >= 0) {
                     os.write(buffer, 0, length);
                     progress.onTick();
                 }
                 finished = !isInterrupted();
             } finally {
                 FileUtils.close(os);
                 FileUtils.close(is);
 
                 // we have started to (over)write dest, but failed.
                 // Try to delete the garbage we'd otherwise leave
                 // behind.
                 if (!finished) {
                     dest.delete();
                 }
             }
             progress.endDownload();
             return true;
         }
\ No newline at end of file
",Buggy,"only enable transparent gzip encoding when explicitly specified
fixes bugzilla issue 57048
"
ant,658.json,d0b4fb3912af11d2c3075c51c0715d581ea085f1,"@@ -1,45 +1,46 @@
     private final void tsort(String root, Hashtable targets,
                              Hashtable state, Stack visiting,
                              Vector ret)
         throws BuildException {
         state.put(root, VISITING);
         visiting.push(root);
 
         Target target = (Target)(targets.get(root));
 
         // Make sure we exist
         if (target == null) {
             StringBuffer sb = new StringBuffer(""Target `"");
             sb.append(root);
             sb.append(""' does not exist in this project. "");
             visiting.pop();
             if (!visiting.empty()) {
                 String parent = (String)visiting.peek();
                 sb.append(""It is used from target `"");
                 sb.append(parent);
                 sb.append(""'."");
             }
 
             throw new BuildException(new String(sb));
         }
 
-        for (Enumeration en=target.getDependencies(); en.hasMoreElements();) {
+        for (Enumeration en = target.getDependencies(); en.hasMoreElements();) {
             String cur = (String) en.nextElement();
-            String m=(String)state.get(cur);
+            String m = (String)state.get(cur);
             if (m == null) {
                 // Not been visited
                 tsort(cur, targets, state, visiting, ret);
             }
             else if (m == VISITING) {
                 // Currently visiting this node, so have a cycle
                 throw makeCircularException(cur, visiting);
             }
         }
 
         String p = (String) visiting.pop();
         if (root != p) {
-            throw new RuntimeException(""Unexpected internal error: expected to pop ""+root+"" but got ""+p);
+            throw new RuntimeException(""Unexpected internal error: expected to ""
+                + ""pop "" + root + "" but got "" + p);
         }
         state.put(root, VISITED);
         ret.addElement(target);
     }
\ No newline at end of file
",NotBuggy,"Fix up errors in Project format and javadoc picked up with checkstyle


git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@271747 13f79535-47bb-0310-9956-ffa450edef68
"
ant,624.json,d0b4fb3912af11d2c3075c51c0715d581ea085f1,"@@ -1,7 +1,7 @@
-    public void addTarget(Target target) {
+    public void addTarget(Target target) throws BuildException {
         String name = target.getName();
         if (targets.get(name) != null) {
-            throw new BuildException(""Duplicate target: `""+name+""'"");
+            throw new BuildException(""Duplicate target: `"" + name + ""'"");
         }
         addOrReplaceTarget(name, target);
     }
\ No newline at end of file
",NotBuggy,"Fix up errors in Project format and javadoc picked up with checkstyle


git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@271747 13f79535-47bb-0310-9956-ffa450edef68
"
ant,1464.json,3d3b941aa7dd1e582d95c63df93ecd61423fa41d,"@@ -1,15 +1,25 @@
     private void processComment( final String line )
     {
         final String lineSeparator = System.getProperty( ""line.separator"" );
-        if( line.startsWith( ""======"" ) || line.startsWith( ""------"" ) )
+        if( line.startsWith( ""======"" ) )
+        {
+            //We have ended changelog for that particular file
+            //so we can save it
+            final int end = m_comment.length() - lineSeparator.length(); //was -1
+            m_comment = m_comment.substring( 0, end );
+            m_comment = ""<![CDATA["" + m_comment + ""]]>"";
+            saveEntry();
+            m_status = GET_FILE;
+        }
+        else if( line.startsWith( ""------"" ) )
         {
             final int end = m_comment.length() - lineSeparator.length(); //was -1
             m_comment = m_comment.substring( 0, end );
             m_comment = ""<![CDATA["" + m_comment + ""]]>"";
             m_status = GET_PREVIOUS_REV;
         }
         else
         {
             m_comment += line + lineSeparator;
         }
     }
\ No newline at end of file
",Buggy,"Fix bug where a log of a single file without other logs in between would only retrieve first change


git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@272104 13f79535-47bb-0310-9956-ffa450edef68
"
ant,1463.json,3d3b941aa7dd1e582d95c63df93ecd61423fa41d,"@@ -1,24 +1,25 @@
     public void stdout( final String line )
     {
         switch( m_status )
         {
             case GET_FILE:
                 processFile( line );
                 break;
             case GET_REVISION:
                 processRevision( line );
                 //Was a fall through ....
-                //break;
+                break;
+
             case GET_DATE:
                 processDate( line );
                 break;
 
             case GET_COMMENT:
                 processComment( line );
                 break;
 
             case GET_PREVIOUS_REV:
                 processGetPreviousRevision( line );
                 break;
         }
     }
\ No newline at end of file
",Buggy,"Fix bug where a log of a single file without other logs in between would only retrieve first change


git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@272104 13f79535-47bb-0310-9956-ffa450edef68
"
ant,1468.json,3d3b941aa7dd1e582d95c63df93ecd61423fa41d,"@@ -1,36 +1,13 @@
     private void processGetPreviousRevision( final String line )
     {
-        final String entryKey = m_date + m_author + m_comment;
-        if( line.startsWith( ""revision"" ) )
+        if( !line.startsWith( ""revision"" ) )
         {
-            m_previousRevision = line.substring( 9 );
-            m_status = GET_FILE;
+            throw new IllegalStateException( ""Unexpected line from CVS: "" + line );
+        }
+        m_previousRevision = line.substring( 9 );
 
-            CVSEntry entry;
-            if( !m_entries.containsKey( entryKey ) )
-            {
-                entry = new CVSEntry( parseDate( m_date ), m_author, m_comment );
-                m_entries.put( entryKey, entry );
-            }
-            else
-            {
-                entry = (CVSEntry)m_entries.get( entryKey );
-            }
-            entry.addFile( m_file, m_revision, m_previousRevision );
-        }
-        else if( line.startsWith( ""======"" ) )
-        {
-            m_status = GET_FILE;
-            CVSEntry entry;
-            if( !m_entries.containsKey( entryKey ) )
-            {
-                entry = new CVSEntry( parseDate( m_date ), m_author, m_comment );
-                m_entries.put( entryKey, entry );
-            }
-            else
-            {
-                entry = (CVSEntry)m_entries.get( entryKey );
-            }
-            entry.addFile( m_file, m_revision );
-        }
+        saveEntry();
+
+        m_revision = m_previousRevision;
+        m_status = GET_COMMENT;
     }
\ No newline at end of file
",Buggy,"Fix bug where a log of a single file without other logs in between would only retrieve first change


git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@272104 13f79535-47bb-0310-9956-ffa450edef68
"
ant,5442.json,7ee236d89f0e870cebb3ad9128de6b27689bea28,"@@ -1,116 +1,115 @@
     public void execute() throws BuildException {
         if (usedMatchingTask) {
             log(""DEPRECATED - Use of the implicit FileSet is deprecated.  ""
-                + ""Use a nested fileset element instead."");
+                + ""Use a nested fileset element instead."", quiet ? Project.MSG_VERBOSE : verbosity);
         }
 
         if (file == null && dir == null && filesets.size() == 0 && rcs == null) {
             throw new BuildException(""At least one of the file or dir ""
                                      + ""attributes, or a nested resource collection, ""
                                      + ""must be set."");
         }
 
         if (quiet && failonerror) {
             throw new BuildException(""quiet and failonerror cannot both be ""
                                      + ""set to true"", getLocation());
         }
 
         // delete the single file
         if (file != null) {
             if (file.exists()) {
                 if (file.isDirectory()) {
                     log(""Directory "" + file.getAbsolutePath()
                         + "" cannot be removed using the file attribute.  ""
-                        + ""Use dir instead."");
+                        + ""Use dir instead."", quiet ? Project.MSG_VERBOSE : verbosity);
                 } else {
                     log(""Deleting: "" + file.getAbsolutePath());
 
                     if (!delete(file)) {
                         handle(""Unable to delete file "" + file.getAbsolutePath());
                     }
                 }
             } else {
                 log(""Could not find file "" + file.getAbsolutePath()
-                    + "" to delete."",
-                    Project.MSG_VERBOSE);
+                    + "" to delete."", quiet ? Project.MSG_VERBOSE : verbosity);
             }
         }
 
         // delete the directory
         if (dir != null && dir.exists() && dir.isDirectory()
             && !usedMatchingTask) {
             /*
                If verbosity is MSG_VERBOSE, that mean we are doing
                regular logging (backwards as that sounds).  In that
                case, we want to print one message about deleting the
                top of the directory tree.  Otherwise, the removeDir
                method will handle messages for _all_ directories.
              */
             if (verbosity == Project.MSG_VERBOSE) {
                 log(""Deleting directory "" + dir.getAbsolutePath());
             }
             removeDir(dir);
         }
         Resources resourcesToDelete = new Resources();
         resourcesToDelete.setProject(getProject());
         Resources filesetDirs = new Resources();
         filesetDirs.setProject(getProject());
 
-        for (int i = 0; i < filesets.size(); i++) {
+        for (int i = 0, size = filesets.size(); i < size; i++) {
             FileSet fs = (FileSet) filesets.get(i);
             if (fs.getProject() == null) {
                 log(""Deleting fileset with no project specified;""
                     + "" assuming executing project"", Project.MSG_VERBOSE);
                 fs = (FileSet) fs.clone();
                 fs.setProject(getProject());
             }
             resourcesToDelete.add(fs);
             if (includeEmpty && fs.getDir().isDirectory()) {
               filesetDirs.add(new ReverseDirs(fs.getDir(),
                   fs.getDirectoryScanner().getIncludedDirectories()));
             }
         }
         if (usedMatchingTask && dir != null && dir.isDirectory()) {
             //add the files from the default fileset:
             FileSet implicit = getImplicitFileSet();
             resourcesToDelete.add(implicit);
             if (includeEmpty) {
               filesetDirs.add(new ReverseDirs(dir,
                   implicit.getDirectoryScanner().getIncludedDirectories()));
             }
         }
         resourcesToDelete.add(filesetDirs);
         if (rcs != null) {
             // sort first to files, then dirs
             Restrict exists = new Restrict();
             exists.add(EXISTS);
             exists.add(rcs);
             Sort s = new Sort();
             s.add(REVERSE_FILESYSTEM);
             s.add(exists);
             resourcesToDelete.add(s);
         }
         try {
             if (resourcesToDelete.isFilesystemOnly()) {
                 for (Iterator iter = resourcesToDelete.iterator(); iter.hasNext();) {
                     FileResource r = (FileResource) iter.next();
                     // nonexistent resources could only occur if we already
                     // deleted something from a fileset:
                     if (!r.isExists()) {
                         continue;
                     }
                     if (!(r.isDirectory()) || r.getFile().list().length == 0) {
                         log(""Deleting "" + r, verbosity);
                         if (!delete(r.getFile()) && failonerror) {
                             handle(""Unable to delete ""
                                 + (r.isDirectory() ? ""directory "" : ""file "") + r);
                         }
                     }
                 }
             } else {
                  handle(getTaskName() + "" handles only filesystem resources"");
             }
         } catch (Exception e) {
             handle(e);
         }
     }
\ No newline at end of file
",Buggy,"fix bug#32738, implement quiet check for every message logged

git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@395510 13f79535-47bb-0310-9956-ffa450edef68
"
ant,5446.json,7ee236d89f0e870cebb3ad9128de6b27689bea28,"@@ -1,22 +1,22 @@
     protected void removeDir(File d) {
         String[] list = d.list();
         if (list == null) {
             list = new String[0];
         }
         for (int i = 0; i < list.length; i++) {
             String s = list[i];
             File f = new File(d, s);
             if (f.isDirectory()) {
                 removeDir(f);
             } else {
-                log(""Deleting "" + f.getAbsolutePath(), verbosity);
+                log(""Deleting "" + f.getAbsolutePath(), quiet ? Project.MSG_VERBOSE : verbosity);
                 if (!delete(f)) {
                     handle(""Unable to delete file "" + f.getAbsolutePath());
                 }
             }
         }
         log(""Deleting directory "" + d.getAbsolutePath(), verbosity);
         if (!delete(d)) {
             handle(""Unable to delete directory "" + dir.getAbsolutePath());
         }
     }
\ No newline at end of file
",Buggy,"fix bug#32738, implement quiet check for every message logged

git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@395510 13f79535-47bb-0310-9956-ffa450edef68
"
ant,5444.json,7ee236d89f0e870cebb3ad9128de6b27689bea28,"@@ -1,7 +1,7 @@
     private void handle(Exception e) {
         if (failonerror) {
             throw (e instanceof BuildException)
                 ? (BuildException) e : new BuildException(e);
         }
-        log(e.getMessage(), quiet ? Project.MSG_VERBOSE : Project.MSG_WARN);
+        log(e.getMessage(), quiet ? Project.MSG_VERBOSE : verbosity);
     }
\ No newline at end of file
",Buggy,"fix bug#32738, implement quiet check for every message logged

git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@395510 13f79535-47bb-0310-9956-ffa450edef68
"
ant,1828.json,85f6ea3795fa8d4393723ec229e9168f8b824f28,"@@ -1,11 +1,22 @@
     public void execute() throws BuildException {
+        ScriptRunner runner = new ScriptRunner();
+        if (language != null) {
+            runner.setLanguage(language);
+        }
+        if (src != null) {
+            runner.setSrc(src);
+        }
+        if (text != null) {
+            runner.addText(text);
+        }
+        
         runner.addBeans(getProject().getProperties());
         runner.addBeans(getProject().getUserProperties());
         runner.addBeans(getProject().getTargets());
         runner.addBeans(getProject().getReferences());
 
         runner.addBean(""project"", getProject());
         runner.addBean(""self"", this);
 
         runner.executeScript(""<ANT>"");
     }
\ No newline at end of file
",Buggy,"Fix for script memory retaining problem.
PR: 25394
Obtained from: Jose Alberto Fernandez /  Antoine Levy-Lambert


git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@275836 13f79535-47bb-0310-9956-ffa450edef68
"
lucene-solr,14918.json,8bd7e5c9d254c1d629a784e0b601885adea2f57b,"@@ -1,20 +1,3 @@
   public static SolrDocument convertLuceneDocToSolrDoc(Document doc, final IndexSchema schema) {
-    SolrDocument out = new SolrDocument();
-    for (IndexableField f : doc.getFields()) {
-      // Make sure multivalued fields are represented as lists
-      Object existing = out.get(f.name());
-      if (existing == null) {
-        SchemaField sf = schema.getFieldOrNull(f.name());
-        if (sf != null && sf.multiValued()) {
-          List<Object> vals = new ArrayList<>();
-          vals.add(f);
-          out.setField(f.name(), vals);
-        } else {
-          out.setField(f.name(), f);
-        }
-      } else {
-        out.addField(f.name(), f);
-      }
-    }
-    return out;
+    return convertLuceneDocToSolrDoc(doc,schema, new SolrReturnFields());
   }
\ No newline at end of file
",Buggy,"SOLR-11891: DocStreamer now respects the ReturnFields when populating a SolrDocument
This is an optimization that reduces the number of unneccessary fields a ResponseWriter will see if documentCache is used

This commit also includes fixes for SOLR-12107 & SOLR-12108 -- two bugs that were previously dependent on the
un-optimized behavior of DocStreamer in order to function properly.

- SOLR-12107: Fixed a error in [child] transformer that could ocur if documentCache was not used
- SOLR-12108: Fixed the fallback behavior of [raw] and [xml] transformers when an incompatble 'wt' was specified,
  the field value was lost if documentCache was not used.
"
lucene-solr,14569.json,8bd7e5c9d254c1d629a784e0b601885adea2f57b,"@@ -1,30 +1,31 @@
   public DocTransformer create(String display, SolrParams params, SolrQueryRequest req) {
     String field = params.get(""f"");
     if(Strings.isNullOrEmpty(field)) {
       field = display;
     }
     // When a 'wt' is specified in the transformer, only apply it to the same wt
     boolean apply = true;
     if(applyToWT!=null) {
       String qwt = req.getParams().get(CommonParams.WT);
       if(qwt==null) {
         QueryResponseWriter qw = req.getCore().getQueryResponseWriter(req);
         QueryResponseWriter dw = req.getCore().getQueryResponseWriter(applyToWT);
         if(qw!=dw) {
           apply = false;
         }
       }
       else {
         apply = applyToWT.equals(qwt);
       }
     }
 
     if(apply) {
       return new RawTransformer( field, display );
     }
     
-    if(field.equals(display)) {
-      return null; // nothing
+    if (field.equals(display)) {
+      // we have to ensure the field is returned
+      return new NoopFieldTransformer(field);
     }
     return new RenameFieldTransformer( field, display, false );
   }
\ No newline at end of file
",Buggy,"SOLR-11891: DocStreamer now respects the ReturnFields when populating a SolrDocument
This is an optimization that reduces the number of unneccessary fields a ResponseWriter will see if documentCache is used

This commit also includes fixes for SOLR-12107 & SOLR-12108 -- two bugs that were previously dependent on the
un-optimized behavior of DocStreamer in order to function properly.

- SOLR-12107: Fixed a error in [child] transformer that could ocur if documentCache was not used
- SOLR-12108: Fixed the fallback behavior of [raw] and [xml] transformers when an incompatble 'wt' was specified,
  the field value was lost if documentCache was not used.
"
lucene-solr,17639.json,9548481c8c301740067229d09af5db0f06dccb94,"@@ -1,32 +1,35 @@
-  private Map<String, Object> monitorZookeeper(String zkHostPort) throws SolrException {
+  protected Map<String, Object> monitorZookeeper(String zkHostPort) throws SolrException {
     Map<String, Object> obj = new HashMap<>();
     List<String> errors = new ArrayList<>();
     obj.put(""host"", zkHostPort);
     List<String> lines = getZkRawResponse(zkHostPort, ""ruok"");
+    validateZkRawResponse(lines, zkHostPort,""ruok"");
     boolean ok = ""imok"".equals(lines.get(0));
     obj.put(""ok"", ok);
     lines = getZkRawResponse(zkHostPort, ""mntr"");
+    validateZkRawResponse(lines, zkHostPort,""mntr"");
     for (String line : lines) {
       String[] parts = line.split(""\t"");
       if (parts.length >= 2) {
         obj.put(parts[0], parts[1]);
       } else {
-        String err = String.format(""Unexpected line in 'mntr' response from Zookeeper %s: %s"", zkHostPort, line);
+        String err = String.format(Locale.ENGLISH, ""Unexpected line in 'mntr' response from Zookeeper %s: %s"", zkHostPort, line);
         log.warn(err);
         errors.add(err);
       }
     }
     lines = getZkRawResponse(zkHostPort, ""conf"");
+    validateZkRawResponse(lines, zkHostPort,""conf"");
     for (String line : lines) {
       String[] parts = line.split(""="");
       if (parts.length >= 2) {
         obj.put(parts[0], parts[1]);
       } else if (!line.startsWith(""membership:"")) {
-        String err = String.format(""Unexpected line in 'conf' response from Zookeeper %s: %s"", zkHostPort, line);
+        String err = String.format(Locale.ENGLISH, ""Unexpected line in 'conf' response from Zookeeper %s: %s"", zkHostPort, line);
         log.warn(err);
         errors.add(err);
       }
     }
     obj.put(""errors"", errors);
     return obj;
   }
\ No newline at end of file
",NotBuggy,"Fix precommit
Remove errors from each host detail map
Display secureClientPort and server.1, server.2, server.3...
Added test for various failure responses and expected result from multiple nodes
"
lucene-solr,38367.json,0a70e721ce98b3c4ae10aadf9edcb312d4f57da4,"@@ -1,92 +1,103 @@
     private void initIter(Shape filter) {
       cellNumber = -1;
-      if (filter instanceof LevelledValue && ((LevelledValue)filter).getLevel() == 0)
+      if (filter instanceof LevelledValue && ((LevelledValue) filter).getLevel() == 0)
         filter = null;//world means everything -- no filter
       iterFilter = filter;
 
-      NRCell parent = getLVAtLevel(getLevel()-1);
+      NRCell parent = getLVAtLevel(getLevel() - 1);
 
       // Initialize iter* members.
 
       //no filter means all subcells
       if (filter == null) {
         iterFirstCellNumber = 0;
         iterFirstIsIntersects = false;
         iterLastCellNumber = getNumSubCells(parent) - 1;
         iterLastIsIntersects = false;
         return;
       }
 
       final LevelledValue minLV;
       final LevelledValue maxLV;
+      final int lastLevelInCommon;//between minLV & maxLV
       if (filter instanceof NRShape) {
         NRShape nrShape = (NRShape) iterFilter;
         minLV = nrShape.getMinLV();
         maxLV = nrShape.getMaxLV();
+        lastLevelInCommon = nrShape.getLastLevelInCommon();
       } else {
-        minLV = (LevelledValue)iterFilter;
+        minLV = (LevelledValue) iterFilter;
         maxLV = minLV;
+        lastLevelInCommon = minLV.getLevel();
       }
 
-      //fast path check when using same filter
-      if (iterFilter == parent.iterFilter) {
+      //fast path optimization that is usually true, but never first level
+      if (iterFilter == parent.iterFilter &&
+          (getLevel() <= lastLevelInCommon || parent.iterFirstCellNumber != parent.iterLastCellNumber)) {
+        //TODO benchmark if this optimization pays off. We avoid two comparePrefixLV calls.
         if (parent.iterFirstIsIntersects && parent.cellNumber == parent.iterFirstCellNumber
             && minLV.getLevel() >= getLevel()) {
           iterFirstCellNumber = minLV.getValAtLevel(getLevel());
           iterFirstIsIntersects = (minLV.getLevel() > getLevel());
         } else {
           iterFirstCellNumber = 0;
           iterFirstIsIntersects = false;
         }
         if (parent.iterLastIsIntersects && parent.cellNumber == parent.iterLastCellNumber
             && maxLV.getLevel() >= getLevel()) {
           iterLastCellNumber = maxLV.getValAtLevel(getLevel());
           iterLastIsIntersects = (maxLV.getLevel() > getLevel());
         } else {
           iterLastCellNumber = getNumSubCells(parent) - 1;
           iterLastIsIntersects = false;
         }
         if (iterFirstCellNumber == iterLastCellNumber) {
           if (iterLastIsIntersects)
             iterFirstIsIntersects = true;
           else if (iterFirstIsIntersects)
             iterLastIsIntersects = true;
         }
         return;
       }
 
-      //uncommon to get here, except for level 1 which always happens
+      //not common to get here, except for level 1 which always happens
 
       int startCmp = comparePrefixLV(minLV, parent);
       if (startCmp > 0) {//start comes after this cell
         iterFirstCellNumber = 0;
         iterFirstIsIntersects = false;
         iterLastCellNumber = -1;//so ends early (no cells)
         iterLastIsIntersects = false;
         return;
       }
       int endCmp = comparePrefixLV(maxLV, parent);//compare to end cell
       if (endCmp < 0) {//end comes before this cell
         iterFirstCellNumber = 0;
         iterFirstIsIntersects = false;
         iterLastCellNumber = -1;//so ends early (no cells)
         iterLastIsIntersects = false;
         return;
       }
       if (startCmp < 0 || minLV.getLevel() < getLevel()) {
         //start comes before...
         iterFirstCellNumber = 0;
         iterFirstIsIntersects = false;
       } else {
         iterFirstCellNumber = minLV.getValAtLevel(getLevel());
         iterFirstIsIntersects = (minLV.getLevel() > getLevel());
       }
       if (endCmp > 0 || maxLV.getLevel() < getLevel()) {
         //end comes after...
         iterLastCellNumber = getNumSubCells(parent) - 1;
         iterLastIsIntersects = false;
       } else {
         iterLastCellNumber = maxLV.getValAtLevel(getLevel());
         iterLastIsIntersects = (maxLV.getLevel() > getLevel());
       }
+      if (iterFirstCellNumber == iterLastCellNumber) {
+        if (iterLastIsIntersects)
+          iterFirstIsIntersects = true;
+        else if (iterFirstIsIntersects)
+          iterLastIsIntersects = true;
+      }
     }
\ No newline at end of file
",Buggy,"LUCENE-5648: (NumberRangePrefixTree) Bug-fix in initIter optimization. Re-index required.

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1602857 13f79535-47bb-0310-9956-ffa450edef68
"
lucene-solr,11525.json,1b3b9294cc99985db88c2ef9074f05e802c6b55b,"@@ -1,8 +1,8 @@
   public void collect(int doc) throws IOException {
     delegate.collect(doc);
-    lastDocId = doc;    
     numCollected++;  
-    if(numCollected==maxDocsToCollect) {
-      throw new EarlyTerminatingCollectorException(numCollected, lastDocId);
+    if(maxDocsToCollect <= numCollected) {
+      throw new EarlyTerminatingCollectorException
+        (numCollected, prevReaderCumulativeSize + (doc + 1));
     }
   }
\ No newline at end of file
",Buggy,"SOLR-5122: Fixed bug in spellcheck.collateMaxCollectDocs.  Eliminates risk of divide by zero, and makes estimated hit counts meaningful in non-optimized indexes.

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1514402 13f79535-47bb-0310-9956-ffa450edef68
"
lucene-solr,14422.json,4070bdd8d8b2095b406c404720e5f2c347596350,"@@ -1,4 +1,4 @@
       public void store(AtomicReference ctx) {
-        SolrRequestInfo me = threadLocal.get();
+        SolrRequestInfo me = SolrRequestInfo.getRequestInfo();
         if (me != null) ctx.set(me);
       }
\ No newline at end of file
",Buggy,"SOLR-8657: Fix SolrRequestInfo error logs if QuerySenderListener is being used
"
lucene-solr,14423.json,4070bdd8d8b2095b406c404720e5f2c347596350,"@@ -1,7 +1,7 @@
       public void set(AtomicReference ctx) {
         SolrRequestInfo me = (SolrRequestInfo) ctx.get();
         if (me != null) {
           ctx.set(null);
-          threadLocal.set(me);
+          SolrRequestInfo.setRequestInfo(me);
         }
       }
\ No newline at end of file
",Buggy,"SOLR-8657: Fix SolrRequestInfo error logs if QuerySenderListener is being used
"
lucene-solr,14425.json,4070bdd8d8b2095b406c404720e5f2c347596350,"@@ -1,23 +1,23 @@
   public static ExecutorUtil.InheritableThreadLocalProvider getInheritableThreadLocalProvider() {
     return new ExecutorUtil.InheritableThreadLocalProvider() {
       @Override
       public void store(AtomicReference ctx) {
-        SolrRequestInfo me = threadLocal.get();
+        SolrRequestInfo me = SolrRequestInfo.getRequestInfo();
         if (me != null) ctx.set(me);
       }
 
       @Override
       public void set(AtomicReference ctx) {
         SolrRequestInfo me = (SolrRequestInfo) ctx.get();
         if (me != null) {
           ctx.set(null);
-          threadLocal.set(me);
+          SolrRequestInfo.setRequestInfo(me);
         }
       }
 
       @Override
       public void clean(AtomicReference ctx) {
-        threadLocal.remove();
+        SolrRequestInfo.clearRequestInfo();
       }
     };
   }
\ No newline at end of file
",Buggy,"SOLR-8657: Fix SolrRequestInfo error logs if QuerySenderListener is being used
"
ant,3769.json,2ca342fb2a9191f8e22abfc8fee9aaab94ea8496,"@@ -1,6 +1,6 @@
     public void setServerLanguageCodeConfig(LanguageCode serverLanguageCode) {
-        if (serverLanguageCode != null && !serverLanguageCode.equals("""")) {
+        if (serverLanguageCode != null && !"""".equals(serverLanguageCode.getValue())) {
             this.serverLanguageCodeConfig = serverLanguageCode;
             configurationHasBeenSet();
         }
     }
\ No newline at end of file
",Buggy,"Fixed some obvious errors. (Formatter class is not thread safe, equals from string to another object).

git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@739572 13f79535-47bb-0310-9956-ffa450edef68
"
ant,3780.json,2ca342fb2a9191f8e22abfc8fee9aaab94ea8496,"@@ -1,6 +1,6 @@
     public void setTimestampGranularity(Granularity timestampGranularity) {
-        if (null == timestampGranularity || """".equals(timestampGranularity)) {
+        if (null == timestampGranularity || """".equals(timestampGranularity.getValue())) {
             return;
         }
         this.timestampGranularity = timestampGranularity;
     }
\ No newline at end of file
",Buggy,"Fixed some obvious errors. (Formatter class is not thread safe, equals from string to another object).

git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@739572 13f79535-47bb-0310-9956-ffa450edef68
"
lucene-solr,43949.json,b0db06bad568b7eedf528379a2fe5ac935992d56,"@@ -1,43 +1,45 @@
       public Scorer scorer(LeafReaderContext context) throws IOException {
         SortedNumericDocValues values = getValues(context.reader(), field);
         if (values == null) {
           return null;
         }
-        final NumericDocValues singleton = DocValues.unwrapSingleton(values);
+        final NumericDocValues singleton = null; // TODO: LUCENE-7649, re-consider optimization that broke SOLR-10013
+        // final NumericDocValues singleton = DocValues.unwrapSingleton(values);
         final TwoPhaseIterator iterator;
         if (singleton != null) {
+          assert false : ""imposible code -- or: someone re-enabled singleton optinization w/o reading the whole method"";
           iterator = new TwoPhaseIterator(singleton) {
             @Override
             public boolean matches() throws IOException {
               final long value = singleton.longValue();
               return value >= lowerValue && value <= upperValue;
             }
 
             @Override
             public float matchCost() {
               return 2; // 2 comparisons
             }
           };
         } else {
           iterator = new TwoPhaseIterator(values) {
             @Override
             public boolean matches() throws IOException {
               for (int i = 0, count = values.docValueCount(); i < count; ++i) {
                 final long value = values.nextValue();
                 if (value < lowerValue) {
                   continue;
                 }
                 // Values are sorted, so the first value that is >= lowerValue is our best candidate
                 return value <= upperValue;
               }
               return false; // all values were < lowerValue
             }
 
             @Override
             public float matchCost() {
               return 2; // 2 comparisons
             }
           };
         }
         return new ConstantScoreScorer(this, score(), iterator);
       }
\ No newline at end of file
",Buggy,"SOLR-10013: Fix DV range query bug introduced by LUCENE-7643 by disabling and optimization (LUCENE-7649 to track re-enabling or removing completely)
"
lucene-solr,20864.json,568f6a398a8be76ec0261125f625c5d28942ea4a,"@@ -1,3 +1,3 @@
-  public static ConfigSolr fromSolrHome(String solrHome) {
-    return fromFile(new File(solrHome, SOLR_XML_FILE));
+  public static ConfigSolr fromSolrHome(SolrResourceLoader loader, String solrHome) {
+    return fromFile(loader, new File(solrHome, SOLR_XML_FILE));
   }
\ No newline at end of file
",Buggy,"SOLR-5009: Don't create multiple SolrResourceLoaders for same Solr home, wasting resources and slowing down startup. This fixes the problem where the loader was not correctly closed, making tests fail on Windows.

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1500156 13f79535-47bb-0310-9956-ffa450edef68
"
lucene-solr,20441.json,568f6a398a8be76ec0261125f625c5d28942ea4a,"@@ -1,5 +1,6 @@
   public static CoreContainer createAndLoad(String solrHome, File configFile) {
-    CoreContainer cc = new CoreContainer(new SolrResourceLoader(solrHome), ConfigSolr.fromFile(configFile));
+    SolrResourceLoader loader = new SolrResourceLoader(solrHome);
+    CoreContainer cc = new CoreContainer(loader, ConfigSolr.fromFile(loader, configFile));
     cc.load();
     return cc;
   }
\ No newline at end of file
",Buggy,"SOLR-5009: Don't create multiple SolrResourceLoaders for same Solr home, wasting resources and slowing down startup. This fixes the problem where the loader was not correctly closed, making tests fail on Windows.

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1500156 13f79535-47bb-0310-9956-ffa450edef68
"
lucene-solr,48003.json,5fa6cd3fec996cca528327c6a13815d96e34cf9c,"@@ -1,48 +1,48 @@
   public static void compress(byte[] bytes, int off, int len, DataOutput out, HashTable ht) throws IOException {
 
     final int base = off;
     final int end = off + len;
 
     int anchor = off++;
 
     if (len > LAST_LITERALS + MIN_MATCH) {
 
       final int limit = end - LAST_LITERALS;
       final int matchLimit = limit - MIN_MATCH;
       ht.reset(len);
       final int hashLog = ht.hashLog;
       final PackedInts.Mutable hashTable = ht.hashTable;
 
       main:
-      while (off < limit) {
+      while (off <= limit) {
         // find a match
         int ref;
         while (true) {
           if (off >= matchLimit) {
             break main;
           }
           final int v = readInt(bytes, off);
           final int h = hash(v, hashLog);
           ref = base + (int) hashTable.get(h);
           assert PackedInts.bitsRequired(off - base) <= hashTable.getBitsPerValue();
           hashTable.set(h, off - base);
           if (off - ref < MAX_DISTANCE && readInt(bytes, ref) == v) {
             break;
           }
           ++off;
         }
 
         // compute match length
         final int matchLen = MIN_MATCH + commonBytes(bytes, ref + MIN_MATCH, off + MIN_MATCH, limit);
 
         encodeSequence(bytes, anchor, ref, off, matchLen, out);
         off += matchLen;
         anchor = off;
       }
     }
 
     // last literals
     final int literalLen = end - anchor;
     assert literalLen >= LAST_LITERALS || literalLen == len;
     encodeLastLiterals(bytes, anchor, end - anchor, out);
   }
\ No newline at end of file
",Buggy,"Fix compression bug on highly compressible inputs with LZ4.compressHC.


git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1520060 13f79535-47bb-0310-9956-ffa450edef68
"
lucene-solr,48001.json,5fa6cd3fec996cca528327c6a13815d96e34cf9c,"@@ -1,10 +1,10 @@
     private void addHash(byte[] bytes, int off) {
       final int v = readInt(bytes, off);
       final int h = hashHC(v);
       int delta = off - hashTable[h];
       if (delta >= MAX_DISTANCE) {
         delta = MAX_DISTANCE - 1;
       }
       chainTable[off & MASK] = (short) delta;
-      hashTable[h] = off - base;
+      hashTable[h] = off;
     }
\ No newline at end of file
",Buggy,"Fix compression bug on highly compressible inputs with LZ4.compressHC.


git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1520060 13f79535-47bb-0310-9956-ffa450edef68
"
lucene-solr,41767.json,f5fdea8ddaa3002dc89e624e608582a6345f7e1d,"@@ -1,3 +1 @@
-          public int docID() {
-            return doc;
-          }
\ No newline at end of file
+    public int docID() { return doc; }
\ No newline at end of file
",NotBuggy,"LUCENE-3102: first cut - some refactoring, bug fixes, add test, move to core (trunk)

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1103872 13f79535-47bb-0310-9956-ffa450edef68
"
lucene-solr,41766.json,f5fdea8ddaa3002dc89e624e608582a6345f7e1d,"@@ -1,3 +1 @@
-          public float score() {
-            return score;
-          }
\ No newline at end of file
+    public float score() { return score; }
\ No newline at end of file
",NotBuggy,"LUCENE-3102: first cut - some refactoring, bug fixes, add test, move to core (trunk)

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1103872 13f79535-47bb-0310-9956-ffa450edef68
"
lucene-solr,41782.json,f5fdea8ddaa3002dc89e624e608582a6345f7e1d,"@@ -1,52 +1,60 @@
   public void collect(int doc) throws IOException {
 
     if (curDocs == null) {
       // Cache was too large
-      if (curScores != null) {
-        score = scorer.score();
+      if (cacheScores) {
+        cachedScorer.score = scorer.score();
       }
-      this.doc = doc;
+      cachedScorer.doc = doc;
       other.collect(doc);
       return;
     }
 
+    // Allocate a bigger array or abort caching
     if (upto == curDocs.length) {
       base += upto;
-      final int nextLength;
-      // Max out at 512K arrays:
-      if (curDocs.length < 524288) {
-        nextLength = 8*curDocs.length;
-      } else {
-        nextLength = curDocs.length;
+      
+      // Compute next array length - don't allocate too big arrays
+      int nextLength = 8*curDocs.length;
+      if (nextLength > MAX_ARRAY_SIZE) {
+        nextLength = MAX_ARRAY_SIZE;
       }
 
       if (base + nextLength > maxDocsToCache) {
-        // Too many docs to collect -- clear cache
-        curDocs = null;
-        if (curScores != null) {
-          score = scorer.score();
+        // try to allocate a smaller array
+        nextLength = maxDocsToCache - base;
+        if (nextLength <= 0) {
+          // Too many docs to collect -- clear cache
+          curDocs = null;
+          curScores = null;
+          cachedSegs.clear();
+          cachedDocs.clear();
+          cachedScores.clear();
+          if (cacheScores) {
+            cachedScorer.score = scorer.score();
+          }
+          cachedScorer.doc = doc;
+          other.collect(doc);
+          return;
         }
-        this.doc = doc;
-        other.collect(doc);
-        cachedDocs.clear();
-        cachedScores.clear();
-        return;
       }
+      
       curDocs = new int[nextLength];
       cachedDocs.add(curDocs);
-      if (curScores != null) {
+      if (cacheScores) {
         curScores = new float[nextLength];
         cachedScores.add(curScores);
       }
       upto = 0;
     }
+    
     curDocs[upto] = doc;
     // TODO: maybe specialize private subclass so we don't
     // null check per collect...
-    if (curScores != null) {
-      score = curScores[upto] = scorer.score();
+    if (cacheScores) {
+      cachedScorer.score = curScores[upto] = scorer.score();
     }
     upto++;
-    this.doc = doc;
+    cachedScorer.doc = doc;
     other.collect(doc);
   }
\ No newline at end of file
",Buggy,"LUCENE-3102: first cut - some refactoring, bug fixes, add test, move to core (trunk)

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1103872 13f79535-47bb-0310-9956-ffa450edef68
"
lucene-solr,41774.json,f5fdea8ddaa3002dc89e624e608582a6345f7e1d,"@@ -1,40 +1,42 @@
   public void replay(Collector other) throws IOException {
     if (!isCached()) {
       throw new IllegalStateException(""cannot replay: cache was cleared because too much RAM was required"");
     }
+    
+    if (!other.acceptsDocsOutOfOrder() && this.other.acceptsDocsOutOfOrder()) {
+      throw new IllegalArgumentException(
+          ""cannot replay: given collector does not support ""
+              + ""out-of-order collection, while the wrapped collector does. ""
+              + ""Therefore cached documents may be out-of-order."");
+    }
+
     //System.out.println(""CC: replay totHits="" + (upto + base));
     if (lastReaderContext != null) {
       cachedSegs.add(new SegStart(lastReaderContext, base+upto));
       lastReaderContext = null;
     }
-    final int uptoSav = upto;
-    final int baseSav = base;
-    try {
-      upto = 0;
-      base = 0;
-      int chunkUpto = 0;
-      other.setScorer(cachedScorer);
-      curDocs = EMPTY_INT_ARRAY;
-      for(SegStart seg : cachedSegs) {
-        other.setNextReader(seg.readerContext);
-        while(base+upto < seg.end) {
-          if (upto == curDocs.length) {
-            base += curDocs.length;
-            curDocs = cachedDocs.get(chunkUpto);
-            if (curScores != null) {
-              curScores = cachedScores.get(chunkUpto);
-            }
-            chunkUpto++;
-            upto = 0;
+    
+    int curupto = 0;
+    int curbase = 0;
+    int chunkUpto = 0;
+    other.setScorer(cachedScorer);
+    curDocs = EMPTY_INT_ARRAY;
+    for(SegStart seg : cachedSegs) {
+      other.setNextReader(seg.readerContext);
+      while(curbase+curupto < seg.end) {
+        if (curupto == curDocs.length) {
+          curbase += curDocs.length;
+          curDocs = cachedDocs.get(chunkUpto);
+          if (cacheScores) {
+            curScores = cachedScores.get(chunkUpto);
           }
-          if (curScores != null) {
-            score = curScores[upto];
-          }
-          other.collect(curDocs[upto++]);
+          chunkUpto++;
+          curupto = 0;
         }
+        if (cacheScores) {
+          cachedScorer.score = curScores[curupto];
+        }
+        other.collect(curDocs[curupto++]);
       }
-    } finally {
-      upto = uptoSav;
-      base = baseSav;
     }
   }
\ No newline at end of file
",Buggy,"LUCENE-3102: first cut - some refactoring, bug fixes, add test, move to core (trunk)

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1103872 13f79535-47bb-0310-9956-ffa450edef68
"
lucene-solr,47123.json,52d1ab79192a331e1f3fc5f5a202d6a4c5a633b2,"@@ -1,23 +1,27 @@
-  ByteBuffer[] map(FileChannel fc, long offset, long length) throws IOException {
+  final ByteBuffer[] map(String resourceDescription, FileChannel fc, long offset, long length) throws IOException {
     if ((length >>> chunkSizePower) >= Integer.MAX_VALUE)
-      throw new IllegalArgumentException(""RandomAccessFile too big for chunk size: "" + fc.toString());
+      throw new IllegalArgumentException(""RandomAccessFile too big for chunk size: "" + resourceDescription);
     
     final long chunkSize = 1L << chunkSizePower;
     
     // we always allocate one more buffer, the last one may be a 0 byte one
     final int nrBuffers = (int) (length >>> chunkSizePower) + 1;
     
     ByteBuffer buffers[] = new ByteBuffer[nrBuffers];
     
     long bufferStart = 0L;
     for (int bufNr = 0; bufNr < nrBuffers; bufNr++) { 
       int bufSize = (int) ( (length > (bufferStart + chunkSize))
           ? chunkSize
               : (length - bufferStart)
           );
-      buffers[bufNr] = fc.map(MapMode.READ_ONLY, offset + bufferStart, bufSize);
+      try {
+        buffers[bufNr] = fc.map(MapMode.READ_ONLY, offset + bufferStart, bufSize);
+      } catch (IOException ioe) {
+        throw convertMapFailedIOException(ioe, resourceDescription, bufSize);
+      }
       bufferStart += bufSize;
     }
     
     return buffers;
   }
\ No newline at end of file
",NotBuggy,"LUCENE-5673: MMapDirectory: Work around a ""bug"" in the JDK that throws a confusing OutOfMemoryError wrapped inside IOException if the FileChannel  mapping failed because of lack of virtual address space. The IOException is rethrown with more useful information about the problem, omitting the incorrect OutOfMemoryError

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1595213 13f79535-47bb-0310-9956-ffa450edef68
"
lucene-solr,3974.json,277dd050869d458a370fb7adb837a035e091b89f,"@@ -1,31 +1,32 @@
-    private MapWriter serializeToV2Format(SolrParams params, String[] list) {
+    private MapWriter serializeToV2Format(SolrParams paramsV1, String[] list) {
       return ew -> ew.put(meta.commandName, (MapWriter) ew1 -> {
-        Iterator<String> iter = params.getParameterNamesIterator();
+        Iterator<String> iter = paramsV1.getParameterNamesIterator();
         Map<String, Map<String, String>> subProperties = null;
         while (iter.hasNext()) {
           String key = iter.next();
           if (CoreAdminParams.ACTION.equals(key)) continue;
           Object substitute = meta.getReverseParamSubstitute(key);
           int idx = template.variables.indexOf(substitute);
           if (idx > -1) {
-            String val = params.get(String.valueOf(substitute));
+            String val = paramsV1.get(key);
             if (val == null) throw new RuntimeException(""null value is not valid for "" + key);
             list[idx] = val;
             continue;
           }
           if (substitute instanceof Pair) {//this is a nested object
+            @SuppressWarnings(""unchecked"")
             Pair<String, String> p = (Pair<String, String>) substitute;
             if (subProperties == null) subProperties = new HashMap<>();
-            subProperties.computeIfAbsent(p.first(), s -> new HashMap<>()).put(p.second(), params.get(key));
+            subProperties.computeIfAbsent(p.first(), s -> new HashMap<>()).put(p.second(), paramsV1.get(key));
           } else {
-            Object val = params.get(key);
+            Object val = paramsV1.get(key);
             ew1.put(substitute.toString(), val);
           }
         }
         if (subProperties != null) {
           for (Map.Entry<String, Map<String, String>> e : subProperties.entrySet()) {
             ew1.put(e.getKey(), e.getValue());
           }
         }
       });
     }
\ No newline at end of file
",Buggy,"SOLR-12061: Fix substitution bug in API V1 to V2 migration
"
lucene-solr,3973.json,277dd050869d458a370fb7adb837a035e091b89f,"@@ -1,12 +1,12 @@
-    public V2Request.Builder convert(SolrParams params) {
+    public V2Request.Builder convert(SolrParams paramsV1) {
       String[] list = new String[template.variables.size()];
-      MapWriter data = serializeToV2Format(params, list);
+      MapWriter data = serializeToV2Format(paramsV1, list);
       Map o = data.toMap(new LinkedHashMap<>());
       return new V2Request.Builder(template.apply(s -> {
         int idx = template.variables.indexOf(s);
         return list[idx];
       }))
           .withMethod(meta.getHttpMethod())
           .withPayload(o);
 
     }
\ No newline at end of file
",NotBuggy,"SOLR-12061: Fix substitution bug in API V1 to V2 migration
"
lucene-solr,3975.json,277dd050869d458a370fb7adb837a035e091b89f,"@@ -1,11 +1,11 @@
-  public static V2Request.Builder convert(CollectionAdminRequest request) {
+  public static V2Request.Builder convert(CollectionAdminRequest<?> request) {
     ActionInfo info = mapping.get(request.action);
     if (info == null) throw new RuntimeException(""Unsupported action :"" + request.action);
 
     if (info.meta.getHttpMethod() == SolrRequest.METHOD.POST) {
       if (info.path == null) info.setPath();
       return info.convert(request.getParams());
     }
 
     return null;
   }
\ No newline at end of file
",Buggy,"SOLR-12061: Fix substitution bug in API V1 to V2 migration
"
lucene-solr,30452.json,ef8126e5eab7aec9c8775c2e08bd6c2bb1ef690f,"@@ -1,13 +1,10 @@
   public void setRangeValues(InetAddress min, InetAddress max) {
-    if (StringHelper.compare(BYTES, min.getAddress(), 0, max.getAddress(), 0) > 0) {
-      throw new IllegalArgumentException(""min value cannot be greater than max value for range field (name="" + name + "")"");
-    }
     final byte[] bytes;
     if (fieldsData == null) {
       bytes = new byte[BYTES*2];
       fieldsData = new BytesRef(bytes);
     } else {
       bytes = ((BytesRef)fieldsData).bytes;
     }
     encode(min, max, bytes);
   }
\ No newline at end of file
",Buggy,"LUCENE-7738: Fix min/max verification bug in InetAddressRange to correctly compare IPv4 and IPv6. Update tests.
"
lucene-solr,30453.json,ef8126e5eab7aec9c8775c2e08bd6c2bb1ef690f,"@@ -1,4 +1,11 @@
   private static void encode(final InetAddress min, final InetAddress max, final byte[] bytes) {
-    System.arraycopy(InetAddressPoint.encode(min), 0, bytes, 0, BYTES);
-    System.arraycopy(InetAddressPoint.encode(max), 0, bytes, BYTES, BYTES);
+    // encode min and max value (consistent w/ InetAddressPoint encoding)
+    final byte[] minEncoded = InetAddressPoint.encode(min);
+    final byte[] maxEncoded = InetAddressPoint.encode(max);
+    // ensure min is lt max
+    if (StringHelper.compare(BYTES, minEncoded, 0, maxEncoded, 0) > 0) {
+      throw new IllegalArgumentException(""min value cannot be greater than max value for InetAddressRange field"");
+    }
+    System.arraycopy(minEncoded, 0, bytes, 0, BYTES);
+    System.arraycopy(maxEncoded, 0, bytes, BYTES, BYTES);
   }
\ No newline at end of file
",Buggy,"LUCENE-7738: Fix min/max verification bug in InetAddressRange to correctly compare IPv4 and IPv6. Update tests.
"
lucene-solr,26824.json,d58041803c7be0eaf35b6381762c846df7e58116,"@@ -1,14 +1,17 @@
   public void inform(ResourceLoader loader) {
     String stopTagFiles = args.get(""tags"");
     enablePositionIncrements = getBoolean(""enablePositionIncrements"", false);
+    stopTags = null;
     try {
       CharArraySet cas = getWordSet(loader, stopTagFiles, false);
-      stopTags = new HashSet<String>();
-      for (Object element : cas) {
-        char chars[] = (char[]) element;
-        stopTags.add(new String(chars));
+      if (cas != null) {
+        stopTags = new HashSet<String>();
+        for (Object element : cas) {
+          char chars[] = (char[]) element;
+          stopTags.add(new String(chars));
+        }
       }
     } catch (IOException e) {
       throw new InitializationException(""IOException thrown while loading tags"", e);
     }
   }
\ No newline at end of file
",Buggy,"LUCENE-2510: fix more factory arg bugs found by TestFactories

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/branches/lucene2510@1365426 13f79535-47bb-0310-9956-ffa450edef68
"
lucene-solr,26825.json,d58041803c7be0eaf35b6381762c846df7e58116,"@@ -1,3 +1,4 @@
   public TokenStream create(TokenStream stream) {
-    return new JapanesePartOfSpeechStopFilter(enablePositionIncrements, stream, stopTags);
+    // if stoptags is null, it means the file is empty
+    return stopTags == null ? stream : new JapanesePartOfSpeechStopFilter(enablePositionIncrements, stream, stopTags);
   }
\ No newline at end of file
",Buggy,"LUCENE-2510: fix more factory arg bugs found by TestFactories

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/branches/lucene2510@1365426 13f79535-47bb-0310-9956-ffa450edef68
"
lucene-solr,46955.json,3b35de6599b12e08e5edd7549cd64c947cdb5a15,"@@ -1,12 +1,15 @@
                     public Number next() {
                       if (++curDoc >= maxDoc) {
                         throw new NoSuchElementException(""no more documents to return values for"");
                       }
                       Long updatedValue = updates.get(curDoc);
                       if (updatedValue == null) {
-                        updatedValue = Long.valueOf(currentValues.get(curDoc));
+                        // only read the current value if the document had a value before
+                        if (currentValues != null && docsWithField.get(curDoc)) {
+                          updatedValue = currentValues.get(curDoc);
+                        }
                       } else if (updatedValue == NumericUpdate.MISSING) {
                         updatedValue = null;
                       }
                       return updatedValue;
                     }
\ No newline at end of file
",Buggy,"LUCENE-5189: fix updates-order and docsWithField bugs

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1528837 13f79535-47bb-0310-9956-ffa450edef68
"
lucene-solr,48196.json,ae4723e0b504da902656aedac8ea27cd98e4cf6b,"@@ -1,28 +1,27 @@
   public static IntsRef getSingleton(Automaton a) {
     if (a.isDeterministic() == false) {
       throw new IllegalArgumentException(""input automaton must be deterministic"");
     }
     IntsRefBuilder builder = new IntsRefBuilder();
     HashSet<Integer> visited = new HashSet<>();
     int s = 0;
-    boolean done;
     Transition t = new Transition();
     while (true) {
       visited.add(s);
       if (a.isAccept(s) == false) {
         if (a.getNumTransitions(s) == 1) {
           a.getTransition(s, 0, t);
           if (t.min == t.max && !visited.contains(t.dest)) {
             builder.append(t.min);
             s = t.dest;
             continue;
           }
         }
       } else if (a.getNumTransitions(s) == 0) {
         return builder.get();
       }
 
       // Automaton accepts more than one string:
       return null;
     }
   }
\ No newline at end of file
",NotBuggy,"LUCENE-6365: fix buggy Operations.topoSort; add test

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1689079 13f79535-47bb-0310-9956-ffa450edef68
"
lucene-solr,48202.json,ae4723e0b504da902656aedac8ea27cd98e4cf6b,"@@ -1,26 +1,25 @@
   public static int[] topoSortStates(Automaton a) {
+    if (a.getNumStates() == 0) {
+      return new int[0];
+    }
     int numStates = a.getNumStates();
     int[] states = new int[numStates];
     final BitSet visited = new BitSet(numStates);
-    final LinkedList<Integer> worklist = new LinkedList<>();
-    worklist.add(0);
-    visited.set(0);
-    int upto = 0;
-    states[upto] = 0;
-    upto++;
-    Transition t = new Transition();
-    while (worklist.size() > 0) {
-      int s = worklist.removeFirst();
-      int count = a.initTransition(s, t);
-      for (int i=0;i<count;i++) {
-        a.getNextTransition(t);
-        if (!visited.get(t.dest)) {
-          visited.set(t.dest);
-          worklist.add(t.dest);
-          states[upto++] = t.dest;
-        }
-      }
+    int upto = topoSortStatesRecurse(a, visited, states, 0, 0);
+
+    if (upto < states.length) {
+      // There were dead states
+      int[] newStates = new int[upto];
+      System.arraycopy(states, 0, newStates, 0, upto);
+      states = newStates;
+    }
+
+    // Reverse the order:
+    for(int i=0;i<states.length/2;i++) {
+      int s = states[i];
+      states[i] = states[states.length-1-i];
+      states[states.length-1-i] = s;
     }
 
     return states;
   }
\ No newline at end of file
",Buggy,"LUCENE-6365: fix buggy Operations.topoSort; add test

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1689079 13f79535-47bb-0310-9956-ffa450edef68
"
lucene-solr,49563.json,e48f99c36cb1a5a2cca505266f886fa52fd2be5f,"@@ -1,8 +1,8 @@
   public static ReaderIterator getReaderIterator(DataInput in, int mem) throws IOException {
-    final int version = CodecUtil.checkHeader(in, CODEC_NAME, VERSION_START, VERSION_START);
+    final int version = CodecUtil.checkHeader(in, CODEC_NAME, VERSION_START, VERSION_CURRENT);
     final int bitsPerValue = in.readVInt();
     assert bitsPerValue > 0 && bitsPerValue <= 64: ""bitsPerValue="" + bitsPerValue;
     final int valueCount = in.readVInt();
     final Format format = Format.byId(in.readVInt());
     return getReaderIteratorNoHeader(in, format, version, valueCount, bitsPerValue, mem);
   }
\ No newline at end of file
",Buggy,"Fix error-prone header check.


git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1359861 13f79535-47bb-0310-9956-ffa450edef68
"
lucene-solr,13424.json,cc344dc6bd9e71ed7848618630b51f4633e1dd50,"@@ -1,37 +1,38 @@
   public SlotAcc createSlotAcc(FacetContext fcontext, int numDocs, int numSlots) throws IOException {
     ValueSource vs = getArg();
 
     SchemaField sf = null;
 
     if (vs instanceof FieldNameValueSource) {
       String field = ((FieldNameValueSource)vs).getFieldName();
       sf = fcontext.qcontext.searcher().getSchema().getField(field);
 
       if (sf.multiValued() || sf.getType().multiValuedFieldCache()) {
         vs = null;
         throw new SolrException(SolrException.ErrorCode.BAD_REQUEST, ""min/max aggregations can't be used on multi-valued field "" + field);
       } else {
         vs = sf.getType().getValueSource(sf, null);
       }
     }
 
     if (vs instanceof StrFieldSource) {
       return new SingleValuedOrdAcc(fcontext, sf, numSlots);
     }
 
     // Since functions don't currently have types, we rely on the type of the field
     if (sf != null && sf.getType().getNumberType() != null) {
       switch (sf.getType().getNumberType()) {
         case FLOAT:
         case DOUBLE:
           return new DFuncAcc(vs, fcontext, numSlots);
         case INTEGER:
         case LONG:
-        case DATE:
           return new LFuncAcc(vs, fcontext, numSlots);
+        case DATE:
+          return new DateFuncAcc(vs, fcontext, numSlots);
       }
     }
 
     // numeric functions
     return new DFuncAcc(vs, fcontext, numSlots);
   }
\ No newline at end of file
",NotBuggy,"SOLR-11316: date support for min/max, fix missing bug for int/long fields
"
lucene-solr,13439.json,cc344dc6bd9e71ed7848618630b51f4633e1dd50,"@@ -1,8 +1,3 @@
     public Object getValue(int slot) {
-      long val = result[slot];
-      if (val == 0 && exists.get(slot)) {
-        return null;
-      } else {
-        return val;
-      }
+      return result[slot] == MISSING ? null : new Date(result[slot]);
     }
\ No newline at end of file
",Buggy,"SOLR-11316: date support for min/max, fix missing bug for int/long fields
"
lucene-solr,17606.json,481a1f859d0e9c844113c7693424c6aca1fa5245,"@@ -1,54 +1,54 @@
   public void checkSystemCollection() {
     if (cloudManager != null) {
       try {
         if (cloudManager.isClosed() || Thread.interrupted()) {
           factory.setPersistent(false);
           return;
         }
         ClusterState clusterState = cloudManager.getClusterStateProvider().getClusterState();
         DocCollection systemColl = clusterState.getCollectionOrNull(CollectionAdminParams.SYSTEM_COLL);
         if (systemColl == null) {
           if (logMissingCollection) {
-            log.warn(""Missing "" + CollectionAdminParams.SYSTEM_COLL + "", keeping metrics history in memory"");
+            log.info(""No "" + CollectionAdminParams.SYSTEM_COLL + "" collection, keeping metrics history in memory."");
             logMissingCollection = false;
           }
           factory.setPersistent(false);
           return;
         } else {
           boolean ready = false;
           for (Replica r : systemColl.getReplicas()) {
             if (r.isActive(clusterState.getLiveNodes())) {
               ready = true;
               break;
             }
           }
           if (!ready) {
-            log.debug(CollectionAdminParams.SYSTEM_COLL + "" not ready yet, keeping metrics history in memory"");
+            log.debug(CollectionAdminParams.SYSTEM_COLL + ""collection not ready yet, keeping metrics history in memory"");
             factory.setPersistent(false);
             return;
           }
         }
       } catch (Exception e) {
         if (logMissingCollection) {
           log.warn(""Error getting cluster state, keeping metrics history in memory"", e);
         }
         logMissingCollection = false;
         factory.setPersistent(false);
         return;
       }
       logMissingCollection = true;
       factory.setPersistent(true);
     } else {
       try {
         solrClient.query(CollectionAdminParams.SYSTEM_COLL, new SolrQuery(CommonParams.Q, ""*:*"", CommonParams.ROWS, ""0""));
         factory.setPersistent(true);
         logMissingCollection = true;
       } catch (Exception e) {
         if (logMissingCollection) {
-          log.warn(""Error querying .system collection, keeping metrics history in memory"", e);
+          log.info(""No "" + CollectionAdminParams.SYSTEM_COLL + "" collection, keeping metrics history in memory."");
         }
         logMissingCollection = false;
         factory.setPersistent(false);
       }
     }
   }
\ No newline at end of file
",NotBuggy,"SOLR-11779: Reduce logging, fix index size conversion bug.
"
lucene-solr,17615.json,481a1f859d0e9c844113c7693424c6aca1fa5245,"@@ -1,149 +1,145 @@
   private void collectGlobalMetrics() {
     if (!amIOverseerLeader()) {
       return;
     }
     Set<String> nodes = new HashSet<>(cloudManager.getClusterStateProvider().getLiveNodes());
     NodeStateProvider nodeStateProvider = cloudManager.getNodeStateProvider();
     Set<String> collTags = new HashSet<>();
     collTags.addAll(counters.get(Group.core.toString()));
     collTags.addAll(gauges.get(Group.core.toString()));
 
     Set<String> nodeTags = new HashSet<>();
     String nodePrefix = ""metrics:"" + SolrMetricManager.getRegistryName(Group.node) + "":"";
     counters.get(Group.node.toString()).forEach(name -> {
       nodeTags.add(nodePrefix + name);
     });
     gauges.get(Group.node.toString()).forEach(name -> {
       nodeTags.add(nodePrefix + name);
     });
     String jvmPrefix = ""metrics:"" + SolrMetricManager.getRegistryName(Group.jvm) + "":"";
     counters.get(Group.jvm.toString()).forEach(name -> {
       nodeTags.add(jvmPrefix + name);
     });
     gauges.get(Group.jvm.toString()).forEach(name -> {
       nodeTags.add(jvmPrefix + name);
     });
 
     // per-registry totals
     // XXX at the moment the type of metrics that we collect allows
     // adding all partial values. At some point it may be necessary to implement
     // other aggregation functions.
     // group : registry : name : value
     Map<Group, Map<String, Map<String, Number>>> totals = new HashMap<>();
 
     // collect and aggregate per-collection totals
     for (String node : nodes) {
       if (cloudManager.isClosed() || Thread.interrupted()) {
         return;
       }
       // add core-level stats
       Map<String, Map<String, List<ReplicaInfo>>> infos = nodeStateProvider.getReplicaInfo(node, collTags);
       infos.forEach((coll, shards) -> {
         shards.forEach((sh, replicas) -> {
           String registry = SolrMetricManager.getRegistryName(Group.collection, coll);
           Map<String, Number> perReg = totals
               .computeIfAbsent(Group.collection, g -> new HashMap<>())
               .computeIfAbsent(registry, r -> new HashMap<>());
           replicas.forEach(ri -> {
             collTags.forEach(tag -> {
               double value = ((Number)ri.getVariable(tag, 0.0)).doubleValue();
-              // TODO: fix this when Suggestion.Condition.DISK_IDX uses proper conversion
-              if (tag.contains(Suggestion.coreidxsize)) {
-                value = value * 1024.0 * 1024.0 * 1024.0;
-              }
               DoubleAdder adder = (DoubleAdder)perReg.computeIfAbsent(tag, t -> new DoubleAdder());
               adder.add(value);
             });
           });
         });
       });
       // add node-level stats
       Map<String, Object> nodeValues = nodeStateProvider.getNodeValues(node, nodeTags);
       for (Group g : Arrays.asList(Group.node, Group.jvm)) {
         String registry = SolrMetricManager.getRegistryName(g);
         Map<String, Number> perReg = totals
             .computeIfAbsent(g, gr -> new HashMap<>())
             .computeIfAbsent(registry, r -> new HashMap<>());
         Set<String> names = new HashSet<>();
         names.addAll(counters.get(g.toString()));
         names.addAll(gauges.get(g.toString()));
         names.forEach(name -> {
           String tag = ""metrics:"" + registry + "":"" + name;
           double value = ((Number)nodeValues.getOrDefault(tag, 0.0)).doubleValue();
           DoubleAdder adder = (DoubleAdder)perReg.computeIfAbsent(name, t -> new DoubleAdder());
           adder.add(value);
         });
       }
     }
 
     // add numNodes
     String nodeReg = SolrMetricManager.getRegistryName(Group.node);
     Map<String, Number> perNodeReg = totals
         .computeIfAbsent(Group.node, gr -> new HashMap<>())
         .computeIfAbsent(nodeReg, r -> new HashMap<>());
     perNodeReg.put(NUM_NODES_KEY, nodes.size());
 
     // add some global collection-level stats
     try {
       ClusterState state = cloudManager.getClusterStateProvider().getClusterState();
       state.forEachCollection(coll -> {
         String registry = SolrMetricManager.getRegistryName(Group.collection, coll.getName());
         Map<String, Number> perReg = totals
             .computeIfAbsent(Group.collection, g -> new HashMap<>())
             .computeIfAbsent(registry, r -> new HashMap<>());
         Collection<Slice> slices = coll.getActiveSlices();
         perReg.put(NUM_SHARDS_KEY, slices.size());
         DoubleAdder numActiveReplicas = new DoubleAdder();
         slices.forEach(s -> {
           s.forEach(r -> {
             if (r.isActive(state.getLiveNodes())) {
               numActiveReplicas.add(1.0);
             }
           });
         });
         perReg.put(NUM_REPLICAS_KEY, numActiveReplicas);
       });
     } catch (IOException e) {
       log.warn(""Exception getting cluster state"", e);
     }
 
     // now update the db-s
     totals.forEach((group, perGroup) -> {
       perGroup.forEach((reg, perReg) -> {
         RrdDb db = getOrCreateDb(reg, group);
         if (db == null) {
           return;
         }
         try {
           // set the timestamp
           Sample s = db.createSample(TimeUnit.SECONDS.convert(timeSource.getEpochTimeNs(), TimeUnit.NANOSECONDS));
           AtomicBoolean dirty = new AtomicBoolean(false);
           List<Group> groups = new ArrayList<>();
           groups.add(group);
           if (group == Group.collection) {
             groups.add(Group.core);
           }
           for (Group g : groups) {
             counters.get(g.toString()).forEach(c -> {
               Number val = perReg.get(c);
               if (val != null) {
                 dirty.set(true);
                 s.setValue(c, val.doubleValue());
               }
             });
             gauges.get(g.toString()).forEach(c -> {
               Number val = perReg.get(c);
               if (val != null) {
                 dirty.set(true);
                 s.setValue(c, val.doubleValue());
               }
             });
           }
           if (dirty.get()) {
             s.update();
           }
         } catch (Exception e) {
         }
       });
     });
   }
\ No newline at end of file
",Buggy,"SOLR-11779: Reduce logging, fix index size conversion bug.
"
lucene-solr,50428.json,ceb4f768bf5b71a91872f9ecdc5ebed4d0262903,"@@ -1,22 +1,23 @@
   private GeoPoint[] findAdjoiningPoints(final Plane plane, final GeoPoint pointOnPlane, final Plane envelopePlane) {
     // Compute a normalized perpendicular vector
     final Vector perpendicular = new Vector(plane, pointOnPlane);
     double distanceFactor = 0.0;
     for (int i = 0; i < MAX_ITERATIONS; i++) {
       distanceFactor += DELTA_DISTANCE;
       // Compute two new points along this vector from the original
       final GeoPoint pointA = planetModel.createSurfacePoint(pointOnPlane.x + perpendicular.x * distanceFactor,
         pointOnPlane.y + perpendicular.y * distanceFactor,
         pointOnPlane.z + perpendicular.z * distanceFactor);
       final GeoPoint pointB = planetModel.createSurfacePoint(pointOnPlane.x - perpendicular.x * distanceFactor,
         pointOnPlane.y - perpendicular.y * distanceFactor,
         pointOnPlane.z - perpendicular.z * distanceFactor);
       if (Math.abs(envelopePlane.evaluate(pointA)) > OFF_PLANE_AMOUNT && Math.abs(envelopePlane.evaluate(pointB)) > OFF_PLANE_AMOUNT) {
         //System.out.println(""Distance: ""+computeSquaredDistance(rval[0], pointOnPlane)+"" and ""+computeSquaredDistance(rval[1], pointOnPlane));
         return new GeoPoint[]{pointA, pointB};
       }
       // Loop back around and use a bigger delta
     }
     // Had to abort, so return null.
+    //System.out.println(""     Adjoining points not found.  Are planes parallel?  edge = ""+plane+""; envelope = ""+envelopePlane+""; perpendicular = ""+perpendicular);
     return null;
   }
\ No newline at end of file
",NotBuggy,"LUCENE-8337: Fix problems with how travel planes too close to edge of world are disallowed, and increase the size of the disallowed window by an order of magnitude.
"
lucene-solr,50391.json,ceb4f768bf5b71a91872f9ecdc5ebed4d0262903,"@@ -1,46 +1,47 @@
     public boolean apply(final GeoPoint testPoint, final boolean testPointInSet,
       final double x, final double y, final double z) {
       // First, try with two individual legs.  If that doesn't work, try the DualCrossingIterator.
       try {
         // First, we'll determine if the intersection point is in set or not
         //System.out.println("" Finding whether ""+intersectionPoint+"" is in-set, based on travel from ""+testPoint+"" along ""+firstLegPlane+"" (value=""+firstLegValue+"")"");
         final CountingEdgeIterator testPointEdgeIterator = createLinearCrossingEdgeIterator(testPoint,
           firstLegPlane, firstLegAbovePlane, firstLegBelowPlane,
           intersectionPoint.x, intersectionPoint.y, intersectionPoint.z);
         // Traverse our way from the test point to the check point.  Use the z tree because that's fixed.
         firstLegTree.traverse(testPointEdgeIterator, firstLegValue);
         final boolean intersectionPointOnEdge = testPointEdgeIterator.isOnEdge();
         // If the intersection point is on the edge, we cannot use this combination of legs, since it's not logically possible to compute in-set or out-of-set
         // with such a starting point.
         if (intersectionPointOnEdge) {
           throw new IllegalArgumentException(""Intersection point landed on an edge -- illegal path"");
         }
         final boolean intersectionPointInSet = intersectionPointOnEdge || (((testPointEdgeIterator.getCrossingCount() & 1) == 0)?testPointInSet:!testPointInSet);
         
         //System.out.println(""  Intersection point in-set? ""+intersectionPointInSet+"" On edge? ""+intersectionPointOnEdge);
 
         // Now do the final leg
         //System.out.println("" Finding whether [""+x+"",""+y+"",""+z+""] is in-set, based on travel from ""+intersectionPoint+"" along ""+secondLegPlane+"" (value=""+secondLegValue+"")"");
         final CountingEdgeIterator travelEdgeIterator = createLinearCrossingEdgeIterator(intersectionPoint,
           secondLegPlane, secondLegAbovePlane, secondLegBelowPlane,
           x, y, z);
         // Traverse our way from the test point to the check point.
         secondLegTree.traverse(travelEdgeIterator, secondLegValue);
         final boolean rval = travelEdgeIterator.isOnEdge() || (((travelEdgeIterator.getCrossingCount() & 1) == 0)?intersectionPointInSet:!intersectionPointInSet);
         
         //System.out.println("" Check point in set? ""+rval);
         return rval;
       } catch (IllegalArgumentException e) {
         // Intersection point apparently was on edge, so try another strategy
+        //System.out.println("" Trying dual crossing edge iterator"");
         final CountingEdgeIterator edgeIterator = new DualCrossingEdgeIterator(testPoint,
           firstLegPlane, firstLegAbovePlane, firstLegBelowPlane,
           secondLegPlane, secondLegAbovePlane, secondLegBelowPlane,
           x, y, z, intersectionPoint);
         firstLegTree.traverse(edgeIterator, firstLegValue);
         if (edgeIterator.isOnEdge()) {
           return true;
         }
         secondLegTree.traverse(edgeIterator, secondLegValue);
         return edgeIterator.isOnEdge() || (((edgeIterator.getCrossingCount() & 1) == 0)?testPointInSet:!testPointInSet);
       }
     }
\ No newline at end of file
",NotBuggy,"LUCENE-8337: Fix problems with how travel planes too close to edge of world are disallowed, and increase the size of the disallowed window by an order of magnitude.
"
lucene-solr,50389.json,ceb4f768bf5b71a91872f9ecdc5ebed4d0262903,"@@ -1,17 +1,19 @@
   private CountingEdgeIterator createLinearCrossingEdgeIterator(final GeoPoint testPoint,
     final Plane plane, final Plane abovePlane, final Plane belowPlane,
     final double thePointX, final double thePointY, final double thePointZ) {
     // If thePoint and testPoint are parallel, we won't be able to determine sidedness of the bounding planes.  So detect that case, and build the iterator differently if we find it.
     // This didn't work; not sure why not:
     //if (testPoint.isParallel(thePointX, thePointY, thePointZ)) {
     //  return new FullLinearCrossingEdgeIterator(plane, abovePlane, belowPlane, thePointX, thePointY, thePointZ);
     //}
     //return new SectorLinearCrossingEdgeIterator(plane, abovePlane, belowPlane, thePointX, thePointY, thePointZ);
     //
     try {
+      //System.out.println("" creating sector linear crossing edge iterator"");
       return new SectorLinearCrossingEdgeIterator(testPoint, plane, abovePlane, belowPlane, thePointX, thePointY, thePointZ);
     } catch (IllegalArgumentException e) {
       // Assume we failed because we could not construct bounding planes, so do it another way.
+      //System.out.println("" create full linear crossing edge iterator"");
       return new FullLinearCrossingEdgeIterator(testPoint, plane, abovePlane, belowPlane, thePointX, thePointY, thePointZ);
     }
   }
\ No newline at end of file
",NotBuggy,"LUCENE-8337: Fix problems with how travel planes too close to edge of world are disallowed, and increase the size of the disallowed window by an order of magnitude.
"
lucene-solr,50383.json,ceb4f768bf5b71a91872f9ecdc5ebed4d0262903,"@@ -1,242 +1,242 @@
   private boolean isInSet(final double x, final double y, final double z,
     final GeoPoint testPoint,
     final boolean testPointInSet,
     final Plane testPointFixedXPlane, final Plane testPointFixedXAbovePlane, final Plane testPointFixedXBelowPlane,
     final Plane testPointFixedYPlane, final Plane testPointFixedYAbovePlane, final Plane testPointFixedYBelowPlane,
     final Plane testPointFixedZPlane, final Plane testPointFixedZAbovePlane, final Plane testPointFixedZBelowPlane) {
 
     //System.out.println(""\nIsInSet called for [""+x+"",""+y+"",""+z+""], testPoint=""+testPoint+""; is in set? ""+testPointInSet);
     // If we're right on top of the point, we know the answer.
     if (testPoint.isNumericallyIdentical(x, y, z)) {
       return testPointInSet;
     }
     
     // If we're right on top of any of the test planes, we navigate solely on that plane.
     if (testPointFixedYAbovePlane != null && testPointFixedYBelowPlane != null && testPointFixedYPlane.evaluateIsZero(x, y, z)) {
       // Use the XZ plane exclusively.
       //System.out.println("" Using XZ plane alone"");
       final CountingEdgeIterator crossingEdgeIterator = createLinearCrossingEdgeIterator(testPoint, testPointFixedYPlane, testPointFixedYAbovePlane, testPointFixedYBelowPlane, x, y, z);
       // Traverse our way from the test point to the check point.  Use the y tree because that's fixed.
       yTree.traverse(crossingEdgeIterator, testPoint.y);
       return crossingEdgeIterator.isOnEdge() || (((crossingEdgeIterator.getCrossingCount() & 1) == 0)?testPointInSet:!testPointInSet);
     } else if (testPointFixedXAbovePlane != null && testPointFixedXBelowPlane != null && testPointFixedXPlane.evaluateIsZero(x, y, z)) {
       // Use the YZ plane exclusively.
       //System.out.println("" Using YZ plane alone"");
       final CountingEdgeIterator crossingEdgeIterator = createLinearCrossingEdgeIterator(testPoint, testPointFixedXPlane, testPointFixedXAbovePlane, testPointFixedXBelowPlane, x, y, z);
       // Traverse our way from the test point to the check point.  Use the x tree because that's fixed.
       xTree.traverse(crossingEdgeIterator, testPoint.x);
       return crossingEdgeIterator.isOnEdge() || (((crossingEdgeIterator.getCrossingCount() & 1) == 0)?testPointInSet:!testPointInSet);
     } else if (testPointFixedZAbovePlane != null && testPointFixedZBelowPlane != null && testPointFixedZPlane.evaluateIsZero(x, y, z)) {
       //System.out.println("" Using XY plane alone"");
       final CountingEdgeIterator crossingEdgeIterator = createLinearCrossingEdgeIterator(testPoint, testPointFixedZPlane, testPointFixedZAbovePlane, testPointFixedZBelowPlane, x, y, z);
       // Traverse our way from the test point to the check point.  Use the z tree because that's fixed.
       zTree.traverse(crossingEdgeIterator, testPoint.z);
       return crossingEdgeIterator.isOnEdge() || (((crossingEdgeIterator.getCrossingCount() & 1) == 0)?testPointInSet:!testPointInSet);
     } else {
       //System.out.println("" Using two planes"");
       // This is the expensive part!!
       // Changing the code below has an enormous impact on the queries per second we see with the benchmark.
       
       // We need to use two planes to get there.  We don't know which two planes will do it but we can figure it out.
       final Plane travelPlaneFixedX = new Plane(1.0, 0.0, 0.0, -x);
       final Plane travelPlaneFixedY = new Plane(0.0, 1.0, 0.0, -y);
       final Plane travelPlaneFixedZ = new Plane(0.0, 0.0, 1.0, -z);
 
       Plane fixedYAbovePlane = new Plane(travelPlaneFixedY, true);
-      if (fixedYAbovePlane.D - planetModel.getMaximumYValue() > NEAR_EDGE_CUTOFF || planetModel.getMinimumYValue() - fixedYAbovePlane.D > NEAR_EDGE_CUTOFF) {
+      if (-fixedYAbovePlane.D - planetModel.getMaximumYValue() > NEAR_EDGE_CUTOFF || planetModel.getMinimumYValue() + fixedYAbovePlane.D > NEAR_EDGE_CUTOFF) {
           fixedYAbovePlane = null;
       }
       
       Plane fixedYBelowPlane = new Plane(travelPlaneFixedY, false);
-      if (fixedYBelowPlane.D - planetModel.getMaximumYValue() > NEAR_EDGE_CUTOFF || planetModel.getMinimumYValue() - fixedYBelowPlane.D > NEAR_EDGE_CUTOFF) {
+      if (-fixedYBelowPlane.D - planetModel.getMaximumYValue() > NEAR_EDGE_CUTOFF || planetModel.getMinimumYValue() + fixedYBelowPlane.D > NEAR_EDGE_CUTOFF) {
           fixedYBelowPlane = null;
       }
       
       Plane fixedXAbovePlane = new Plane(travelPlaneFixedX, true);
-      if (fixedXAbovePlane.D - planetModel.getMaximumXValue() > NEAR_EDGE_CUTOFF || planetModel.getMinimumXValue() - fixedXAbovePlane.D > NEAR_EDGE_CUTOFF) {
+      if (-fixedXAbovePlane.D - planetModel.getMaximumXValue() > NEAR_EDGE_CUTOFF || planetModel.getMinimumXValue() + fixedXAbovePlane.D > NEAR_EDGE_CUTOFF) {
           fixedXAbovePlane = null;
       }
       
       Plane fixedXBelowPlane = new Plane(travelPlaneFixedX, false);
-      if (fixedXBelowPlane.D - planetModel.getMaximumXValue() > NEAR_EDGE_CUTOFF || planetModel.getMinimumXValue() - fixedXBelowPlane.D > NEAR_EDGE_CUTOFF) {
+      if (-fixedXBelowPlane.D - planetModel.getMaximumXValue() > NEAR_EDGE_CUTOFF || planetModel.getMinimumXValue() + fixedXBelowPlane.D > NEAR_EDGE_CUTOFF) {
           fixedXBelowPlane = null;
       }
       
       Plane fixedZAbovePlane = new Plane(travelPlaneFixedZ, true);
-      if (fixedZAbovePlane.D - planetModel.getMaximumZValue() > NEAR_EDGE_CUTOFF || planetModel.getMinimumZValue() - fixedZAbovePlane.D > NEAR_EDGE_CUTOFF) {
+      if (-fixedZAbovePlane.D - planetModel.getMaximumZValue() > NEAR_EDGE_CUTOFF || planetModel.getMinimumZValue() + fixedZAbovePlane.D > NEAR_EDGE_CUTOFF) {
           fixedZAbovePlane = null;
       }
       
       Plane fixedZBelowPlane = new Plane(travelPlaneFixedZ, false);
-      if (fixedZBelowPlane.D - planetModel.getMaximumZValue() > NEAR_EDGE_CUTOFF || planetModel.getMinimumZValue() - fixedZBelowPlane.D > NEAR_EDGE_CUTOFF) {
+      if (-fixedZBelowPlane.D - planetModel.getMaximumZValue() > NEAR_EDGE_CUTOFF || planetModel.getMinimumZValue() + fixedZBelowPlane.D > NEAR_EDGE_CUTOFF) {
           fixedZBelowPlane = null;
       }
 
       // Find the intersection points for each one of these and the complementary test point planes.
 
       final List<TraversalStrategy> traversalStrategies = new ArrayList<>(12);
       
       if (testPointFixedYAbovePlane != null && testPointFixedYBelowPlane != null && fixedXAbovePlane != null && fixedXBelowPlane != null) {
         //check if planes intersects  inside world
         final double checkAbove = 4.0 * (fixedXAbovePlane.D * fixedXAbovePlane.D * planetModel.inverseAbSquared + testPointFixedYAbovePlane.D * testPointFixedYAbovePlane.D * planetModel.inverseAbSquared - 1.0);
         final double checkBelow = 4.0 * (fixedXBelowPlane.D * fixedXBelowPlane.D * planetModel.inverseAbSquared + testPointFixedYBelowPlane.D * testPointFixedYBelowPlane.D * planetModel.inverseAbSquared - 1.0);
         if (checkAbove < Vector.MINIMUM_RESOLUTION_SQUARED && checkBelow < Vector.MINIMUM_RESOLUTION_SQUARED) {
           //System.out.println(""  Looking for intersections between travel and test point planes..."");
           final GeoPoint[] XIntersectionsY = travelPlaneFixedX.findIntersections(planetModel, testPointFixedYPlane);
           for (final GeoPoint p : XIntersectionsY) {
             // Travel would be in YZ plane (fixed x) then in XZ (fixed y)
             // We compute distance we need to travel as a placeholder for the number of intersections we might encounter.
             //final double newDistance = p.arcDistance(testPoint) + p.arcDistance(thePoint);
             final double tpDelta1 = testPoint.x - p.x;
             final double tpDelta2 = testPoint.z - p.z;
             final double cpDelta1 = y - p.y;
             final double cpDelta2 = z - p.z;
             final double newDistance = tpDelta1 * tpDelta1 + tpDelta2 * tpDelta2 + cpDelta1 * cpDelta1 + cpDelta2 * cpDelta2;
             //final double newDistance = (testPoint.x - p.x) * (testPoint.x - p.x) + (testPoint.z - p.z) * (testPoint.z - p.z)  + (thePoint.y - p.y) * (thePoint.y - p.y) + (thePoint.z - p.z) * (thePoint.z - p.z);
             //final double newDistance = Math.abs(testPoint.x - p.x) + Math.abs(thePoint.y - p.y);
             traversalStrategies.add(new TraversalStrategy(newDistance, testPoint.y, x,
               testPointFixedYPlane, testPointFixedYAbovePlane, testPointFixedYBelowPlane,
               travelPlaneFixedX, fixedXAbovePlane, fixedXBelowPlane,
               yTree, xTree, p));
           }
         }
       }
       if (testPointFixedZAbovePlane != null && testPointFixedZBelowPlane != null && fixedXAbovePlane != null && fixedXBelowPlane != null) {
         //check if planes intersects  inside world
         final double checkAbove = 4.0 * (fixedXAbovePlane.D * fixedXAbovePlane.D * planetModel.inverseAbSquared + testPointFixedZAbovePlane.D * testPointFixedZAbovePlane.D * planetModel.inverseCSquared - 1.0);
         final double checkBelow = 4.0 * (fixedXBelowPlane.D * fixedXBelowPlane.D * planetModel.inverseAbSquared + testPointFixedZBelowPlane.D * testPointFixedZBelowPlane.D * planetModel.inverseCSquared - 1.0);
         if (checkAbove < Vector.MINIMUM_RESOLUTION_SQUARED && checkBelow < Vector.MINIMUM_RESOLUTION_SQUARED) {
           //System.out.println(""  Looking for intersections between travel and test point planes..."");
           final GeoPoint[] XIntersectionsZ = travelPlaneFixedX.findIntersections(planetModel, testPointFixedZPlane);
           for (final GeoPoint p : XIntersectionsZ) {
             // Travel would be in YZ plane (fixed x) then in XY (fixed z)
             //final double newDistance = p.arcDistance(testPoint) + p.arcDistance(thePoint);
             final double tpDelta1 = testPoint.x - p.x;
             final double tpDelta2 = testPoint.y - p.y;
             final double cpDelta1 = y - p.y;
             final double cpDelta2 = z - p.z;
             final double newDistance = tpDelta1 * tpDelta1 + tpDelta2 * tpDelta2 + cpDelta1 * cpDelta1 + cpDelta2 * cpDelta2;
             //final double newDistance = (testPoint.x - p.x) * (testPoint.x - p.x) + (testPoint.y - p.y) * (testPoint.y - p.y)  + (thePoint.y - p.y) * (thePoint.y - p.y) + (thePoint.z - p.z) * (thePoint.z - p.z);
             //final double newDistance = Math.abs(testPoint.x - p.x) + Math.abs(thePoint.z - p.z);
             traversalStrategies.add(new TraversalStrategy(newDistance, testPoint.z, x,
               testPointFixedZPlane, testPointFixedZAbovePlane, testPointFixedZBelowPlane,
               travelPlaneFixedX, fixedXAbovePlane, fixedXBelowPlane,
               zTree, xTree, p));
           }
         }
       }
       if (testPointFixedXAbovePlane != null && testPointFixedXBelowPlane != null && fixedYAbovePlane != null && fixedYBelowPlane != null) {
         //check if planes intersects inside world
         final double checkAbove = 4.0 * (testPointFixedXAbovePlane.D * testPointFixedXAbovePlane.D * planetModel.inverseAbSquared + fixedYAbovePlane.D * fixedYAbovePlane.D * planetModel.inverseAbSquared - 1.0);
         final double checkBelow = 4.0 * (testPointFixedXBelowPlane.D * testPointFixedXBelowPlane.D * planetModel.inverseAbSquared + fixedYBelowPlane.D * fixedYBelowPlane.D * planetModel.inverseAbSquared - 1.0);
         if (checkAbove < Vector.MINIMUM_RESOLUTION_SQUARED && checkBelow < Vector.MINIMUM_RESOLUTION_SQUARED) {
           //System.out.println(""  Looking for intersections between travel and test point planes..."");
           final GeoPoint[] YIntersectionsX = travelPlaneFixedY.findIntersections(planetModel, testPointFixedXPlane);
           for (final GeoPoint p : YIntersectionsX) {
             // Travel would be in XZ plane (fixed y) then in YZ (fixed x)
             //final double newDistance = p.arcDistance(testPoint) + p.arcDistance(thePoint);
             final double tpDelta1 = testPoint.y - p.y;
             final double tpDelta2 = testPoint.z - p.z;
             final double cpDelta1 = x - p.x;
             final double cpDelta2 = z - p.z;
             final double newDistance = tpDelta1 * tpDelta1 + tpDelta2 * tpDelta2 + cpDelta1 * cpDelta1 + cpDelta2 * cpDelta2;
             //final double newDistance = (testPoint.y - p.y) * (testPoint.y - p.y) + (testPoint.z - p.z) * (testPoint.z - p.z)  + (thePoint.x - p.x) * (thePoint.x - p.x) + (thePoint.z - p.z) * (thePoint.z - p.z);
             //final double newDistance = Math.abs(testPoint.y - p.y) + Math.abs(thePoint.x - p.x);
             traversalStrategies.add(new TraversalStrategy(newDistance, testPoint.x, y,
               testPointFixedXPlane, testPointFixedXAbovePlane, testPointFixedXBelowPlane,
               travelPlaneFixedY, fixedYAbovePlane, fixedYBelowPlane,
               xTree, yTree, p));
           }
         }
       }
       if (testPointFixedZAbovePlane != null && testPointFixedZBelowPlane != null && fixedYAbovePlane != null && fixedYBelowPlane != null) {
         //check if planes intersects inside world
         final double checkAbove = 4.0 * (testPointFixedZAbovePlane.D * testPointFixedZAbovePlane.D * planetModel.inverseCSquared + fixedYAbovePlane.D * fixedYAbovePlane.D * planetModel.inverseAbSquared - 1.0);
         final double checkBelow = 4.0 * (testPointFixedZBelowPlane.D * testPointFixedZBelowPlane.D * planetModel.inverseCSquared + fixedYBelowPlane.D * fixedYBelowPlane.D * planetModel.inverseAbSquared - 1.0);
         if (checkAbove < Vector.MINIMUM_RESOLUTION_SQUARED && checkBelow < Vector.MINIMUM_RESOLUTION_SQUARED) {
           //System.out.println(""  Looking for intersections between travel and test point planes..."");
           final GeoPoint[] YIntersectionsZ = travelPlaneFixedY.findIntersections(planetModel, testPointFixedZPlane);
           for (final GeoPoint p : YIntersectionsZ) {
             // Travel would be in XZ plane (fixed y) then in XY (fixed z)
             //final double newDistance = p.arcDistance(testPoint) + p.arcDistance(thePoint);
             final double tpDelta1 = testPoint.x - p.x;
             final double tpDelta2 = testPoint.y - p.y;
             final double cpDelta1 = x - p.x;
             final double cpDelta2 = z - p.z;
             final double newDistance = tpDelta1 * tpDelta1 + tpDelta2 * tpDelta2 + cpDelta1 * cpDelta1 + cpDelta2 * cpDelta2;
             //final double newDistance = (testPoint.x - p.x) * (testPoint.x - p.x) + (testPoint.y - p.y) * (testPoint.y - p.y)  + (thePoint.x - p.x) * (thePoint.x - p.x) + (thePoint.z - p.z) * (thePoint.z - p.z);
             //final double newDistance = Math.abs(testPoint.y - p.y) + Math.abs(thePoint.z - p.z);
             traversalStrategies.add(new TraversalStrategy(newDistance, testPoint.z, y,
               testPointFixedZPlane, testPointFixedZAbovePlane, testPointFixedZBelowPlane,
               travelPlaneFixedY, fixedYAbovePlane, fixedYBelowPlane,
               zTree, yTree, p));
           }
         }
       }
       if (testPointFixedXAbovePlane != null && testPointFixedXBelowPlane != null && fixedZAbovePlane != null && fixedZBelowPlane != null) {
         //check if planes intersects inside world
         final double checkAbove = 4.0 * (testPointFixedXAbovePlane.D * testPointFixedXAbovePlane.D * planetModel.inverseAbSquared + fixedZAbovePlane.D * fixedZAbovePlane.D * planetModel.inverseCSquared - 1.0);
         final double checkBelow = 4.0 * (testPointFixedXBelowPlane.D * testPointFixedXBelowPlane.D * planetModel.inverseAbSquared + fixedZBelowPlane.D * fixedZBelowPlane.D * planetModel.inverseCSquared - 1.0);
         if (checkAbove < Vector.MINIMUM_RESOLUTION_SQUARED && checkBelow < Vector.MINIMUM_RESOLUTION_SQUARED) {
           //System.out.println(""  Looking for intersections between travel and test point planes..."");
           final GeoPoint[] ZIntersectionsX = travelPlaneFixedZ.findIntersections(planetModel, testPointFixedXPlane);
           for (final GeoPoint p : ZIntersectionsX) {
             // Travel would be in XY plane (fixed z) then in YZ (fixed x)
             //final double newDistance = p.arcDistance(testPoint) + p.arcDistance(thePoint);
             final double tpDelta1 = testPoint.y - p.y;
             final double tpDelta2 = testPoint.z - p.z;
             final double cpDelta1 = y - p.y;
             final double cpDelta2 = x - p.x;
             final double newDistance = tpDelta1 * tpDelta1 + tpDelta2 * tpDelta2 + cpDelta1 * cpDelta1 + cpDelta2 * cpDelta2;
             //final double newDistance = (testPoint.y - p.y) * (testPoint.y - p.y) + (testPoint.z - p.z) * (testPoint.z - p.z)  + (thePoint.y - p.y) * (thePoint.y - p.y) + (thePoint.x - p.x) * (thePoint.x - p.x);
             //final double newDistance = Math.abs(testPoint.z - p.z) + Math.abs(thePoint.x - p.x);
             traversalStrategies.add(new TraversalStrategy(newDistance, testPoint.x, z,
               testPointFixedXPlane, testPointFixedXAbovePlane, testPointFixedXBelowPlane,
               travelPlaneFixedZ, fixedZAbovePlane, fixedZBelowPlane,
               xTree, zTree, p));
           }
         }
       }
       if (testPointFixedYAbovePlane != null && testPointFixedYBelowPlane != null && fixedZAbovePlane != null && fixedZBelowPlane != null) {
         //check if planes intersects inside world
         final double checkAbove = 4.0 * (testPointFixedYAbovePlane.D * testPointFixedYAbovePlane.D * planetModel.inverseAbSquared + fixedZAbovePlane.D * fixedZAbovePlane.D * planetModel.inverseCSquared - 1.0);
         final double checkBelow = 4.0 * (testPointFixedYBelowPlane.D * testPointFixedYBelowPlane.D * planetModel.inverseAbSquared + fixedZBelowPlane.D * fixedZBelowPlane.D * planetModel.inverseCSquared - 1.0);
         if (checkAbove < Vector.MINIMUM_RESOLUTION_SQUARED && checkBelow < Vector.MINIMUM_RESOLUTION_SQUARED) {
           //System.out.println(""  Looking for intersections between travel and test point planes..."");
           final GeoPoint[] ZIntersectionsY = travelPlaneFixedZ.findIntersections(planetModel, testPointFixedYPlane);
           for (final GeoPoint p : ZIntersectionsY) {
             // Travel would be in XY plane (fixed z) then in XZ (fixed y)
             //final double newDistance = p.arcDistance(testPoint) + p.arcDistance(thePoint);
             final double tpDelta1 = testPoint.x - p.x;
             final double tpDelta2 = testPoint.z - p.z;
             final double cpDelta1 = y - p.y;
             final double cpDelta2 = x - p.x;
             final double newDistance = tpDelta1 * tpDelta1 + tpDelta2 * tpDelta2 + cpDelta1 * cpDelta1 + cpDelta2 * cpDelta2;
             //final double newDistance = (testPoint.x - p.x) * (testPoint.x - p.x) + (testPoint.z - p.z) * (testPoint.z - p.z)  + (thePoint.y - p.y) * (thePoint.y - p.y) + (thePoint.x - p.x) * (thePoint.x - p.x);
             //final double newDistance = Math.abs(testPoint.z - p.z) + Math.abs(thePoint.y - p.y);
             traversalStrategies.add(new TraversalStrategy(newDistance, testPoint.y, z,
               testPointFixedYPlane, testPointFixedYAbovePlane, testPointFixedYBelowPlane,
               travelPlaneFixedZ, fixedZAbovePlane, fixedZBelowPlane,
               yTree, zTree, p));
           }
         }
       }
 
       Collections.sort(traversalStrategies);
       
       if (traversalStrategies.size() == 0) {
         throw new IllegalArgumentException(""No dual-plane travel strategies were found"");
       }
 
       // Loop through travel strategies, in order, until we find one that works.
       for (final TraversalStrategy ts : traversalStrategies) {
         try {
           return ts.apply(testPoint, testPointInSet, x, y, z);
         } catch (IllegalArgumentException e) {
           // Continue
         }
       }
       
       throw new IllegalArgumentException(""Exhausted all traversal strategies"");
     }
   }
\ No newline at end of file
",Buggy,"LUCENE-8337: Fix problems with how travel planes too close to edge of world are disallowed, and increase the size of the disallowed window by an order of magnitude.
"
lucene-solr,28702.json,ec788948a64955acc0415281f353d4d7b2f797cc,"@@ -1,132 +1,134 @@
   public SeekStatus scanToTermNonLeaf(BytesRef target, boolean exactOnly) throws IOException {
 
     // if (DEBUG) System.out.println(""    scanToTermNonLeaf: block fp="" + fp + "" prefix="" + prefix + "" nextEnt="" + nextEnt + "" (of "" + entCount + "") target="" + OrdsSegmentTermsEnum.brToString(target) + "" term="" + OrdsSegmentTermsEnum.brToString(ste.term));
 
     assert nextEnt != -1;
 
     if (nextEnt == entCount) {
       if (exactOnly) {
         fillTerm();
         ste.termExists = subCode == 0;
       }
       return SeekStatus.END;
     }
 
     assert prefixMatches(target);
 
     // Loop over each entry (term or sub-block) in this block:
     //nextTerm: while(nextEnt < entCount) {
     nextTerm: while (true) {
       nextEnt++;
 
       final int code = suffixesReader.readVInt();
       suffix = code >>> 1;
       // if (DEBUG) {
       //   BytesRef suffixBytesRef = new BytesRef();
       //   suffixBytesRef.bytes = suffixBytes;
       //   suffixBytesRef.offset = suffixesReader.getPosition();
       //   suffixBytesRef.length = suffix;
       //   System.out.println(""      cycle: "" + ((code&1)==1 ? ""sub-block"" : ""term"") + "" "" + (nextEnt-1) + "" (of "" + entCount + "") suffix="" + brToString(suffixBytesRef));
       // }
 
       ste.termExists = (code & 1) == 0;
       final int termLen = prefix + suffix;
       startBytePos = suffixesReader.getPosition();
       suffixesReader.skipBytes(suffix);
+      // Must save ord before we skip over a sub-block in case we push, below:
+      long prevTermOrd = termOrd;
       if (ste.termExists) {
         state.termBlockOrd++;
         termOrd++;
         subCode = 0;
       } else {
         subCode = suffixesReader.readVLong();
         termOrd += suffixesReader.readVLong();
         lastSubFP = fp - subCode;
       }
 
       final int targetLimit = target.offset + (target.length < termLen ? target.length : termLen);
       int targetPos = target.offset + prefix;
 
       // Loop over bytes in the suffix, comparing to
       // the target
       int bytePos = startBytePos;
       while(true) {
         final int cmp;
         final boolean stop;
         if (targetPos < targetLimit) {
           cmp = (suffixBytes[bytePos++]&0xFF) - (target.bytes[targetPos++]&0xFF);
           stop = false;
         } else {
           assert targetPos == targetLimit;
           cmp = termLen - target.length;
           stop = true;
         }
 
         if (cmp < 0) {
           // Current entry is still before the target;
           // keep scanning
 
           if (nextEnt == entCount) {
             if (exactOnly) {
               fillTerm();
               //termExists = true;
             }
             // We are done scanning this block
             break nextTerm;
           } else {
             continue nextTerm;
           }
         } else if (cmp > 0) {
 
           // Done!  Current entry is after target --
           // return NOT_FOUND:
           fillTerm();
 
           if (!exactOnly && !ste.termExists) {
             // We are on a sub-block, and caller wants
             // us to position to the next term after
             // the target, so we must recurse into the
             // sub-frame(s):
-            ste.currentFrame = ste.pushFrame(null, ste.currentFrame.lastSubFP, termLen, ste.currentFrame.termOrd);
+            ste.currentFrame = ste.pushFrame(null, ste.currentFrame.lastSubFP, termLen, prevTermOrd);
             ste.currentFrame.loadBlock();
             while (ste.currentFrame.next()) {
-              ste.currentFrame = ste.pushFrame(null, ste.currentFrame.lastSubFP, ste.term.length, ste.currentFrame.termOrd);
+              ste.currentFrame = ste.pushFrame(null, ste.currentFrame.lastSubFP, ste.term.length, prevTermOrd);
               ste.currentFrame.loadBlock();
             }
           }
                 
           //if (DEBUG) System.out.println(""        not found"");
           return SeekStatus.NOT_FOUND;
         } else if (stop) {
           // Exact match!
 
           // This cannot be a sub-block because we
           // would have followed the index to this
           // sub-block from the start:
 
           assert ste.termExists;
           fillTerm();
           //if (DEBUG) System.out.println(""        found!"");
           return SeekStatus.FOUND;
         }
       }
     }
 
     // It is possible (and OK) that terms index pointed us
     // at this block, but, we scanned the entire block and
     // did not find the term to position to.  This happens
     // when the target is after the last term in the block
     // (but, before the next term in the index).  EG
     // target could be foozzz, and terms index pointed us
     // to the foo* block, but the last term in this block
     // was fooz (and, eg, first term in the next block will
     // bee fop).
     //if (DEBUG) System.out.println(""      block end"");
     if (exactOnly) {
       fillTerm();
     }
 
     // TODO: not consistent that in the
     // not-exact case we don't next() into the next
     // frame here
     return SeekStatus.END;
   }
\ No newline at end of file
",Buggy,"LUCENE-5819: fix ord bug; add test case; remove dead code

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1612217 13f79535-47bb-0310-9956-ffa450edef68
"
lucene-solr,42320.json,ec788948a64955acc0415281f353d4d7b2f797cc,"@@ -1,123 +1,110 @@
   public SeekStatus scanToTermLeaf(BytesRef target, boolean exactOnly) throws IOException {
 
     // if (DEBUG) System.out.println(""    scanToTermLeaf: block fp="" + fp + "" prefix="" + prefix + "" nextEnt="" + nextEnt + "" (of "" + entCount + "") target="" + brToString(target) + "" term="" + brToString(term));
 
     assert nextEnt != -1;
 
     ste.termExists = true;
     subCode = 0;
 
     if (nextEnt == entCount) {
       if (exactOnly) {
         fillTerm();
       }
       return SeekStatus.END;
     }
 
     assert prefixMatches(target);
 
     // Loop over each entry (term or sub-block) in this block:
     //nextTerm: while(nextEnt < entCount) {
     nextTerm: while (true) {
       nextEnt++;
 
       suffix = suffixesReader.readVInt();
 
       // if (DEBUG) {
       //   BytesRef suffixBytesRef = new BytesRef();
       //   suffixBytesRef.bytes = suffixBytes;
       //   suffixBytesRef.offset = suffixesReader.getPosition();
       //   suffixBytesRef.length = suffix;
       //   System.out.println(""      cycle: term "" + (nextEnt-1) + "" (of "" + entCount + "") suffix="" + brToString(suffixBytesRef));
       // }
 
       final int termLen = prefix + suffix;
       startBytePos = suffixesReader.getPosition();
       suffixesReader.skipBytes(suffix);
 
       final int targetLimit = target.offset + (target.length < termLen ? target.length : termLen);
       int targetPos = target.offset + prefix;
 
       // Loop over bytes in the suffix, comparing to
       // the target
       int bytePos = startBytePos;
       while(true) {
         final int cmp;
         final boolean stop;
         if (targetPos < targetLimit) {
           cmp = (suffixBytes[bytePos++]&0xFF) - (target.bytes[targetPos++]&0xFF);
           stop = false;
         } else {
           assert targetPos == targetLimit;
           cmp = termLen - target.length;
           stop = true;
         }
 
         if (cmp < 0) {
           // Current entry is still before the target;
           // keep scanning
 
           if (nextEnt == entCount) {
             if (exactOnly) {
               fillTerm();
             }
             // We are done scanning this block
             break nextTerm;
           } else {
             continue nextTerm;
           }
         } else if (cmp > 0) {
 
           // Done!  Current entry is after target --
           // return NOT_FOUND:
           fillTerm();
 
-          if (!exactOnly && !ste.termExists) {
-            // We are on a sub-block, and caller wants
-            // us to position to the next term after
-            // the target, so we must recurse into the
-            // sub-frame(s):
-            ste.currentFrame = ste.pushFrame(null, ste.currentFrame.lastSubFP, termLen);
-            ste.currentFrame.loadBlock();
-            while (ste.currentFrame.next()) {
-              ste.currentFrame = ste.pushFrame(null, ste.currentFrame.lastSubFP, ste.term.length);
-              ste.currentFrame.loadBlock();
-            }
-          }
-                
           //if (DEBUG) System.out.println(""        not found"");
           return SeekStatus.NOT_FOUND;
         } else if (stop) {
           // Exact match!
 
           // This cannot be a sub-block because we
           // would have followed the index to this
           // sub-block from the start:
 
           assert ste.termExists;
           fillTerm();
           //if (DEBUG) System.out.println(""        found!"");
           return SeekStatus.FOUND;
         }
       }
     }
 
     // It is possible (and OK) that terms index pointed us
     // at this block, but, we scanned the entire block and
     // did not find the term to position to.  This happens
     // when the target is after the last term in the block
     // (but, before the next term in the index).  EG
     // target could be foozzz, and terms index pointed us
     // to the foo* block, but the last term in this block
     // was fooz (and, eg, first term in the next block will
     // bee fop).
     //if (DEBUG) System.out.println(""      block end"");
     if (exactOnly) {
       fillTerm();
     }
 
     // TODO: not consistent that in the
     // not-exact case we don't next() into the next
     // frame here
     return SeekStatus.END;
   }
\ No newline at end of file
",NotBuggy,"LUCENE-5819: fix ord bug; add test case; remove dead code

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1612217 13f79535-47bb-0310-9956-ffa450edef68
"
lucene-solr,28701.json,ec788948a64955acc0415281f353d4d7b2f797cc,"@@ -1,124 +1,111 @@
   public SeekStatus scanToTermLeaf(BytesRef target, boolean exactOnly) throws IOException {
 
     // if (DEBUG) System.out.println(""    scanToTermLeaf: block fp="" + fp + "" prefix="" + prefix + "" nextEnt="" + nextEnt + "" (of "" + entCount + "") target="" + OrdsSegmentTermsEnum.brToString(target) + "" term="" + OrdsSegmentTermsEnum.brToString(ste.term));
 
     assert nextEnt != -1;
 
     ste.termExists = true;
     subCode = 0;
 
     if (nextEnt == entCount) {
       if (exactOnly) {
         fillTerm();
       }
       return SeekStatus.END;
     }
 
     assert prefixMatches(target);
 
     // Loop over each entry (term or sub-block) in this block:
     //nextTerm: while(nextEnt < entCount) {
     nextTerm: while (true) {
       nextEnt++;
       termOrd++;
 
       suffix = suffixesReader.readVInt();
 
       // if (DEBUG) {
       //    BytesRef suffixBytesRef = new BytesRef();
       //    suffixBytesRef.bytes = suffixBytes;
       //    suffixBytesRef.offset = suffixesReader.getPosition();
       //    suffixBytesRef.length = suffix;
       //    System.out.println(""      cycle: term "" + (nextEnt-1) + "" (of "" + entCount + "") suffix="" + OrdsSegmentTermsEnum.brToString(suffixBytesRef));
       // }
 
       final int termLen = prefix + suffix;
       startBytePos = suffixesReader.getPosition();
       suffixesReader.skipBytes(suffix);
 
       final int targetLimit = target.offset + (target.length < termLen ? target.length : termLen);
       int targetPos = target.offset + prefix;
 
       // Loop over bytes in the suffix, comparing to
       // the target
       int bytePos = startBytePos;
       while(true) {
         final int cmp;
         final boolean stop;
         if (targetPos < targetLimit) {
           cmp = (suffixBytes[bytePos++]&0xFF) - (target.bytes[targetPos++]&0xFF);
           stop = false;
         } else {
           assert targetPos == targetLimit;
           cmp = termLen - target.length;
           stop = true;
         }
 
         if (cmp < 0) {
           // Current entry is still before the target;
           // keep scanning
 
           if (nextEnt == entCount) {
             if (exactOnly) {
               fillTerm();
             }
             // We are done scanning this block
             break nextTerm;
           } else {
             continue nextTerm;
           }
         } else if (cmp > 0) {
 
           // Done!  Current entry is after target --
           // return NOT_FOUND:
           fillTerm();
 
-          if (!exactOnly && !ste.termExists) {
-            // We are on a sub-block, and caller wants
-            // us to position to the next term after
-            // the target, so we must recurse into the
-            // sub-frame(s):
-            ste.currentFrame = ste.pushFrame(null, ste.currentFrame.lastSubFP, termLen, ste.currentFrame.termOrd);
-            ste.currentFrame.loadBlock();
-            while (ste.currentFrame.next()) {
-              ste.currentFrame = ste.pushFrame(null, ste.currentFrame.lastSubFP, ste.term.length, ste.currentFrame.termOrd);
-              ste.currentFrame.loadBlock();
-            }
-          }
-                
           //if (DEBUG) System.out.println(""        not found"");
           return SeekStatus.NOT_FOUND;
         } else if (stop) {
           // Exact match!
 
           // This cannot be a sub-block because we
           // would have followed the index to this
           // sub-block from the start:
 
           assert ste.termExists;
           fillTerm();
           //if (DEBUG) System.out.println(""        found!"");
           return SeekStatus.FOUND;
         }
       }
     }
 
     // It is possible (and OK) that terms index pointed us
     // at this block, but, we scanned the entire block and
     // did not find the term to position to.  This happens
     // when the target is after the last term in the block
     // (but, before the next term in the index).  EG
     // target could be foozzz, and terms index pointed us
     // to the foo* block, but the last term in this block
     // was fooz (and, eg, first term in the next block will
     // bee fop).
     //if (DEBUG) System.out.println(""      block end"");
     if (exactOnly) {
       fillTerm();
     }
 
     // TODO: not consistent that in the
     // not-exact case we don't next() into the next
     // frame here
     return SeekStatus.END;
   }
\ No newline at end of file
",NotBuggy,"LUCENE-5819: fix ord bug; add test case; remove dead code

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1612217 13f79535-47bb-0310-9956-ffa450edef68
"
lucene-solr,20313.json,766b017b1a356f57a5eb6e73bd70e67f34534013,"@@ -1,11 +1,6 @@
-  private IndexSchema initSchema(SolrConfig config, IndexSchema schema) {
+  private void initSchema(SolrConfig config, IndexSchema schema) {
     if (schema == null) {
       schema = IndexSchemaFactory.buildIndexSchema(IndexSchema.DEFAULT_SCHEMA_FILE, config);
     }
-    final SimilarityFactory similarityFactory = schema.getSimilarityFactory();
-    if (similarityFactory instanceof SolrCoreAware) {
-      // Similarity needs SolrCore before inform() is called on all registered SolrCoreAware listeners below
-      ((SolrCoreAware) similarityFactory).inform(this);
-    }
-    return schema;
+    setLatestSchema(schema);
   }
\ No newline at end of file
",Buggy,"SOLR-8280: Fixed bug in SimilarityFactory initialization that prevented SolrCoreAware factories from functioning properly with managed schema features

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1715215 13f79535-47bb-0310-9956-ffa450edef68
"
lucene-solr,12746.json,766b017b1a356f57a5eb6e73bd70e67f34534013,"@@ -1,4 +1,6 @@
   public Similarity getSimilarity() {
-    assert core != null : ""inform must be called first"";
+    if (null == core) {
+      throw new IllegalStateException(""SchemaSimilarityFactory can not be used until SolrCoreAware.inform has been called"");
+    }
     return similarity;
   }
\ No newline at end of file
",NotBuggy,"SOLR-8280: Fixed bug in SimilarityFactory initialization that prevented SolrCoreAware factories from functioning properly with managed schema features

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1715215 13f79535-47bb-0310-9956-ffa450edef68
"
lucene-solr,43373.json,9952af099ae65f051056fc8ff55c8e8f4cfb3b93,"@@ -1,18 +1,16 @@
   private static final boolean isIntersectingPolygon(final Node start, final double x0, final double y0,
                                                      final double x1, final double y1) {
     Node node = start;
     Node nextNode;
     do {
       nextNode = node.next;
-      if(node.getX() != x0 && node.getY() != y0 && nextNode.getX() != x0
-          && nextNode.getY() != y0 && node.getX() != x1 && node.getY() != y1
-          && nextNode.getX() != x1 && nextNode.getY() != y1) {
+      if(isVertexEquals(node, x0, y0) == false && isVertexEquals(node, x1, y1) == false) {
         if (linesIntersect(node.getX(), node.getY(), nextNode.getX(), nextNode.getY(), x0, y0, x1, y1)) {
           return true;
         }
       }
       node = nextNode;
     } while (node != start);
 
     return false;
   }
\ No newline at end of file
",Buggy,"LUCENE-8559: Fix bug where polygon edges were skipped when checking for intersections
"
lucene-solr,43381.json,9952af099ae65f051056fc8ff55c8e8f4cfb3b93,"@@ -1,3 +1,3 @@
   private static final boolean isVertexEquals(final Node a, final Node b) {
-    return a.getX() == b.getX() && a.getY() == b.getY();
+    return isVertexEquals(a, b.getX(), b.getY());
   }
\ No newline at end of file
",NotBuggy,"LUCENE-8559: Fix bug where polygon edges were skipped when checking for intersections
"
lucene-solr,43382.json,9952af099ae65f051056fc8ff55c8e8f4cfb3b93,"@@ -1,3 +1,3 @@
-  private static final boolean isVertexEquals(final Node a, final Node b) {
-    return a.getX() == b.getX() && a.getY() == b.getY();
+  private static final boolean isVertexEquals(final Node a, final double x, final  double y) {
+    return a.getX() == x && a.getY() == y;
   }
\ No newline at end of file
",NotBuggy,"LUCENE-8559: Fix bug where polygon edges were skipped when checking for intersections
"
lucene-solr,38533.json,b33d7176aa3624df2de1708b17919f20d034872f,"@@ -1,15 +1,16 @@
-  private static void intersectInterval(double heatMin, double heatMax, double heatCellLen, int heatLen,
+  private static void intersectInterval(double heatMin, double heatMax, double heatCellLen, int numCells,
                                         double cellMin, double cellMax,
                                         int[] out) {
+    assert heatMin < heatMax && cellMin < cellMax;
     //precondition: we know there's an intersection
     if (heatMin >= cellMin) {
       out[0] = 0;
     } else {
       out[0] = (int) Math.round((cellMin - heatMin) / heatCellLen);
     }
     if (heatMax <= cellMax) {
-      out[1] = heatLen - 1;
+      out[1] = numCells - 1;
     } else {
       out[1] = (int) Math.round((cellMax - heatMin) / heatCellLen) - 1;
     }
   }
\ No newline at end of file
",NotBuggy,"LUCENE-7291: Fix spatial HeatmapFacetCounter bug with dateline and large non-point shapes
"
lucene-solr,38532.json,b33d7176aa3624df2de1708b17919f20d034872f,"@@ -1,152 +1,153 @@
   public static Heatmap calcFacets(PrefixTreeStrategy strategy, IndexReaderContext context, Bits topAcceptDocs,
                                    Shape inputShape, final int facetLevel, int maxCells) throws IOException {
     if (maxCells > (MAX_ROWS_OR_COLUMNS * MAX_ROWS_OR_COLUMNS)) {
       throw new IllegalArgumentException(""maxCells ("" + maxCells + "") should be <= "" + MAX_ROWS_OR_COLUMNS);
     }
     if (inputShape == null) {
       inputShape = strategy.getSpatialContext().getWorldBounds();
     }
     final Rectangle inputRect = inputShape.getBoundingBox();
     //First get the rect of the cell at the bottom-left at depth facetLevel
     final SpatialPrefixTree grid = strategy.getGrid();
     final SpatialContext ctx = grid.getSpatialContext();
     final Point cornerPt = ctx.makePoint(inputRect.getMinX(), inputRect.getMinY());
     final CellIterator cellIterator = grid.getTreeCellIterator(cornerPt, facetLevel);
     Cell cornerCell = null;
     while (cellIterator.hasNext()) {
       cornerCell = cellIterator.next();
     }
     assert cornerCell != null && cornerCell.getLevel() == facetLevel : ""Cell not at target level: "" + cornerCell;
     final Rectangle cornerRect = (Rectangle) cornerCell.getShape();
     assert cornerRect.hasArea();
     //Now calculate the number of columns and rows necessary to cover the inputRect
     double heatMinX = cornerRect.getMinX();//note: we might change this below...
     final double cellWidth = cornerRect.getWidth();
     final Rectangle worldRect = ctx.getWorldBounds();
     final int columns = calcRowsOrCols(cellWidth, heatMinX, inputRect.getWidth(), inputRect.getMinX(), worldRect.getWidth());
     final double heatMinY = cornerRect.getMinY();
     final double cellHeight = cornerRect.getHeight();
     final int rows = calcRowsOrCols(cellHeight, heatMinY, inputRect.getHeight(), inputRect.getMinY(), worldRect.getHeight());
     assert rows > 0 && columns > 0;
     if (columns > MAX_ROWS_OR_COLUMNS || rows > MAX_ROWS_OR_COLUMNS || columns * rows > maxCells) {
       throw new IllegalArgumentException(
           ""Too many cells ("" + columns + "" x "" + rows + "") for level "" + facetLevel + "" shape "" + inputRect);
     }
 
     //Create resulting heatmap bounding rectangle & Heatmap object.
     final double halfCellWidth = cellWidth / 2.0;
     // if X world-wraps, use world bounds' range
     if (columns * cellWidth + halfCellWidth > worldRect.getWidth()) {
       heatMinX = worldRect.getMinX();
     }
     double heatMaxX = heatMinX + columns * cellWidth;
     if (Math.abs(heatMaxX - worldRect.getMaxX()) < halfCellWidth) {//numeric conditioning issue
       heatMaxX = worldRect.getMaxX();
     } else if (heatMaxX > worldRect.getMaxX()) {//wraps dateline (won't happen if !geo)
       heatMaxX = heatMaxX - worldRect.getMaxX() +  worldRect.getMinX();
     }
     final double halfCellHeight = cellHeight / 2.0;
     double heatMaxY = heatMinY + rows * cellHeight;
     if (Math.abs(heatMaxY - worldRect.getMaxY()) < halfCellHeight) {//numeric conditioning issue
       heatMaxY = worldRect.getMaxY();
     }
 
     final Heatmap heatmap = new Heatmap(columns, rows, ctx.makeRectangle(heatMinX, heatMaxX, heatMinY, heatMaxY));
 
     //All ancestor cell counts (of facetLevel) will be captured during facet visiting and applied later. If the data is
     // just points then there won't be any ancestors.
     //Facet count of ancestors covering all of the heatmap:
     int[] allCellsAncestorCount = new int[1]; // single-element array so it can be accumulated in the inner class
     //All other ancestors:
     Map<Rectangle,Integer> ancestors = new HashMap<>();
 
     //Now lets count some facets!
     PrefixTreeFacetCounter.compute(strategy, context, topAcceptDocs, inputShape, facetLevel,
         new PrefixTreeFacetCounter.FacetVisitor() {
       @Override
       public void visit(Cell cell, int count) {
         final double heatMinX = heatmap.region.getMinX();
         final Rectangle rect = (Rectangle) cell.getShape();
         if (cell.getLevel() == facetLevel) {//heatmap level; count it directly
           //convert to col & row
           int column;
           if (rect.getMinX() >= heatMinX) {
             column = (int) Math.round((rect.getMinX() - heatMinX) / cellWidth);
           } else { // due to dateline wrap
             column = (int) Math.round((rect.getMinX() + 360 - heatMinX) / cellWidth);
           }
           int row = (int) Math.round((rect.getMinY() - heatMinY) / cellHeight);
           //note: unfortunately, it's possible for us to visit adjacent cells to the heatmap (if the SpatialPrefixTree
           // allows adjacent cells to overlap on the seam), so we need to skip them
           if (column < 0 || column >= heatmap.columns || row < 0 || row >= heatmap.rows) {
             return;
           }
           // increment
           heatmap.counts[column * heatmap.rows + row] += count;
 
         } else if (rect.relate(heatmap.region) == SpatialRelation.CONTAINS) {//containing ancestor
           allCellsAncestorCount[0] += count;
 
         } else { // ancestor
           // note: not particularly efficient (possible put twice, and Integer wrapper); oh well
           Integer existingCount = ancestors.put(rect, count);
           if (existingCount != null) {
             ancestors.put(rect, count + existingCount);
           }
         }
       }
     });
 
     //Update the heatmap counts with ancestor counts
 
     // Apply allCellsAncestorCount
     if (allCellsAncestorCount[0] > 0) {
       for (int i = 0; i < heatmap.counts.length; i++) {
         heatmap.counts[i] += allCellsAncestorCount[0];
       }
     }
 
     // Apply ancestors
     //  note: This approach isn't optimized for a ton of ancestor cells. We'll potentially increment the same cells
     //    multiple times in separate passes if any ancestors overlap. IF this poses a problem, we could optimize it
     //    with additional complication by keeping track of intervals in a sorted tree structure (possible TreeMap/Set)
     //    and iterate them cleverly such that we just make one pass at this stage.
 
     int[] pair = new int[2];//output of intersectInterval
     for (Map.Entry<Rectangle, Integer> entry : ancestors.entrySet()) {
-      Rectangle rect = entry.getKey();
+      Rectangle rect = entry.getKey(); // from a cell (thus doesn't cross DL)
       final int count = entry.getValue();
+
       //note: we approach this in a way that eliminates int overflow/underflow (think huge cell, tiny heatmap)
       intersectInterval(heatMinY, heatMaxY, cellHeight, rows, rect.getMinY(), rect.getMaxY(), pair);
       final int startRow = pair[0];
       final int endRow = pair[1];
 
       if (!heatmap.region.getCrossesDateLine()) {
         intersectInterval(heatMinX, heatMaxX, cellWidth, columns, rect.getMinX(), rect.getMaxX(), pair);
         final int startCol = pair[0];
         final int endCol = pair[1];
         incrementRange(heatmap, startCol, endCol, startRow, endRow, count);
 
       } else {
+        // note: the cell rect might intersect 2 disjoint parts of the heatmap, so we do the left & right separately
+        final int leftColumns = (int) Math.round((180 - heatMinX) / cellWidth);
+        final int rightColumns = heatmap.columns - leftColumns;
         //left half of dateline:
-        if (rect.getMaxX() >= heatMinX) {
-          final int leftColumns = (int) Math.round((180 - heatMinX) / cellWidth) + 1;
+        if (rect.getMaxX() > heatMinX) {
           intersectInterval(heatMinX, 180, cellWidth, leftColumns, rect.getMinX(), rect.getMaxX(), pair);
           final int startCol = pair[0];
           final int endCol = pair[1];
           incrementRange(heatmap, startCol, endCol, startRow, endRow, count);
         }
         //right half of dateline
-        if (rect.getMinY() <= heatMaxX) {
-          final int rightColumns = (int) Math.round(heatMaxX / cellWidth) + 1;
-          intersectInterval(0, heatMaxX, cellWidth, rightColumns, rect.getMinX(), rect.getMaxX(), pair);
-          final int startCol = pair[0];
-          final int endCol = pair[1];
+        if (rect.getMinX() < heatMaxX) {
+          intersectInterval(-180, heatMaxX, cellWidth, rightColumns, rect.getMinX(), rect.getMaxX(), pair);
+          final int startCol = pair[0] + leftColumns;
+          final int endCol = pair[1] + leftColumns;
           incrementRange(heatmap, startCol, endCol, startRow, endRow, count);
         }
       }
-
     }
 
     return heatmap;
   }
\ No newline at end of file
",Buggy,"LUCENE-7291: Fix spatial HeatmapFacetCounter bug with dateline and large non-point shapes
"
lucene-solr,36488.json,75b0b5312c6f7722b88088fbc590259e9cd31567,"@@ -1,42 +1,34 @@
   private void count(ValueSource valueSource, List<MatchingDocs> matchingDocs) throws IOException {
 
     DoubleRange[] ranges = (DoubleRange[]) this.ranges;
 
     LongRange[] longRanges = new LongRange[ranges.length];
     for(int i=0;i<ranges.length;i++) {
       DoubleRange range = ranges[i];
       longRanges[i] =  new LongRange(range.label,
                                      NumericUtils.doubleToSortableLong(range.minIncl), true,
                                      NumericUtils.doubleToSortableLong(range.maxIncl), true);
     }
 
     LongRangeCounter counter = new LongRangeCounter(longRanges);
 
-    // Compute min & max over all ranges:
-    double minIncl = Double.POSITIVE_INFINITY;
-    double maxIncl = Double.NEGATIVE_INFINITY;
-    for(DoubleRange range : ranges) {
-      minIncl = Math.min(minIncl, range.minIncl);
-      maxIncl = Math.max(maxIncl, range.maxIncl);
-    }
-
     int missingCount = 0;
     for (MatchingDocs hits : matchingDocs) {
       FunctionValues fv = valueSource.getValues(Collections.emptyMap(), hits.context);
       final int length = hits.bits.length();
       int doc = 0;
       totCount += hits.totalHits;
       while (doc < length && (doc = hits.bits.nextSetBit(doc)) != -1) {
         // Skip missing docs:
         if (fv.exists(doc)) {
           counter.add(NumericUtils.doubleToSortableLong(fv.doubleVal(doc)));
         } else {
           missingCount++;
         }
         doc++;
       }
     }
 
     missingCount += counter.fillCounts(counts);
     totCount -= missingCount;
   }
\ No newline at end of file
",NotBuggy,"fix test bug; remove dead code

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1555715 13f79535-47bb-0310-9956-ffa450edef68
"
lucene-solr,36489.json,75b0b5312c6f7722b88088fbc590259e9cd31567,"@@ -1,39 +1,31 @@
   private void count(ValueSource valueSource, List<MatchingDocs> matchingDocs) throws IOException {
 
     LongRange[] ranges = (LongRange[]) this.ranges;
 
-    // Compute min & max over all ranges:
-    long minIncl = Long.MAX_VALUE;
-    long maxIncl = Long.MIN_VALUE;
-    for(LongRange range : ranges) {
-      minIncl = Math.min(minIncl, range.minIncl);
-      maxIncl = Math.max(maxIncl, range.maxIncl);
-    }
-
     LongRangeCounter counter = new LongRangeCounter(ranges);
 
     int missingCount = 0;
     for (MatchingDocs hits : matchingDocs) {
       FunctionValues fv = valueSource.getValues(Collections.emptyMap(), hits.context);
       final int length = hits.bits.length();
       int doc = 0;
       totCount += hits.totalHits;
       while (doc < length && (doc = hits.bits.nextSetBit(doc)) != -1) {
         // Skip missing docs:
         if (fv.exists(doc)) {
           counter.add(fv.longVal(doc));
         } else {
           missingCount++;
         }
 
         doc++;
       }
     }
     
     int x = counter.fillCounts(counts);
 
     missingCount += x;
 
     //System.out.println(""totCount "" + totCount + "" missingCount "" + counter.missingCount);
     totCount -= missingCount;
   }
\ No newline at end of file
",NotBuggy,"fix test bug; remove dead code

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1555715 13f79535-47bb-0310-9956-ffa450edef68
"
lucene-solr,46441.json,e283271aaf6da3033156f36b421d3241b5499d4e,"@@ -1,45 +1,51 @@
   private DocMap[] buildDocMaps(List<CodecReader> readers, Sort indexSort) throws IOException {
 
     int numReaders = readers.size();
 
     if (indexSort == null) {
       // no index sort ... we only must map around deletions, and rebase to the merged segment's docID space
 
       int totalDocs = 0;
       DocMap[] docMaps = new DocMap[numReaders];
 
       // Remap docIDs around deletions:
       for (int i = 0; i < numReaders; i++) {
         LeafReader reader = readers.get(i);
         Bits liveDocs = reader.getLiveDocs();
 
         final PackedLongValues delDocMap;
         if (liveDocs != null) {
           delDocMap = removeDeletes(reader.maxDoc(), liveDocs);
         } else {
           delDocMap = null;
         }
 
         final int docBase = totalDocs;
         docMaps[i] = new DocMap() {
           @Override
           public int get(int docID) {
             if (liveDocs == null) {
               return docBase + docID;
             } else if (liveDocs.get(docID)) {
               return docBase + (int) delDocMap.get(docID);
             } else {
               return -1;
             }
           }
         };
         totalDocs += reader.numDocs();
       }
 
       return docMaps;
 
     } else {
       // do a merge sort of the incoming leaves:
-      return MultiSorter.sort(indexSort, readers);
+      long t0 = System.nanoTime();
+      DocMap[] result = MultiSorter.sort(indexSort, readers);
+      long t1 = System.nanoTime();
+      if (infoStream.isEnabled(""SM"")) {
+        infoStream.message(""SM"", String.format(Locale.ROOT, ""%.2f msec to build merge sorted DocMaps"", (t1-t0)/1000000.0));
+      }
+      return result;
     }
   }
\ No newline at end of file
",NotBuggy,"LUCENE-6766: more IW.infoStream logging around sorting; fix test bug
"
lucene-solr,46444.json,e283271aaf6da3033156f36b421d3241b5499d4e,"@@ -1,61 +1,65 @@
   private List<CodecReader> maybeSortReaders(List<CodecReader> originalReaders, SegmentInfo segmentInfo) throws IOException {
 
     // Default to identity:
     for(int i=0;i<originalReaders.size();i++) {
       leafDocMaps[i] = new DocMap() {
           @Override
           public int get(int docID) {
             return docID;
           }
         };
     }
 
     Sort indexSort = segmentInfo.getIndexSort();
     if (indexSort == null) {
       return originalReaders;
     }
 
     // If an incoming reader is not sorted, because it was flushed by IW, we sort it here:
     final Sorter sorter = new Sorter(indexSort);
     List<CodecReader> readers = new ArrayList<>(originalReaders.size());
 
     for (CodecReader leaf : originalReaders) {
       Sort segmentSort = leaf.getIndexSort();
 
       if (segmentSort == null) {
         // TODO: fix IW to also sort when flushing?  It's somewhat tricky because of stored fields and term vectors, which write ""live""
         // to their index files on each indexed document:
 
         // This segment was written by flush, so documents are not yet sorted, so we sort them now:
+        long t0 = System.nanoTime();
         Sorter.DocMap sortDocMap = sorter.sort(leaf);
+        long t1 = System.nanoTime();
+        double msec = (t1-t0)/1000000.0;
+        
         if (sortDocMap != null) {
           if (infoStream.isEnabled(""SM"")) {
-            infoStream.message(""SM"", ""segment "" + leaf + "" is not sorted; wrapping for sort "" + indexSort + "" now"");
+            infoStream.message(""SM"", String.format(Locale.ROOT, ""segment %s is not sorted; wrapping for sort %s now (%.2f msec to sort)"", leaf, indexSort, msec));
           }
           leaf = SlowCodecReaderWrapper.wrap(SortingLeafReader.wrap(new MergeReaderWrapper(leaf), sortDocMap));
           leafDocMaps[readers.size()] = new DocMap() {
               @Override
               public int get(int docID) {
                 return sortDocMap.oldToNew(docID);
               }
             };
         } else {
           if (infoStream.isEnabled(""SM"")) {
-            infoStream.message(""SM"", ""segment "" + leaf + "" is not sorted, but is already accidentally in sort "" + indexSort + "" order"");
+            infoStream.message(""SM"", String.format(Locale.ROOT, ""segment %s is not sorted, but is already accidentally in sort %s order (%.2f msec to sort)"", leaf, indexSort, msec));
           }
         }
 
       } else {
         if (segmentSort.equals(indexSort) == false) {
           throw new IllegalArgumentException(""index sort mismatch: merged segment has sort="" + indexSort + "" but to-be-merged segment has sort="" + segmentSort);
         }
         if (infoStream.isEnabled(""SM"")) {
           infoStream.message(""SM"", ""segment "" + leaf + "" already sorted"");
         }
       }
 
       readers.add(leaf);
     }
 
     return readers;
   }
\ No newline at end of file
",NotBuggy,"LUCENE-6766: more IW.infoStream logging around sorting; fix test bug
"
lucene-solr,44598.json,a2a9f2a6f9cba3b27b248102d88431b8b234530e,"@@ -1,32 +1,34 @@
     public SeekStatus seekCeil(BytesRef text) {
 
       // TODO: we could instead keep the BytesRefHash
       // intact so this is a hash lookup
 
       // binary search:
       int lo = 0;
       int hi = numTerms - 1;
       while (hi >= lo) {
         int mid = (lo + hi) >>> 1;
         int textStart = postingsArray.textStarts[sortedTermIDs[mid]];
         terms.bytePool.setBytesRef(scratch, textStart);
         int cmp = scratch.compareTo(text);
         if (cmp < 0) {
           lo = mid + 1;
         } else if (cmp > 0) {
           hi = mid - 1;
         } else {
           // found:
           ord = mid;
           return SeekStatus.FOUND;
         }
       }
 
       // not found:
       ord = lo + 1;
-      if (ord == numTerms) {
+      if (ord >= numTerms) {
         return SeekStatus.END;
       } else {
+        int textStart = postingsArray.textStarts[sortedTermIDs[ord]];
+        terms.bytePool.setBytesRef(scratch, textStart);
         return SeekStatus.NOT_FOUND;
       }
     }
\ No newline at end of file
",Buggy,"test seekCeil in pull postings API; fix trunk-only bug

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1611305 13f79535-47bb-0310-9956-ffa450edef68
"
jna,165.json,535518713bc51e6eacefeaeaccc7033ade905a9a,"@@ -1,14 +1,15 @@
         private static long getVisualID(GraphicsConfiguration config) {
             // Use reflection to call
             // X11GraphicsConfig.getVisual
             try {
                 Object o = config.getClass()
                     .getMethod(""getVisual"", (Class[])null)
                     .invoke(config, (Object[])null);
                 return ((Number)o).longValue();
             }
             catch (Exception e) {
+                // FIXME properly handle this error
                 e.printStackTrace();
                 return -1;
             }
         }
\ No newline at end of file
",NotBuggy,"fix mappings to properly work on 32-bit windows (fixes memory faults)
"
jna,146.json,535518713bc51e6eacefeaeaccc7033ade905a9a,"@@ -1,17 +1,18 @@
-				public boolean callback(final HWND hwnd, final Pointer arg1) {
-					try {
-						final boolean visible = !onlyVisibleWindows
-								|| User32.INSTANCE.IsWindowVisible(hwnd);
-						if (visible) {
-							final String title = getWindowTitle(hwnd);
-							final String filePath = getProcessFilePath(hwnd);
-							final Rectangle locAndSize = getWindowLocationAndSize(hwnd);
-							result.add(new DesktopWindow(hwnd, title, filePath,
-									locAndSize));
-						}
-					} catch (final Exception e) {
-						e.printStackTrace();
-					}
-
-					return true;
-				}
\ No newline at end of file
+                public boolean callback(final HWND hwnd, final Pointer arg1) {
+                    try {
+                        final boolean visible = !onlyVisibleWindows
+                            || User32.INSTANCE.IsWindowVisible(hwnd);
+                        if (visible) {
+                            final String title = getWindowTitle(hwnd);
+                            final String filePath = getProcessFilePath(hwnd);
+                            final Rectangle locAndSize = getWindowLocationAndSize(hwnd);
+                            result.add(new DesktopWindow(hwnd, title, filePath,
+                                                         locAndSize));
+                        }
+                    } catch (final Exception e) {
+                        // FIXME properly handle whatever error is raised
+                        e.printStackTrace();
+                    }
+                    
+                    return true;
+                }
\ No newline at end of file
",Buggy,"fix mappings to properly work on 32-bit windows (fixes memory faults)
"
jna,3926.json,e5958a2a159cd87a8168c801f569f5bcc7511c25,"@@ -1,86 +1,84 @@
     public Object invoke(Class returnType, Object[] inArgs, Map options) {
         // Clone the argument array to obtain a scratch space for modified
         // types/values
         Object[] args = { };
         if (inArgs != null) {
             if (inArgs.length > MAX_NARGS) {
                 throw new UnsupportedOperationException(""Maximum argument count is "" + MAX_NARGS);
             }
             args = new Object[inArgs.length];
             System.arraycopy(inArgs, 0, args, 0, args.length);
         }
 
         TypeMapper mapper = 
             (TypeMapper)options.get(Library.OPTION_TYPE_MAPPER);
         Method invokingMethod = (Method)options.get(OPTION_INVOKING_METHOD);
         for (int i=0; i < args.length; i++) {
             args[i] = convertArgument(args, i, invokingMethod, mapper);
         }
         
         Class nativeType = returnType;
         FromNativeConverter resultConverter = null;
         if (NativeMapped.class.isAssignableFrom(returnType)) {
             NativeMappedConverter tc = new NativeMappedConverter(returnType);
             resultConverter = tc;
             nativeType = tc.nativeType();
         }
         else if (mapper != null) {
             resultConverter = mapper.getFromNativeConverter(returnType);
             if (resultConverter != null) {
                 nativeType = resultConverter.nativeType();
             }
         }
 
         Object result = invoke(args, nativeType);
 
         // Convert the result to a custom value/type if appropriate
         if (resultConverter != null) {
             FromNativeContext context;
             
             if (invokingMethod != null) {
                 context = new MethodResultContext(returnType, this, inArgs, invokingMethod);
             } else {
                 context = new FunctionResultContext(returnType, this, inArgs);
             }
             result = resultConverter.fromNative(result, context);
         }
 
         // Sync all memory which might have been modified by the native call
         if (inArgs != null) {
             for (int i=0; i < inArgs.length; i++) {
                 Object arg = inArgs[i];
                 if (arg == null)
                     continue;
                 if (arg instanceof Structure) {
                     if (!(arg instanceof Structure.ByValue)) {
                         ((Structure)arg).read();
                     }
                 }
                 else if (args[i] instanceof StringArray) {
-                    // Read back arrays of String, just in case they
-                    // were modified
                     ((StringArray)args[i]).read();
                 }
                 else if (args[i] instanceof PointerArray) {
                     PointerArray array = (PointerArray)args[i];
                     array.read();
                     if (Structure.ByReference[].class.isAssignableFrom(arg.getClass())) {
                         Class type = arg.getClass().getComponentType();
                         Structure[] ss = (Structure[])arg;
                         for (int si=0;si < ss.length;si++) {
                             Pointer p = array.getPointer(Pointer.SIZE * si);
                             ss[si] = Structure.updateStructureByReference(type, ss[si], p);
                         }
                     }
                 }
                 else if (Structure[].class.isAssignableFrom(arg.getClass())) {
                     Structure[] ss = (Structure[])arg;
                     for (int si=0;si < ss.length;si++) {
                         ss[si].read();
                     }
                 }
             }
         }
                         
         return result;
     }
\ No newline at end of file
",NotBuggy,"Fix bug in stdcall function mapping when using struct by value
Defer size_t/off_t definition, for now

git-svn-id: https://svn.java.net/svn/jna~svn/trunk@436 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80
"
jna,3554.json,e5958a2a159cd87a8168c801f569f5bcc7511c25,"@@ -1,23 +1,30 @@
-    private int getNativeSize(Class type, Object value) {
-        if (Structure.class.isAssignableFrom(type)) {
-            if (ByReference.class.isAssignableFrom(type)) {
-                return Pointer.SIZE;
-            }
-            else {
-                if (value == null)
-                    value = newInstance(type);
-                Structure s = (Structure)value;
-                return s.size();
-            }
-        }
+    private static int getNativeSize(Class type, Object value) {
         if (type.isArray()) {
             int len = Array.getLength(value);
             if (len > 0) {
                 Object o = Array.get(value, 0);
                 return len * getNativeSize(type.getComponentType(), o);
             }
             // Don't process zero-length arrays
-            throw new IllegalArgumentException(""Arrays of length zero not allowed in structure: "" + this);
+            throw new IllegalArgumentException(""Arrays of length zero not allowed in structure: "" + type);
         }
-        return getNativeSize(type);
+        // May provide this in future; problematic on read, since we can't
+        // auto-create a java.nio.Buffer w/o knowing its size
+        if (Buffer.class.isAssignableFrom(type)) {
+            throw new IllegalArgumentException(""the type \"""" + type.getName() 
+                                               + ""\"" is not supported as a structure field"");
+        }
+        if (Structure.class.isAssignableFrom(type)
+            && !Structure.ByReference.class.isAssignableFrom(type)) {
+            if (value == null)
+                value = newInstance(type);
+            return ((Structure)value).size();
+        }
+        try {
+            return Native.getNativeSize(type);
+        }
+        catch(IllegalArgumentException e) {
+            throw new IllegalArgumentException(""The type \"""" + type.getName() 
+                                               + ""\"" is not supported as a structure field"");
+        }
     }
\ No newline at end of file
",Buggy,"Fix bug in stdcall function mapping when using struct by value
Defer size_t/off_t definition, for now

git-svn-id: https://svn.java.net/svn/jna~svn/trunk@436 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80
"
jna,3652.json,4068c6da1a057942ee7eb167c0e5436b0f225761,"@@ -1,9 +1,10 @@
     Object getField(StructField structField) {
         try {
             return structField.field.get(this);
         }
         catch (Exception e) {
             throw new Error(""Exception reading field '""
-                            + structField.name + ""' in "" + getClass(), e);
+                            + structField.name + ""' in "" + getClass() 
+                            + "": "" + e);
         }
     }
\ No newline at end of file
",NotBuggy,"Fix bug in nested struct array read/write

git-svn-id: https://svn.java.net/svn/jna~svn/trunk@445 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80
"
jna,4096.json,4068c6da1a057942ee7eb167c0e5436b0f225761,"@@ -1,137 +1,147 @@
     void writeField(StructField structField) {
         // Get the offset of the field
         int offset = structField.offset;
 
         // Get the value from the field
         Object value = getField(structField);
         
         // Determine the type of the field
         Class nativeType = structField.type;
         ToNativeConverter converter = structField.writeConverter;
         if (converter != null) {
             value = converter.toNative(value, 
                     new StructureWriteContext(this, structField.field));
             // Assume any null values are pointers
             nativeType = value != null ? value.getClass() : Pointer.class;
         }
 
         // Java strings get converted to C strings, where a Pointer is used
         if (String.class == nativeType
             || WString.class == nativeType) {
 
             // Allocate a new string in memory
             boolean wide = nativeType == WString.class;
             if (value != null) {
                 NativeString nativeString = new NativeString(value.toString(), wide);
                 // Keep track of allocated C strings to avoid 
                 // premature garbage collection of the memory.
                 nativeStrings.put(structField.name, nativeString);
                 value = nativeString.getPointer();
             }
             else {
                 value = null;
             }
         }
 
         // Set the value at the offset according to its type
         if (nativeType == boolean.class || nativeType == Boolean.class) {
             memory.setInt(offset, Boolean.TRUE.equals(value) ? -1 : 0);
         }
         else if (nativeType == byte.class || nativeType == Byte.class) {
             memory.setByte(offset, ((Byte)value).byteValue());
         }
         else if (nativeType == short.class || nativeType == Short.class) {
             memory.setShort(offset, ((Short)value).shortValue());
         }
         else if (nativeType == char.class || nativeType == Character.class) {
             memory.setChar(offset, ((Character)value).charValue());
         }
         else if (nativeType == int.class || nativeType == Integer.class) {
             memory.setInt(offset, ((Integer)value).intValue());
         }
         else if (nativeType == long.class || nativeType == Long.class) {
             memory.setLong(offset, ((Long)value).longValue());
         }
         else if (nativeType == float.class || nativeType == Float.class) {
             memory.setFloat(offset, ((Float)value).floatValue());
         }
         else if (nativeType == double.class || nativeType == Double.class) {
             memory.setDouble(offset, ((Double)value).doubleValue());
         }
         else if (nativeType == Pointer.class) {
             memory.setPointer(offset, (Pointer)value);
         }
         else if (nativeType == String.class) {
             memory.setPointer(offset, (Pointer)value);
         }
         else if (nativeType == WString.class) {
             memory.setPointer(offset, (Pointer)value);
         }
         else if (nativeType.isArray()) {
             Class cls = nativeType.getComponentType();
             if (cls == byte.class) {
                 byte[] buf = (byte[])value;
                 memory.write(offset, buf, 0, buf.length);
             }
             else if (cls == short.class) {
                 short[] buf = (short[])value;
                 memory.write(offset, buf, 0, buf.length);
             }
             else if (cls == char.class) {
                 char[] buf = (char[])value;
                 memory.write(offset, buf, 0, buf.length);
             }
             else if (cls == int.class) {
                 int[] buf = (int[])value;
                 memory.write(offset, buf, 0, buf.length);
             }
             else if (cls == long.class) {
                 long[] buf = (long[])value;
                 memory.write(offset, buf, 0, buf.length);
             }
             else if (cls == float.class) {
                 float[] buf = (float[])value;
                 memory.write(offset, buf, 0, buf.length);
             }
             else if (cls == double.class) {
                 double[] buf = (double[])value;
                 memory.write(offset, buf, 0, buf.length);
             }
             else if (Pointer.class.isAssignableFrom(cls)) {
                 Pointer[] buf = (Pointer[])value;
                 memory.write(offset, buf, 0, buf.length);
             }
-            else if (Structure.class.isAssignableFrom(cls)
-                     && ByReference.class.isAssignableFrom(cls)) {
+            else if (Structure.class.isAssignableFrom(cls)) {
                 Structure[] sbuf = (Structure[])value;
-                Pointer[] buf = new Pointer[sbuf.length];
-                for (int i=0;i < sbuf.length;i++) {
-                    buf[i] = sbuf[i] == null ? null : sbuf[i].getPointer();
+                if (ByReference.class.isAssignableFrom(cls)) {
+                    Pointer[] buf = new Pointer[sbuf.length];
+                    for (int i=0;i < sbuf.length;i++) {
+                        buf[i] = sbuf[i] == null ? null : sbuf[i].getPointer();
+                    }
+                    memory.write(offset, buf, 0, buf.length);
                 }
-                memory.write(offset, buf, 0, buf.length);
+                else {
+                    for (int i=0;i < sbuf.length;i++) {
+                        if (sbuf[i] == null) {
+                            sbuf[i] = newInstance(cls);
+                            sbuf[i].useMemory(memory, offset + i * sbuf[i].size());
+                        }
+                        sbuf[i].write();
+                    }
+                }
             }
             else {
                 throw new IllegalArgumentException(""Inline array of ""
                                                    + cls + "" not supported"");
             }
         }
         else if (Structure.class.isAssignableFrom(nativeType)) {
             Structure s = (Structure)value;
             if (ByReference.class.isAssignableFrom(nativeType)) {
                 memory.setPointer(offset, s == null ? null : s.getPointer());
             }
             else {
                 s.useMemory(memory, offset);
                 s.write();
             }
         }
         else if (Callback.class.isAssignableFrom(nativeType)) {
             memory.setPointer(offset, CallbackReference.getFunctionPointer((Callback)value));
         }
         else {
         	String msg = ""Structure field \"""" + structField.name
         	    + ""\"" was declared as "" + nativeType 
         	    + "", which is not supported within a Structure"";
             throw new IllegalArgumentException(msg);
         }
     }
\ No newline at end of file
",Buggy,"Fix bug in nested struct array read/write

git-svn-id: https://svn.java.net/svn/jna~svn/trunk@445 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80
"
jna,4092.json,4068c6da1a057942ee7eb167c0e5436b0f225761,"@@ -1,136 +1,146 @@
     Object readField(StructField structField) {
         
         // Get the offset of the field
         int offset = structField.offset;
 
         // Determine the type of the field
         Class nativeType = structField.type;
         FromNativeConverter readConverter = structField.readConverter;
         if (readConverter != null) {
             nativeType = readConverter.nativeType();
         }
 
         // Get the value at the offset according to its type
         Object result = null;
         if (Structure.class.isAssignableFrom(nativeType)) {
             Structure s = (Structure)getField(structField);
             if (ByReference.class.isAssignableFrom(nativeType)) {
                 s = updateStructureByReference(nativeType, s, memory.getPointer(offset));
             }
             else {
                 s.useMemory(memory, offset);
                 s.read();
             }
             result = s;
         }
         else if (nativeType == boolean.class || nativeType == Boolean.class) {
             result = Boolean.valueOf(memory.getInt(offset) != 0);
         }
         else if (nativeType == byte.class || nativeType == Byte.class) {
             result = new Byte(memory.getByte(offset));
         }
         else if (nativeType == short.class || nativeType == Short.class) {
             result = new Short(memory.getShort(offset));
         }
         else if (nativeType == char.class || nativeType == Character.class) {
             result = new Character(memory.getChar(offset));
         }
         else if (nativeType == int.class || nativeType == Integer.class) {
             result = new Integer(memory.getInt(offset));
         }
         else if (nativeType == long.class || nativeType == Long.class) {
             result = new Long(memory.getLong(offset));
         }
         else if (nativeType == float.class || nativeType == Float.class) {
             result=new Float(memory.getFloat(offset));
         }
         else if (nativeType == double.class || nativeType == Double.class) {
             result = new Double(memory.getDouble(offset));
         }
         else if (nativeType == Pointer.class) {
             result = memory.getPointer(offset);
         }
         else if (nativeType == String.class) {
             Pointer p = memory.getPointer(offset);
             result = p != null ? p.getString(0) : null;
         }
         else if (nativeType == WString.class) {
             Pointer p = memory.getPointer(offset);
             result = p != null ? new WString(p.getString(0, true)) : null;
         }
         else if (Callback.class.isAssignableFrom(nativeType)) {
             // Overwrite the Java memory if the native pointer is a different
             // function pointer.
             Pointer fp = memory.getPointer(offset);
             if (fp == null) {
                 result = null;
             }
             else {
                 Callback cb = (Callback)getField(structField);
                 Pointer oldfp = CallbackReference.getFunctionPointer(cb);
                 if (!fp.equals(oldfp)) {
                     cb = CallbackReference.getCallback(nativeType, fp);
                 }
                 result = cb;
             }
         }
         else if (nativeType.isArray()) {
             Class cls = nativeType.getComponentType();
             int length = 0;
             Object o = getField(structField);
             if (o == null) {
                 throw new IllegalStateException(""Array field in Structure not initialized"");
             }
             length = Array.getLength(o);
             result = o;
 
             if (cls == byte.class) {
                 memory.read(offset, (byte[])result, 0, length);
             }
             else if (cls == short.class) {
                 memory.read(offset, (short[])result, 0, length);
             }
             else if (cls == char.class) {
                 memory.read(offset, (char[])result, 0, length);
             }
             else if (cls == int.class) {
                 memory.read(offset, (int[])result, 0, length);
             }
             else if (cls == long.class) {
                 memory.read(offset, (long[])result, 0, length);
             }
             else if (cls == float.class) {
                 memory.read(offset, (float[])result, 0, length);
             }
             else if (cls == double.class) {
                 memory.read(offset, (double[])result, 0, length);
             }
             else if (Pointer.class.isAssignableFrom(cls)) {
                 memory.read(offset, (Pointer[])result, 0, length);
             }
-            else if (Structure.class.isAssignableFrom(cls)
-                     && ByReference.class.isAssignableFrom(cls)) {
+            else if (Structure.class.isAssignableFrom(cls)) {
                 Structure[] sarray = (Structure[])result;
-                Pointer[] parray = memory.getPointerArray(offset, sarray.length);
-                for (int i=0;i < sarray.length;i++) {
-                    sarray[i] = updateStructureByReference(cls, sarray[i], parray[i]);
+                if (ByReference.class.isAssignableFrom(cls)) {
+                    Pointer[] parray = memory.getPointerArray(offset, sarray.length);
+                    for (int i=0;i < sarray.length;i++) {
+                        sarray[i] = updateStructureByReference(cls, sarray[i], parray[i]);
+                    }
+                }
+                else {
+                    for (int i=0;i < sarray.length;i++) {
+                        if (sarray[i] == null) {
+                            sarray[i] = newInstance(cls);
+                            sarray[i].useMemory(memory, offset + i * sarray[i].size());
+                        }
+                        sarray[i].read();
+                    }
                 }
             }
             else {
                 throw new IllegalArgumentException(""Array of ""
                                                    + cls + "" not supported"");
             }
         }
         else {
             throw new IllegalArgumentException(""Unsupported field type \""""
                                                + nativeType + ""\"""");
         }
 
         if (readConverter != null) {
             result = readConverter.fromNative(result, structField.context);
         }
 
         // Update the value on the field
         setField(structField, result);
         return result;
     }
\ No newline at end of file
",Buggy,"Fix bug in nested struct array read/write

git-svn-id: https://svn.java.net/svn/jna~svn/trunk@445 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80
"
jna,2043.json,fe79ff84115369d6cc0e1d6fa240d2c431094af7,"@@ -1,3 +1,3 @@
     public static boolean FAILED(int hr) {
-        return (hr != S_OK);
+        return hr < 0;
     }
\ No newline at end of file
",Buggy,"Fix SUCCEEDED and FAILED instead of trying to fix the bug where it's visible. See MSDN for FAILED and SUCCEEDED definitions

Changes
"
jna,2041.json,fe79ff84115369d6cc0e1d6fa240d2c431094af7,"@@ -1,6 +1,3 @@
     public static boolean SUCCEEDED(int hr) {
-        if (hr == S_OK)
-            return true;
-        else
-            return false;
+        return hr >= 0;
     }
\ No newline at end of file
",Buggy,"Fix SUCCEEDED and FAILED instead of trying to fix the bug where it's visible. See MSDN for FAILED and SUCCEEDED definitions

Changes
"
jna,4111.json,64466deb5eb01a0d9c3e27ceb2a89d4e6d546908,"@@ -1,21 +1,21 @@
     private void validateField(String name, Class type) {
         if (typeMapper != null) {
             ToNativeConverter toNative = typeMapper.getToNativeConverter(type);
             if (toNative != null) {
                 validateField(name, toNative.nativeType());
                 return;
             }
         }
         if (type.isArray()) {
             validateField(name, type.getComponentType());
         }
         else {
             try {
                 getNativeSize(type);
             }
             catch(IllegalArgumentException e) {
-                String msg = ""Invalid Structure field in "" + getClass() + "", field name '"" + name + ""' ("" + type + "")"";
+                String msg = ""Invalid Structure field in "" + getClass() + "", field name '"" + name + ""' ("" + type + ""): "" + e.getMessage();
                 throw new IllegalArgumentException(msg, e);
             }
         }
     }
\ No newline at end of file
",NotBuggy,"Ensure exception message includes all faulty field information (fixes broken test)
"
jna,4113.json,64466deb5eb01a0d9c3e27ceb2a89d4e6d546908,"@@ -1,147 +1,147 @@
     private LayoutInfo deriveLayout(boolean force, boolean avoidFFIType) {
         int calculatedSize = 0;
         List fields = getFields(force);
         if (fields == null) {
             return null;
         }
 
         LayoutInfo info = new LayoutInfo();
         info.alignType = this.alignType;
         info.typeMapper = this.typeMapper;
 
         boolean firstField = true;
         for (Iterator i=fields.iterator();i.hasNext();firstField=false) {
             Field field = (Field)i.next();
             int modifiers = field.getModifiers();
 
             Class type = field.getType();
             if (type.isArray()) {
                 info.variable = true;
             }
             StructField structField = new StructField();
             structField.isVolatile = Modifier.isVolatile(modifiers);
             structField.isReadOnly = Modifier.isFinal(modifiers);
             if (structField.isReadOnly) {
                 if (!Platform.RO_FIELDS) {
                     throw new IllegalArgumentException(""This VM does not support read-only fields (field '""
                                                        + field.getName() + ""' within "" + getClass() + "")"");
                 }
                 // In J2SE VMs, this allows overriding the value of final
                 // fields
                 field.setAccessible(true);
             }
             structField.field = field;
             structField.name = field.getName();
             structField.type = type;
 
             // Check for illegal field types
             if (Callback.class.isAssignableFrom(type) && !type.isInterface()) {
                 throw new IllegalArgumentException(""Structure Callback field '""
                                                    + field.getName()
                                                    + ""' must be an interface"");
             }
             if (type.isArray()
                 && Structure.class.equals(type.getComponentType())) {
                 String msg = ""Nested Structure arrays must use a ""
                     + ""derived Structure type so that the size of ""
                     + ""the elements can be determined"";
                 throw new IllegalArgumentException(msg);
             }
 
             int fieldAlignment = 1;
             if (!Modifier.isPublic(field.getModifiers())) {
                 continue;
             }
 
             Object value = getFieldValue(structField.field);
             if (value == null && type.isArray()) {
                 if (force) {
                     throw new IllegalStateException(""Array fields must be initialized"");
                 }
                 // can't calculate size yet, defer until later
                 return null;
             }
             Class nativeType = type;
             if (NativeMapped.class.isAssignableFrom(type)) {
                 NativeMappedConverter tc = NativeMappedConverter.getInstance(type);
                 nativeType = tc.nativeType();
                 structField.writeConverter = tc;
                 structField.readConverter = tc;
                 structField.context = new StructureReadContext(this, field);
             }
             else if (typeMapper != null) {
                 ToNativeConverter writeConverter = typeMapper.getToNativeConverter(type);
                 FromNativeConverter readConverter = typeMapper.getFromNativeConverter(type);
                 if (writeConverter != null && readConverter != null) {
                     value = writeConverter.toNative(value,
                                                     new StructureWriteContext(this, structField.field));
                     nativeType = value != null ? value.getClass() : Pointer.class;
                     structField.writeConverter = writeConverter;
                     structField.readConverter = readConverter;
                     structField.context = new StructureReadContext(this, field);
                 }
                 else if (writeConverter != null || readConverter != null) {
                     String msg = ""Structures require bidirectional type conversion for "" + type;
                     throw new IllegalArgumentException(msg);
                 }
             }
 
             if (value == null) {
                 value = initializeField(structField.field, type);
             }
 
             try {
                 structField.size = getNativeSize(nativeType, value);
                 fieldAlignment = getNativeAlignment(nativeType, value, firstField);
             }
             catch(IllegalArgumentException e) {
                 // Might simply not yet have a type mapper set yet
                 if (!force && typeMapper == null) {
                     return null;
                 }
-                String msg = ""Invalid Structure field in "" + getClass() + "", field name '"" + structField.name + ""' ("" + structField.type + "")"";
+                String msg = ""Invalid Structure field in "" + getClass() + "", field name '"" + structField.name + ""' ("" + structField.type + ""): "" + e.getMessage();
                 throw new IllegalArgumentException(msg, e);
             }
 
             // Align fields as appropriate
             if (fieldAlignment == 0) {
                 throw new Error(""Field alignment is zero for field '"" + structField.name + ""' within "" + getClass());
             }
             info.alignment = Math.max(info.alignment, fieldAlignment);
             if ((calculatedSize % fieldAlignment) != 0) {
                 calculatedSize += fieldAlignment - (calculatedSize % fieldAlignment);
             }
             if (this instanceof Union) {
                 structField.offset = 0;
                 calculatedSize = Math.max(calculatedSize, structField.size);
             }
             else {
                 structField.offset = calculatedSize;
                 calculatedSize += structField.size;
             }
 
             // Save the field in our list
             info.fields.put(structField.name, structField);
 
             if (info.typeInfoField == null
                 || info.typeInfoField.size < structField.size
                 || (info.typeInfoField.size == structField.size
                     && Structure.class.isAssignableFrom(structField.type))) {
                 info.typeInfoField = structField;
             }
         }
 
         if (calculatedSize > 0) {
             int size = addPadding(calculatedSize, info.alignment);
             // Update native FFI type information, if needed
             if (this instanceof ByValue && !avoidFFIType) {
                 getTypeInfo();
             }
             info.size = size;
             return info;
         }
 
         throw new IllegalArgumentException(""Structure "" + getClass()
                                            + "" has unknown or zero size (ensure ""
                                            + ""all fields are public)"");
     }
\ No newline at end of file
",NotBuggy,"Ensure exception message includes all faulty field information (fixes broken test)
"
spring-framework,25502.json,98218687070fc47eb6f91e81d3d714bf96068cc5,"@@ -1,9 +1,7 @@
 	public static void sortBySpecificityAndQuality(List<MediaType> mediaTypes) {
 		Assert.notNull(mediaTypes, ""'mediaTypes' must not be null"");
 		if (mediaTypes.size() > 1) {
-			Comparator<?>[] comparators = new Comparator[2];
-			comparators[0] = MediaType.SPECIFICITY_COMPARATOR;
-			comparators[1] = MediaType.QUALITY_VALUE_COMPARATOR;
-			Collections.sort(mediaTypes, new CompoundComparator<MediaType>(comparators));
+			Collections.sort(mediaTypes, new CompoundComparator<MediaType>(
+					MediaType.SPECIFICITY_COMPARATOR, MediaType.QUALITY_VALUE_COMPARATOR));
 		}
 	}
\ No newline at end of file
",NotBuggy,"Refactor and polish various Comparator impls

 - Refactor CompoundComparator constructor to use varargs
 - Refactor MediaType to consume new varargs constructor
 - Add notNull assertions where appropriate
 - Add generic typing where appropriate
 - Suppress generics warnings elsewhere
 - Fix whitespace errors
"
spring-framework,15028.json,98218687070fc47eb6f91e81d3d714bf96068cc5,"@@ -1,10 +1,10 @@
 	public boolean equals(Object obj) {
 		if (this == obj) {
 			return true;
 		}
 		if (!(obj instanceof NullSafeComparator)) {
 			return false;
 		}
-		NullSafeComparator other = (NullSafeComparator) obj;
+		NullSafeComparator<T> other = (NullSafeComparator<T>) obj;
 		return (this.nonNullComparator.equals(other.nonNullComparator) && this.nullsLow == other.nullsLow);
 	}
\ No newline at end of file
",NotBuggy,"Refactor and polish various Comparator impls

 - Refactor CompoundComparator constructor to use varargs
 - Refactor MediaType to consume new varargs constructor
 - Add notNull assertions where appropriate
 - Add generic typing where appropriate
 - Suppress generics warnings elsewhere
 - Fix whitespace errors
"
spring-framework,15035.json,98218687070fc47eb6f91e81d3d714bf96068cc5,"@@ -1,10 +1,10 @@
 	public boolean equals(Object obj) {
 		if (this == obj) {
 			return true;
 		}
 		if (!(obj instanceof InvertibleComparator)) {
 			return false;
 		}
-		InvertibleComparator other = (InvertibleComparator) obj;
+		InvertibleComparator<T> other = (InvertibleComparator<T>) obj;
 		return (this.comparator.equals(other.comparator) && this.ascending == other.ascending);
 	}
\ No newline at end of file
",NotBuggy,"Refactor and polish various Comparator impls

 - Refactor CompoundComparator constructor to use varargs
 - Refactor MediaType to consume new varargs constructor
 - Add notNull assertions where appropriate
 - Add generic typing where appropriate
 - Suppress generics warnings elsewhere
 - Fix whitespace errors
"
spring-framework,15051.json,98218687070fc47eb6f91e81d3d714bf96068cc5,"@@ -1,10 +1,10 @@
 	public boolean equals(Object obj) {
 		if (this == obj) {
 			return true;
 		}
 		if (!(obj instanceof CompoundComparator)) {
 			return false;
 		}
-		CompoundComparator other = (CompoundComparator) obj;
+		CompoundComparator<T> other = (CompoundComparator<T>) obj;
 		return this.comparators.equals(other.comparators);
 	}
\ No newline at end of file
",NotBuggy,"Refactor and polish various Comparator impls

 - Refactor CompoundComparator constructor to use varargs
 - Refactor MediaType to consume new varargs constructor
 - Add notNull assertions where appropriate
 - Add generic typing where appropriate
 - Suppress generics warnings elsewhere
 - Fix whitespace errors
"
spring-framework,15045.json,98218687070fc47eb6f91e81d3d714bf96068cc5,"@@ -1,5 +1,5 @@
 	public void invertOrder() {
-		for (InvertibleComparator comparator : this.comparators) {
+		for (InvertibleComparator<T> comparator : this.comparators) {
 			comparator.invertOrder();
 		}
 	}
\ No newline at end of file
",NotBuggy,"Refactor and polish various Comparator impls

 - Refactor CompoundComparator constructor to use varargs
 - Refactor MediaType to consume new varargs constructor
 - Add notNull assertions where appropriate
 - Add generic typing where appropriate
 - Suppress generics warnings elsewhere
 - Fix whitespace errors
"
spring-framework,16701.json,67a06f5edcc8697af0941e238ef29bdb2a73245d,"@@ -1,8 +1,8 @@
 	public ClientResponse build() {
+
 		ClientHttpResponse httpResponse =
 				new BuiltClientHttpResponse(this.statusCode, this.headers, this.cookies, this.body);
 
-		// When building ClientResponse manually, the ClientRequest.logPrefix() has to be passed,
-		// e.g. via ClientResponse.Builder, but this (builder) is not used currently.
-		return new DefaultClientResponse(httpResponse, this.strategies, """", """", () -> this.request);
+		return new DefaultClientResponse(
+				httpResponse, this.strategies, """", """", () -> this.request);
 	}
\ No newline at end of file
",NotBuggy,"Add mutate() to ClientResponse and deprecate from()

from() has the flaw of ignoring the body and it can't be fixed because
applications are guaranteed to be setting it already and if set twice
the builder drains the first body.

mutate() is a better fit in any case for what needs to be done in a
filter chain. It can be done more efficiently and is consistent with
similar options on the server side.

See gh-24680
"
spring-framework,16453.json,67a06f5edcc8697af0941e238ef29bdb2a73245d,"@@ -1,8 +1,7 @@
 	public static ExchangeFilterFunction limitResponseSize(long maxByteCount) {
 		return (request, next) ->
-				next.exchange(request).map(response -> {
-					Flux<DataBuffer> body = response.body(BodyExtractors.toDataBuffers());
-					body = DataBufferUtils.takeUntilByteCount(body, maxByteCount);
-					return ClientResponse.from(response).body(body).build();
-				});
+				next.exchange(request).map(response ->
+						response.mutate()
+								.body(body -> DataBufferUtils.takeUntilByteCount(body, maxByteCount))
+								.build());
 	}
\ No newline at end of file
",Buggy,"Add mutate() to ClientResponse and deprecate from()

from() has the flaw of ignoring the body and it can't be fixed because
applications are guaranteed to be setting it already and if set twice
the builder drains the first body.

mutate() is a better fit in any case for what needs to be done in a
filter chain. It can be done more efficiently and is consistent with
similar options on the server side.

See gh-24680
"
spring-framework,16698.json,67a06f5edcc8697af0941e238ef29bdb2a73245d,"@@ -1,11 +1,10 @@
 	public ClientResponse.Builder body(String body) {
 		Assert.notNull(body, ""Body must not be null"");
 		releaseBody();
-		DataBufferFactory dataBufferFactory = new DefaultDataBufferFactory();
 		this.body = Flux.just(body).
 				map(s -> {
 					byte[] bytes = body.getBytes(StandardCharsets.UTF_8);
-					return dataBufferFactory.wrap(bytes);
+					return new DefaultDataBufferFactory().wrap(bytes);
 				});
 		return this;
 	}
\ No newline at end of file
",NotBuggy,"Add mutate() to ClientResponse and deprecate from()

from() has the flaw of ignoring the body and it can't be fixed because
applications are guaranteed to be setting it already and if set twice
the builder drains the first body.

mutate() is a better fit in any case for what needs to be done in a
filter chain. It can be done more efficiently and is consistent with
similar options on the server side.

See gh-24680
"
spring-framework,16585.json,67a06f5edcc8697af0941e238ef29bdb2a73245d,"@@ -1,3 +1,3 @@
 	static Builder from(ClientResponse other) {
-		return new DefaultClientResponseBuilder(other);
+		return new DefaultClientResponseBuilder(other, false);
 	}
\ No newline at end of file
",Buggy,"Add mutate() to ClientResponse and deprecate from()

from() has the flaw of ignoring the body and it can't be fixed because
applications are guaranteed to be setting it already and if set twice
the builder drains the first body.

mutate() is a better fit in any case for what needs to be done in a
filter chain. It can be done more efficiently and is consistent with
similar options on the server side.

See gh-24680
"
sonarqube,9310.json,e582be977c992d38fff928388bb1f1ae928fd146,"@@ -1,14 +1,13 @@
   private java.util.Optional<CeTask> submit(CeTaskSubmit submission, EnumSet<SubmitOption> submitOptions) {
-    checkState(!submitPaused.get(), ""Compute Engine does not currently accept new tasks"");
     try (DbSession dbSession = dbClient.openSession(false)) {
       if (submitOptions.contains(UNIQUE_QUEUE_PER_COMPONENT)
         && submission.getComponentUuid() != null
         && dbClient.ceQueueDao().countByStatusAndComponentUuid(dbSession, PENDING, submission.getComponentUuid()) > 0) {
         return java.util.Optional.empty();
       }
       CeQueueDto dto = addToQueueInDb(dbSession, submission);
       CeTask task = loadTask(dbSession, dto);
       dbSession.commit();
       return java.util.Optional.of(task);
     }
   }
\ No newline at end of file
",NotBuggy,"Fix Quality flaws

mainly by removing unused code
"
sonarqube,9312.json,e582be977c992d38fff928388bb1f1ae928fd146,"@@ -1,16 +1,15 @@
   public List<CeTask> massSubmit(Collection<CeTaskSubmit> submissions, SubmitOption... options) {
-    checkState(!submitPaused.get(), ""Compute Engine does not currently accept new tasks"");
     if (submissions.isEmpty()) {
       return Collections.emptyList();
     }
 
     try (DbSession dbSession = dbClient.openSession(true)) {
       List<CeQueueDto> ceQueueDtos = submissions.stream()
         .filter(filterBySubmitOptions(options, submissions, dbSession))
         .map(submission -> addToQueueInDb(dbSession, submission))
         .collect(Collectors.toList());
       List<CeTask> tasks = loadTasks(dbSession, ceQueueDtos);
       dbSession.commit();
       return tasks;
     }
   }
\ No newline at end of file
",NotBuggy,"Fix Quality flaws

mainly by removing unused code
"
sonarqube,8268.json,3bfcfa0de67e7f00d7cd0dc74649fef7e5772298,"@@ -1,3 +1,3 @@
   public void stop() {
-
+    // do nothing
   }
\ No newline at end of file
",NotBuggy,"Fix some quality flaws
"
sonarqube,1454.json,3bfcfa0de67e7f00d7cd0dc74649fef7e5772298,"@@ -1,3 +1,3 @@
-  public String metadata() {
-    return metadata;
+  public String internalKey() {
+    return internalKey;
   }
\ No newline at end of file
",NotBuggy,"Fix some quality flaws
"
sonarqube,1485.json,3bfcfa0de67e7f00d7cd0dc74649fef7e5772298,"@@ -1,4 +1,4 @@
-  public NewRule setMetadata(@Nullable String metadata) {
-    this.metadata = metadata;
+  public NewRule setInternalKey(@Nullable String s) {
+    this.internalKey = s;
     return this;
   }
\ No newline at end of file
",NotBuggy,"Fix some quality flaws
"
sonarqube,2297.json,074f5c655822a466819c899ed9c90aef4ba1d2b4,"@@ -1,14 +1,15 @@
   boolean isDescendant(DbSession dbSession, QualityProfileDto childProfile, @Nullable QualityProfileDto parentProfile) {
     QualityProfileDto currentParent = parentProfile;
     while (currentParent != null) {
       if (childProfile.getName().equals(currentParent.getName())) {
         return true;
       }
-      if (currentParent.getParentKee() != null) {
-        currentParent = db.qualityProfileDao().getByKey(dbSession, currentParent.getParentKee());
+      String parentKey = currentParent.getParentKee();
+      if (parentKey != null) {
+        currentParent = db.qualityProfileDao().getByKey(dbSession, parentKey);
       } else {
         currentParent = null;
       }
     }
     return false;
   }
\ No newline at end of file
",NotBuggy,"Fix some quality flaws
"
sonarqube,6627.json,074f5c655822a466819c899ed9c90aef4ba1d2b4,"@@ -1,30 +1,34 @@
   private ActiveRuleDto doUpdate(ActiveRuleChange change, RuleActivatorContext context, DbSession dbSession) {
     ActiveRuleDto activeRule;
     ActiveRuleDao dao = db.activeRuleDao();
     activeRule = context.activeRule();
-    activeRule.setSeverity(change.getSeverity());
-    if (change.getInheritance() != null) {
-      activeRule.setInheritance(change.getInheritance().name());
+    String severity = change.getSeverity();
+    if (severity != null) {
+      activeRule.setSeverity(severity);
+    }
+    ActiveRule.Inheritance inheritance = change.getInheritance();
+    if (inheritance != null) {
+      activeRule.setInheritance(inheritance.name());
     }
     dao.update(dbSession, activeRule);
 
     for (Map.Entry<String, String> param : change.getParameters().entrySet()) {
       ActiveRuleParamDto activeRuleParamDto = context.activeRuleParamsAsMap().get(param.getKey());
       if (activeRuleParamDto == null) {
         // did not exist
         if (param.getValue() != null) {
           activeRuleParamDto = ActiveRuleParamDto.createFor(context.ruleParamsByKeys().get(param.getKey()));
           activeRuleParamDto.setValue(param.getValue());
           dao.addParam(dbSession, activeRule, activeRuleParamDto);
         }
       } else {
         if (param.getValue() != null) {
           activeRuleParamDto.setValue(param.getValue());
           dao.updateParam(dbSession, activeRule, activeRuleParamDto);
         } else {
           dao.deleteParam(dbSession, activeRule, activeRuleParamDto);
         }
       }
     }
     return activeRule;
   }
\ No newline at end of file
",NotBuggy,"Fix some quality flaws
"
sonarqube,2295.json,074f5c655822a466819c899ed9c90aef4ba1d2b4,"@@ -1,27 +1,27 @@
   void setParent(DbSession dbSession, String profileKey, @Nullable String parentKey) {
     QualityProfileDto profile = db.qualityProfileDao().getNonNullByKey(dbSession, profileKey);
     if (parentKey == null) {
       // unset if parent is defined, else nothing to do
       removeParent(dbSession, profile);
 
-    } else if (profile.getParentKee() == null || !profile.getParentKee().equals(parentKey)) {
+    } else if (profile.getParentKee() == null || !parentKey.equals(profile.getParentKee())) {
       QualityProfileDto parentProfile = db.qualityProfileDao().getNonNullByKey(dbSession, parentKey);
       if (isDescendant(dbSession, profile, parentProfile)) {
         throw new BadRequestException(String.format(""Descendant profile '%s' can not be selected as parent of '%s'"", parentKey, profileKey));
       }
       removeParent(dbSession, profile);
 
       // set new parent
       profile.setParentKee(parentKey);
       db.qualityProfileDao().update(dbSession, profile);
       for (ActiveRuleDto parentActiveRule : db.activeRuleDao().findByProfileKey(dbSession, parentKey)) {
         try {
           RuleActivation activation = new RuleActivation(parentActiveRule.getKey().ruleKey());
           activate(dbSession, activation, profileKey);
         } catch (BadRequestException e) {
           // for example because rule status is REMOVED
           // TODO return errors
         }
       }
     }
   }
\ No newline at end of file
",NotBuggy,"Fix some quality flaws
"
sonarqube,6621.json,074f5c655822a466819c899ed9c90aef4ba1d2b4,"@@ -1,57 +1,58 @@
   private List<ActiveRuleChange> doActivate(DbSession dbSession, RuleActivation activation, RuleActivatorContext context) {
     context.verifyForActivation();
     List<ActiveRuleChange> changes = Lists.newArrayList();
     ActiveRuleChange change;
     boolean stopPropagation = false;
 
-    if (context.activeRule() == null) {
+    ActiveRuleDto activeRule = context.activeRule();
+    if (activeRule == null) {
       if (activation.isReset()) {
         // ignore reset when rule is not activated
         return changes;
       }
       // new activation
       change = ActiveRuleChange.createFor(ActiveRuleChange.Type.ACTIVATED, context.activeRuleKey());
       applySeverityAndParamToChange(activation, context, change);
       if (activation.isCascade() || context.isSameAsParent(change)) {
         change.setInheritance(ActiveRule.Inheritance.INHERITED);
       }
     } else {
       // already activated
-      if (activation.isCascade() && context.activeRule().doesOverride()) {
+      if (activation.isCascade() && activeRule.doesOverride()) {
         // propagating to descendants, but child profile already overrides rule -> stop propagation
         return changes;
       }
       change = ActiveRuleChange.createFor(ActiveRuleChange.Type.UPDATED, context.activeRuleKey());
-      if (activation.isCascade() && context.activeRule().getInheritance() == null) {
+      if (activation.isCascade() && activeRule.getInheritance() == null) {
         // activate on child, then on parent -> mark child as overriding parent
         change.setInheritance(ActiveRule.Inheritance.OVERRIDES);
         change.setSeverity(context.currentSeverity());
         change.setParameters(context.activeRuleParamsAsStringMap());
         stopPropagation = true;
       } else {
         applySeverityAndParamToChange(activation, context, change);
         if (!activation.isCascade() && context.parentActiveRule() != null) {
           // override rule which is already declared on parents
           change.setInheritance(context.isSameAsParent(change) ? ActiveRule.Inheritance.INHERITED : ActiveRule.Inheritance.OVERRIDES);
         }
       }
       if (context.isSame(change)) {
         change = null;
       }
     }
 
     if (change != null) {
       changes.add(change);
       persist(change, context, dbSession);
     }
 
     if (!stopPropagation) {
       changes.addAll(cascadeActivation(dbSession, activation, context.profile().getKey()));
     }
 
     if (!changes.isEmpty()) {
       updateProfileDate(dbSession, context);
       previewCache.reportGlobalModification(dbSession);
     }
     return changes;
   }
\ No newline at end of file
",NotBuggy,"Fix some quality flaws
"
sonarqube,11064.json,e582be977c992d38fff928388bb1f1ae928fd146,"@@ -1,8 +1,8 @@
   private static String groupSearchToSql(@Nullable String query) {
     if (query == null) {
       return null;
     }
 
     String upperCasedNameQuery = StringUtils.upperCase(query, Locale.ENGLISH);
-    return DaoDatabaseUtils.buildLikeValue(upperCasedNameQuery, WildcardPosition.BEFORE_AND_AFTER);
+    return DaoUtils.buildLikeValue(upperCasedNameQuery, WildcardPosition.BEFORE_AND_AFTER);
   }
\ No newline at end of file
",NotBuggy,"Fix Quality flaws

mainly by removing unused code
"
sonarqube,12391.json,e582be977c992d38fff928388bb1f1ae928fd146,"@@ -1,13 +1,13 @@
   private Optional<CeQueueDto> tryToPeek(DbSession session, EligibleTaskDto eligible, String workerUuid) {
     long now = system2.now();
     int touchedRows = mapper(session).updateIf(eligible.getUuid(),
       new UpdateIf.NewProperties(IN_PROGRESS, workerUuid, eligible.getExecutionCount() + 1, now, now),
       new UpdateIf.OldProperties(PENDING, eligible.getExecutionCount()));
     if (touchedRows != 1) {
       return Optional.empty();
     }
 
     CeQueueDto result = mapper(session).selectByUuid(eligible.getUuid());
     session.commit();
-    return Optional.of(result);
+    return Optional.ofNullable(result);
   }
\ No newline at end of file
",NotBuggy,"Fix Quality flaws

mainly by removing unused code
"
sonarqube,14783.json,1c73879c6bd7bb325e7e95acfadbb8431adc39f3,"@@ -1,18 +1,18 @@
-  private static Optional<Double> getDoubleValue(Optional<Measure> measureOptional) {
-    if (!measureOptional.isPresent()) {
-      return Optional.absent();
-    }
-    Measure measure = measureOptional.get();
-    switch (measure.getValueType()) {
-      case DOUBLE:
-        return Optional.of(measure.getDoubleValue());
-      case LONG:
-        return Optional.of((double) measure.getLongValue());
-      case INT:
-        return Optional.of((double) measure.getIntValue());
-      case NO_VALUE:
+    private Optional<Double> getDoubleValue(Optional<Measure> measureOptional) {
+      if (!measureOptional.isPresent()) {
         return Optional.absent();
-      default:
-        throw new IllegalArgumentException(String.format(""Measure of type '%s' are not supported"", measure.getValueType().name()));
-    }
-  }
\ No newline at end of file
+      }
+      Measure measure = measureOptional.get();
+      switch (measure.getValueType()) {
+        case DOUBLE:
+          return Optional.of(measure.getDoubleValue());
+        case LONG:
+          return Optional.of((double) measure.getLongValue());
+        case INT:
+          return Optional.of((double) measure.getIntValue());
+        case NO_VALUE:
+          return Optional.absent();
+        default:
+          throw new IllegalArgumentException(String.format(""Measure of type '%s' are not supported"", measure.getValueType().name()));
+      }
+    }
\ No newline at end of file
",NotBuggy,"Fix quality flaws
"
sonarqube,14622.json,1c73879c6bd7bb325e7e95acfadbb8431adc39f3,"@@ -1,8 +1,8 @@
-  private static String convertType(Constants.ComponentLinkType reportType) {
-    String type = typesConverter.get(reportType);
-    if (type != null) {
-      return type;
-    } else {
-      throw new IllegalArgumentException(String.format(""Unsupported type %s"", reportType.name()));
-    }
-  }
\ No newline at end of file
+    private String convertType(Constants.ComponentLinkType reportType) {
+      String type = typesConverter.get(reportType);
+      if (type != null) {
+        return type;
+      } else {
+        throw new IllegalArgumentException(String.format(""Unsupported type %s"", reportType.name()));
+      }
+    }
\ No newline at end of file
",NotBuggy,"Fix quality flaws
"
sonarqube,14062.json,1c73879c6bd7bb325e7e95acfadbb8431adc39f3,"@@ -1,6 +1,6 @@
-  private static String computeRevision(@Nullable Changeset latestChange) {
-    if (latestChange == null) {
-      return null;
-    }
-    return latestChange.getRevision();
-  }
\ No newline at end of file
+    private String computeRevision(@Nullable Changeset latestChange) {
+      if (latestChange == null) {
+        return null;
+      }
+      return latestChange.getRevision();
+    }
\ No newline at end of file
",NotBuggy,"Fix quality flaws
"
sonarqube,13389.json,1c73879c6bd7bb325e7e95acfadbb8431adc39f3,"@@ -1,16 +1,16 @@
-  private static DbCommons.TextRange.Builder convertTextRange(BatchReport.TextRange sourceRange) {
-    DbCommons.TextRange.Builder targetRange = DbCommons.TextRange.newBuilder();
-    if (sourceRange.hasStartLine()) {
-      targetRange.setStartLine(sourceRange.getStartLine());
-    }
-    if (sourceRange.hasStartOffset()) {
-      targetRange.setStartOffset(sourceRange.getStartOffset());
-    }
-    if (sourceRange.hasEndLine()) {
-      targetRange.setEndLine(sourceRange.getEndLine());
-    }
-    if (sourceRange.hasEndOffset()) {
-      targetRange.setEndOffset(sourceRange.getEndOffset());
-    }
-    return targetRange;
-  }
\ No newline at end of file
+    private DbCommons.TextRange.Builder convertTextRange(BatchReport.TextRange sourceRange) {
+      DbCommons.TextRange.Builder targetRange = DbCommons.TextRange.newBuilder();
+      if (sourceRange.hasStartLine()) {
+        targetRange.setStartLine(sourceRange.getStartLine());
+      }
+      if (sourceRange.hasStartOffset()) {
+        targetRange.setStartOffset(sourceRange.getStartOffset());
+      }
+      if (sourceRange.hasEndLine()) {
+        targetRange.setEndLine(sourceRange.getEndLine());
+      }
+      if (sourceRange.hasEndOffset()) {
+        targetRange.setEndOffset(sourceRange.getEndOffset());
+      }
+      return targetRange;
+    }
\ No newline at end of file
",NotBuggy,"Fix quality flaws
"
sonarqube,1136.json,371ab065edbef2e92b502878eec9a73d310af54b,"@@ -1,3 +1,3 @@
     public Reader getReader() {
-      return new StringReader(source_code);
+      return new StringReader(sourceCode);
     }
\ No newline at end of file
",NotBuggy,"Fix some quality flaws
"
sonarqube,1134.json,371ab065edbef2e92b502878eec9a73d310af54b,"@@ -1,3 +1,3 @@
     public Reader getReader() {
-      return new StringReader(source_code);
+      return new StringReader(sourceCode);
     }
\ No newline at end of file
",NotBuggy,"Fix some quality flaws
"
sonarqube,18140.json,4a108310e196bcff760bc81de326346b1ee4ac4c,"@@ -1,7 +1,7 @@
   public String toString() {
     return Objects.toStringHelper(DebtRemediationFunction.class)
       .add(""type"", type)
-      .add(""coefficient"", factor)
+      .add(""coefficient"", coefficient)
       .add(""offset"", offset)
       .toString();
   }
\ No newline at end of file
",NotBuggy,"Fix quality flaws
"
sonarqube,18137.json,4a108310e196bcff760bc81de326346b1ee4ac4c,"@@ -1,21 +1,21 @@
   private void validate() {
     switch (type) {
       case LINEAR:
-        if (this.factor == null || this.offset != null) {
+        if (this.coefficient == null || this.offset != null) {
           throw new IllegalArgumentException(String.format(""Only coefficient must be set on %s"", this));
         }
         break;
       case LINEAR_OFFSET:
-        if (this.factor == null || this.offset == null) {
+        if (this.coefficient == null || this.offset == null) {
           throw new IllegalArgumentException(String.format(""Both coefficient and offset are required on %s"", this));
         }
         break;
       case CONSTANT_ISSUE:
-        if (this.factor != null || this.offset == null) {
+        if (this.coefficient != null || this.offset == null) {
           throw new IllegalArgumentException(String.format(""Only offset must be set on %s"", this));
         }
         break;
       default:
         throw new IllegalArgumentException(String.format(""Unknown type on %s"", this));
     }
   }
\ No newline at end of file
",NotBuggy,"Fix quality flaws
"
sonarqube,18133.json,4a108310e196bcff760bc81de326346b1ee4ac4c,"@@ -1,3 +1,3 @@
   public String coefficient() {
-    return factor;
+    return coefficient;
   }
\ No newline at end of file
",NotBuggy,"Fix quality flaws
"
sonarqube,18138.json,4a108310e196bcff760bc81de326346b1ee4ac4c,"@@ -1,16 +1,14 @@
   public boolean equals(Object o) {
+    if (!(o instanceof DefaultDebtRemediationFunction)) {
+      return false;
+    }
     if (this == o) {
       return true;
     }
-    if (o == null || getClass() != o.getClass()) {
-      return false;
-    }
-    DefaultDebtRemediationFunction that = (DefaultDebtRemediationFunction) o;
-    if (factor != null ? !factor.equals(that.factor) : that.factor != null) {
-      return false;
-    }
-    if (offset != null ? !offset.equals(that.offset) : that.offset != null) {
-      return false;
-    }
-    return type == that.type;
+    DefaultDebtRemediationFunction other = (DefaultDebtRemediationFunction) o;
+    return new EqualsBuilder()
+      .append(coefficient, other.coefficient())
+      .append(offset, other.offset())
+      .append(type, other.type())
+      .isEquals();
   }
\ No newline at end of file
",NotBuggy,"Fix quality flaws
"
sonarqube,18139.json,4a108310e196bcff760bc81de326346b1ee4ac4c,"@@ -1,6 +1,6 @@
   public int hashCode() {
     int result = type.hashCode();
-    result = 31 * result + (factor != null ? factor.hashCode() : 0);
+    result = 31 * result + (coefficient != null ? coefficient.hashCode() : 0);
     result = 31 * result + (offset != null ? offset.hashCode() : 0);
     return result;
   }
\ No newline at end of file
",NotBuggy,"Fix quality flaws
"
sonarqube,10480.json,d20f21e4cd409de904ef4a0ae5926b61706b402e,"@@ -1,4 +1,4 @@
-  public QualityProfileDto setParent(String parent) {
+  public QualityProfileDto setParent(@Nullable String parent) {
     this.parent = parent;
     return this;
   }
\ No newline at end of file
",NotBuggy,"Fix quality flaws
"
sonarqube,10472.json,d20f21e4cd409de904ef4a0ae5926b61706b402e,"@@ -1,4 +1,4 @@
-  public QualityProfileDto setParent(String parent) {
+  public QualityProfileDto setParent(@Nullable String parent) {
     this.parent = parent;
     return this;
   }
\ No newline at end of file
",NotBuggy,"Fix quality flaws
"
sonarqube,9636.json,d20f21e4cd409de904ef4a0ae5926b61706b402e,"@@ -1,4 +1,4 @@
-  public QualityProfileDto setParent(String parent) {
+  public QualityProfileDto setParent(@Nullable String parent) {
     this.parent = parent;
     return this;
   }
\ No newline at end of file
",NotBuggy,"Fix quality flaws
"
sonarqube,19951.json,d102a8a9916bac0ab600cd5e90ba5359766f8d6d,"@@ -1,12 +1,12 @@
   private void autodetection() {
-    for (ScmProvider provider : providerPerKey.values()) {
-      if (provider.supports(projectReactor.getRoot().getBaseDir())) {
+    for (ScmProvider installedProvider : providerPerKey.values()) {
+      if (installedProvider.supports(projectReactor.getRoot().getBaseDir())) {
         if (this.provider == null) {
-          this.provider = provider;
+          this.provider = installedProvider;
         } else {
-          throw new IllegalStateException(""SCM provider autodetection failed. Both "" + this.provider.key() + "" and "" + provider.key()
+          throw new IllegalStateException(""SCM provider autodetection failed. Both "" + this.provider.key() + "" and "" + installedProvider.key()
             + "" claim to support this project. Please use "" + CoreProperties.SCM_PROVIDER_KEY + "" to define SCM of your project."");
         }
       }
     }
   }
\ No newline at end of file
",NotBuggy,"Fix some quality flaws
"
sonarqube,19956.json,d102a8a9916bac0ab600cd5e90ba5359766f8d6d,"@@ -1,3 +1,3 @@
   public void stop() {
-
+    // Nothing to do
   }
\ No newline at end of file
",NotBuggy,"Fix some quality flaws
"
sonarqube,4891.json,289be70bf6056b5f3c66a797ecab019891e731d6,"@@ -1,28 +1,30 @@
   public void handle(Request request, Response response) throws Exception {
     int pageSize = request.mandatoryParamAsInt(Param.PAGE_SIZE);
     int page = request.mandatoryParamAsInt(Param.PAGE);
     String queryString = request.param(Param.TEXT_QUERY);
     String selected = request.mandatoryParam(Param.SELECTED);
 
     try (DbSession dbSession = dbClient.openSession(false)) {
       GroupId group = support.findGroup(dbSession, request);
       userSession.checkPermission(OrganizationPermission.ADMINISTER, group.getOrganizationUuid());
 
       UserMembershipQuery query = UserMembershipQuery.builder()
         .groupId(group.getId())
         .organizationUuid(group.getOrganizationUuid())
         .memberSearch(queryString)
         .membership(getMembership(selected))
         .pageIndex(page)
         .pageSize(pageSize)
         .build();
       int total = dbClient.groupMembershipDao().countMembers(dbSession, query);
       Paging paging = forPageIndex(page).withPageSize(pageSize).andTotal(total);
       List<UserMembershipDto> users = dbClient.groupMembershipDao().selectMembers(dbSession, query, paging.offset(), paging.pageSize());
 
-      JsonWriter json = response.newJsonWriter().beginObject();
-      writeMembers(json, users);
-      writePaging(json, paging);
-      json.endObject().close();
+      try (JsonWriter json = response.newJsonWriter()) {
+        json.beginObject();
+        writeMembers(json, users);
+        writePaging(json, paging);
+        json.endObject();
+      }
     }
   }
\ No newline at end of file
",NotBuggy,"Fix Quality flaws
"
sonarqube,2559.json,289be70bf6056b5f3c66a797ecab019891e731d6,"@@ -1,7 +1,9 @@
   static void writeResponse(BulkChangeResult result, Response response) {
-    JsonWriter json = response.newJsonWriter().beginObject();
-    json.prop(""succeeded"", result.countSucceeded());
-    json.prop(""failed"", result.countFailed());
-    WebServiceEngine.writeErrors(json, result.getErrors());
-    json.endObject().close();
+    try (JsonWriter json = response.newJsonWriter()) {
+      json.beginObject();
+      json.prop(""succeeded"", result.countSucceeded());
+      json.prop(""failed"", result.countFailed());
+      WebServiceEngine.writeErrors(json, result.getErrors());
+      json.endObject();
+    }
   }
\ No newline at end of file
",NotBuggy,"Fix Quality flaws
"
sonarqube,18845.json,38e53c0572db4e267a704666cb0d1343992df5e1,"@@ -1,3 +1,3 @@
-  public void resolveOrder() throws CyclicDependenciesException {
+  public void resolveOrder() {
     resolveOrder(toString());
   }
\ No newline at end of file
",NotBuggy,"Fix some quality flaws
"
sonarqube,18846.json,38e53c0572db4e267a704666cb0d1343992df5e1,"@@ -1,19 +1,19 @@
-  private int resolveOrder(String path) throws CyclicDependenciesException {
+  private int resolveOrder(String path) {
     seen = true;
     try {
       int highOrder = -1;
       for (Node dep : dependencies) {
         if (dep.seen) {
           throw new CyclicDependenciesException(path + "" -> "" + dep.toString());
         }
         highOrder = Math.max(highOrder, dep.resolveOrder(path + "" -> "" + dep.toString()));
 
       }
 
       order = highOrder + 1;
       return order;
 
     } finally {
       seen = false;
     }
   }
\ No newline at end of file
",NotBuggy,"Fix some quality flaws
"
sonarqube,8517.json,38e53c0572db4e267a704666cb0d1343992df5e1,"@@ -1,35 +1,33 @@
   public static Collection<String> listResources(ClassLoader classLoader, String rootPath, Predicate<String> predicate) {
     try {
       Collection<String> paths = Lists.newArrayList();
       rootPath = StringUtils.removeStart(rootPath, ""/"");
 
       URL root = classLoader.getResource(rootPath);
       if (root != null) {
-        if (!""jar"".equals(root.getProtocol())) {
-          throw new IllegalStateException(""Unsupported protocol: "" + root.getProtocol());
-        }
+        checkJarFile(root);
 
         // Path of the root directory
         // Examples :
         // org/sonar/sqale/index.txt  -> rootDirectory is org/sonar/sqale
         // org/sonar/sqale/  -> rootDirectory is org/sonar/sqale
         // org/sonar/sqale  -> rootDirectory is org/sonar/sqale
         String rootDirectory = rootPath;
         if (StringUtils.substringAfterLast(rootPath, ""/"").indexOf('.') >= 0) {
           rootDirectory = StringUtils.substringBeforeLast(rootPath, ""/"");
         }
         String jarPath = root.getPath().substring(5, root.getPath().indexOf(""!"")); //strip out only the JAR file
         JarFile jar = new JarFile(URLDecoder.decode(jarPath, CharEncoding.UTF_8));
         Enumeration<JarEntry> entries = jar.entries();
         while (entries.hasMoreElements()) {
           String name = entries.nextElement().getName();
           if (name.startsWith(rootDirectory) && predicate.apply(name)) {
             paths.add(name);
           }
         }
       }
       return paths;
     } catch (Exception e) {
       throw Throwables.propagate(e);
     }
   }
\ No newline at end of file
",NotBuggy,"Fix some quality flaws
"
sonarqube,7268.json,fd78d281d57d7b1ffa49d27cd03de39b6a961592,"@@ -1,14 +1,14 @@
   private UserDto synchronize(String userLogin, UserDetails details, HttpServletRequest request) {
     String name = details.getName();
     UserIdentity.Builder userIdentityBuilder = UserIdentity.builder()
       .setLogin(userLogin)
-      .setName(isNullOrEmpty(name) ? userLogin : name)
+      .setName(isEmpty(name) ? userLogin : name)
       .setEmail(trimToNull(details.getEmail()))
       .setProviderLogin(userLogin);
     if (externalGroupsProvider != null) {
       ExternalGroupsProvider.Context context = new ExternalGroupsProvider.Context(userLogin, request);
       Collection<String> groups = externalGroupsProvider.doGetGroups(context);
       userIdentityBuilder.setGroups(new HashSet<>(groups));
     }
     return userIdentityAuthenticator.authenticate(userIdentityBuilder.build(), new ExternalIdentityProvider());
   }
\ No newline at end of file
",NotBuggy,"Fix Quality flaws

- missing tests for Protobuf
- remove incorrect imports of org.elasticsearch.common.Strings
"
sonarqube,7206.json,fd78d281d57d7b1ffa49d27cd03de39b6a961592,"@@ -1,12 +1,12 @@
   private static Optional<String> getTokenFromCookie(HttpServletRequest request) {
     Optional<Cookie> jwtCookie = findCookie(JWT_COOKIE, request);
     if (!jwtCookie.isPresent()) {
       return Optional.empty();
     }
     Cookie cookie = jwtCookie.get();
     String token = cookie.getValue();
-    if (isNullOrEmpty(token)) {
+    if (isEmpty(token)) {
       return Optional.empty();
     }
     return Optional.of(token);
   }
\ No newline at end of file
",NotBuggy,"Fix Quality flaws

- missing tests for Protobuf
- remove incorrect imports of org.elasticsearch.common.Strings
"
sonarqube,3674.json,fd78d281d57d7b1ffa49d27cd03de39b6a961592,"@@ -1,7 +1,7 @@
   private List<Setting> loadDefaultSettings(Set<String> keys) {
     return propertyDefinitions.getAll().stream()
       .filter(definition -> keys.contains(definition.key()))
-      .filter(defaultProperty -> !isNullOrEmpty(defaultProperty.defaultValue()))
+      .filter(defaultProperty -> !isEmpty(defaultProperty.defaultValue()))
       .map(Setting::createForDefinition)
       .collect(Collectors.toList());
   }
\ No newline at end of file
",NotBuggy,"Fix Quality flaws

- missing tests for Protobuf
- remove incorrect imports of org.elasticsearch.common.Strings
"
sonarqube,4743.json,fd78d281d57d7b1ffa49d27cd03de39b6a961592,"@@ -1,8 +1,8 @@
   private UserDto authenticate(HttpServletRequest request) {
     String login = request.getParameter(""login"");
     String password = request.getParameter(""password"");
-    if (isNullOrEmpty(login) || isNullOrEmpty(password)) {
+    if (isEmpty(login) || isEmpty(password)) {
       throw new UnauthorizedException();
     }
     return credentialsAuthenticator.authenticate(login, password, request);
   }
\ No newline at end of file
",NotBuggy,"Fix Quality flaws

- missing tests for Protobuf
- remove incorrect imports of org.elasticsearch.common.Strings
"
sonarqube,20010.json,5e0b742ac8299c7ddcd2bf3dfe682482c4d8eda4,"@@ -1,9 +1,9 @@
   private static void cleanTempFolders(Path path) throws IOException {
-    if (Files.exists(path)) {
+    if (path.toFile().exists()) {
       try (DirectoryStream<Path> stream = Files.newDirectoryStream(path, new CleanFilter())) {
         for (Path p : stream) {
           deleteQuietly(p.toFile());
         }
       }
     }
   }
\ No newline at end of file
",NotBuggy,"Fix Quality flaws
"
sonarqube,20011.json,5e0b742ac8299c7ddcd2bf3dfe682482c4d8eda4,"@@ -1,24 +1,24 @@
     public boolean accept(Path path) throws IOException {
-      if (!Files.isDirectory(path)) {
+      if (!path.toFile().exists()) {
         return false;
       }
 
       if (!path.getFileName().toString().startsWith(TMP_NAME_PREFIX)) {
         return false;
       }
 
       long threshold = System.currentTimeMillis() - CLEAN_MAX_AGE;
 
       // we could also check the timestamp in the name, instead
       BasicFileAttributes attrs;
 
       try {
         attrs = Files.readAttributes(path, BasicFileAttributes.class);
       } catch (IOException ioe) {
         LOG.error(String.format(""Couldn't read file attributes for %s : "", path), ioe);
         return false;
       }
 
       long creationTime = attrs.creationTime().toMillis();
       return creationTime < threshold;
     }
\ No newline at end of file
",NotBuggy,"Fix Quality flaws
"
sonarqube,8900.json,5e0b742ac8299c7ddcd2bf3dfe682482c4d8eda4,"@@ -1,7 +1,7 @@
-  public static void main(String[] args) throws Exception {
+  public static void main(String[] args) {
     ProcessEntryPoint entryPoint = ProcessEntryPoint.createForArguments(args);
     Props props = entryPoint.getProps();
     new WebServerProcessLogging().configure(props);
     WebServer server = new WebServer(props);
     entryPoint.launch(server);
   }
\ No newline at end of file
",NotBuggy,"Fix Quality flaws
"
sonarqube,4469.json,0584dc8d5d5d82a2035763c34afba0e12cf6e8d0,"@@ -1,15 +1,15 @@
   public void handle(Request wsRequest, Response wsResponse) throws Exception {
     try (DbSession dbSession = dbClient.openSession(false)) {
       WsTemplateRef templateRef = WsTemplateRef.fromRequest(wsRequest);
       PermissionTemplateDto template = support.findTemplate(dbSession, templateRef);
       checkGlobalAdmin(userSession, template.getOrganizationUuid());
 
       PermissionQuery query = buildPermissionQuery(wsRequest);
-      int total = dbClient.permissionTemplateDao().countGroupNamesByQueryAndTemplate(dbSession, query, template.getId());
+      int total = dbClient.permissionTemplateDao().countGroupNamesByQueryAndTemplate(dbSession, query, template.getOrganizationUuid(), template.getId());
       Paging paging = Paging.forPageIndex(wsRequest.mandatoryParamAsInt(PAGE)).withPageSize(wsRequest.mandatoryParamAsInt(PAGE_SIZE)).andTotal(total);
       List<GroupDto> groups = findGroups(dbSession, query, template);
       List<PermissionTemplateGroupDto> groupPermissions = findGroupPermissions(dbSession, groups, template);
       WsPermissions.WsGroupsResponse groupsResponse = buildResponse(groups, groupPermissions, paging);
       writeProtobuf(groupsResponse, wsRequest, wsResponse);
     }
   }
\ No newline at end of file
",Buggy,"SONAR-8682 fix error when filtering on name

and a given group name exists in multiple organizations
"
sonarqube,12672.json,0584dc8d5d5d82a2035763c34afba0e12cf6e8d0,"@@ -1,3 +1,3 @@
-  public List<String> selectGroupNamesByQueryAndTemplate(DbSession session, PermissionQuery query, long templateId) {
-    return mapper(session).selectGroupNamesByQueryAndTemplate(query, templateId, new RowBounds(query.getPageOffset(), query.getPageSize()));
+  public List<String> selectGroupNamesByQueryAndTemplate(DbSession session, PermissionQuery query, String organizationUuid, long templateId) {
+    return mapper(session).selectGroupNamesByQueryAndTemplate(organizationUuid, templateId, query, new RowBounds(query.getPageOffset(), query.getPageSize()));
   }
\ No newline at end of file
",Buggy,"SONAR-8682 fix error when filtering on name

and a given group name exists in multiple organizations
"
sonarqube,4472.json,0584dc8d5d5d82a2035763c34afba0e12cf6e8d0,"@@ -1,8 +1,8 @@
   private List<GroupDto> findGroups(DbSession dbSession, PermissionQuery dbQuery, PermissionTemplateDto template) {
-    List<String> orderedNames = dbClient.permissionTemplateDao().selectGroupNamesByQueryAndTemplate(dbSession, dbQuery, template.getId());
+    List<String> orderedNames = dbClient.permissionTemplateDao().selectGroupNamesByQueryAndTemplate(dbSession, dbQuery, template.getOrganizationUuid(), template.getId());
     List<GroupDto> groups = dbClient.groupDao().selectByNames(dbSession, template.getOrganizationUuid(), orderedNames);
     if (orderedNames.contains(DefaultGroups.ANYONE)) {
       groups.add(0, new GroupDto().setId(0L).setName(DefaultGroups.ANYONE));
     }
     return Ordering.explicit(orderedNames).onResultOf(GroupDto::getName).immutableSortedCopy(groups);
   }
\ No newline at end of file
",Buggy,"SONAR-8682 fix error when filtering on name

and a given group name exists in multiple organizations
"
sonarqube,12673.json,0584dc8d5d5d82a2035763c34afba0e12cf6e8d0,"@@ -1,3 +1,3 @@
-  public int countGroupNamesByQueryAndTemplate(DbSession session, PermissionQuery query, long templateId) {
-    return mapper(session).countGroupNamesByQueryAndTemplate(query, templateId);
+  public int countGroupNamesByQueryAndTemplate(DbSession session, PermissionQuery query, String organizationUuid, long templateId) {
+    return mapper(session).countGroupNamesByQueryAndTemplate(organizationUuid, query, templateId);
   }
\ No newline at end of file
",Buggy,"SONAR-8682 fix error when filtering on name

and a given group name exists in multiple organizations
"
voldemort,9608.json,4a463214895e56db53db78064bde3ebd10b6e949,"@@ -1,8 +1,8 @@
-    public void recordOpTimeUs(SocketDestination dest, long opTimeUs) {
+    public void recordOpTimeNs(SocketDestination dest, long opTimeNs) {
         if (dest != null) {
-            getOrCreateNodeStats(dest).recordOpTimeUs(null, opTimeUs);
-            recordOpTimeUs(null, opTimeUs);
+            getOrCreateNodeStats(dest).recordOpTimeNs(null, opTimeNs);
+            recordOpTimeNs(null, opTimeNs);
         } else {
-            this.opTimeRequestCounter.addRequest(opTimeUs * Time.NS_PER_US);
+            this.opTimeRequestCounter.addRequest(opTimeNs);
         }
     }
\ No newline at end of file
",Buggy,"Fix time convertion (Nano to micro) bug

Make the method accept nanoseconds to avoid unnecessary
convertion.
"
voldemort,8659.json,da027c470c327f2e0759acae2b3b46dfa0b114b2,"@@ -1,15 +1,15 @@
         void streamingPut(ByteArray key, Versioned<byte[]> value) {
-            if(overwrite == false) {
-                dstStreamingClient.streamingPut(key, value);
-            } else {
+            if(overwrite) {
                 VectorClock denseClock = VectorClockUtils.makeClockWithCurrentTime(dstServerIds);
                 Versioned<byte[]> updatedValue = new Versioned<byte[]>(value.getValue(), denseClock);
                 dstStreamingClient.streamingPut(key, updatedValue);
+            } else {
+                dstStreamingClient.streamingPut(key, value);
             }
 
             entriesForkLifted++;
             if(entriesForkLifted % progressOps == 0) {
                 logger.info(workName + "" fork lifted "" + entriesForkLifted
                             + "" entries successfully"");
             }
         }
\ No newline at end of file
",NotBuggy,"Incorporate code review comments

Fix error message
Change the order of if/else
"
voldemort,8669.json,da027c470c327f2e0759acae2b3b46dfa0b114b2,"@@ -1,82 +1,82 @@
     public static void main(String[] args) throws Exception {
         OptionParser parser = null;
         OptionSet options = null;
         try {
             parser = getParser();
             options = parser.parse(args);
         } catch(Exception oe) {
             logger.error(""Exception processing command line options"", oe);
             parser.printHelpOn(System.out);
             return;
         }
 
         /* validate options */
         if(options.has(""help"")) {
             parser.printHelpOn(System.out);
             return;
         }
 
         if(!options.has(""src-url"") || !options.has(""dst-url"")) {
             logger.error(""Both 'src-url' and 'dst-url' options are mandatory"");
             parser.printHelpOn(System.out);
             return;
         }
 
         String srcBootstrapUrl = (String) options.valueOf(""src-url"");
         String dstBootstrapUrl = (String) options.valueOf(""dst-url"");
         int maxPutsPerSecond = DEFAULT_MAX_PUTS_PER_SEC;
         if(options.has(""max-puts-per-second""))
             maxPutsPerSecond = (Integer) options.valueOf(""max-puts-per-second"");
         List<String> storesList = null;
         if(options.has(""stores"")) {
             storesList = new ArrayList<String>((List<String>) options.valuesOf(""stores""));
         }
         List<Integer> partitions = null;
         if(options.has(""partitions"")) {
             partitions = (List<Integer>) options.valuesOf(""partitions"");
         }
 
         int partitionParallelism = DEFAULT_PARTITION_PARALLELISM;
         if(options.has(""parallelism"")) {
             partitionParallelism = (Integer) options.valueOf(""parallelism"");
         }
         int progressOps = DEFAULT_PROGRESS_PERIOD_OPS;
         if(options.has(""progress-period-ops"")) {
             progressOps = (Integer) options.valueOf(""progress-period-ops"");
         }
 
         ForkLiftTaskMode mode;
         mode = ForkLiftTaskMode.primary_resolution;
         if(options.has(""mode"")) {
             mode = Utils.getEnumFromString(ForkLiftTaskMode.class, (String) options.valueOf(""mode""));
             if(mode == null)
                 mode = ForkLiftTaskMode.primary_resolution;
 
         }
 
         Boolean overwrite = false;
-        if(options.has(""overwrite"")) {
-            if(options.hasArgument(""overwrite"")) {
-                overwrite = (Boolean) options.valueOf(""overwrite"");
+        if(options.has(OVERWRITE_OPTION)) {
+            if(options.hasArgument(OVERWRITE_OPTION)) {
+                overwrite = (Boolean) options.valueOf(OVERWRITE_OPTION);
             } else {
                 overwrite = true;
             }
         }
 
         if(overwrite) {
             logger.warn(OVERWRITE_WARNING_MESSAGE);
         }
 
         ClusterForkLiftTool forkLiftTool = new ClusterForkLiftTool(srcBootstrapUrl,
                                                                    dstBootstrapUrl,
                                                                    overwrite,
                                                                    maxPutsPerSecond,
                                                                    partitionParallelism,
                                                                    progressOps,
                                                                    storesList,
                                                                    partitions,
                                                                    mode);
         forkLiftTool.run();
         // TODO cleanly shut down the hanging threadpool
         System.exit(0);
     }
\ No newline at end of file
",NotBuggy,"Incorporate code review comments

Fix error message
Change the order of if/else
"
voldemort,9827.json,8fe6ef89e6f219a246413f918167b573f69e070c,"@@ -1,18 +1,20 @@
     public boolean delete(ByteArray key, Version version) throws VoldemortException {
         boolean deleteSuccessful = false;
         StoreUtils.assertValidKey(key);
         String keyString = new String(key.get());
         String initialValue = this.metadataMap.get(keyString);
         if(initialValue != null) {
             String removedValue = this.metadataMap.remove(keyString);
             if(removedValue != null) {
                 deleteSuccessful = (initialValue.equals(removedValue));
             }
         }
         if(deleteSuccessful) {
             this.flushData();
             // Reset the vector clock and persist it.
+            // FIXME this also needs to be done per entry, as opposed to
+            // versioning the file.
             writeVersion(new VectorClock());
         }
         return deleteSuccessful;
     }
\ No newline at end of file
",NotBuggy,"Workaround SystemStore bug and fix quota store inserts
"
voldemort,9441.json,e7ecec1bd3dd879221a56714fc774a2001d843e8,"@@ -1,35 +1,36 @@
     public void run() {
         Node proxyNode = metadata.getCluster().getNodeById(destinationNode);
         long startNs = System.nanoTime();
         try {
             // TODO there are no retries now if the node we want to write to is
             // unavailable
             redirectingStore.checkNodeAvailable(proxyNode);
             Store<ByteArray, byte[], byte[]> socketStore = redirectingStore.getRedirectingSocketStore(redirectingStore.getName(),
                                                                                                       destinationNode);
 
             socketStore.put(key, value, transforms);
             redirectingStore.recordSuccess(proxyNode, startNs);
+            redirectingStore.reportProxyPutSuccess();
             if(logger.isTraceEnabled()) {
                 logger.trace(""Proxy write for store "" + redirectingStore.getName() + "" key ""
-                             + ByteUtils.toBinaryString(key.get()) + "" to destinationNode:""
+                             + ByteUtils.toHexString(key.get()) + "" to destinationNode:""
                              + destinationNode);
             }
         } catch(UnreachableStoreException e) {
             redirectingStore.recordException(proxyNode, startNs, e);
             logFailedProxyPutIfNeeded(e);
         } catch(ObsoleteVersionException ove) {
             /*
              * Proxy puts can get an OVE if somehow there are two stealers for
              * the same proxy node and the other stealer's proxy put already got
              * tothe proxy node.. This will not result from online put winning,
              * since we don't issue proxy puts if the proxy node is still a
              * replica
              */
             logFailedProxyPutIfNeeded(ove);
         } catch(Exception e) {
             // Just log the key.. Not sure having values in the log is a good
             // idea.
             logFailedProxyPutIfNeeded(e);
         }
     }
\ No newline at end of file
",NotBuggy,"1.Enabling proxy puts by dafault
2. Bug fix in proxy put stats
3. Changing order of state change updates for correctness
4. Setting proxy put tests to do one batch rebalancing
"
voldemort,7092.json,e7ecec1bd3dd879221a56714fc774a2001d843e8,"@@ -1,122 +1,150 @@
     public void rebalanceStateChange(Cluster cluster,
                                      List<RebalancePartitionsInfo> rebalancePartitionsInfo,
                                      boolean swapRO,
                                      boolean changeClusterMetadata,
                                      boolean changeRebalanceState,
                                      boolean rollback) {
         Cluster currentCluster = metadataStore.getCluster();
 
         logger.info(""Server doing rebalance state change with options [ cluster metadata change - ""
                     + changeClusterMetadata + "" ], [ changing rebalancing state - ""
                     + changeRebalanceState + "" ], [ changing swapping RO - "" + swapRO
                     + "" ], [ rollback - "" + rollback + "" ]"");
 
         // Variables to track what has completed
         List<RebalancePartitionsInfo> completedRebalancePartitionsInfo = Lists.newArrayList();
         List<String> swappedStoreNames = Lists.newArrayList();
         boolean completedClusterChange = false;
         boolean completedRebalanceSourceClusterChange = false;
         Cluster previousRebalancingSourceCluster = null;
 
         try {
-            // CHANGE CLUSTER METADATA
-            if(changeClusterMetadata) {
-                logger.info(""Switching metadata from "" + currentCluster + "" to "" + cluster);
-                changeCluster(MetadataStore.CLUSTER_KEY, cluster);
-                completedClusterChange = true;
-            }
 
-            // SWAP RO DATA FOR ALL STORES
-            if(swapRO) {
-                swapROStores(swappedStoreNames, false);
-            }
-
+            /*
+             * Do the rebalancing state changes. It is important that this
+             * happens before the actual cluster metadata is changed. Here's
+             * what could happen otherwise. When a batch completes with
+             * {current_cluster c2, rebalancing_source_cluster c1} and the next
+             * rebalancing state changes it to {current_cluster c3,
+             * rebalancing_source_cluster c2} is set for the next batch, then
+             * there could be a window during which the state is
+             * {current_cluster c3, rebalancing_source_cluster c1}. On the other
+             * hand, when we update the rebalancing source cluster first, there
+             * is a window where the state is {current_cluster c2,
+             * rebalancing_source_cluster c2}, which still fine, because of the
+             * following. Successful completion of a batch means the cluster is
+             * finalized, so its okay to stop proxying based on {current_cluster
+             * c2, rebalancing_source_cluster c1}. And since the cluster
+             * metadata has not yet been updated to c3, the writes will happen
+             * based on c2.
+             * 
+             * Even if some clients have already seen the {current_cluster c3,
+             * rebalancing_source_cluster c2} state from other servers, the
+             * operation will be rejected with InvalidMetadataException since
+             * this server itself is not aware of C3
+             */
             // CHANGE REBALANCING STATE
             if(changeRebalanceState) {
                 try {
                     previousRebalancingSourceCluster = metadataStore.getRebalancingSourceCluster();
                     if(!rollback) {
                         // Save up the current cluster for Redirecting store
+                        logger.info(""Setting rebalancing source cluster xml from ""
+                                    + previousRebalancingSourceCluster + ""to "" + currentCluster);
                         changeCluster(MetadataStore.REBALANCING_SOURCE_CLUSTER_XML, currentCluster);
                         completedRebalanceSourceClusterChange = true;
 
                         for(RebalancePartitionsInfo info: rebalancePartitionsInfo) {
                             metadataStore.addRebalancingState(info);
                             completedRebalancePartitionsInfo.add(info);
                         }
                     } else {
                         // Reset the rebalancing source cluster back to null
+                        logger.info(""Resetting rebalancing source cluster xml from ""
+                                    + previousRebalancingSourceCluster + ""to null"");
                         changeCluster(MetadataStore.REBALANCING_SOURCE_CLUSTER_XML, null);
                         completedRebalanceSourceClusterChange = true;
 
                         for(RebalancePartitionsInfo info: rebalancePartitionsInfo) {
                             metadataStore.deleteRebalancingState(info);
                             completedRebalancePartitionsInfo.add(info);
                         }
                     }
                 } catch(Exception e) {
                     throw new VoldemortException(e);
                 }
             }
+
+            // CHANGE CLUSTER METADATA
+            if(changeClusterMetadata) {
+                logger.info(""Switching metadata from "" + currentCluster + "" to "" + cluster);
+                changeCluster(MetadataStore.CLUSTER_KEY, cluster);
+                completedClusterChange = true;
+            }
+
+            // SWAP RO DATA FOR ALL STORES
+            if(swapRO) {
+                swapROStores(swappedStoreNames, false);
+            }
         } catch(VoldemortException e) {
 
             logger.error(""Got exception while changing state, now rolling back changes"", e);
 
             // ROLLBACK CLUSTER CHANGE
             if(completedClusterChange) {
                 try {
                     logger.info(""Rolling back cluster.xml to "" + currentCluster);
                     changeCluster(MetadataStore.CLUSTER_KEY, currentCluster);
                 } catch(Exception exception) {
                     logger.error(""Error while rolling back cluster metadata to "" + currentCluster,
                                  exception);
                 }
             }
 
             // SWAP RO DATA FOR ALL COMPLETED STORES
             if(swappedStoreNames.size() > 0) {
                 try {
                     swapROStores(swappedStoreNames, true);
                 } catch(Exception exception) {
                     logger.error(""Error while swapping back to old state "", exception);
                 }
             }
 
             // CHANGE BACK ALL REBALANCING STATES FOR COMPLETED ONES
             if(completedRebalancePartitionsInfo.size() > 0) {
                 if(!rollback) {
                     for(RebalancePartitionsInfo info: completedRebalancePartitionsInfo) {
                         try {
                             metadataStore.deleteRebalancingState(info);
                         } catch(Exception exception) {
                             logger.error(""Error while deleting back rebalance info during error rollback ""
                                                  + info,
                                          exception);
                         }
                     }
                 } else {
                     for(RebalancePartitionsInfo info: completedRebalancePartitionsInfo) {
                         try {
                             metadataStore.addRebalancingState(info);
                         } catch(Exception exception) {
                             logger.error(""Error while adding back rebalance info during error rollback ""
                                                  + info,
                                          exception);
                         }
                     }
                 }
 
             }
 
             // Revert changes to REBALANCING_SOURCE_CLUSTER_XML
             if(completedRebalanceSourceClusterChange) {
                 logger.info(""Reverting the REBALANCING_SOURCE_CLUSTER_XML back to ""
                             + previousRebalancingSourceCluster);
                 changeCluster(MetadataStore.REBALANCING_SOURCE_CLUSTER_XML,
                               previousRebalancingSourceCluster);
             }
 
             throw e;
         }
 
     }
\ No newline at end of file
",Buggy,"1.Enabling proxy puts by dafault
2. Bug fix in proxy put stats
3. Changing order of state change updates for correctness
4. Setting proxy put tests to do one batch rebalancing
"
voldemort,9466.json,e7ecec1bd3dd879221a56714fc774a2001d843e8,"@@ -1,4 +1,3 @@
     protected void recordSuccess(Node node, long startNs) {
-        proxyPutStats.reportProxyPutCompletion();
         failureDetector.recordSuccess(node, (System.nanoTime() - startNs) / Time.NS_PER_MS);
     }
\ No newline at end of file
",Buggy,"1.Enabling proxy puts by dafault
2. Bug fix in proxy put stats
3. Changing order of state change updates for correctness
4. Setting proxy put tests to do one batch rebalancing
"
voldemort,8840.json,e0707033c5a5c63fd044a59e7ee4055453334a01,"@@ -1,13 +1,11 @@
     public int getCheckedInResourcesCount(K key) {
-        int rc = 0;
-        if(!resourcePoolMap.containsKey(key)) {
-            return rc;
+        if(resourcePoolMap.containsKey(key)) {
+            try {
+                Pool<V> resourcePool = getResourcePoolForExistingKey(key);
+                return resourcePool.queue.size();
+            } catch(IllegalArgumentException iae) {
+                logger.debug(""getCheckedInResourceCount called on invalid key: "", iae);
+            }
         }
-        try {
-            Pool<V> resourcePool = getResourcePoolForExistingKey(key);
-            rc = resourcePool.queue.size();
-        } catch(IllegalArgumentException iae) {
-            logger.debug(""getCheckedInResourceCount called on invalid key: "", iae);
-        }
-        return rc;
+        return 0;
     }
\ No newline at end of file
",NotBuggy,"Clean up get stats methods in (Queued)KeyedResourcePool. Fix error in test case.
"
voldemort,8883.json,e0707033c5a5c63fd044a59e7ee4055453334a01,"@@ -1,14 +1,12 @@
     public int getRegisteredResourceRequestCount(K key) {
-        int rc = 0;
-        if(!requestQueueMap.containsKey(key)) {
-            return rc;
+        if(requestQueueMap.containsKey(key)) {
+            try {
+                Queue<AsyncResourceRequest<V>> requestQueue = getRequestQueueForExistingKey(key);
+                // FYI: .size() is not constant time in the next call. ;)
+                return requestQueue.size();
+            } catch(IllegalArgumentException iae) {
+                logger.debug(""getRegisteredResourceRequestCount called on invalid key: "", iae);
+            }
         }
-        try {
-            Queue<AsyncResourceRequest<V>> requestQueue = getRequestQueueForExistingKey(key);
-            // FYI: .size() is not constant time in the next call. ;)
-            rc = requestQueue.size();
-        } catch(IllegalArgumentException iae) {
-            logger.debug(""getRegisteredResourceRequestCount called on invalid key: "", iae);
-        }
-        return rc;
+        return 0;
     }
\ No newline at end of file
",NotBuggy,"Clean up get stats methods in (Queued)KeyedResourcePool. Fix error in test case.
"
voldemort,8838.json,e0707033c5a5c63fd044a59e7ee4055453334a01,"@@ -1,13 +1,11 @@
     public int getTotalResourceCount(K key) {
-        int rc = 0;
-        if(!resourcePoolMap.containsKey(key)) {
-            return rc;
+        if(resourcePoolMap.containsKey(key)) {
+            try {
+                Pool<V> resourcePool = getResourcePoolForExistingKey(key);
+                return resourcePool.size.get();
+            } catch(IllegalArgumentException iae) {
+                logger.debug(""getTotalResourceCount called on invalid key: "", iae);
+            }
         }
-        try {
-            Pool<V> resourcePool = getResourcePoolForExistingKey(key);
-            rc = resourcePool.size.get();
-        } catch(IllegalArgumentException iae) {
-            logger.debug(""getTotalResourceCount called on invalid key: "", iae);
-        }
-        return rc;
+        return 0;
     }
\ No newline at end of file
",NotBuggy,"Clean up get stats methods in (Queued)KeyedResourcePool. Fix error in test case.
"
voldemort,8842.json,e0707033c5a5c63fd044a59e7ee4055453334a01,"@@ -1,13 +1,11 @@
     public int getBlockingGetsCount(K key) {
-        int rc = 0;
-        if(!resourcePoolMap.containsKey(key)) {
-            return rc;
+        if(resourcePoolMap.containsKey(key)) {
+            try {
+                Pool<V> resourcePool = getResourcePoolForExistingKey(key);
+                return resourcePool.blockingGets.get();
+            } catch(IllegalArgumentException iae) {
+                logger.debug(""getBlockingGetsCount called on invalid key: "", iae);
+            }
         }
-        try {
-            Pool<V> resourcePool = getResourcePoolForExistingKey(key);
-            rc = resourcePool.blockingGets.get();
-        } catch(IllegalArgumentException iae) {
-            logger.debug(""getBlockingGetsCount called on invalid key: "", iae);
-        }
-        return rc;
+        return 0;
     }
\ No newline at end of file
",NotBuggy,"Clean up get stats methods in (Queued)KeyedResourcePool. Fix error in test case.
"
voldemort,532.json,81f0a160898ca88338ebf4834f7f1fd07f66c63b,"@@ -1,14 +1,18 @@
     public RebalancePlan getPlan(Cluster finalCluster,
                                  List<StoreDefinition> finalStoreDefs,
                                  int batchSize) {
         RebalanceUtils.validateClusterStores(finalCluster, finalStoreDefs);
         RebalanceUtils.validateCurrentFinalCluster(currentCluster, finalCluster);
 
+        // TODO: (currentCluster vs interimCluster) Add more validation before
+        // constructing plan? Given that currentCluster was polled from prod
+        // cluster, should confirm that it is an ""interim cluster"" i.e., has
+        // same (superset?) of nodes as are in finalCluster.
         String outputDir = null;
         return new RebalancePlan(currentCluster,
                                  currentStoreDefs,
                                  finalCluster,
                                  finalStoreDefs,
                                  batchSize,
                                  outputDir);
     }
\ No newline at end of file
",NotBuggy,"Fix some bugs I introduced and added more TODOs

Fixed overflow introduced in AdminClient.waitForCompletion by passing in
Long.MAX_VALUE for duration.

Verify cluster store definition in StoreRoutingPlan. This requires
working around existing problems with how system stores are handled (the
store definition is hard-coded for two zones). Left some TODOs about
testing and fixing all of this.

Added TODOs about currentCluster vs interimCluster. Need to tweak
interface to RebalanceController and RebalancePlan to be consistent with
recommended usage (i.e., deploying interimCluster before starting
rebalance).

Minor tweaks to tests based on above changes.
"
voldemort,887.json,81f0a160898ca88338ebf4834f7f1fd07f66c63b,"@@ -1,3 +1,3 @@
         public String waitForCompletion(int nodeId, int requestId) {
-            return waitForCompletion(nodeId, requestId, Long.MAX_VALUE, TimeUnit.SECONDS, null);
+            return waitForCompletion(nodeId, requestId, 0, TimeUnit.SECONDS, null);
         }
\ No newline at end of file
",Buggy,"Fix some bugs I introduced and added more TODOs

Fixed overflow introduced in AdminClient.waitForCompletion by passing in
Long.MAX_VALUE for duration.

Verify cluster store definition in StoreRoutingPlan. This requires
working around existing problems with how system stores are handled (the
store definition is hard-coded for two zones). Left some TODOs about
testing and fixing all of this.

Added TODOs about currentCluster vs interimCluster. Need to tweak
interface to RebalanceController and RebalancePlan to be consistent with
recommended usage (i.e., deploying interimCluster before starting
rebalance).

Minor tweaks to tests based on above changes.
"
voldemort,54.json,0b2ef083f53872f2686e10990e3586177c693bd6,"@@ -1,39 +1,42 @@
     public void reduce(BytesWritable key,
                        Iterator<BytesWritable> values,
                        OutputCollector<Text, Text> output,
                        Reporter reporter) throws IOException {
         BytesWritable writable = values.next();
         byte[] valueBytes = writable.get();
 
         if(this.nodeId == -1)
             this.nodeId = ByteUtils.readInt(valueBytes, 0);
         if(this.chunkId == -1)
             this.chunkId = ReadOnlyUtils.chunk(key.get(), this.numChunks);
 
         // Write key and position
         this.indexFileStream.write(key.get(), 0, key.getSize());
-        this.checkSumDigestIndex.update(key.get(), 0, key.getSize());
         this.indexFileStream.writeInt(this.position);
-        this.checkSumDigestIndex.update(this.position);
+        if(this.checkSumDigestIndex != null) {
+            this.checkSumDigestIndex.update(key.get(), 0, key.getSize());
+            this.checkSumDigestIndex.update(this.position);
+        }
 
         // Write length and value
         int valueLength = writable.getSize() - 4;
         this.valueFileStream.writeInt(valueLength);
-        this.checkSumDigestValue.update(valueLength);
         this.valueFileStream.write(valueBytes, 4, valueLength);
-        this.checkSumDigestValue.update(valueBytes, 4, valueLength);
-
+        if(this.checkSumDigestValue != null) {
+            this.checkSumDigestValue.update(valueLength);
+            this.checkSumDigestValue.update(valueBytes, 4, valueLength);
+        }
         this.position += 4 + valueLength;
         if(this.position < 0)
             throw new VoldemortException(""Chunk overflow exception: chunk "" + chunkId
                                          + "" has exceeded "" + Integer.MAX_VALUE + "" bytes."");
 
         // if we have multiple values for this md5 that is a collision, throw an
         // exception--either the data itself has duplicates, there are trillions
         // of keys, or someone is attempting something malicious
         if(values.hasNext())
             throw new VoldemortException(""Duplicate keys detected for md5 sum ""
                                          + ByteUtils.toHexString(ByteUtils.copy(key.get(),
                                                                                 0,
                                                                                 key.getSize())));
     }
\ No newline at end of file
",Buggy,"Fixed minor bug which returns NPE when Checksum is None
"
voldemort,10530.json,0b2ef083f53872f2686e10990e3586177c693bd6,"@@ -1,10 +1,12 @@
     public static String toString(CheckSumType type) {
         if(type == CheckSumType.ADLER32) {
             return ""adler32"";
         } else if(type == CheckSumType.CRC32) {
             return ""crc32"";
         } else if(type == CheckSumType.MD5) {
             return ""md5"";
+        } else if(type == CheckSumType.NONE) {
+            return ""none"";
         }
-        return null;
+        return ""none"";
     }
\ No newline at end of file
",NotBuggy,"Fixed minor bug which returns NPE when Checksum is None
"
weka,27677.json,29dadd8d55df37a7a89f355922eb92adc307f713,"@@ -1,27 +1,26 @@
   private double instanceTransformationProbability(Instance first, 
 						   Instance second) {
     String debug = ""(KStar.instanceTransformationProbability) "";
     double transProb = 1.0;
     int numMissAttr = 0;
     for (int i = 0; i < m_NumAttributes; i++) {
       if (i == m_Train.classIndex()) {
 	continue; // ignore class attribute
       }
       if (first.isMissing(i)) { // test instance attribute value is missing
 	numMissAttr++;
 	continue;
       }
       transProb *= attrTransProb(first, second, i);
       // normilize for missing values
       if (numMissAttr != m_NumAttributes) {
-	// I don't know where this comes from!!!
 	transProb = Math.pow(transProb, (double)m_NumAttributes / 
 			     (m_NumAttributes - numMissAttr));
       }
       else { // weird case!
 	transProb = 0.0;
       }
     }
     // normilize for the train dataset
      return transProb / m_NumInstances;
   }
\ No newline at end of file
",NotBuggy,"Fixed bug that prevented correct initialization for -E option during incremental
training.


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@445 e0a1b77d-ad91-4216-81b1-defd5f83fa92
"
weka,27694.json,29dadd8d55df37a7a89f355922eb92adc307f713,"@@ -1,3 +1,4 @@
   private void update_m_Attributes() {
     m_NumInstances = m_Train.numInstances();
+    m_InitFlag = ON;
   }
\ No newline at end of file
",Buggy,"Fixed bug that prevented correct initialization for -E option during incremental
training.


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@445 e0a1b77d-ad91-4216-81b1-defd5f83fa92
"
weka,31023.json,91f37b47e0458a307defac739c4967d86935770c,"@@ -1,13 +1,14 @@
   public void setSource(InputStream input) throws IOException {
     BufferedReader	reader;
     String		line;
     
     m_structure    = null;
     m_sourceFile   = null;
     m_File         = null;
 
     m_StreamBuffer = new StringBuffer();
     reader         = new BufferedReader(new InputStreamReader(input));
-    while ((line = reader.readLine()) != null)
+    while ((line = reader.readLine()) != null) {
       m_StreamBuffer.append(line + ""\n"");
+    }
   }
\ No newline at end of file
",NotBuggy,"Moved some code from setSource in ArffLoader to AbstractFileLoader so that other Loaders can handle gzip compression. Fixed bug in CSVLoader that was causing the source file to be loaded twice into the StringBuffer


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@4322 e0a1b77d-ad91-4216-81b1-defd5f83fa92
"
weka,30923.json,91f37b47e0458a307defac739c4967d86935770c,"@@ -1,18 +1,22 @@
   public void setSource(File file) throws IOException {
     m_structure = null;
+    
     setRetrieval(NONE);
 
-    if (file == null) {
+    if (file == null)
       throw new IOException(""Source file object is null!"");
-    }
 
     try {
-      setSource(new FileInputStream(file));
+      if (file.getName().endsWith(getFileExtension() + FILE_EXTENSION_COMPRESSED)) {
+	setSource(new GZIPInputStream(new FileInputStream(file)));
+      } else {
+	setSource(new FileInputStream(file));
+      }
     }
     catch (FileNotFoundException ex) {
       throw new IOException(""File not found"");
     }
-
+    
     m_sourceFile = file;
     m_File       = file.getAbsolutePath();
-  }
\ No newline at end of file
+    }
\ No newline at end of file
",Buggy,"Moved some code from setSource in ArffLoader to AbstractFileLoader so that other Loaders can handle gzip compression. Fixed bug in CSVLoader that was causing the source file to be loaded twice into the StringBuffer


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@4322 e0a1b77d-ad91-4216-81b1-defd5f83fa92
"
weka,11692.json,38a69e67c3d1f3dcb2e0c53e54f54b37ff25a090,"@@ -1,53 +1,52 @@
 	public void drawGraph() {
 		// build the panel
 		try {
 		  remove(canvas3D);
-		  System.out.println(""remove ok"");	
 		
 		} catch (Exception e) {
 		}
 //		if (!m_canvasCreated) {
 		  canvas3D = new Canvas3D(SimpleUniverse.getPreferredConfiguration());
 //		}
 
 		int scrHeight = (new Double(this.getSize().getHeight())).intValue();
 		int scrWidth = (new Double(this.getSize().getWidth())).intValue();
 		
 		canvas3D.setSize(scrWidth - 120, scrHeight - 50);
 		
 //		if (!m_canvasCreated) {
 		add(canvas3D, java.awt.BorderLayout.CENTER);
 		m_canvasCreated = true;
 //		}
 		
 		freeResources();				
 		
 		// build the visualisation
                 m_scene = createSceneGraph();
 
                 // compile the scene
                 m_scene.compile();
 
 	        // build the universe
 		m_simpleU = new SimpleUniverse(canvas3D);
 
 
 		// add the behaviors to the ViewingPlatform
 		ViewingPlatform viewingPlatform = m_simpleU.getViewingPlatform();
 
 		viewingPlatform.setNominalViewingTransform();
 
 		// add orbit behavior to ViewingPlatform
 		orbit =
 			new OrbitBehavior(
 				canvas3D,
 				OrbitBehavior.REVERSE_ALL | OrbitBehavior.STOP_ZOOM);
 		BoundingSphere bounds =
 			new BoundingSphere(new Point3d(0.0, 0.0, 0.0), 100.0);
 		orbit.setSchedulingBounds(bounds);
 		viewingPlatform.setViewPlatformBehavior(orbit);
 		
 
 		m_simpleU.addBranchGraph(m_scene);
 
 	}
\ No newline at end of file
",NotBuggy,"Fixed a refresh bug that prevented the switching back to the rules selection tab from the 3D viewer tab. Now depends on the scatterPlot3D package for the Java3D libraries

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@12305 e0a1b77d-ad91-4216-81b1-defd5f83fa92
"
weka,11730.json,38a69e67c3d1f3dcb2e0c53e54f54b37ff25a090,"@@ -1,23 +1,37 @@
 	private void panelChanged() {
 		int numTab = viewerTabbedPanel.getSelectedIndex();
 		visu1Rules = selectionPanel.getSelectedRules(1);
 /*		visu2Rules = selectionPanel.getSelectedRules(2);
 		visu3Rules = selectionPanel.getSelectedRules(3); */
 
 		switch (numTab) {
+		case 0:
+			visu1PanelHolder.removeAll();
+			visu1PanelHolder.revalidate();
+			visu1PanelHolder.repaint();
+			break;
 			case 1 :
+				visu1PanelHolder.add(visu1Panel3D, BorderLayout.CENTER);
+				revalidate();
+				repaint();
 				String[] selectedCriteria =
 					selectionPanel.getSelectedCriteria();
 				visu1Panel3D.setData(visu1Rules, selectedCriteria);
 //				visu1Panel.setSelectedRules(visu2Rules);
 				break;
 			case 2 :
 				visu2Panel.setData(visu2Rules, criteres);
 				visu2Panel.setSelectedRules(visu3Rules);
+				visu1PanelHolder.removeAll();
+				visu1PanelHolder.revalidate();
+				visu1PanelHolder.repaint();
 				break;
 			case 3 :
 				visu3Panel.setData(visu3Rules);
+				visu1PanelHolder.removeAll();
+				visu1PanelHolder.revalidate();
+				visu1PanelHolder.repaint();
 				break;
 		}
 
 	}
\ No newline at end of file
",Buggy,"Fixed a refresh bug that prevented the switching back to the rules selection tab from the 3D viewer tab. Now depends on the scatterPlot3D package for the Java3D libraries

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@12305 e0a1b77d-ad91-4216-81b1-defd5f83fa92
"
weka,11722.json,38a69e67c3d1f3dcb2e0c53e54f54b37ff25a090,"@@ -1,114 +1,115 @@
 	private void initComponents() {
 	    setLayout(new java.awt.BorderLayout());
 		viewerTabbedPanel = new javax.swing.JTabbedPane();
 		selectionPanel = new selection.SelectionPanel();
 		visu1Panel3D = new Panel3D();
+		visu1PanelHolder.add(visu1Panel3D, BorderLayout.CENTER);
 		/*visu1Panel = new RulesSelectionPanel(visu1Panel3D);
 		visu1Panel.addActionListener(this); */
 /*		visu2PanelLine = new PanelLine();
 		visu2Panel = new RulesSelectionPanel(visu2PanelLine);
 		visu2Panel.setSingleSelection();
 		visu2Panel.addActionListener(this);
 		visu2Panel.setColored();
 		visu3Panel = new visu3.PanelDDecker(); */
 		// viewerBar = new javax.swing.JMenuBar();
 /*		fileMenu = new javax.swing.JMenu();
 		openItem = new javax.swing.JMenuItem();
 		printItem = new javax.swing.JMenuItem();
 		saveItem = new javax.swing.JMenuItem();
 		quitItem = new javax.swing.JMenuItem();
 		helpMenu = new javax.swing.JMenu();
 		aboutItem = new javax.swing.JMenuItem();
 		contentsItem = new javax.swing.JMenuItem(); */
 
 		selectionPanel.addMultipleListSelectionListener(this);
 
 //		setTitle(""Association Rules Viewer"");
 /*		addWindowListener(new java.awt.event.WindowAdapter() {
 			public void windowClosing(java.awt.event.WindowEvent evt) {
 				exitForm(evt);
 			}
 		}); */
 
 		viewerTabbedPanel.addChangeListener(new ChangeListener() {
 			public void stateChanged(ChangeEvent e) {
 				panelChanged();
 			}
 
 		});
 
 		viewerTabbedPanel.addTab(""Selection"", selectionPanel);
-		viewerTabbedPanel.addTab(""3D Representation"", visu1Panel3D);
+		viewerTabbedPanel.addTab(""3D Representation"", visu1PanelHolder);
 		/*viewerTabbedPanel.addTab(""N Dimensional Line"", visu2Panel);
 		viewerTabbedPanel.addTab(""Double Decker Plot"", visu3Panel); */
 
 		viewerTabbedPanel.setEnabledAt(1, false);
 		// viewerTabbedPanel.setEnabledAt(2, false);
 //		viewerTabbedPanel.setEnabledAt(3, false);
 
 		add(viewerTabbedPanel, java.awt.BorderLayout.CENTER);
 
 /*		fileMenu.setText(""File"");
 		openItem.setText(""Open"");
 		openItem.addActionListener(new java.awt.event.ActionListener() {
 			public void actionPerformed(java.awt.event.ActionEvent evt) {
 				openPerformed(evt);
 			}
 		});
 
 		fileMenu.add(openItem);
 
 		printItem.setText(""Print"");
 		printItem.addActionListener(new java.awt.event.ActionListener() {
 			public void actionPerformed(java.awt.event.ActionEvent evt) {
 				printPerformed(evt);
 			}
 		});
 
 		fileMenu.add(printItem);
 
 		saveItem.setText(""Save as"");
 		saveItem.addActionListener(new java.awt.event.ActionListener() {
 			public void actionPerformed(java.awt.event.ActionEvent evt) {
 				savePerformed(evt);
 			}
 		});
 
 		fileMenu.add(saveItem);
 
 		quitItem.setText(""Quit"");
 		quitItem.addActionListener(new java.awt.event.ActionListener() {
 			public void actionPerformed(java.awt.event.ActionEvent evt) {
 				quitPerformed(evt);
 			}
 		});
 
 		fileMenu.add(quitItem);
 
 		viewerBar.add(fileMenu);
 
 		helpMenu.setText(""Help"");
 		aboutItem.setText(""About"");
 		aboutItem.addActionListener(new java.awt.event.ActionListener() {
 			public void actionPerformed(java.awt.event.ActionEvent evt) {
 				showAbout(evt);
 			}
 		});
 
 		helpMenu.add(aboutItem);
 
 		contentsItem.setText(""Contents"");
 		contentsItem.addActionListener(new java.awt.event.ActionListener() {
 			public void actionPerformed(java.awt.event.ActionEvent evt) {
 				showHelp(evt);
 			}
 		});
 
 		helpMenu.add(contentsItem);
 
 		viewerBar.add(helpMenu);
 
 		setJMenuBar(viewerBar);
 
 		pack(); */
 	}
\ No newline at end of file
",Buggy,"Fixed a refresh bug that prevented the switching back to the rules selection tab from the 3D viewer tab. Now depends on the scatterPlot3D package for the Java3D libraries

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@12305 e0a1b77d-ad91-4216-81b1-defd5f83fa92
"
weka,28529.json,c34e6f5c40e4a29dfcedb4b3333188288fb79717,"@@ -1,11 +1,12 @@
     public static void main(String[] args) {
         try {
+	    System.err.println(""okidoki"");
             BIFReader br = new BIFReader();
             br.processFile(args[0]);
 	    System.out.println(br.toString());
         
         }
         catch (Throwable t) {
             t.printStackTrace();
         }
     } // main
\ No newline at end of file
",NotBuggy,"Bug fix spotted by Gladys Castillo Jordan


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@2176 e0a1b77d-ad91-4216-81b1-defd5f83fa92
"
weka,28685.json,c34e6f5c40e4a29dfcedb4b3333188288fb79717,"@@ -1,10 +1,10 @@
     public Enumeration listOptions() {
         Vector newVector = new Vector(4);
 
-        newVector.addElement(new Option(""\tUse ADTree data structure\n"", ""D"", 0, ""-D""));
+        newVector.addElement(new Option(""\tDo not use ADTree data structure\n"", ""D"", 0, ""-D""));
         newVector.addElement(new Option(""\tBIF file to compare with\n"", ""B"", 1, ""-B <BIF file>""));
         newVector.addElement(new Option(""\tSearch algorithm\n"", ""Q"", 1, ""-Q weka.classifiers.bayes.net.search.SearchAlgorithm""));
         newVector.addElement(new Option(""\tEstimator algorithm\n"", ""E"", 1, ""-E weka.classifiers.bayes.net.estimate.SimpleEstimator""));
 
         return newVector.elements();
     } // listOptions
\ No newline at end of file
",Buggy,"Bug fix spotted by Gladys Castillo Jordan


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@2176 e0a1b77d-ad91-4216-81b1-defd5f83fa92
"
weka,28381.json,c34e6f5c40e4a29dfcedb4b3333188288fb79717,"@@ -1,40 +1,41 @@
 	public double kFoldCV(BayesNet bayesNet, int nNrOfFolds) throws Exception {
 		m_BayesNet = bayesNet;
 		double fAccuracy = 0.0;
 		double fWeight = 0.0;
 		Instances instances = bayesNet.m_Instances;
 		// estimate CPTs based on complete data set
 		bayesNet.estimateCPTs();
 		int nFoldStart = 0;
 		int nFoldEnd = instances.numInstances() / nNrOfFolds;
 		int iFold = 1;
 		while (nFoldStart < instances.numInstances()) {
 			// remove influence of fold iFold from the probability distribution
 			for (int iInstance = nFoldStart; iInstance < nFoldEnd; iInstance++) {
 				Instance instance = instances.instance(iInstance);
 				instance.setWeight(-instance.weight());
 				bayesNet.updateClassifier(instance);
 			}
 			
 			// measure accuracy on fold iFold
 			for (int iInstance = nFoldStart; iInstance < nFoldEnd; iInstance++) {
 				Instance instance = instances.instance(iInstance);
 				instance.setWeight(-instance.weight());
 				fAccuracy += accuracyIncrease(instance);
+				instance.setWeight(-instance.weight());
 				fWeight += instance.weight();
 			}
 
 			// restore influence of fold iFold from the probability distribution
 			for (int iInstance = nFoldStart; iInstance < nFoldEnd; iInstance++) {
 				Instance instance = instances.instance(iInstance);
 				instance.setWeight(-instance.weight());
 				bayesNet.updateClassifier(instance);
 			}
 
 			// go to next fold
 			nFoldStart = nFoldEnd;
 			iFold++;
 			nFoldEnd = iFold * instances.numInstances() / nNrOfFolds;
 		}
 		return fAccuracy / fWeight;
 	} // kFoldCV
\ No newline at end of file
",Buggy,"Bug fix spotted by Gladys Castillo Jordan


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@2176 e0a1b77d-ad91-4216-81b1-defd5f83fa92
"
weka,25948.json,449c6a2d0acb111174652c53dff0960ed4f6e606,"@@ -1,61 +1,57 @@
   private double findSplitNominalNominal(int index) throws Exception {
 
     double bestVal = Double.MAX_VALUE, currVal;
     double[][] counts = new double[theInstances.attribute(index).numValues() 
 				  + 1][theInstances.numClasses()];
     double[] sumCounts = new double[theInstances.numClasses()];
     double[][] bestDist = new double[3][theInstances.numClasses()];
     int numMissing = 0;
 
     // Compute counts for all the values
-
     for (int i = 0; i < theInstances.numInstances(); i++) {
       Instance inst = theInstances.instance(i);
       if (inst.isMissing(index)) {
 	numMissing++;
 	counts[theInstances.attribute(index).numValues()]
 	  [(int)inst.classValue()] += inst.weight();
       } else {
 	counts[(int)inst.value(index)][(int)inst.classValue()] += inst
 	  .weight();
       }
     }
 
     // Compute sum of counts
-
     for (int i = 0; i < theInstances.attribute(index).numValues() + 1; i++) {
       for (int j = 0; j < theInstances.numClasses(); j++) {
 	sumCounts[j] += counts[i][j];
       }
     }
     
     // Make split counts for each possible split and evaluate
-
     System.arraycopy(counts[theInstances.attribute(index).numValues()], 0,
 		     m_Distribution[2], 0, theInstances.numClasses());
     for (int i = 0; i < theInstances.attribute(index).numValues(); i++) {
       for (int j = 0; j < theInstances.numClasses(); j++) {
 	m_Distribution[0][j] = counts[i][j];
 	m_Distribution[1][j] = sumCounts[j] - counts[i][j];
       }
       currVal = ContingencyTables.entropyConditionedOnRows(m_Distribution);
       if (Utils.sm(currVal, bestVal)) {
 	bestVal = currVal;
 	m_SplitPoint = (double)i;
 	for (int j = 0; j < 3; j++) {
 	  System.arraycopy(m_Distribution[j], 0, bestDist[j], 0, 
 			   theInstances.numClasses());
 	}
       }
     }
 
     // No missing values in training data.
-
     if (numMissing == 0) {
       System.arraycopy(sumCounts, 0, bestDist[2], 0, 
 		       theInstances.numClasses());
     }
    
     m_Distribution = bestDist;
     return bestVal;
   }
\ No newline at end of file
",NotBuggy,"Fixed division by zero bugs for numeric prediction.


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@26 e0a1b77d-ad91-4216-81b1-defd5f83fa92
"
weka,25951.json,449c6a2d0acb111174652c53dff0960ed4f6e606,"@@ -1,54 +1,50 @@
   private double findSplitNumericNominal(int index) throws Exception {
 
     double bestVal = Double.MAX_VALUE, currVal, currCutPoint;
     int numMissing = 0;
     double[] sum = new double[theInstances.numClasses()];
     double[][] bestDist = new double[3][theInstances.numClasses()];
 
     // Compute counts for all the values
-
     for (int i = 0; i < theInstances.numInstances(); i++) {
       Instance inst = theInstances.instance(i);
       if (!inst.isMissing(index)) {
 	m_Distribution[1][(int)inst.classValue()] += inst.weight();
       } else {
 	m_Distribution[2][(int)inst.classValue()] += inst.weight();
 	numMissing++;
       }
     }
     System.arraycopy(m_Distribution[1], 0, sum, 0, theInstances.numClasses());
 
     // Sort instances
-
     theInstances.sort(index);
     
     // Make split counts for each possible split and evaluate
-
     for (int i = 0; i < theInstances.numInstances() - (numMissing + 1); i++) {
       Instance inst = theInstances.instance(i);
       Instance instPlusOne = theInstances.instance(i + 1);
       m_Distribution[0][(int)inst.classValue()] += inst.weight();
       m_Distribution[1][(int)inst.classValue()] -= inst.weight();
       if (Utils.sm(inst.value(index), instPlusOne.value(index))) {
 	currCutPoint = (inst.value(index) + instPlusOne.value(index)) / 2.0;
 	currVal = ContingencyTables.entropyConditionedOnRows(m_Distribution);
 	if (Utils.sm(currVal, bestVal)) {
 	  m_SplitPoint = currCutPoint;
 	  bestVal = currVal;
 	  for (int j = 0; j < 3; j++) {
 	    System.arraycopy(m_Distribution[j], 0, bestDist[j], 0, 
 			     theInstances.numClasses());
 	  }
 	}
       }
     }
 
     // No missing values in training data.
-
     if (numMissing == 0) {
       System.arraycopy(sum, 0, bestDist[2], 0, theInstances.numClasses());
     }
  
     m_Distribution = bestDist;
     return bestVal;
   }
\ No newline at end of file
",NotBuggy,"Fixed division by zero bugs for numeric prediction.


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@26 e0a1b77d-ad91-4216-81b1-defd5f83fa92
"
weka,25940.json,449c6a2d0acb111174652c53dff0960ed4f6e606,"@@ -1,63 +1,58 @@
   public void buildClassifier(Instances instances) throws Exception {
     
     double bestVal = Double.MAX_VALUE, currVal;
     double bestPoint = -Double.MAX_VALUE, sum;
     int bestAtt = -1, numClasses;
 
     if (instances.checkForStringAttributes()) {
       throw new Exception(""Can't handle string attributes!"");
     }
 
     double[][] bestDist = new double[3][instances.numClasses()];
 
     theInstances = new Instances(instances);
     theInstances.deleteWithMissingClass();
     if (theInstances.classAttribute().isNominal()) {
       numClasses = theInstances.numClasses();
     } else {
       numClasses = 1;
     }
 
     // For each attribute
-    
     for (int i = 0; i < theInstances.numAttributes(); i++) {
       if (i != theInstances.classIndex()) {
 	
 	// Reserve space for distribution.
-	
 	m_Distribution = new double[3][numClasses];
 
 	// Compute value of criterion for best split on attribute
-	
 	if (theInstances.attribute(i).isNominal()) {
 	  currVal = findSplitNominal(i);
 	} else {
 	  currVal = findSplitNumeric(i);
 	}
 	if (Utils.sm(currVal, bestVal)) {
 	  bestVal = currVal;
 	  bestAtt = i;
 	  bestPoint = m_SplitPoint;
 	  for (int j = 0; j < 3; j++) {
 	    System.arraycopy(m_Distribution[j], 0, bestDist[j], 0, 
 			     numClasses);
 	  }
 	}
       }
     }
     
     // Set attribute, split point and distribution.
-    
     m_AttIndex = bestAtt;
     m_SplitPoint = bestPoint;
     m_Distribution = bestDist;
     if (theInstances.classAttribute().isNominal()) {
       for (int i = 0; i < m_Distribution.length; i++) {
 	Utils.normalize(m_Distribution[i]);
       }
     }
     
     // Save memory
-    
     theInstances = new Instances(theInstances, 0);
   }
\ No newline at end of file
",NotBuggy,"Fixed division by zero bugs for numeric prediction.


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@26 e0a1b77d-ad91-4216-81b1-defd5f83fa92
"
weka,25952.json,449c6a2d0acb111174652c53dff0960ed4f6e606,"@@ -1,64 +1,60 @@
   private double findSplitNumericNumeric(int index) throws Exception {
 
     double bestVal = Double.MAX_VALUE, currVal, currCutPoint;
     int numMissing = 0;
     double[] sumsSquares = new double[3], sumOfWeights = new double[3];
     double[][] bestDist = new double[3][1];
-    double meanNoMissing;
+    double totalSum = 0, totalSumOfWeights = 0;
 
     // Compute counts for all the values
-
     for (int i = 0; i < theInstances.numInstances(); i++) {
       Instance inst = theInstances.instance(i);
       if (!inst.isMissing(index)) {
 	m_Distribution[1][0] += inst.classValue() * inst.weight();
 	sumsSquares[1] += inst.classValue() * inst.classValue() 
 	  * inst.weight();
 	sumOfWeights[1] += inst.weight();
       } else {
 	m_Distribution[2][0] += inst.classValue() * inst.weight();
 	sumsSquares[2] += inst.classValue() * inst.classValue() 
 	  * inst.weight();
 	sumOfWeights[2] += inst.weight();
 	numMissing++;
       }
+      totalSumOfWeights += inst.weight();
+      totalSum += inst.classValue() * inst.weight();
     }
-    meanNoMissing = m_Distribution[1][0] / sumOfWeights[1];
 
     // Sort instances
-
     theInstances.sort(index);
     
     // Make split counts for each possible split and evaluate
-
     for (int i = 0; i < theInstances.numInstances() - (numMissing + 1); i++) {
       Instance inst = theInstances.instance(i);
       Instance instPlusOne = theInstances.instance(i + 1);
       m_Distribution[0][0] += inst.classValue() * inst.weight();
       sumsSquares[0] += inst.classValue() * inst.classValue() * inst.weight();
       sumOfWeights[0] += inst.weight();
       m_Distribution[1][0] -= inst.classValue() * inst.weight();
       sumsSquares[1] -= inst.classValue() * inst.classValue() * inst.weight();
       sumOfWeights[1] -= inst.weight();
       if (Utils.sm(inst.value(index), instPlusOne.value(index))) {
 	currCutPoint = (inst.value(index) + instPlusOne.value(index)) / 2.0;
 	currVal = variance(m_Distribution, sumsSquares, sumOfWeights);
 	if (Utils.sm(currVal, bestVal)) {
 	  m_SplitPoint = currCutPoint;
 	  bestVal = currVal;
 	  for (int j = 0; j < 3; j++) {
-	    bestDist[j][0] = m_Distribution[j][0] / sumOfWeights[j];
+	    if (!Utils.eq(sumOfWeights[j], 0)) {
+	      bestDist[j][0] = m_Distribution[j][0] / sumOfWeights[j];
+	    } else {
+	      bestDist[j][0] = totalSum / totalSumOfWeights;
+	    }
 	  }
 	}
       }
     }
 
-    // No missing values in training data
-    
-    if (numMissing == 0) {
-      bestDist[2][0] = meanNoMissing;
-    }
-
     m_Distribution = bestDist;
     return bestVal;
   }
\ No newline at end of file
",Buggy,"Fixed division by zero bugs for numeric prediction.


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@26 e0a1b77d-ad91-4216-81b1-defd5f83fa92
"
weka,20096.json,f39f7d042b70f510b9721bbff0535ef0a3d348a8,"@@ -1,38 +1,40 @@
   public void performRequest(String request) {
     if (request.compareTo(""Show chart"") == 0) {
       try {
-	// popup visualize panel
-	if (!m_framePoppedUp) {
-	  m_framePoppedUp = true;
+        // popup visualize panel
+        if (!m_framePoppedUp) {
+          m_framePoppedUp = true;
 
-	  final javax.swing.JFrame jf = 
-	    new javax.swing.JFrame(""Model Performance Chart"");
-	  jf.setSize(800,600);
-	  jf.getContentPane().setLayout(new BorderLayout());
-	  jf.getContentPane().add(m_visPanel, BorderLayout.CENTER);
-	  jf.addWindowListener(new java.awt.event.WindowAdapter() {
-	      public void windowClosing(java.awt.event.WindowEvent e) {
-		jf.dispose();
-		m_framePoppedUp = false;
-	      }
-	    });
-	  jf.setVisible(true);
-	  m_popupFrame = jf;
-	} else {
-	  m_popupFrame.toFront();
-	}
+          final javax.swing.JFrame jf = new javax.swing.JFrame(
+              ""Model Performance Chart"");
+          jf.setSize(800, 600);
+          jf.getContentPane().setLayout(new BorderLayout());
+          jf.getContentPane().add(m_visPanel, BorderLayout.CENTER);
+          jf.addWindowListener(new java.awt.event.WindowAdapter() {
+            @Override
+            public void windowClosing(java.awt.event.WindowEvent e) {
+              jf.dispose();
+              m_framePoppedUp = false;
+            }
+          });
+          jf.setVisible(true);
+          m_popupFrame = jf;
+        } else {
+          m_popupFrame.toFront();
+        }
       } catch (Exception ex) {
-	ex.printStackTrace();
-	m_framePoppedUp = false;
+        ex.printStackTrace();
+        m_framePoppedUp = false;
       }
     } else if (request.equals(""Clear all plots"")) {
-        m_visPanel.removeAllPlots();
-        m_visPanel.validate(); m_visPanel.repaint();
-        m_visPanel = null;
-        m_masterPlot = null;
-        m_offscreenPlotData = null;
+      m_visPanel.removeAllPlots();
+      m_visPanel.validate();
+      m_visPanel.repaint();
+      m_visPanel = null;
+      m_masterPlot = null;
+      m_offscreenPlotData = null;
     } else {
       throw new IllegalArgumentException(request
-					 + "" not supported (Model Performance Chart)"");
+          + "" not supported (Model Performance Chart)"");
     }
   }
\ No newline at end of file
",NotBuggy,"Fixed a bug for error plots where once the master plot had been set it did not get changed for subsequent incoming VisualizableErrorEvents (unless manually clearing all plots via the GUI).

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@9452 e0a1b77d-ad91-4216-81b1-defd5f83fa92
"
weka,20081.json,f39f7d042b70f510b9721bbff0535ef0a3d348a8,"@@ -1,174 +1,179 @@
   public synchronized void acceptDataSet(VisualizableErrorEvent e) {
     if (m_env == null) {
       m_env = Environment.getSystemWide();
     }
 
     if (!GraphicsEnvironment.isHeadless()) {
       if (m_visPanel == null) {
         m_visPanel = new VisualizePanel();
       }
-      if (m_masterPlot == null) {
-        m_masterPlot = e.getDataSet();
-      }
+
+      m_masterPlot = e.getDataSet();
+
       try {
         m_visPanel.setMasterPlot(m_masterPlot);
       } catch (Exception ex) {
-        System.err.println(""Problem setting up visualization (ModelPerformanceChart)"");
+        System.err
+            .println(""Problem setting up visualization (ModelPerformanceChart)"");
         ex.printStackTrace();
       }
       m_visPanel.validate();
       m_visPanel.repaint();
     } else {
       m_headlessEvents = new ArrayList<EventObject>();
       m_headlessEvents.add(e);
     }
-    
+
     if (m_imageListeners.size() > 0 && !m_processingHeadlessEvents) {
       // configure the renderer (if necessary)
       setupOffscreenRenderer();
-     
-      m_offscreenPlotData = new ArrayList<Instances>();      
+
+      m_offscreenPlotData = new ArrayList<Instances>();
       Instances predictedI = e.getDataSet().getPlotInstances();
       if (predictedI.classAttribute().isNominal()) {
-        
+
         // split the classes out into individual series.
         // add a new attribute to hold point sizes - correctly
-        // classified instances get default point size (2); 
+        // classified instances get default point size (2);
         // misclassified instances get point size (5).
         // WekaOffscreenChartRenderer can take advantage of this
         // information - other plugin renderers may or may not
         // be able to use it
         FastVector atts = new FastVector();
         for (int i = 0; i < predictedI.numAttributes(); i++) {
           atts.add(predictedI.attribute(i).copy());
         }
         atts.add(new Attribute(""@@size@@""));
-        Instances newInsts = new Instances(predictedI.relationName(),
-            atts, predictedI.numInstances());
+        Instances newInsts = new Instances(predictedI.relationName(), atts,
+            predictedI.numInstances());
         newInsts.setClassIndex(predictedI.classIndex());
-        
+
         for (int i = 0; i < predictedI.numInstances(); i++) {
           double[] vals = new double[newInsts.numAttributes()];
           for (int j = 0; j < predictedI.numAttributes(); j++) {
             vals[j] = predictedI.instance(i).value(j);
           }
           vals[vals.length - 1] = 2; // default shape size
           Instance ni = new DenseInstance(1.0, vals);
           newInsts.add(ni);
         }
-        
+
         // predicted class attribute is always actualClassIndex - 1
         Instances[] classes = new Instances[newInsts.numClasses()];
         for (int i = 0; i < newInsts.numClasses(); i++) {
           classes[i] = new Instances(newInsts, 0);
           classes[i].setRelationName(newInsts.classAttribute().value(i));
         }
         Instances errors = new Instances(newInsts, 0);
         int actualClass = newInsts.classIndex();
         for (int i = 0; i < newInsts.numInstances(); i++) {
           Instance current = newInsts.instance(i);
-          classes[(int)current.classValue()].add((Instance)current.copy());
-          
+          classes[(int) current.classValue()].add((Instance) current.copy());
+
           if (current.value(actualClass) != current.value(actualClass - 1)) {
-            Instance toAdd = (Instance)current.copy();
-            
+            Instance toAdd = (Instance) current.copy();
+
             // larger shape for an error
             toAdd.setValue(toAdd.numAttributes() - 1, 5);
-            
+
             // swap predicted and actual class value so
             // that the color plotted for the error series
             // is that of the predicted class
             double actualClassV = toAdd.value(actualClass);
             double predictedClassV = toAdd.value(actualClass - 1);
             toAdd.setValue(actualClass, predictedClassV);
             toAdd.setValue(actualClass - 1, actualClassV);
-              
-            errors.add(toAdd);            
+
+            errors.add(toAdd);
           }
         }
-        
+
         errors.setRelationName(""Errors"");
         m_offscreenPlotData.add(errors);
-        
+
         for (int i = 0; i < classes.length; i++) {
           m_offscreenPlotData.add(classes[i]);
         }
-  
+
       } else {
         // numeric class - have to make a new set of instances
         // with the point sizes added as an additional attribute
         FastVector atts = new FastVector();
         for (int i = 0; i < predictedI.numAttributes(); i++) {
           atts.add(predictedI.attribute(i).copy());
         }
         atts.add(new Attribute(""@@size@@""));
-        Instances newInsts = new Instances(predictedI.relationName(),
-            atts, predictedI.numInstances());
+        Instances newInsts = new Instances(predictedI.relationName(), atts,
+            predictedI.numInstances());
 
         int[] shapeSizes = e.getDataSet().getShapeSize();
 
         for (int i = 0; i < predictedI.numInstances(); i++) {
           double[] vals = new double[newInsts.numAttributes()];
           for (int j = 0; j < predictedI.numAttributes(); j++) {
             vals[j] = predictedI.instance(i).value(j);
           }
           vals[vals.length - 1] = shapeSizes[i];
           Instance ni = new DenseInstance(1.0, vals);
           newInsts.add(ni);
         }
         newInsts.setRelationName(predictedI.classAttribute().name());
         m_offscreenPlotData.add(newInsts);
       }
-      
+
       List<String> options = new ArrayList<String>();
-      
+
       String additional = ""-color="" + predictedI.classAttribute().name()
-        + "",-hasErrors"";
+          + "",-hasErrors"";
       if (m_additionalOptions != null && m_additionalOptions.length() > 0) {
         additional += "","" + m_additionalOptions;
         try {
           additional = m_env.substitute(additional);
-        } catch (Exception ex) { }
-      }            
+        } catch (Exception ex) {
+        }
+      }
       String[] optionsParts = additional.split("","");
       for (String p : optionsParts) {
         options.add(p.trim());
       }
-      
-//      if (predictedI.classAttribute().isNumeric()) {
+
+      // if (predictedI.classAttribute().isNumeric()) {
       options.add(""-shapeSize=@@size@@"");
-//      }
-      
+      // }
+
       String xAxis = m_xAxis;
       try {
         xAxis = m_env.substitute(xAxis);
-      } catch (Exception ex) { }
-      
+      } catch (Exception ex) {
+      }
+
       String yAxis = m_yAxis;
       try {
         yAxis = m_env.substitute(yAxis);
-      } catch (Exception ex) { }
-      
+      } catch (Exception ex) {
+      }
+
       String width = m_width;
       String height = m_height;
       int defWidth = 500;
       int defHeight = 400;
       try {
         width = m_env.substitute(width);
         height = m_env.substitute(height);
-        
+
         defWidth = Integer.parseInt(width);
         defHeight = Integer.parseInt(height);
-      } catch (Exception ex) { }
-      
+      } catch (Exception ex) {
+      }
+
       try {
-        BufferedImage osi = m_offscreenRenderer.renderXYScatterPlot(defWidth, defHeight, 
-            m_offscreenPlotData, xAxis, yAxis, options);
+        BufferedImage osi = m_offscreenRenderer.renderXYScatterPlot(defWidth,
+            defHeight, m_offscreenPlotData, xAxis, yAxis, options);
 
         ImageEvent ie = new ImageEvent(this, osi);
         notifyImageListeners(ie);
       } catch (Exception e1) {
         e1.printStackTrace();
-      }      
+      }
     }
   }
\ No newline at end of file
",Buggy,"Fixed a bug for error plots where once the master plot had been set it did not get changed for subsequent incoming VisualizableErrorEvents (unless manually clearing all plots via the GUI).

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@9452 e0a1b77d-ad91-4216-81b1-defd5f83fa92
"
weka,18379.json,41f296c55b87a1ead276fffbafb67535b858a70f,"@@ -1,44 +1,52 @@
   private void saveExperiment() {
 
     int returnVal = m_FileChooser.showSaveDialog(this);
     if (returnVal != JFileChooser.APPROVE_OPTION) {
       return;
     }
     File expFile = m_FileChooser.getSelectedFile();
-    if ( !(    (expFile.getName().toLowerCase().endsWith(Experiment.FILE_EXTENSION))
-          || (KOML.isPresent() && expFile.getName().toLowerCase().endsWith(KOML.FILE_EXTENSION))
-          || (expFile.getName().toLowerCase().endsWith("".xml"")) ) )
-    {
-      expFile = new File(expFile.getParent(), expFile.getName()
-                         + Experiment.FILE_EXTENSION);
+    
+    // add extension if necessary
+    if (m_FileChooser.getFileFilter() == m_ExpFilter) {
+      if (!expFile.getName().toLowerCase().endsWith(Experiment.FILE_EXTENSION))
+        expFile = new File(expFile.getParent(), expFile.getName() + Experiment.FILE_EXTENSION);
     }
+    else if (m_FileChooser.getFileFilter() == m_KOMLFilter) {
+      if (!expFile.getName().toLowerCase().endsWith(KOML.FILE_EXTENSION))
+        expFile = new File(expFile.getParent(), expFile.getName() + KOML.FILE_EXTENSION);
+    }
+    else if (m_FileChooser.getFileFilter() == m_XMLFilter) {
+      if (!expFile.getName().toLowerCase().endsWith("".xml""))
+        expFile = new File(expFile.getParent(), expFile.getName() + "".xml"");
+    }
+    
     try {
        // KOML?
        if ( (KOML.isPresent()) && (expFile.getAbsolutePath().toLowerCase().endsWith(KOML.FILE_EXTENSION)) ) {
           KOML.write(expFile.getAbsolutePath(), m_Exp);
        }
        else
        // XML?
        if (expFile.getAbsolutePath().toLowerCase().endsWith("".xml"")) {
           XMLExperiment xml = new XMLExperiment(); 
           xml.write(expFile, m_Exp);
        }
        // binary
        else {
           FileOutputStream fo = new FileOutputStream(expFile);
           ObjectOutputStream oo = new ObjectOutputStream(
                                   new BufferedOutputStream(fo));
           oo.writeObject(m_Exp);
           oo.close();
        }
       
       System.err.println(""Saved experiment:\n"" + m_Exp);
     } catch (Exception ex) {
       ex.printStackTrace();
       JOptionPane.showMessageDialog(this, ""Couldn't save experiment file:\n""
 				    + expFile
 				    + ""\nReason:\n"" + ex.getMessage(),
 				    ""Save Experiment"",
 				    JOptionPane.ERROR_MESSAGE);
     }
   }
\ No newline at end of file
",Buggy,"A few bug fixes from Peter regarding the latest GUI additions. Also eliminated some superfluous output from NaiveBayesSimple.


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@2259 e0a1b77d-ad91-4216-81b1-defd5f83fa92
"
weka,8611.json,41f296c55b87a1ead276fffbafb67535b858a70f,"@@ -1,31 +1,29 @@
   public double[] distributionForInstance(Instance instance) throws Exception {
     
     double [] probs = new double[instance.numClasses()];
     int attIndex;
     
     for (int j = 0; j < instance.numClasses(); j++) {
       probs[j] = 1;
       Enumeration enumAtts = instance.enumerateAttributes();
       attIndex = 0;
       while (enumAtts.hasMoreElements()) {
 	Attribute attribute = (Attribute) enumAtts.nextElement();
 	if (!instance.isMissing(attribute)) {
 	  if (attribute.isNominal()) {
 	    probs[j] *= m_Counts[j][attIndex][(int)instance.value(attribute)];
 	  } else {
 	    probs[j] *= normalDens(instance.value(attribute),
 				   m_Means[j][attIndex],
 				   m_Devs[j][attIndex]);}
 	}
 	attIndex++;
       }
-      System.out.println(probs[j] + "" "");
       probs[j] *= m_Priors[j];
     }
-    System.out.println();
 
     // Normalize probabilities
     Utils.normalize(probs);
 
     return probs;
   }
\ No newline at end of file
",NotBuggy,"A few bug fixes from Peter regarding the latest GUI additions. Also eliminated some superfluous output from NaiveBayesSimple.


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@2259 e0a1b77d-ad91-4216-81b1-defd5f83fa92
"
weka,18418.json,41f296c55b87a1ead276fffbafb67535b858a70f,"@@ -1,47 +1,55 @@
   private void openExperiment() {
     
     int returnVal = m_FileChooser.showOpenDialog(this);
     if (returnVal != JFileChooser.APPROVE_OPTION) {
       return;
     }
     File expFile = m_FileChooser.getSelectedFile();
-    if ( !(    (expFile.getName().toLowerCase().endsWith(Experiment.FILE_EXTENSION))
-          || (KOML.isPresent() && expFile.getName().toLowerCase().endsWith(KOML.FILE_EXTENSION))
-          || (expFile.getName().toLowerCase().endsWith("".xml"")) ) )
-    {
-       expFile = new File(expFile.getParent(), expFile.getName()
-                          + Experiment.FILE_EXTENSION);
+    
+    // add extension if necessary
+    if (m_FileChooser.getFileFilter() == m_ExpFilter) {
+      if (!expFile.getName().toLowerCase().endsWith(Experiment.FILE_EXTENSION))
+        expFile = new File(expFile.getParent(), expFile.getName() + Experiment.FILE_EXTENSION);
     }
+    else if (m_FileChooser.getFileFilter() == m_KOMLFilter) {
+      if (!expFile.getName().toLowerCase().endsWith(KOML.FILE_EXTENSION))
+        expFile = new File(expFile.getParent(), expFile.getName() + KOML.FILE_EXTENSION);
+    }
+    else if (m_FileChooser.getFileFilter() == m_XMLFilter) {
+      if (!expFile.getName().toLowerCase().endsWith("".xml""))
+        expFile = new File(expFile.getParent(), expFile.getName() + "".xml"");
+    }
+    
     try {
       Experiment exp; 
       
       // KOML?
       if ( (KOML.isPresent()) && (expFile.getAbsolutePath().toLowerCase().endsWith(KOML.FILE_EXTENSION)) ) {
          exp = (Experiment) KOML.read(expFile.getAbsolutePath());
       }
       else
       // XML?
       if (expFile.getAbsolutePath().toLowerCase().endsWith("".xml"")) {
          XMLExperiment xml = new XMLExperiment(); 
          exp = (Experiment) xml.read(expFile);
       }
       // binary
       else {
          FileInputStream fi = new FileInputStream(expFile);
          ObjectInputStream oi = new ObjectInputStream(
                                 new BufferedInputStream(fi));
          exp = (Experiment)oi.readObject();
          oi.close();
       }
       setExperiment(exp);
       System.err.println(""Opened experiment:\n"" + m_Exp);
     } catch (Exception ex) {
       ex.printStackTrace();
       JOptionPane.showMessageDialog(this, ""Couldn't open experiment file:\n""
 				    + expFile
 				    + ""\nReason:\n"" + ex.getMessage(),
 				    ""Open Experiment"",
 				    JOptionPane.ERROR_MESSAGE);
       // Pop up error dialog
     }
   }
\ No newline at end of file
",Buggy,"A few bug fixes from Peter regarding the latest GUI additions. Also eliminated some superfluous output from NaiveBayesSimple.


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@2259 e0a1b77d-ad91-4216-81b1-defd5f83fa92
"
weka,18378.json,41f296c55b87a1ead276fffbafb67535b858a70f,"@@ -1,50 +1,58 @@
   private void openExperiment() {
     
     int returnVal = m_FileChooser.showOpenDialog(this);
     if (returnVal != JFileChooser.APPROVE_OPTION) {
       return;
     }
     File expFile = m_FileChooser.getSelectedFile();
-    if ( !(    (expFile.getName().toLowerCase().endsWith(Experiment.FILE_EXTENSION))
-            || (KOML.isPresent() && expFile.getName().toLowerCase().endsWith(KOML.FILE_EXTENSION))
-            || (expFile.getName().toLowerCase().endsWith("".xml"")) ) )
-    {
-      expFile = new File(expFile.getParent(), expFile.getName()
-                         + Experiment.FILE_EXTENSION);
+    
+    // add extension if necessary
+    if (m_FileChooser.getFileFilter() == m_ExpFilter) {
+      if (!expFile.getName().toLowerCase().endsWith(Experiment.FILE_EXTENSION))
+        expFile = new File(expFile.getParent(), expFile.getName() + Experiment.FILE_EXTENSION);
     }
+    else if (m_FileChooser.getFileFilter() == m_KOMLFilter) {
+      if (!expFile.getName().toLowerCase().endsWith(KOML.FILE_EXTENSION))
+        expFile = new File(expFile.getParent(), expFile.getName() + KOML.FILE_EXTENSION);
+    }
+    else if (m_FileChooser.getFileFilter() == m_XMLFilter) {
+      if (!expFile.getName().toLowerCase().endsWith("".xml""))
+        expFile = new File(expFile.getParent(), expFile.getName() + "".xml"");
+    }
+    
     try {
       Experiment exp; 
       
       // KOML?
       if ( (KOML.isPresent()) && (expFile.getAbsolutePath().toLowerCase().endsWith(KOML.FILE_EXTENSION)) ) {
          exp = (Experiment) KOML.read(expFile.getAbsolutePath());
       }
       else
       // XML?
       if (expFile.getAbsolutePath().toLowerCase().endsWith("".xml"")) {
          XMLExperiment xml = new XMLExperiment(); 
          exp = (Experiment) xml.read(expFile);
       }
       // binary
       else {
          FileInputStream fi = new FileInputStream(expFile);
          ObjectInputStream oi = new ObjectInputStream(
                                 new BufferedInputStream(fi));
          exp = (Experiment)oi.readObject();
          oi.close();
       }
       
       if (!setExperiment(exp)) {
 	if (m_modePanel != null) m_modePanel.switchToAdvanced(exp);
       }
       System.err.println(""Opened experiment:\n"" + exp);
     } catch (Exception ex) {
       ex.printStackTrace();
       JOptionPane.showMessageDialog(this, ""Couldn't open experiment file:\n""
 				    + expFile
 				    + ""\nReason:\n"" + ex.getMessage(),
 				    ""Open Experiment"",
 				    JOptionPane.ERROR_MESSAGE);
       // Pop up error dialog
     }
   }
\ No newline at end of file
",Buggy,"A few bug fixes from Peter regarding the latest GUI additions. Also eliminated some superfluous output from NaiveBayesSimple.


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@2259 e0a1b77d-ad91-4216-81b1-defd5f83fa92
"
weka,18419.json,41f296c55b87a1ead276fffbafb67535b858a70f,"@@ -1,43 +1,51 @@
   private void saveExperiment() {
 
     int returnVal = m_FileChooser.showSaveDialog(this);
     if (returnVal != JFileChooser.APPROVE_OPTION) {
       return;
     }
     File expFile = m_FileChooser.getSelectedFile();
-    if ( !(    (expFile.getName().toLowerCase().endsWith(Experiment.FILE_EXTENSION))
-          || (KOML.isPresent() && expFile.getName().toLowerCase().endsWith(KOML.FILE_EXTENSION))
-          || (expFile.getName().toLowerCase().endsWith("".xml"")) ) )
-    {
-       expFile = new File(expFile.getParent(), expFile.getName()
-                          + Experiment.FILE_EXTENSION);
+    
+    // add extension if necessary
+    if (m_FileChooser.getFileFilter() == m_ExpFilter) {
+      if (!expFile.getName().toLowerCase().endsWith(Experiment.FILE_EXTENSION))
+        expFile = new File(expFile.getParent(), expFile.getName() + Experiment.FILE_EXTENSION);
     }
+    else if (m_FileChooser.getFileFilter() == m_KOMLFilter) {
+      if (!expFile.getName().toLowerCase().endsWith(KOML.FILE_EXTENSION))
+        expFile = new File(expFile.getParent(), expFile.getName() + KOML.FILE_EXTENSION);
+    }
+    else if (m_FileChooser.getFileFilter() == m_XMLFilter) {
+      if (!expFile.getName().toLowerCase().endsWith("".xml""))
+        expFile = new File(expFile.getParent(), expFile.getName() + "".xml"");
+    }
+    
     try {
       // KOML?
       if ( (KOML.isPresent()) && (expFile.getAbsolutePath().toLowerCase().endsWith(KOML.FILE_EXTENSION)) ) {
          KOML.write(expFile.getAbsolutePath(), m_Exp);
       }
       else
       // XML?
       if (expFile.getAbsolutePath().toLowerCase().endsWith("".xml"")) {
          XMLExperiment xml = new XMLExperiment(); 
          xml.write(expFile, m_Exp);
       }
       // binary
       else {
          FileOutputStream fo = new FileOutputStream(expFile);
          ObjectOutputStream oo = new ObjectOutputStream(
                                  new BufferedOutputStream(fo));
          oo.writeObject(m_Exp);
          oo.close();
       }
       System.err.println(""Saved experiment:\n"" + m_Exp);
     } catch (Exception ex) {
       ex.printStackTrace();
       JOptionPane.showMessageDialog(this, ""Couldn't save experiment file:\n""
 				    + expFile
 				    + ""\nReason:\n"" + ex.getMessage(),
 				    ""Save Experiment"",
 				    JOptionPane.ERROR_MESSAGE);
     }
   }
\ No newline at end of file
",Buggy,"A few bug fixes from Peter regarding the latest GUI additions. Also eliminated some superfluous output from NaiveBayesSimple.


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@2259 e0a1b77d-ad91-4216-81b1-defd5f83fa92
"
weka,24330.json,0613647d320672d37f6da68efd32bd14bb88435b,"@@ -1,7 +1,15 @@
   public void preProcess() throws Exception {
     
     if (m_ResultProducer == null) {
       throw new Exception(""No ResultProducer set"");
     }
+    // Tell the resultproducer to send results to us
+    m_ResultProducer.setResultListener(this);
+    findKeyIndex();
+    if (m_KeyIndex == -1) {
+      throw new Exception(""No key field called "" + m_KeyFieldName
+			  + "" produced by ""
+			  + m_ResultProducer.getClass().getName());
+    }
     m_ResultProducer.preProcess();
   }
\ No newline at end of file
",Buggy,"- Fixed bug where sometimes the sub-ResultProducer would not be correctly
connected.


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@171 e0a1b77d-ad91-4216-81b1-defd5f83fa92
"
weka,24356.json,0613647d320672d37f6da68efd32bd14bb88435b,"@@ -1,5 +1,6 @@
   public void setResultProducer(ResultProducer newResultProducer) {
-    
+
     m_ResultProducer = newResultProducer;
+    m_ResultProducer.setResultListener(this);
     findKeyIndex();
   }
\ No newline at end of file
",Buggy,"- Fixed bug where sometimes the sub-ResultProducer would not be correctly
connected.


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@171 e0a1b77d-ad91-4216-81b1-defd5f83fa92
"
weka,24326.json,0613647d320672d37f6da68efd32bd14bb88435b,"@@ -1,71 +1,63 @@
   protected void doAverageResult(Object [] template) throws Exception {
 
     // Generate the key and ask whether the result is required
     String [] newKey = new String [template.length - 1];
     System.arraycopy(template, 0, newKey, 0, m_KeyIndex);
     System.arraycopy(template, m_KeyIndex + 1,
 		     newKey, m_KeyIndex,
 		     template.length - m_KeyIndex - 1);
-    /*
-    System.err.println(""new key: "" + DatabaseUtils.arrayToString(newKey));
-    */
     if (m_ResultListener.isResultRequired(this, newKey)) {
       Object [] resultTypes = m_ResultProducer.getResultTypes();
       Stats [] stats = new Stats [resultTypes.length];
       for (int i = 0; i < stats.length; i++) {
 	stats[i] = new Stats();
       }
       Object [] result = getResultTypes();
       int numMatches = 0;
       for (int i = 0; i < m_Keys.size(); i++) {
 	Object [] currentKey = (Object [])m_Keys.elementAt(i);
 	// Skip non-matching keys
 	if (!matchesTemplate(template, currentKey)) {
 	  continue;
 	}
 	// Add the results to the stats accumulator
 	Object [] currentResult = (Object [])m_Results.elementAt(i);
 	numMatches++;
-	/*
-	System.err.println(""Match: "" + DatabaseUtils.arrayToString(currentKey)
-			   + "" -- ""
-			   + DatabaseUtils.arrayToString(currentResult));
-	*/
 	for (int j = 0; j < resultTypes.length; j++) {
 	  if (resultTypes[j] instanceof Double) {
 	    if (currentResult[j] == null) {
 	      throw new Exception(""Null numeric result field found:\n""
 				  + DatabaseUtils.arrayToString(currentKey)
 				  + "" -- ""
 				  + DatabaseUtils
 				  .arrayToString(currentResult));
 	    }
 	    double currentVal = ((Double)currentResult[j]).doubleValue();
 	    stats[j].add(currentVal);
 	  }
 	}
       }
       if (numMatches != m_ExpectedResultsPerAverage) {
 	throw new Exception(""Expected "" + m_ExpectedResultsPerAverage
 			    + "" results matching key \""""
 			    + DatabaseUtils.arrayToString(template)
 			    + ""\"" but got ""
 			    + numMatches);
       }
       result[0] = new Double(numMatches);
       Object [] currentResult = (Object [])m_Results.elementAt(0);
       int k = 1;
       for (int j = 0; j < resultTypes.length; j++) {
 	if (resultTypes[j] instanceof Double) {
 	  stats[j].calculateDerived();
 	  result[k++] = new Double(stats[j].mean);
 	  if (getCalculateStdDevs()) {
 	    result[k++] = new Double(stats[j].stdDev);
 	  }
 	} else {
 	  result[k++] = currentResult[j];
 	}
       }
       m_ResultListener.acceptResult(this, newKey, result);      
     }
   }
\ No newline at end of file
",NotBuggy,"- Fixed bug where sometimes the sub-ResultProducer would not be correctly
connected.


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@171 e0a1b77d-ad91-4216-81b1-defd5f83fa92
"
weka,24324.json,0613647d320672d37f6da68efd32bd14bb88435b,"@@ -1,33 +1,31 @@
   public void doRun(int run) throws Exception {
-
+    
     if (m_Instances == null) {
       throw new Exception(""No Instances set"");
     }
-    // Tell the resultproducer to send results to us
-    m_ResultProducer.setResultListener(this);
     m_ResultProducer.setInstances(m_Instances);
-    
+
     // Clear the collected results
     m_Keys.removeAllElements();
     m_Results.removeAllElements();
     
     //    System.err.println(""Starting run "" + run);
     // Collect all the results
     // Should be smarter -- first doing a run collecting only the keys
     // from isResultRequired(), then determining if the average is required,
     // then getting the actual results.
     m_ResultProducer.doRun(run);
 
     // Average the results collected
     //System.err.println(""Number of results collected: "" + m_Keys.size());
 
     // Check that the keys only differ on the selected key field
     checkForMultipleDifferences();
 
     Object [] template = (Object [])((Object [])m_Keys.elementAt(0)).clone();
     template[m_KeyIndex] = null;
     // Check for duplicate keys
     checkForDuplicateKeys(template);
     // Calculate the average and submit it if necessary
     doAverageResult(template);
   }
\ No newline at end of file
",Buggy,"- Fixed bug where sometimes the sub-ResultProducer would not be correctly
connected.


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@171 e0a1b77d-ad91-4216-81b1-defd5f83fa92
"
weka,24382.json,0613647d320672d37f6da68efd32bd14bb88435b,"@@ -1,7 +1,8 @@
   public void preProcess() throws Exception {
     
     if (m_ResultProducer == null) {
       throw new Exception(""No ResultProducer set"");
     }
+    m_ResultProducer.setResultListener(this);
     m_ResultProducer.preProcess();
   }
\ No newline at end of file
",Buggy,"- Fixed bug where sometimes the sub-ResultProducer would not be correctly
connected.


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@171 e0a1b77d-ad91-4216-81b1-defd5f83fa92
"
weka,19514.json,90f4455c8174476ac55591cfcab3ea403fa3db02,"@@ -1,58 +1,66 @@
   public boolean eventGeneratable(String eventName) {
     if (eventName.compareTo(""trainingSet"") == 0) { 
       if (m_trainingProvider == null) {
 	return false;
       } else {
 	if (m_trainingProvider instanceof EventConstraints) {
 	  if (!((EventConstraints)m_trainingProvider).
 	      eventGeneratable(""trainingSet"")) {
 	    return false;
 	  }
 	}
       }
     }
 
     if (eventName.compareTo(""dataSet"") == 0) { 
       if (m_dataProvider == null) {
-	m_connectedFormat = null;
-	notifyDataFormatListeners();
+	if (m_instanceProvider == null) {
+	  m_connectedFormat = null;
+	  notifyDataFormatListeners();
+	}
 	return false;
       } else {
 	if (m_dataProvider instanceof EventConstraints) {
 	  if (!((EventConstraints)m_dataProvider).
 	      eventGeneratable(""dataSet"")) {
 	    m_connectedFormat = null;
 	    notifyDataFormatListeners();
 	    return false;
 	  }
 	}
       }
     }
 
     if (eventName.compareTo(""instance"") == 0) { 
       if (m_instanceProvider == null) {
+	if (m_dataProvider == null) {
+	  m_connectedFormat = null;
+	  notifyDataFormatListeners();
+	}
 	return false;
       } else {
 	if (m_instanceProvider instanceof EventConstraints) {
 	  if (!((EventConstraints)m_instanceProvider).
 	      eventGeneratable(""instance"")) {
+	    m_connectedFormat = null;
+	    notifyDataFormatListeners();
 	    return false;
 	  }
 	}
       }
     }
 
     if (eventName.compareTo(""testSet"") == 0) {
       if (m_testProvider == null) {
 	return false;
       } else {
 	if (m_testProvider instanceof EventConstraints) {
 	  if (!((EventConstraints)m_testProvider).
 	      eventGeneratable(""testSet"")) {
 	    return false;
 	  }
 	}
       }
     }
     return true;
   }
\ No newline at end of file
",Buggy,"Fixed bug in format handling


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@1966 e0a1b77d-ad91-4216-81b1-defd5f83fa92
"
weka,19490.json,90f4455c8174476ac55591cfcab3ea403fa3db02,"@@ -1,17 +1,18 @@
   public void acceptInstance(InstanceEvent e) {
     if (e.getStatus() == InstanceEvent.FORMAT_AVAILABLE) {
       //      Instances dataSet = e.getInstance().dataset();
       m_connectedFormat = e.getStructure();
       
       //      System.err.println(""Assigning class column..."");
       assignClass(m_connectedFormat);
       notifyInstanceListeners(e);
 
       // tell any listening customizers (or other interested parties)
+      System.err.println(""Notifying customizer..."");
       notifyDataFormatListeners();
     } else {
       //      Instances dataSet = e.getInstance().dataset();
       //      assignClass(dataSet);
       notifyInstanceListeners(e);
     }
   }
\ No newline at end of file
",NotBuggy,"Fixed bug in format handling


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@1966 e0a1b77d-ad91-4216-81b1-defd5f83fa92
"
weka,25728.json,296933fb5c56e6b698f0f76c710c4ef61eaa9a3c,"@@ -1,35 +1,37 @@
     protected void performBoostingCV() throws Exception{			
 	
 	//completed iteration keeps track of the number of iterations that have been
 	//performed in every fold (some might stop earlier than others). 
 	//Best iteration is selected only from these.
 	int completedIterations = m_maxIterations;
 	
 	Instances allData = new Instances(m_train);
 	
 	allData.stratify(m_numFoldsBoosting);	      
 
 	double[] error = new double[m_maxIterations + 1];	
 	
+        SimpleLinearRegression[][] backup = m_regressions;
+
 	for (int i = 0; i < m_numFoldsBoosting; i++) {
 	    //split into training/test data in fold
 	    Instances train = allData.trainCV(m_numFoldsBoosting,i);
 	    Instances test = allData.testCV(m_numFoldsBoosting,i);
 
 	    //initialize LogitBoost
 	    m_numRegressions = 0;
-	    m_regressions = initRegressions();
+	    m_regressions = copyRegressions(backup);
 
 	    //run LogitBoost iterations
 	    int iterations = performBoosting(train,test,error,completedIterations);	    
 	    if (iterations < completedIterations) completedIterations = iterations;	    
 	}
 
 	//determine iteration with minimum error over the folds
 	int bestIteration = getBestIteration(error,completedIterations);
 
 	//rebuild model on all of the training data
 	m_numRegressions = 0;
-        m_regressions = initRegressions();
+        m_regressions = backup;
 	performBoosting(bestIteration);
     }    
\ No newline at end of file
",Buggy,"Bug fix for the case where cross-validation is performed locally at each node.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@10104 e0a1b77d-ad91-4216-81b1-defd5f83fa92
"
weka,25729.json,296933fb5c56e6b698f0f76c710c4ef61eaa9a3c,"@@ -1,22 +1,13 @@
     protected SimpleLinearRegression[][] copyRegressions(SimpleLinearRegression[][] a)	
         throws Exception {
     
         SimpleLinearRegression[][] result = initRegressions();
         for (int i = 0; i < a.length; i++) {
             for (int j = 0; j < a[i].length; j++) {
                 if (j != m_numericDataHeader.classIndex()) {
                     result[i][j].addModel(a[i][j]);
                 }
             }
         }
-
-        /*        SimpleLinearRegression[][] result = null;
-        try {
-            SerializedObject so = new SerializedObject(a);
-            result = (SimpleLinearRegression[][])so.getObject();
-        } catch (Exception ex) {
-            System.err.println(""Can't copy array of simple linear regression objects."");
-            System.err.println(ex);
-            }*/
         return result;
     }
\ No newline at end of file
",NotBuggy,"Bug fix for the case where cross-validation is performed locally at each node.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@10104 e0a1b77d-ad91-4216-81b1-defd5f83fa92
"
weka,20414.json,d5169a182f63b31a737d9b5d57ecdb49b8fbd56a,"@@ -1,15 +1,15 @@
   protected void newStructure() throws Exception {
     
     m_Loader.reset();
     
     // Set environment variables
     if (m_Loader instanceof EnvironmentHandler && m_env != null) {
       try {
         ((EnvironmentHandler)m_Loader).setEnvironment(m_env);
       }catch (Exception ex) {
       }
     }
     m_dataFormat = m_Loader.getStructure();
-//    System.out.println(""[Loader] Notifying listeners of instance structure avail."");
-//    notifyStructureAvailable(m_dataFormat);
+    System.out.println(""[Loader] Notifying listeners of instance structure avail."");
+    notifyStructureAvailable(m_dataFormat);
   }  
\ No newline at end of file
",NotBuggy,"Fixed a bug where configuration changes (new files selected or database configuration changed) was not getting sent to downstream steps

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@7854 e0a1b77d-ad91-4216-81b1-defd5f83fa92
"
weka,20407.json,d5169a182f63b31a737d9b5d57ecdb49b8fbd56a,"@@ -1,4 +1,11 @@
   public void setDB(boolean flag){
   
       m_dbSet = flag;
+      if (m_dbSet) {
+        try {
+          newStructure();
+        } catch (Exception e) {
+          e.printStackTrace();
+        }
+      }
   }
\ No newline at end of file
",Buggy,"Fixed a bug where configuration changes (new files selected or database configuration changed) was not getting sent to downstream steps

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@7854 e0a1b77d-ad91-4216-81b1-defd5f83fa92
"
weka,19057.json,d5169a182f63b31a737d9b5d57ecdb49b8fbd56a,"@@ -1,6 +1,41 @@
   private void setUpOther() {
     removeAll();
     add(m_LoaderEditor, BorderLayout.CENTER);
+    
+    JPanel buttonsP = new JPanel();
+    buttonsP.setLayout(new FlowLayout());
+    JButton ok,cancel;
+    buttonsP.add(ok = new JButton(""OK""));
+    buttonsP.add(cancel=new JButton(""Cancel""));
+    ok.addActionListener(new ActionListener(){
+      public void actionPerformed(ActionEvent evt){
+        
+        // Tell the editor that we are closing under an OK condition
+        // so that it can pass on the message to any customizer that
+        // might be in use
+        m_LoaderEditor.closingOK();
+        
+        if (m_parentWindow != null) {
+          m_parentWindow.dispose();
+        }
+      }
+    });
+    cancel.addActionListener(new ActionListener(){
+      public void actionPerformed(ActionEvent evt){
+        
+        // Tell the editor that we are closing under a CANCEL condition
+        // so that it can pass on the message to any customizer that
+        // might be in use
+        m_LoaderEditor.closingCancel();
+        
+        if (m_parentWindow != null) {
+          m_parentWindow.dispose();
+        }
+      }
+    });
+    
+    add(buttonsP, BorderLayout.SOUTH);
+    
     validate();
     repaint();
   }
\ No newline at end of file
",Buggy,"Fixed a bug where configuration changes (new files selected or database configuration changed) was not getting sent to downstream steps

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@7854 e0a1b77d-ad91-4216-81b1-defd5f83fa92
"
titan,4498.json,3b4dd304515746e895b4ea7cd1728c0bcfd5d460,"@@ -1,4 +1,4 @@
         public Builder set(String path, Object value) {
-            super.set(path, value);
+            writeConfiguration.set(path, value);
             return this;
         }
\ No newline at end of file
",Buggy,"Let TitanFactory.Builder accept arbitrary keys

Elasticsearch reserves a Titan config namespace under which the user
may provide arbitrary Elasticsearch config options.  These options
can't be validated, since it's fundamentally a bit of a perversion of
the config API: the keys are defined in and controlled by
Elasticsearch, but we're cramming them into a Titan configuration.

This commit tweaks TitanFactory.Builder to use a WriteConfiguration
(which is based on dumb strings) instead of a ModifiableConfiguration
(which is based on ConfigOption and includes validation).

A more elegant way to approach this might be to introduce an
abstraction to support Elasticsearch's reserved namespace: some kind
of boolean field that says, in effect, ""don't try to validate any keys
underneath me"".  That still wouldn't totally address the problem,
though; (User)ModifiableConfiguration still wouldn't be a suitable
basis for TitanFactory.Builder, since it requires that any
user-provided config key string map to a ConfigOption.

This commit also adds a test (that fails without the TitanFactory
change).

Fixes #1114
"
titan,353.json,3b4dd304515746e895b4ea7cd1728c0bcfd5d460,"@@ -1,16 +1,16 @@
     public Map<ConfigElement.PathIdentifier,Object> getAll() {
         Map<ConfigElement.PathIdentifier,Object> result = Maps.newHashMap();
 
         for (String key : config.getKeys("""")) {
             Preconditions.checkArgument(StringUtils.isNotBlank(key));
             try {
                 ConfigElement.PathIdentifier pid = ConfigElement.parse(getRootNamespace(),key);
                 Preconditions.checkArgument(pid.element.isOption() && !pid.lastIsUmbrella);
                 result.put(pid,get((ConfigOption)pid.element,pid.umbrellaElements));
             } catch (IllegalArgumentException e) {
-                log.info(""Ignored configuration entry for {} since it does not map to an option"",key,e);
+                log.debug(""Ignored configuration entry for {} since it does not map to an option"",key,e);
                 continue;
             }
         }
         return result;
     }
\ No newline at end of file
",NotBuggy,"Let TitanFactory.Builder accept arbitrary keys

Elasticsearch reserves a Titan config namespace under which the user
may provide arbitrary Elasticsearch config options.  These options
can't be validated, since it's fundamentally a bit of a perversion of
the config API: the keys are defined in and controlled by
Elasticsearch, but we're cramming them into a Titan configuration.

This commit tweaks TitanFactory.Builder to use a WriteConfiguration
(which is based on dumb strings) instead of a ModifiableConfiguration
(which is based on ConfigOption and includes validation).

A more elegant way to approach this might be to introduce an
abstraction to support Elasticsearch's reserved namespace: some kind
of boolean field that says, in effect, ""don't try to validate any keys
underneath me"".  That still wouldn't totally address the problem,
though; (User)ModifiableConfiguration still wouldn't be a suitable
basis for TitanFactory.Builder, since it requires that any
user-provided config key string map to a ConfigOption.

This commit also adds a test (that fails without the TitanFactory
change).

Fixes #1114
"
titan,4499.json,3b4dd304515746e895b4ea7cd1728c0bcfd5d460,"@@ -1,3 +1,5 @@
         public TitanGraph open() {
-            return TitanFactory.open(super.getConfiguration());
+            ModifiableConfiguration mc = new ModifiableConfiguration(GraphDatabaseConfiguration.ROOT_NS,
+                    writeConfiguration.copy(), BasicConfiguration.Restriction.NONE);
+            return TitanFactory.open(mc);
         }
\ No newline at end of file
",Buggy,"Let TitanFactory.Builder accept arbitrary keys

Elasticsearch reserves a Titan config namespace under which the user
may provide arbitrary Elasticsearch config options.  These options
can't be validated, since it's fundamentally a bit of a perversion of
the config API: the keys are defined in and controlled by
Elasticsearch, but we're cramming them into a Titan configuration.

This commit tweaks TitanFactory.Builder to use a WriteConfiguration
(which is based on dumb strings) instead of a ModifiableConfiguration
(which is based on ConfigOption and includes validation).

A more elegant way to approach this might be to introduce an
abstraction to support Elasticsearch's reserved namespace: some kind
of boolean field that says, in effect, ""don't try to validate any keys
underneath me"".  That still wouldn't totally address the problem,
though; (User)ModifiableConfiguration still wouldn't be a suitable
basis for TitanFactory.Builder, since it requires that any
user-provided config key string map to a ConfigOption.

This commit also adds a test (that fails without the TitanFactory
change).

Fixes #1114
"
