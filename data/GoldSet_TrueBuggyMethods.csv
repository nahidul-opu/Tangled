Project,File,CommitHash,Diff,CommitMessage,Decision
spring-boot,5691.json,abe3d3852761430c9f5f1368d82509d0c19ac4d9,"@@ -1,12 +1,11 @@
 	private Stream<Wrapper> getLoadOnStartupWrappers(Container[] children) {
 		Map<Integer, List<Wrapper>> grouped = new TreeMap<>();
 		for (Container child : children) {
 			Wrapper wrapper = (Wrapper) child;
 			int order = wrapper.getLoadOnStartup();
 			if (order >= 0) {
-				grouped.computeIfAbsent(order, ArrayList::new);
-				grouped.get(order).add(wrapper);
+				grouped.computeIfAbsent(order, (o) -> new ArrayList<>()).add(wrapper);
 			}
 		}
 		return grouped.values().stream().flatMap(List::stream);
 	}
\ No newline at end of file
","Fix OoM error when starting Tomcat with max int load on startup

Fixes gh-17927
",Buggy
spring-boot,164.json,9c5f207e2221226c9cfdb1970bb2ed2946e142d1,"@@ -1,10 +1,9 @@
 		public ResourceConfigCustomizer resourceConfigCustomizer(
 				final ObjectMapper objectMapper) {
 			addJaxbAnnotationIntrospectorIfPresent(objectMapper);
 			return (ResourceConfig config) -> {
-				JerseyAutoConfiguration.this.config.register(JacksonFeature.class);
-				JerseyAutoConfiguration.this.config.register(
-						new ObjectMapperContextResolver(objectMapper),
+				config.register(JacksonFeature.class);
+				config.register(new ObjectMapperContextResolver(objectMapper),
 						ContextResolver.class);
 			};
 		}
\ No newline at end of file
","Fix merge error
",Buggy
spring-boot,7647.json,809a3965c961752bcbbc4bcae488f34be062d480,"@@ -1,12 +1,8 @@
 	public Iterable<Tag> tags(ClientRequest request, ClientResponse response, Throwable throwable) {
 		Tag method = WebClientExchangeTags.method(request);
 		Tag uri = WebClientExchangeTags.uri(request);
 		Tag clientName = WebClientExchangeTags.clientName(request);
-		if (response != null) {
-			return Arrays.asList(method, uri, clientName, WebClientExchangeTags.status(response),
-					WebClientExchangeTags.outcome(response));
-		}
-		else {
-			return Arrays.asList(method, uri, clientName, WebClientExchangeTags.status(throwable));
-		}
+		return Arrays.asList(method, uri, clientName,
+				(response != null) ? WebClientExchangeTags.status(response) : WebClientExchangeTags.status(throwable),
+				WebClientExchangeTags.outcome(response));
 	}
\ No newline at end of file
","Add missing outcome tag for WebClient metrics

On error cases, the ""outcome"" tag would be missing from recorded metrics
for the `WebClient`.

This commit fixes this issue and improves the reference documentation by
mentioning the tag values used for error cases, when the client response
is not received (I/O errors, client error, etc).

Fixes gh-17219
",Buggy
spring-boot,6747.json,3153117429756fc94489c1c9350b2149435a3b3a,"@@ -1,10 +1,13 @@
 	public boolean isAncestorOf(ConfigurationPropertyName name) {
+		if (this.equals(EMPTY)) {
+			return true;
+		}
 		ConfigurationPropertyName candidate = (name == null ? null : name.getParent());
 		while (candidate != null) {
 			if (candidate.equals(this)) {
 				return true;
 			}
 			candidate = candidate.getParent();
 		}
 		return false;
 	}
\ No newline at end of file
","Fix ConfigurationPropertyName ancestor bug

Fix an issue with `ConfigurationPropertyName` where the `isAncesorOf`
method would not work with `ConfigurationPropertyName.EMPTY`

See gh-9000
",Buggy
spring-boot,6206.json,a657a28f58e0eb8487eede9c60062186d850408d,"@@ -1,18 +1,18 @@
 		private void readUnicode() throws IOException {
 			this.character = 0;
 			for (int i = 0; i < 4; i++) {
 				int digit = this.reader.read();
-				if (digit > -'0' && digit <= '9') {
+				if (digit >= '0' && digit <= '9') {
 					this.character = (this.character << 4) + digit - '0';
 				}
-				else if (digit > -'a' && digit <= 'f') {
+				else if (digit >= 'a' && digit <= 'f') {
 					this.character = (this.character << 4) + digit - 'a' + 10;
 				}
-				else if (digit > -'A' && digit <= 'F') {
+				else if (digit >= 'A' && digit <= 'F') {
 					this.character = (this.character << 4) + digit - 'A' + 10;
 				}
 				else {
-					throw new IllegalArgumentException(""Malformed \\uxxxx encoding."");
+					throw new IllegalStateException(""Malformed \\uxxxx encoding."");
 				}
 			}
 		}
\ No newline at end of file
","Fix properties unicode value decoding

Fix a range error when checking for unicode hex chars.

Fixes gh-12716
",Buggy
spring-boot,2030.json,eea83e935eda0f05e1aaa11a38b0e7e379527f40,"@@ -1,10 +1,10 @@
 	private List<String> getData(int errorStatus) {
-		HttpStatus errorHttpStatus = HttpStatus.resolve(errorStatus);
 		List<String> data = new ArrayList<>();
 		data.add(""error/"" + errorStatus);
-		if (errorHttpStatus != null) {
-			data.add(""error/"" + SERIES_VIEWS.get(errorHttpStatus.series()));
+		HttpStatus.Series series = HttpStatus.Series.resolve(errorStatus);
+		if (series != null) {
+			data.add(""error/"" + SERIES_VIEWS.get(series));
 		}
 		data.add(""error/error"");
 		return data;
 	}
\ No newline at end of file
","Resolve httpstatus error series using raw int code

See gh-16691
",Buggy
guava,22893.json,201bb362a9b6de3fec6507ff435ac6022b92da7b,"@@ -1,7 +1,8 @@
   public void addListener(Runnable runnable, Executor executor) {
+    Listener listener = new Listener(runnable, executor);
     if (isDone()) {
-      executor.execute(runnable);
+      listener.execute();
     } else {
-      listeners.add(new Listener(runnable, executor));
+      listeners.add(listener);
     }
   }
\ No newline at end of file
","Add and use helper methods like assertDone() in tests.
This found no bugs -- well, maybe one if you count the inconsistent propagation of interruption from the delegate, though I had suspected as much already.

Add another ""misbehaving listener"" test, this one for the case in which the Future is already done.
This found a bug, which I've fixed.
-------------
Created by MOE: http://code.google.com/p/moe-java
MOE_MIGRATED_REVID=85074586
",Buggy
guava,16853.json,1ed32d483d0e583f7a245b60932c8c291c9a1e37,"@@ -1,19 +1,19 @@
-  static <E, E2 extends E> ImmutableMultiset<E> copyFromEntries(
-      Collection<Entry<E2>> entries) {
+  static <E> ImmutableMultiset<E> copyFromEntries(
+      Collection<? extends Entry<? extends E>> entries) {
     long size = 0;
     ImmutableMap.Builder<E, Integer> builder = ImmutableMap.builder();
-    for (Entry<E2> entry : entries) {
+    for (Entry<? extends E> entry : entries) {
       int count = entry.getCount();
       if (count > 0) {
         // Since ImmutableMap.Builder throws an NPE if an element is null, no
         // other null checks are needed.
         builder.put(entry.getElement(), count);
         size += count;
       }
     }
 
     if (size == 0) {
       return of();
     }
     return new RegularImmutableMultiset<E>(builder.build(), Ints.saturatedCast(size));
   }
\ No newline at end of file
","Fix ImmutableMultiset 1.6.0u24 compilation error.
",Buggy
guava,15762.json,2b7e8589db7c8ba987c6a960114a3194a7c2fe0e,"@@ -1,8 +1,9 @@
   @Override public int compare(Comparable left, Comparable right) {
-    checkNotNull(right); // left null is caught later
+    checkNotNull(left); // for GWT
+    checkNotNull(right);
     if (left == right) {
       return 0;
     }
 
     return left.compareTo(right);
   }
\ No newline at end of file
","Make SerializableTester.reserialize a no-op under GWT so that test authors can use it as part of larger test methods.
With that done, eliminate the equivalent, awful hack in RangeTest.
Further, with bug 5599623 fixed, run OrderingTest under GWT.
-------------
Created by MOE: http://code.google.com/p/moe-java
MOE_MIGRATED_REVID=25672151
",Buggy
guava,19040.json,20a42756c477b03c0123870b763148f4a18bdc8e,"@@ -1,39 +1,39 @@
   public static long checkedPow(long b, int k) {
     checkNonNegative(""exponent"", k);
     if (b >= -2 & b <= 2) {
       switch ((int) b) {
         case 0:
           return (k == 0) ? 1 : 0;
         case 1:
           return 1;
         case (-1):
           return ((k & 1) == 0) ? 1 : -1;
         case 2:
           checkNoOverflow(k < Long.SIZE - 1);
           return 1L << k;
         case (-2):
           checkNoOverflow(k < Long.SIZE);
           return ((k & 1) == 0) ? (1L << k) : (-1L << k);
         default:
           throw new AssertionError();
       }
     }
     long accum = 1;
     while (true) {
       switch (k) {
         case 0:
           return accum;
         case 1:
           return checkedMultiply(accum, b);
         default:
           if ((k & 1) != 0) {
             accum = checkedMultiply(accum, b);
           }
           k >>= 1;
           if (k > 0) {
-            checkNoOverflow(b <= FLOOR_SQRT_MAX_LONG);
+            checkNoOverflow(-FLOOR_SQRT_MAX_LONG <= b && b <= FLOOR_SQRT_MAX_LONG);
             b *= b;
           }
       }
     }
   }
\ No newline at end of file
","Fix LongMath.checkedPow to correctly error out on large negative inputs, and fix LongMathTest to test a full range of long inputs.  See https://github.com/google/guava/issues/2036 .
-------------
Created by MOE: http://code.google.com/p/moe-java
MOE_MIGRATED_REVID=92571001
",Buggy
guava,14536.json,93ce68b41636faafb78d391dcf720e06154862da,"@@ -1,6 +1,6 @@
   private static void closeAll(BaseStream<?, ?>[] toClose) {
     for (BaseStream<?, ?> stream : toClose) {
-      // TODO(b/198102330): Catch exceptions, rethrowing later with extras as suppressed exceptions.
+      // TODO(b/80534298): Catch exceptions, rethrowing later with extras as suppressed exceptions.
       stream.close();
     }
   }
\ No newline at end of file
","Fix ""bug"" link that was actually a CL.

RELNOTES=n/a

-------------
Created by MOE: https://github.com/google/moe
MOE_MIGRATED_REVID=265457436
",Buggy
guava,16180.json,ac579e0d20dd45ac8a713789e4708858a19fa894,"@@ -1,6 +1,5 @@
   public static <E extends Comparable> int binarySearch(List<? extends E> list, E e,
       KeyPresentBehavior presentBehavior, KeyAbsentBehavior absentBehavior) {
     checkNotNull(e);
-    return binarySearch(
-        list, checkNotNull(e), Ordering.natural(), presentBehavior, absentBehavior);
+    return binarySearch(list, e, Ordering.natural(), presentBehavior, absentBehavior);
   }
\ No newline at end of file
","Fix some bugs related to calling Preconditions.checkNotNull on expressions
that are definitely non-null.

Created via a work-in-progress error-prone check for unnecessary null checks.
-------------
Created by MOE: http://code.google.com/p/moe-java
MOE_MIGRATED_REVID=81594383
",Buggy
guava,17257.json,13800999134027e799b9250d261dd2c2a969183d,"@@ -1,12 +1,12 @@
   public static <K, V> MapDifference<K, V> difference(
       Map<? extends K, ? extends V> left, Map<? extends K, ? extends V> right,
       Equivalence<? super V> valueEquivalence) {
     Preconditions.checkNotNull(valueEquivalence);
 
-    Map<K, V> onlyOnLeft = newHashMap();
-    Map<K, V> onlyOnRight = new HashMap<K, V>(right); // will whittle it down
-    Map<K, V> onBoth = newHashMap();
-    Map<K, MapDifference.ValueDifference<V>> differences = newHashMap();
+    Map<K, V> onlyOnLeft = newLinkedHashMap();
+    Map<K, V> onlyOnRight = new LinkedHashMap<K, V>(right); // will whittle it down
+    Map<K, V> onBoth = newLinkedHashMap();
+    Map<K, MapDifference.ValueDifference<V>> differences = newLinkedHashMap();
     doDifference(left, right, valueEquivalence, onlyOnLeft, onlyOnRight, onBoth, differences);
     return new MapDifferenceImpl<K, V>(onlyOnLeft, onlyOnRight, onBoth, differences);
   }
\ No newline at end of file
","Fix hash map ordering bug.
-------------
Created by MOE: http://code.google.com/p/moe-java
MOE_MIGRATED_REVID=74779605
",Buggy
guava,15442.json,61110e175fc90fa2e8d675c8de85dff4ed699b07,"@@ -1,6 +1,6 @@
   public void forEachEntry(ObjIntConsumer<? super E> action) {
     checkNotNull(action);
-    for (int i = 0; i < size(); i++) {
+    for (int i = 0; i < length; i++) {
       action.accept(elementSet.asList().get(i), getCount(i));
     }
   }
\ No newline at end of file
","Fix embarrassing forEachEntry bug in ImmutableSortedMultiset.

-------------
Created by MOE: https://github.com/google/moe
MOE_MIGRATED_REVID=151063670
",Buggy
guava,22117.json,44d99fc5f83f06f577f61cf63569604d3142d96a,"@@ -1,3 +1,5 @@
     final void addInitialException(Set<Throwable> seen) {
-      addCausalChain(seen, trustedGetException());
+      if (!isCancelled()) {
+        addCausalChain(seen, trustedGetException());
+      }
     }
\ No newline at end of file
","Recognize that the reason for an early completion might be cancellation rather than exception.
This fixes the bug ""com.google.common.util.concurrent.AbstractFuture$Cancellation cannot be cast to com.google.common.util.concurrent.AbstractFuture$Failure""

TODO(cpovirk): Write basher tests at some point.
-------------
Created by MOE: http://code.google.com/p/moe-java
MOE_MIGRATED_REVID=96784416
",Buggy
pmd,6789.json,b86f0aec59762277d67960ed30249f1f8de815c4,"@@ -1,3 +1,12 @@
     public Object visit(ASTConditionalExpression node, Object data) {
-        return node.isTernary() ? sumChildrenComplexities(node, data) + 2 : 1;
+        // bool comp of guard clause + complexity of last two children (= total - 1)
+
+        if (node.isTernary()) {
+            ASTExpression wrapper = new ASTExpression(Integer.MAX_VALUE);
+            wrapper.jjtAddChild(node.jjtGetChild(0), 0);
+            int boolCompTernary = CycloMetric.booleanExpressionComplexity(wrapper);
+
+            return boolCompTernary + sumChildrenComplexities(node, data) - 1;
+        }
+        return 1;
     }
\ No newline at end of file
","Fix npath bugs with ternary
",Buggy
pmd,7930.json,be11288e2e0855a52298fdedb8363e66684b2252,"@@ -1 +1 @@
-    public Object visit(ASTIfStatement node, Object data){openScope(node);return data;}
\ No newline at end of file
+    public Object visit(ASTSwitchStatement node, Object data){openScope(node);return data;}
\ No newline at end of file
","Fixed bug in symbol table; it wasn't creating a scope level when it hit a switch statement


git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@1388 51baf565-9d33-0410-a72c-fc3788e3496d
",Buggy
pmd,1467.json,5c049b6946c8a2fddc780312e6783a539935feaa,"@@ -1,38 +1,42 @@
     public void apply( List acus, RuleContext ctx ) {
 		visitAll( acus, ctx );
 
 		double deviation = 0.0;
 		double minimum = 0.0;
 		
 		if (hasProperty(""sigma"")) {
 			deviation = getStdDev();
 			double sigma = getDoubleProperty(""sigma"");
 			
 			minimum = getMean() + (sigma * deviation);
 		}
 	
 		if (hasProperty(""minimum"")) {
 			double mMin = getDoubleProperty(""minimum"");
 			if (mMin > minimum) {
                 minimum = mMin;
             }
 		} 
 
 		SortedSet newPoints = applyMinimumValue(dataPoints, minimum);
 			
 		if (hasProperty(""topscore"")) {
 			int topScore = getIntProperty(""topscore"");
 			if (newPoints.size() >= topScore) {
 		    	newPoints = 
 		    		applyTopScore(newPoints, topScore);
 			}
 		}
 		
 		makeViolations(ctx, newPoints);
-		
-		double low = ((DataPoint) dataPoints.first()).getScore();
-		double high = ((DataPoint) dataPoints.last()).getScore();
-	
+
+        double low = 0.0d;
+        double high = 0.0d;
+        if (!dataPoints.isEmpty()) {
+            low = ((DataPoint) dataPoints.first()).getScore();
+            high = ((DataPoint) dataPoints.last()).getScore();
+        }
+
 		ctx.getReport().addMetric( new Metric( this.getName(), low, high,
 		                                       getMean(), getStdDev()));
     }
\ No newline at end of file
","fixed bug which caused Metrics stuff to fail on interfaces - it was calling first() on an empty SortedSet


git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@994 51baf565-9d33-0410-a72c-fc3788e3496d
",Buggy
pmd,658.json,05948ab5d813a0fe683625ee6da797360f1c8bd8,"@@ -1,4 +1,4 @@
     private String createTimestampAttr() {
-        SimpleDateFormat sdf = new SimpleDateFormat(""yyyy-MM-dd'T'HH:mm:ss.SSSZ"");
+        SimpleDateFormat sdf = new SimpleDateFormat(""yyyy-MM-dd'T'HH:mm:ss.SSS"");
         return "" timestamp=\"""" + sdf.format(new Date()) + ""\"""";
     }
\ No newline at end of file
","Fixed bug 1183032 - The XMLRenderer no longer throws a SimpleDateFormat exception when run with JDK 1.3.


git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@3433 51baf565-9d33-0410-a72c-fc3788e3496d
",Buggy
pmd,658.json,90eb57ade9a06904052833ea92076cc787b68615,"@@ -1,4 +1,4 @@
     private String createTimestampAttr() {
-        SimpleDateFormat sdf = new SimpleDateFormat(""yyyy-MM-dd'T'hh:mm:ss.SSSZ"");
+        SimpleDateFormat sdf = new SimpleDateFormat(""yyyy-MM-dd'T'HH:mm:ss.SSSZ"");
         return "" timestamp=\"""" + sdf.format(new Date()) + ""\"""";
     }
\ No newline at end of file
","Fixed [ pmd-Bugs-1100196 ] timestamp attribute in xml should use 24h clock


git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@3126 51baf565-9d33-0410-a72c-fc3788e3496d
",Buggy
pmd,2488.json,051136af5fe667edd815597c68bab215b4f49001,"@@ -1,7 +1,7 @@
     private boolean isLegalPath(String path, LanguageConfig config) {
     	String[] extensions = config.extensions();
     	for (int i=0; i<extensions.length; i++) {
-    		if (path.endsWith(extensions[i])) return true;
+    		if (path.endsWith(extensions[i]) && extensions[i].length() > 0) return true;
     	}
     	return false;
     }
\ No newline at end of file
","Fixed bug 1593292 - The CPD GUI now works with the 'by extension' option selected.


git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@4833 51baf565-9d33-0410-a72c-fc3788e3496d
",Buggy
pmd,6071.json,aeffeaec3d7763ca46f208be9f93ee2036ce8003,"@@ -1,8 +1,8 @@
-  public Object childrenAccept(JspParserVisitor visitor, Object data) {
-    if (children != null) {
-      for (int i = 0; i < children.length; ++i) {
-        children[i].jjtAccept(visitor, data);
-      }
-    }
-    return data;
-  }
\ No newline at end of file
+    public Object childrenAccept(JspParserVisitor visitor, Object data) {
+        if (children != null) {
+            for (int i = 0; i < children.length; ++i) {
+                ((SimpleNode)children[i]).jjtAccept(visitor, data);
+            }
+        }
+        return data;
+    }
\ No newline at end of file
","Fixed compilation problems, JSP tests are not yet working, but all other tests run


git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@4208 51baf565-9d33-0410-a72c-fc3788e3496d
",Buggy
pmd,7746.json,109f458dbf0d6b8c64d77943f9523d98700162d9,"@@ -1,7 +1,10 @@
     public boolean isInterfaceMember() {
-        ASTClassOrInterfaceBody body = getFirstParentOfType(ASTClassOrInterfaceBody.class);
-        if (body != null && body.jjtGetParent() instanceof ASTClassOrInterfaceDeclaration) {
-            return ((ASTClassOrInterfaceDeclaration) body.jjtGetParent()).isInterface();
+        // for a real class/interface the 3rd parent is a ClassOrInterfaceDeclaration,
+        // for anonymous classes, the parent is e.g. a AllocationExpression
+        Node potentialTypeDeclaration = getNthParent(3);
+
+        if (potentialTypeDeclaration instanceof ASTClassOrInterfaceDeclaration) {
+            return ((ASTClassOrInterfaceDeclaration) potentialTypeDeclaration).isInterface();
         }
         return false;
     }
\ No newline at end of file
","Fixes #793 [java] Parser error with private method in nested classes in interfaces

*   Remember old state to allow nesting
*   Fix ASTMethodDeclaration.isInterfaceMember
*   Extended tests
",Buggy
pmd,7746.json,64b862eef965aaa39c17db1808063e2f129d7057,"@@ -1,4 +1,7 @@
     public boolean isInterfaceMember() {
-        ASTClassOrInterfaceDeclaration clz = getFirstParentOfType(ASTClassOrInterfaceDeclaration.class);
-        return clz != null && clz.isInterface();
+        ASTClassOrInterfaceBody body = getFirstParentOfType(ASTClassOrInterfaceBody.class);
+        if (body != null && body.jjtGetParent() instanceof ASTClassOrInterfaceDeclaration) {
+            return ((ASTClassOrInterfaceDeclaration) body.jjtGetParent()).isInterface();
+        }
+        return false;
     }
\ No newline at end of file
","Fixes #793 [java] Parser error with private method in nested classes in interfaces
",Buggy
pmd,7746.json,078ec6e2c8fdee2c51c2fb6a9bf6c6220d2a7032,"@@ -1,3 +1,4 @@
     public boolean isInterfaceMember() {
-        return ((ASTClassOrInterfaceDeclaration)getFirstParentOfType(ASTClassOrInterfaceDeclaration.class)).isInterface();
+        ASTClassOrInterfaceDeclaration clz = (ASTClassOrInterfaceDeclaration)getFirstParentOfType(ASTClassOrInterfaceDeclaration.class);
+        return clz != null && clz.isInterface();
     }
\ No newline at end of file
","Fixed bug 1400754 - A NPE is no longer thrown on certain JDK 1.5 enum usages.


git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@4127 51baf565-9d33-0410-a72c-fc3788e3496d
",Buggy
pmd,7774.json,0f2e98bf9112c38ee071489286a8d827ae02a460,"@@ -1,3 +1,3 @@
     public String getPackageNameImage() {
-        return ((ASTName)jjtGetChild(0)).getImage();
+	return ((ASTName) jjtGetChild(this.jjtGetNumChildren() - 1)).getImage();
     }
\ No newline at end of file
","bug fix: typecast exception in LoosePackageCoupling for annotation before package name


git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@6077 51baf565-9d33-0410-a72c-fc3788e3496d
",Buggy
pmd,4667.json,64e193fcb69b2fbd3ccdeeccecae0b45f02ff055,"@@ -1,11 +1,21 @@
     public Object visit(ASTUserClass node, Object data) {
         if (Helper.isTestMethodOrClass(node)) {
             return data;
         }
 
+        List<ASTVariableDeclaration> variableDecls = node.findDescendantsOfType(ASTVariableDeclaration.class);
+        for (ASTVariableDeclaration varDecl : variableDecls) {
+            findSafeLiterals(varDecl);
+        }
+
+        List<ASTFieldDeclaration> fieldDecl = node.findDescendantsOfType(ASTFieldDeclaration.class);
+        for (ASTFieldDeclaration fDecl : fieldDecl) {
+            findSafeLiterals(fDecl);
+        }
+
         List<ASTNewObjectExpression> newObjects = node.findDescendantsOfType(ASTNewObjectExpression.class);
         for (ASTNewObjectExpression newObj : newObjects) {
             checkNewObjects(newObj, data);
         }
         return data;
     }
\ No newline at end of file
","Bug fix - contd
",Buggy
pmd,1144.json,5ca779d9e255f093175f8b738e3feca1c9758742,"@@ -1,11 +1,13 @@
     public Node getNthParent(int n) {
-	Node result = null;
-	for (int i = 0; i < n; i++) {
-	    if (result == null) {
-		result = this.jjtGetParent();
-	    } else {
-		result = result.jjtGetParent();
-	    }
-	}
-	return result;
+        if (n <= 0) {
+            throw new IllegalArgumentException();
+        }
+        Node result = this.jjtGetParent();
+        for (int i = 1; i < n; i++) {
+            if (result == null) {
+                return null;
+            }
+            result = result.jjtGetParent();
+        }
+        return result;
     }
\ No newline at end of file
","bug fix: getNthParent() in AbstractNode was looping if argument was higher than ancestor number

git-svn-id: https://pmd.svn.sourceforge.net/svnroot/pmd/trunk@6238 51baf565-9d33-0410-a72c-fc3788e3496d
",Buggy
pmd,4676.json,3079ce26a85a9ed32d86bd039606c87decf23c82,"@@ -1,6 +1,6 @@
     private void checkForSharingDeclaration(ApexNode<?> node, Object data, boolean sharingFound) {
-        final boolean foundAnyDMLorSOQL = Helper.foundAnyDML(node) && Helper.foundAnySOQLorSOSL(node);
+        final boolean foundAnyDMLorSOQL = Helper.foundAnyDML(node) || Helper.foundAnySOQLorSOSL(node);
         if (!sharingFound && !Helper.isTestMethodOrClass(node) && foundAnyDMLorSOQL) {
             addViolation(data, node);
         }
     }
\ No newline at end of file
","Bug fix
",Buggy
pmd,31.json,18ea8600ece06f02ae605f9fb1c19c07a4e02c6a,"@@ -1,7 +1,7 @@
     public static boolean applies(Rule rule, LanguageVersion languageVersion) {
         final LanguageVersion min = rule.getMinimumLanguageVersion();
-        final LanguageVersion max = rule.getMinimumLanguageVersion();
+        final LanguageVersion max = rule.getMaximumLanguageVersion();
         return rule.getLanguage().equals(languageVersion.getLanguage())
                 && (min == null || min.compareTo(languageVersion) <= 0)
                 && (max == null || max.compareTo(languageVersion) >= 0);
     }
\ No newline at end of file
","Fix problem that some rules where not executed - max language version was
determined wrongly
",Buggy
pmd,2559.json,b745f331b8ca490e0046b566b5a94a2eb10aca84,"@@ -1,19 +1,17 @@
     public void tokenize(SourceCode sourceCode, Tokens tokenEntries) {
         StringBuilder buffer = sourceCode.getCodeBuffer();
         try (Reader reader = new StringReader(buffer.toString())) {
-            final TokenFilter tokenFilter = new JavaCCTokenFilter(new ObjectiveCTokenManager(reader));
+            ObjectiveCTokenManager tokenManager = new ObjectiveCTokenManager(reader);
+            tokenManager.setFileName(sourceCode.getFileName());
+            final TokenFilter tokenFilter = new JavaCCTokenFilter(tokenManager);
             Token currentToken = (Token) tokenFilter.getNextToken();
             while (currentToken != null) {
                 tokenEntries.add(new TokenEntry(currentToken.image, sourceCode.getFileName(), currentToken.beginLine));
                 currentToken = (Token) tokenFilter.getNextToken();
             }
-            tokenEntries.add(TokenEntry.getEOF());
-            System.err.println(""Added "" + sourceCode.getFileName());
-        } catch (TokenMgrError err) {
-            err.printStackTrace();
-            System.err.println(""Skipping "" + sourceCode.getFileName() + "" due to parse error"");
-            tokenEntries.add(TokenEntry.getEOF());
         } catch (IOException e) {
             e.printStackTrace();
+        } finally {
+            tokenEntries.add(TokenEntry.getEOF());
         }
     }
\ No newline at end of file
","CPD: Fix error handling for lexical errors

* TokenMgrError must not be caught by the tokenizer. This is handled
  by CPD itself
* The token managers need to know the filename for proper error messages
",Buggy
pmd,2220.json,9075cb005c37782d5248485d8628d90dff4a238f,"@@ -1,10 +1,14 @@
     public List<V> valueFrom(String valueString) throws IllegalArgumentException {
+        if (StringUtil.isEmpty(valueString)) {
+            return Collections.emptyList();
+        }
+
         String[] strValues = valueString.split(Pattern.quote("""" + multiValueDelimiter()));
 
         List<V> values = new ArrayList<>(strValues.length);
-        for (int i = 0; i < strValues.length; i++) {
-            values.add(createFrom(strValues[i]));
+        for (String strValue : strValues) {
+            values.add(createFrom(strValue));
         }
 
         return values;
     }
\ No newline at end of file
","Fix bug with empty value strings
",Buggy
pmd,4201.json,8ffaffc567168576ecfc1176fbfab03b5f9896b0,"@@ -1,20 +1,20 @@
 	void calculateLineNumbers(SourceCodePositioner positioner) {
 		if (!hasRealLoc()) {
 			return;
 		}
 
 		RealLoc loc = (RealLoc) node.getLoc();
 		int startOffset = loc.startIndex;
 		int endOffset = loc.endIndex;
+		// end column will be interpreted as inclusive, while endOffset/endIndex is exclusive
+		endOffset -= 1;
 
 		this.beginLine = positioner.lineNumberFromOffset(startOffset);
 		this.beginColumn = positioner.columnFromOffset(this.beginLine, startOffset);
 		this.endLine = positioner.lineNumberFromOffset(endOffset);
-		this.endColumn = positioner.columnFromOffset(this.endLine, endOffset) - 1; // end
-																					// column
-																					// is
-																					// inclusive
+		this.endColumn = positioner.columnFromOffset(this.endLine, endOffset);
+
 		if (this.endColumn < 0) {
 			this.endColumn = 0;
 		}
 	}
\ No newline at end of file
","Fixes #1485 Analysis of some apex classes cause a stackoverflow error
Test file must use windows line endings
Fixes Up2Go/pmd#36
",Buggy
pmd,7241.json,733c871b9690e787c9137aceb34f4338e2617533,"@@ -1,3 +1,3 @@
     public boolean isAnonymousClass() {
-        return jjtGetParent().hasDescendantOfType(ASTClassOrInterfaceBody.class);
+        return jjtGetParent().getFirstChildOfType(ASTClassOrInterfaceBody.class) != null;
     }
\ No newline at end of file
","Fix nested anonymous class bug with type resolution
",Buggy
hbase,30032.json,b635414e8337be7bc14ca6ae605749c35569b4f7,"@@ -1,31 +1,36 @@
   private Result regroupResults(final Result result) throws IOException {
     partialResultsRow = result.getRow();
     partialResults.add(result);
     partialResultsCellSizes += result.size();
     if (scan.getBatch() > 0 && partialResultsCellSizes >= scan.getBatch()) {
       Cell[] cells = new Cell[scan.getBatch()];
       int count = 0;
       boolean stale = false;
       while (count < scan.getBatch()) {
         Result res = partialResults.poll();
         stale = stale || res.isStale();
         if (res.size() + count <= scan.getBatch()) {
           System.arraycopy(res.rawCells(), 0, cells, count, res.size());
           count += res.size();
         } else {
           int len = scan.getBatch() - count;
           System.arraycopy(res.rawCells(), 0, cells, count, len);
           Cell[] remainingCells = new Cell[res.size() - len];
           System.arraycopy(res.rawCells(), len, remainingCells, 0, res.size() - len);
           Result remainingRes = Result.create(remainingCells, res.getExists(), res.isStale(),
               res.mayHaveMoreCellsInRow());
           partialResults.addFirst(remainingRes);
           count = scan.getBatch();
         }
       }
       partialResultsCellSizes -= scan.getBatch();
+      if (partialResultsCellSizes == 0) {
+        // We have nothing in partialResults, clear the flags to prevent returning empty Result
+        // when next result belongs to the next row.
+        clearPartialResults();
+      }
       return Result.create(cells, null, stale,
           partialResultsCellSizes > 0 || result.mayHaveMoreCellsInRow());
     }
     return null;
   }
\ No newline at end of file
","HBASE-15484 Correct the semantic of batch and partial - amend to fix bug and revise the JavaDoc for related APIs.
",Buggy
hbase,10174.json,537a3caccd22e069e8b026a4ba7da419fdb68324,"@@ -1,53 +1,53 @@
   static Status splitLog(String name, CancelableProgressable p, Configuration conf,
       RegionServerServices server, LastSequenceId sequenceIdChecker, WALFactory factory) {
     Path walDir;
     FileSystem fs;
     try {
       walDir = CommonFSUtils.getWALRootDir(conf);
       fs = walDir.getFileSystem(conf);
     } catch (IOException e) {
       LOG.warn(""Resigning, could not find root dir or fs"", e);
       return Status.RESIGNED;
     }
     try {
       if (!processSyncReplicationWAL(name, conf, server, fs, walDir)) {
         return Status.DONE;
       }
     } catch (IOException e) {
       LOG.warn(""failed to process sync replication wal {}"", name, e);
       return Status.RESIGNED;
     }
     // TODO have to correctly figure out when log splitting has been
     // interrupted or has encountered a transient error and when it has
     // encountered a bad non-retry-able persistent error.
     try {
       SplitLogWorkerCoordination splitLogWorkerCoordination =
           server.getCoordinatedStateManager() == null ? null
               : server.getCoordinatedStateManager().getSplitLogWorkerCoordination();
       if (!WALSplitter.splitLogFile(walDir, fs.getFileStatus(new Path(walDir, name)), fs, conf, p,
         sequenceIdChecker, splitLogWorkerCoordination, factory, server)) {
         return Status.PREEMPTED;
       }
     } catch (InterruptedIOException iioe) {
-      LOG.warn(""Resigning, interrupted splitting WAL {}"", filename, iioe);
+      LOG.warn(""Resigning, interrupted splitting WAL {}"", name, iioe);
       return Status.RESIGNED;
     } catch (IOException e) {
       if (e instanceof FileNotFoundException) {
         // A wal file may not exist anymore. Nothing can be recovered so move on
-        LOG.warn(""Done, WAL {} does not exist anymore"", filename, e);
+        LOG.warn(""Done, WAL {} does not exist anymore"", name, e);
         return Status.DONE;
       }
       Throwable cause = e.getCause();
       if (e instanceof RetriesExhaustedException && (cause instanceof NotServingRegionException
           || cause instanceof ConnectException || cause instanceof SocketTimeoutException)) {
-        LOG.warn(""Resigning, can't connect to target regionserver splitting WAL {}"", filename, e);
+        LOG.warn(""Resigning, can't connect to target regionserver splitting WAL {}"", name, e);
         return Status.RESIGNED;
       } else if (cause instanceof InterruptedException) {
-        LOG.warn(""Resigning, interrupted splitting WAL {}"", filename, e);
+        LOG.warn(""Resigning, interrupted splitting WAL {}"", name, e);
         return Status.RESIGNED;
       }
-      LOG.warn(""Error splitting WAL {}"", filename, e);
+      LOG.warn(""Error splitting WAL {}"", name, e);
       return Status.ERR;
     }
     return Status.DONE;
   }
\ No newline at end of file
"," HBASE-24574 Procedure V2 - Distributed WAL Splitting => LOGGING (#1912)
 Addendum 2 fix compile error.
",Buggy
hbase,36767.json,cb85bf2e0aa48700bf635183302bdb28a36cb635,"@@ -1,21 +1,24 @@
   public void doFilter(ServletRequest req, ServletResponse rsp,
       FilterChain chain) throws IOException, ServletException {
     HttpServletRequest request = (HttpServletRequest)req;
     HttpServletResponse response = (HttpServletResponse)rsp;
     String contentEncoding = request.getHeader(""content-encoding"");
     String acceptEncoding = request.getHeader(""accept-encoding"");
     String contentType = request.getHeader(""content-type"");
     if ((contentEncoding != null) &&
         (contentEncoding.toLowerCase().indexOf(""gzip"") > -1)) {
       request = new GZIPRequestWrapper(request);
     }
     if (((acceptEncoding != null) &&
           (acceptEncoding.toLowerCase().indexOf(""gzip"") > -1)) ||
         ((contentType != null) && mimeTypes.contains(contentType))) {
       response = new GZIPResponseWrapper(response);
     }
     chain.doFilter(request, response);
-    if ((response instanceof GZIPResponseWrapper)) {
-      ((GZIPResponseStream)response.getOutputStream()).finish();
+    if (response instanceof GZIPResponseWrapper) {
+      OutputStream os = response.getOutputStream();
+      if (os instanceof GZIPResponseStream) {
+        ((GZIPResponseStream)os).finish();
+      }
     }
   }
\ No newline at end of file
","HBASE-3275 [rest] No gzip/deflat content encoding support; fix error handling in GzipFilter

git-svn-id: https://svn.apache.org/repos/asf/hbase/trunk@1082792 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
hbase,3377.json,65bcf55892efefb72b41fcf6c9974688578b5021,"@@ -1,11 +1,11 @@
   private static <T extends Enum<T>> T tryValueOf(final Class<T> clazz,
     final String value) {
     if (clazz == null || value == null) {
       return null;
     }
     try {
-      return T.valueOf(clazz, value);
+      return Enum.valueOf(clazz, value);
     } catch (IllegalArgumentException e) {
       return null;
     }
   }
\ No newline at end of file
","HBASE-23653 Expose content of meta table in web ui; addendum (#1061)

Fix error prone problem

Signed-off-by: Nick Dimiduk <ndimiduk@apache.org>
Signed-off-by: Viraj Jasani <vjasani@apache.org>
Signed-off-by: stack <stack@apache.org>",Buggy
hbase,8735.json,8c4b09dfbaf53fd770fe3963df6095fc690f2ef5,"@@ -1,33 +1,34 @@
     private void _readMvccVersion(int offsetFromPos) {
       // This is Bytes#bytesToVint inlined so can save a few instructions in this hot method; i.e.
       // previous if one-byte vint, we'd redo the vint call to find int size.
       // Also the method is kept small so can be inlined.
       byte firstByte = blockBuffer.getByteAfterPosition(offsetFromPos);
       int len = WritableUtils.decodeVIntSize(firstByte);
       if (len == 1) {
         this.currMemstoreTS = firstByte;
       } else {
         int remaining = len -1;
         long i = 0;
         offsetFromPos++;
         if (remaining >= Bytes.SIZEOF_INT) {
-          i = blockBuffer.getIntAfterPosition(offsetFromPos);
+          // The int read has to be converted to unsigned long so the & op
+          i = (blockBuffer.getIntAfterPosition(offsetFromPos) & 0x00000000ffffffffL);
           remaining -= Bytes.SIZEOF_INT;
           offsetFromPos += Bytes.SIZEOF_INT;
         }
         if (remaining >= Bytes.SIZEOF_SHORT) {
           short s = blockBuffer.getShortAfterPosition(offsetFromPos);
           i = i << 16;
           i = i | (s & 0xFFFF);
           remaining -= Bytes.SIZEOF_SHORT;
           offsetFromPos += Bytes.SIZEOF_SHORT;
         }
         for (int idx = 0; idx < remaining; idx++) {
           byte b = blockBuffer.getByteAfterPosition(offsetFromPos + idx);
           i = i << 8;
           i = i | (b & 0xFF);
         }
         currMemstoreTS = (WritableUtils.isNegativeVInt(firstByte) ? ~i : i);
       }
       this.currMemstoreTSLen = len;
     }
\ No newline at end of file
","HBASE-16624 Fix MVCC DeSerialization bug in the HFileScannerImpl

Change-Id: Ia970619ac7369d24ed432e827319dfdca16143c2

Signed-off-by: stack <stack@apache.org>
",Buggy
hbase,28257.json,78d532e5f344edda04fb9ce44bef9cd79e0d1935,"@@ -1,14 +1,14 @@
-  public void validatePut(final Put put) throws IllegalArgumentException{
+  public static void validatePut(Put put, int maxKeyValueSize) throws IllegalArgumentException {
     if (put.isEmpty()) {
       throw new IllegalArgumentException(""No columns to insert"");
     }
     if (maxKeyValueSize > 0) {
       for (List<Cell> list : put.getFamilyCellMap().values()) {
         for (Cell cell : list) {
           if (KeyValueUtil.length(cell) > maxKeyValueSize) {
             throw new IllegalArgumentException(""KeyValue size too large"");
           }
         }
       }
     }
   }
\ No newline at end of file
","HBASE-12086 Fix bug of HTableMultipliexer

Signed-off-by: Elliott Clark <eclark@apache.org>
",Buggy
hbase,3341.json,05378cbf69957b76e8559185ea20235242a8b2e6,"@@ -1,5 +1,5 @@
       protected void encode(ChannelHandlerContext channelHandlerContext,
                             ClusterStatus clusterStatus, List<Object> objects) {
-        ClusterStatusProtos.ClusterStatus csp = clusterStatus.convert();
+        ClusterStatusProtos.ClusterStatus csp = ProtobufUtil.convert(clusterStatus);
         objects.add(new DatagramPacket(Unpooled.wrappedBuffer(csp.toByteArray()), isa));
       }
\ No newline at end of file
","HBASE-15609 Addendum fix compilation error
",Buggy
hbase,1117.json,8c74d177f68bbd5412cef96dc33f16ba33ff7875,"@@ -1,43 +1,43 @@
   public void refreshSources(String peerId) throws IOException {
     String terminateMessage = ""Peer "" + peerId +
       "" state or config changed. Will close the previous replication source and open a new one"";
     ReplicationPeer peer = replicationPeers.getPeer(peerId);
     ReplicationSourceInterface src = createSource(peerId, peer);
     // synchronized on latestPaths to avoid missing the new log
     synchronized (this.latestPaths) {
       ReplicationSourceInterface toRemove = this.sources.put(peerId, src);
       if (toRemove != null) {
         LOG.info(""Terminate replication source for "" + toRemove.getPeerId());
         toRemove.terminate(terminateMessage);
       }
       for (SortedSet<String> walsByGroup : walsById.get(peerId).values()) {
         walsByGroup.forEach(wal -> src.enqueueLog(new Path(this.logDir, wal)));
       }
     }
     LOG.info(""Startup replication source for "" + src.getPeerId());
     src.startup();
 
     List<ReplicationSourceInterface> toStartup = new ArrayList<>();
     // synchronized on oldsources to avoid race with NodeFailoverWorker
     synchronized (this.oldsources) {
       List<String> previousQueueIds = new ArrayList<>();
       for (ReplicationSourceInterface oldSource : this.oldsources) {
         if (oldSource.getPeerId().equals(peerId)) {
           previousQueueIds.add(oldSource.getQueueId());
           oldSource.terminate(terminateMessage);
           this.oldsources.remove(oldSource);
         }
       }
       for (String queueId : previousQueueIds) {
         ReplicationSourceInterface replicationSource = createSource(queueId, peer);
         this.oldsources.add(replicationSource);
         for (SortedSet<String> walsByGroup : walsByIdRecoveredQueues.get(queueId).values()) {
           walsByGroup.forEach(wal -> src.enqueueLog(new Path(wal)));
         }
         toStartup.add(replicationSource);
       }
     }
-    for (ReplicationSourceInterface replicationSource : oldsources) {
+    for (ReplicationSourceInterface replicationSource : toStartup) {
       replicationSource.startup();
     }
   }
\ No newline at end of file
","HBASE-20082 Fix findbugs errors only on master which are introduced by HBASE-19397
",Buggy
hbase,5759.json,741d0a4511b9c397b2eb821aef49e858e217bf1e,"@@ -1,22 +1,22 @@
   public synchronized void moveTables(
       Set<TableName> tableNames, String groupName) throws IOException {
     if (groupName != null && !rsGroupMap.containsKey(groupName)) {
       throw new DoNotRetryIOException(""Group ""+groupName+"" does not exist or is a special group"");
     }
 
     Map<String,RSGroupInfo> newGroupMap = Maps.newHashMap(rsGroupMap);
     for(TableName tableName: tableNames) {
       if (tableMap.containsKey(tableName)) {
-        RSGroupInfo src = new RSGroupInfo(rsGroupMap.get(tableMap.get(tableName)));
+        RSGroupInfo src = new RSGroupInfo(newGroupMap.get(tableMap.get(tableName)));
         src.removeTable(tableName);
         newGroupMap.put(src.getName(), src);
       }
       if(groupName != null) {
         RSGroupInfo dst = new RSGroupInfo(newGroupMap.get(groupName));
         dst.addTable(tableName);
         newGroupMap.put(dst.getName(), dst);
       }
     }
 
     flushConfig(newGroupMap);
   }
\ No newline at end of file
","HBASE-16430 Fix RegionServer Group's bug when moving multiple tables (Guangxu Cheng)
",Buggy
hbase,5759.json,ad16676f9218b5ae3f693f8024e538e1f15e0e9a,"@@ -1,22 +1,22 @@
   public synchronized void moveTables(
       Set<TableName> tableNames, String groupName) throws IOException {
     if (groupName != null && !rsGroupMap.containsKey(groupName)) {
       throw new DoNotRetryIOException(""Group ""+groupName+"" does not exist or is a special group"");
     }
 
     Map<String,RSGroupInfo> newGroupMap = Maps.newHashMap(rsGroupMap);
     for(TableName tableName: tableNames) {
       if (tableMap.containsKey(tableName)) {
-        RSGroupInfo src = new RSGroupInfo(rsGroupMap.get(tableMap.get(tableName)));
+        RSGroupInfo src = new RSGroupInfo(newGroupMap.get(tableMap.get(tableName)));
         src.removeTable(tableName);
         newGroupMap.put(src.getName(), src);
       }
       if(groupName != null) {
         RSGroupInfo dst = new RSGroupInfo(newGroupMap.get(groupName));
         dst.addTable(tableName);
         newGroupMap.put(dst.getName(), dst);
       }
     }
 
     flushConfig(newGroupMap);
   }
\ No newline at end of file
","Fix RegionServer Group's bug when moving multiple tables (Guangxu Cheng)
",Buggy
hbase,13091.json,07e93458fe69b7701ea2045926b4afe30d166cb5,"@@ -1,3 +1,4 @@
   public Cell forceCopyOfBigCellInto(Cell cell) {
-    throw new IllegalStateException(""This is an Immutable MemStoreLAB."");
+    MemStoreLAB mslab = this.mslabs.get(0);
+    return mslab.forceCopyOfBigCellInto(cell);
   }
\ No newline at end of file
","HBASE-19930: Fixing the bug, in the rare case when there is a merge into CCM and the one of the old segments has a big cell allocated on-heap and it needs to be copied to the MSLAB
",Buggy
hbase,34108.json,c222e2b4862045d5ef7040103e1c50b6593dda20,"@@ -1,50 +1,50 @@
     public void map(LongWritable offset, Text value,
       Context context)
     throws IOException {
       byte[] lineBytes = value.getBytes();
 
       try {
         TsvParser.ParsedLine parsed = parser.parse(
             lineBytes, value.getLength());
         ImmutableBytesWritable rowKey =
           new ImmutableBytesWritable(lineBytes,
               parsed.getRowKeyOffset(),
               parsed.getRowKeyLength());
 
         Put put = new Put(rowKey.copyBytes());
         for (int i = 0; i < parsed.getColumnCount(); i++) {
           if (i == parser.getRowKeyColumnIndex()) continue;
           KeyValue kv = new KeyValue(
               lineBytes, parsed.getRowKeyOffset(), parsed.getRowKeyLength(),
               parser.getFamily(i), 0, parser.getFamily(i).length,
               parser.getQualifier(i), 0, parser.getQualifier(i).length,
               ts,
               KeyValue.Type.Put,
               lineBytes, parsed.getColumnOffset(i), parsed.getColumnLength(i));
           put.add(kv);
         }
         context.write(rowKey, put);
       } catch (BadTsvLineException badLine) {
         if (skipBadLines) {
           System.err.println(
               ""Bad line at offset: "" + offset.get() + "":\n"" +
               badLine.getMessage());
           badLineCount.increment(1);
           return;
         } else {
           throw new IOException(badLine);
         }
       } catch (IllegalArgumentException e) {
         if (skipBadLines) {
           System.err.println(
               ""Bad line at offset: "" + offset.get() + "":\n"" +
-              badLine.getMessage());
+              e.getMessage());
           badLineCount.increment(1);
           return;
         } else {
-          throw new IOException(badLine);
+          throw new IOException(e);
         }
       } catch (InterruptedException e) {
         e.printStackTrace();
       }
     }
\ No newline at end of file
","HBASE-3711 - amend patch to fix compilation error

git-svn-id: https://svn.apache.org/repos/asf/hbase/trunk@1086747 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
ant,5957.json,79a591966485337a98ec87cfcda01218969b73da,"@@ -1,164 +1,164 @@
     public void execute() throws BuildException {
 
         if ( (sourceFileSets.size() == 0) && (sourceFileLists.size() == 0) ) { 
           throw new BuildException(""At least one <srcfileset> or <srcfilelist> element must be set"");
         }
 
         if ( (targetFileSets.size() == 0) && (targetFileLists.size() == 0) ) {
           throw new BuildException(""At least one <targetfileset> or <targetfilelist> element must be set"");
         }
 
         long now = (new Date()).getTime();
         /*
           If we're on Windows, we have to munge the time up to 2 secs to
           be able to check file modification times.
           (Windows has a max resolution of two secs for modification times)
         */
         if (Os.isFamily(""windows"")) {
             now += 2000;
         }
 
         //
         // Grab all the target files specified via filesets
         //
         Vector  allTargets         = new Vector();
         long oldestTargetTime = 0;
         File oldestTarget = null;
         Enumeration enumTargetSets = targetFileSets.elements();
         while (enumTargetSets.hasMoreElements()) {
                  
            FileSet targetFS          = (FileSet) enumTargetSets.nextElement();
            DirectoryScanner targetDS = targetFS.getDirectoryScanner(project);
            String[] targetFiles      = targetDS.getIncludedFiles();
                  
            for (int i = 0; i < targetFiles.length; i++) {
                     
               File dest = new File(targetFS.getDir(project), targetFiles[i]);
               allTargets.addElement(dest);
 
               if (dest.lastModified() > now) {
                  log(""Warning: ""+targetFiles[i]+"" modified in the future."", 
                      Project.MSG_WARN);
               }
 
               if (oldestTarget == null ||
                   dest.lastModified() < oldestTargetTime) {
                   oldestTargetTime = dest.lastModified();
                   oldestTarget = dest;
               }
            }
         }
 
         //
         // Grab all the target files specified via filelists
         //
         boolean upToDate            = true;
         Enumeration enumTargetLists = targetFileLists.elements();
         while (enumTargetLists.hasMoreElements()) {
                  
            FileList targetFL    = (FileList) enumTargetLists.nextElement();
            String[] targetFiles = targetFL.getFiles(project);
                  
            for (int i = 0; i < targetFiles.length; i++) {
                     
               File dest = new File(targetFL.getDir(project), targetFiles[i]);
               if (!dest.exists()) {
                  log(targetFiles[i]+ "" does not exist."", Project.MSG_VERBOSE);
                  upToDate = false;
                  continue;
               }
               else {
                  allTargets.addElement(dest);
               }
               if (dest.lastModified() > now) {
                  log(""Warning: ""+targetFiles[i]+"" modified in the future."", 
                      Project.MSG_WARN);
               }
+
               if (oldestTarget == null ||
                   dest.lastModified() < oldestTargetTime) {
                   oldestTargetTime = dest.lastModified();
                   oldestTarget = dest;
               }
            }
         }
         if (oldestTarget != null) {
             log(oldestTarget + "" is oldest target file"", Project.MSG_VERBOSE);
         } else { 
             // no target files, then we cannot remove any target files and
             // skip the following tests right away
             upToDate = false;
         }
 
         //
         // Check targets vs source files specified via filelists
         //
         if (upToDate) {
            Enumeration enumSourceLists = sourceFileLists.elements();
            while (upToDate && enumSourceLists.hasMoreElements()) {
           
               FileList sourceFL         = (FileList) enumSourceLists.nextElement();
               String[] sourceFiles      = sourceFL.getFiles(project);
 
-              int i = 0;
-              do {
+              for (int i=0; upToDate && i < sourceFiles.length; i++) {
                  File src = new File(sourceFL.getDir(project), sourceFiles[i]);
 
                  if (src.lastModified() > now) {
                     log(""Warning: ""+sourceFiles[i]+"" modified in the future."", 
                         Project.MSG_WARN);
                  }
 
                  if (!src.exists()) {
                     log(sourceFiles[i]+ "" does not exist."", Project.MSG_VERBOSE);
                     upToDate = false;
                     break;
                  }
 
                  if (src.lastModified() > oldestTargetTime) {
                     upToDate = false;
                     log(oldestTarget + "" is out of date with respect to "" +
                         sourceFiles[i], Project.MSG_VERBOSE);
                  }
-              } while (upToDate && (++i < sourceFiles.length) );
+              }
            }
         }
 
         //
         // Check targets vs source files specified via filesets
         //
         if (upToDate) {
            Enumeration enumSourceSets = sourceFileSets.elements();
            while (upToDate && enumSourceSets.hasMoreElements()) {
           
               FileSet sourceFS          = (FileSet) enumSourceSets.nextElement();
               DirectoryScanner sourceDS = sourceFS.getDirectoryScanner(project);
               String[] sourceFiles      = sourceDS.getIncludedFiles();
 
               for (int i=0; upToDate && i < sourceFiles.length; i++) {
                  File src = new File(sourceFS.getDir(project), sourceFiles[i]);
 
                  if (src.lastModified() > now) {
                     log(""Warning: ""+sourceFiles[i]+"" modified in the future."", 
                         Project.MSG_WARN);
                  }
 
                  if (src.lastModified() > oldestTargetTime) {
                     upToDate = false;
                     log(oldestTarget + "" is out of date with respect to "" +
                         sourceFiles[i], Project.MSG_VERBOSE);
                  }
               }
            }
         }
 
         if (!upToDate) {
            log(""Deleting all target files. "", Project.MSG_VERBOSE);
            for (Enumeration e = allTargets.elements(); e.hasMoreElements(); ) {
               File fileToRemove = (File)e.nextElement();
               log(""Deleting file "" + fileToRemove.getAbsolutePath(), Project.MSG_VERBOSE);
               fileToRemove.delete();
            }
         }
         
 
     } //-- execute
\ No newline at end of file
","fix boundary checking problem similiar to the one fixed for bug report 4290

Actually this wouldn't throw an ArrayIndexOutOuBounds- but a
BuildException as FileList.getFiles barfs out on empty lists, but that
way it is more consistent.


git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@271456 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
ant,9265.json,12ae031068c8dc69dc744f1a4060aba054975801,"@@ -1,16 +1,18 @@
     public static IntrospectionHelper getHelper(Project p, Class c) {
-        IntrospectionHelper ih = (IntrospectionHelper) HELPERS.get(c);
-        if (ih == null) {
+        IntrospectionHelper ih = (IntrospectionHelper) HELPERS.get(c.getName());
+        // If a helper cannot be found, or if the helper is for another
+        // classloader, create a new IH
+        if (ih == null || ih.bean != c) {
             ih = new IntrospectionHelper(c);
             if (p != null) {
                 // #30162: do *not* cache this if there is no project, as we
                 // cannot guarantee that the cache will be cleared.
-                HELPERS.put(c, ih);
+                HELPERS.put(c.getName(), ih);
             }
         }
         if (p != null) {
             // Cleanup at end of project
             p.addBuildListener(ih);
         }
         return ih;
     }
\ No newline at end of file
","Fix for OOME with <*ant*> and <typedef>
Bugzilla report 28283 and 33061

IH had a map of class->IH objects. The
class is the typedefed class and IH is the
attributes, elements etc of that class.
This works fine, except that the class is kept
until the build ends, this means that the classloader
for the class is also kept, a classloader contains
pointers to all the classes loaded by it - so a lot
of memory can be blocked.
When ant, or antcall is used and the called project
typedef the antcontrib, these will be new classloaders,
hence the memory being used up.

The fix is to use the name of the class, check if the IH
in the map is the same class, and if not replace that IH.




git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@465073 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
ant,9998.json,f40cbc60b34a952432e7abfb70181d0feabd4dd6,"@@ -1,13 +1,13 @@
     public String removeLeadingPath(File leading, File path) {
-        String l = normalize(leading.getAbsolutePath()).getAbsolutePath();
+        // if leading's path ends with a slash, it will be stripped by
+        // normalize - we always add one so we never think /foo was a
+        // parent directory of /foobar
+        String l = normalize(leading.getAbsolutePath()).getAbsolutePath()
+            + File.separator;
         String p = normalize(path.getAbsolutePath()).getAbsolutePath();
         if (p.startsWith(l)) {
-            String result = p.substring(l.length());
-            if (result.startsWith(File.separator)) {
-                result = result.substring(File.separator.length());
-            }
-            return result;
+            return p.substring(l.length());
         } else {
             return p;
         }
     }
\ No newline at end of file
","Merge over a bug-fix needed to get jakarta-tomcat built by Gump.


git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@272855 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
ant,3709.json,d3f03ad754ffdd5d27796dc492ca2db38a7bf444,"@@ -1,95 +1,95 @@
         private void checkIncludePatterns() {
             Hashtable newroots = new Hashtable();
             // put in the newroots vector the include patterns without
             // wildcard tokens
             for (int icounter = 0; icounter < includes.length; icounter++) {
                 String newpattern =
                     SelectorUtils.rtrimWildcardTokens(includes[icounter]);
                 newroots.put(newpattern, includes[icounter]);
             }
             if (remotedir == null) {
                 try {
                     remotedir = ftp.printWorkingDirectory();
                 } catch (IOException e) {
                     throw new BuildException(""could not read current ftp directory"",
                         getLocation());
                 }
             }
             AntFTPFile baseFTPFile = new AntFTPRootFile(ftp, remotedir);
             rootPath = baseFTPFile.getAbsolutePath();
             // construct it
             if (newroots.containsKey("""")) {
                 // we are going to scan everything anyway
-                scandir(remotedir, """", true);
+                scandir(rootPath, """", true);
             } else {
                 // only scan directories that can include matched files or
                 // directories
                 Enumeration enum2 = newroots.keys();
 
                 while (enum2.hasMoreElements()) {
                     String currentelement = (String) enum2.nextElement();
                     String originalpattern = (String) newroots.get(currentelement);
                     AntFTPFile myfile = new AntFTPFile(baseFTPFile, currentelement);
                     boolean isOK = true;
                     boolean traversesSymlinks = false;
                     String path = null;
 
                     if (myfile.exists()) {
                         if (remoteSensitivityChecked
                             && remoteSystemCaseSensitive && isFollowSymlinks()) {
                             // cool case,
                             //we do not need to scan all the subdirs in the relative path
                             path = myfile.getFastRelativePath();
                         } else {
                             // may be on a case insensitive file system.  We want
                             // the results to show what's really on the disk, so
                             // we need to double check.
                             try {
                                 path = myfile.getRelativePath();
                                 traversesSymlinks = myfile.isTraverseSymlinks();
                             }  catch (IOException be) {
                                 throw new BuildException(be, getLocation());
                             } catch (BuildException be) {
                                 isOK = false;
 
                             }
                         }
                     } else {
                         isOK = false;
                     }
                     if (isOK) {
                         currentelement = path.replace(remoteFileSep.charAt(0), File.separatorChar);
                         if (!isFollowSymlinks()
                             && traversesSymlinks) {
                             continue;
                         }
 
                         if (myfile.isDirectory()) {
                             if (isIncluded(currentelement)
                                 && currentelement.length() > 0) {
                                 accountForIncludedDir(currentelement, myfile, true);
                             }  else {
                                 if (currentelement.length() > 0) {
                                     if (currentelement.charAt(currentelement
                                                               .length() - 1)
                                         != File.separatorChar) {
                                         currentelement =
                                             currentelement + File.separatorChar;
                                     }
                                 }
                                 scandir(myfile.getAbsolutePath(), currentelement, true);
                             }
                         } else {
                             if (isCaseSensitive
                                 && originalpattern.equals(currentelement)) {
                                 accountForIncludedFile(currentelement);
                             } else if (!isCaseSensitive
                                        && originalpattern
                                        .equalsIgnoreCase(currentelement)) {
                                 accountForIncludedFile(currentelement);
                             }
                         }
                     }
                 }
             }
         }
\ No newline at end of file
","Merge from ANT_16_BRANCH
Fix problem with non absolute remote dirs
PR: 23833


git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@275510 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
ant,8803.json,bb975e67e154a84b5dd47b5a5b24f853758dc7a5,"@@ -1,15 +1,15 @@
     protected void dieOnCircularReference(Stack<Object> stk, Project p)
         throws BuildException {
         if (isChecked()) {
             return;
         }
         if (isReference()) {
             super.dieOnCircularReference(stk, p);
         } else {
-            if (nested instanceof DataType) {
+            if (nested != null) {
                 pushAndInvokeCircularReferenceCheck((DataType) nested, stk,
                                                     p);
             }
             setChecked(true);
         }
     }
\ No newline at end of file
","Fix the problem of instanceof test always return true.

This instanceof test will always return true because DataType is the superclass of variable nested's class ResourceComparator. The variable nested is not initialized, it would be better to do a null test rather than an instanceof test.
http://findbugs.sourceforge.net/bugDescriptions.html#BC_VACUOUS_INSTANCEOF
",Buggy
ant,3291.json,3549562783e517c3fbf00a6e914bc48d624847cc,"@@ -1,25 +1,25 @@
     public void execute() throws BuildException {
 
         // first off, make sure that we've got a from and to extension
         if (fromExtension == null || toExtension == null || srcDir == null) {
-            throw new BuildException(""srcDir, destDir, fromExtension and toExtension attributes must be set!"");
+            throw new BuildException(""srcDir, fromExtension and toExtension attributes must be set!"");
         }
 
         // scan source and dest dirs to build up rename list
         DirectoryScanner ds = getDirectoryScanner(srcDir);
 
         String[] files = ds.getIncludedFiles();
 
         Hashtable renameList = scanDir(srcDir, files);
 
         Enumeration e = renameList.keys();
         File fromFile = null;
         File toFile = null;
         while (e.hasMoreElements()) {
             fromFile = (File)e.nextElement();
             toFile = (File)renameList.get(fromFile);
             if (toFile.exists() && replace) toFile.delete();
             if (!fromFile.renameTo(toFile)) throw new BuildException(""Rename from: '"" + fromFile + ""' to '"" + toFile + ""' failed."");
         }
 
     }
\ No newline at end of file
","fixed comments and error message
Submitted by: dIon Gillard <dion@multitask.com.au>


git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@267640 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
ant,1040.json,cdf128015bad588566b90d913fba4b346460d82d,"@@ -1,45 +1,45 @@
     public void execute() throws BuildException {
         Method setProjectM = null;
         try {
             Class c = proxy.getClass();
             setProjectM = 
                 c.getMethod(""setProject"", new Class[] {Project.class});
             if (setProjectM != null) {
                 setProjectM.invoke(proxy, new Object[] {getProject()});
             }
         } catch (NoSuchMethodException e) {
             // ignore this if the class being used as a task does not have
             // a set project method.
         } catch (Exception ex) {
             log(""Error setting project in "" + proxy.getClass(), 
                 Project.MSG_ERR);
             throw new BuildException(ex);
         }
 
 
         Method executeM = null;
         try {
             Class c = proxy.getClass();
             executeM = c.getMethod(""execute"", new Class[0]);
             if (executeM == null) {
                 log(""No public execute() in "" + proxy.getClass(), 
                     Project.MSG_ERR);
                 throw new BuildException(""No public execute() in "" 
                     + proxy.getClass());
             }
             executeM.invoke(proxy, null);
             return; 
         } catch (java.lang.reflect.InvocationTargetException ie) {
-            log(""Error in "" + proxy.getClass(), Project.MSG_ERR);
+            log(""Error in "" + proxy.getClass(), Project.MSG_VERBOSE);
             Throwable t = ie.getTargetException();
             if (t instanceof BuildException) {
                 throw ((BuildException) t);
             } else {
                 throw new BuildException(t);
             }
         } catch (Exception ex) {
-            log(""Error in "" + proxy.getClass(), Project.MSG_ERR);
+            log(""Error in "" + proxy.getClass(), Project.MSG_VERBOSE);
             throw new BuildException(ex);
         }
 
     }
\ No newline at end of file
","Fix for 20499:
When a proxied task throws a build exception, or other
exception, the taskadapter reports this at
error level. This is incorrect as the
intent of taskadapter is to transparently adapt
a task, the exception should be reported
at verbose level.


git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@274649 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
ant,6876.json,320e41bc89d8ac60180cbea1c4110dea68cebc33,"@@ -1,3 +1,9 @@
-    public void setTag(String p) {
-	this.tag = p;
-    }
\ No newline at end of file
+    public void setTag(String p) { 
+        // Check if not real tag => set it to null 
+        if (p != null) { 
+            if (p.trim().equals("""")) 
+                p = null; 
+        } 
+
+        this.tag = p; 
+    } 
\ No newline at end of file
","Fixed problem when an empty tag was supplied.

Submitted by:	Jean-Noel Gadreau <jngadreau@activcard.com>


git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@267670 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
ant,5580.json,c807cf91c6fa47ef199cce3ae19a9d0e74fb4b18,"@@ -1,28 +1,28 @@
     private int removeEmptyDirectories(File dir, boolean removeIfEmpty,
                                        Set preservedEmptyDirectories) {
         int removedCount = 0;
-        if (!preservedEmptyDirectories.contains(dir) && dir.isDirectory()) {
+        if (dir.isDirectory()) {
             File[] children = dir.listFiles();
             for (int i = 0; i < children.length; ++i) {
                 File file = children[i];
                 // Test here again to avoid method call for non-directories!
-                if (!preservedEmptyDirectories.contains(file)
-                    && file.isDirectory()) {
+                if (file.isDirectory()) {
                     removedCount +=
                         removeEmptyDirectories(file, true,
                                                preservedEmptyDirectories);
                 }
             }
             if (children.length > 0) {
                 // This directory may have become empty...
                 // We need to re-query its children list!
                 children = dir.listFiles();
             }
-            if (children.length < 1 && removeIfEmpty) {
+            if (children.length < 1 && removeIfEmpty
+                && !preservedEmptyDirectories.contains(dir)) {
                 log(""Removing empty directory: "" + dir, Project.MSG_DEBUG);
                 dir.delete();
                 ++removedCount;
             }
         }
         return removedCount;
     }
\ No newline at end of file
","properly handle non-recursive excludes (breaks one other test because of the same slowscan bug that I'm going to fix later)

git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@727978 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
ant,244.json,99684cfd77a3851d098824e9eb871cd6c087934f,"@@ -1,79 +1,79 @@
     private byte[] createCentralFileHeader(ZipEntry ze, ByteBuffer name, long lfhOffset,
                                            boolean needsZip64Extra) throws IOException {
         byte[] extra = ze.getCentralDirectoryExtra();
 
         // file comment length
         String comm = ze.getComment();
         if (comm == null) {
             comm = """";
         }
 
         ByteBuffer commentB = getEntryEncoding(ze).encode(comm);
         final int nameLen = name.limit() - name.position();
         final int commentLen = commentB.limit() - commentB.position();
         int len= CFH_FILENAME_OFFSET + nameLen + extra.length + commentLen;
         byte[] buf = new byte[len];
 
         System.arraycopy(CFH_SIG,  0, buf, CFH_SIG_OFFSET, WORD);
 
         // version made by
         // CheckStyle:MagicNumber OFF
         putShort((ze.getPlatform() << 8) | (!hasUsedZip64 ? DATA_DESCRIPTOR_MIN_VERSION : ZIP64_MIN_VERSION),
                 buf, CFH_VERSION_MADE_BY_OFFSET);
 
         final int zipMethod = ze.getMethod();
         final boolean encodable = zipEncoding.canEncode(ze.getName());
         putShort(versionNeededToExtract(zipMethod, needsZip64Extra), buf, CFH_VERSION_NEEDED_OFFSET);
         getGeneralPurposeBits(zipMethod, !encodable && fallbackToUTF8).encode(buf, CFH_GPB_OFFSET);
 
         // compression method
         putShort(zipMethod, buf, CFH_METHOD_OFFSET);
 
 
         // last mod. time and date
         ZipUtil.toDosTime(calendarInstance, ze.getTime(), buf, CFH_TIME_OFFSET);
 
         // CRC
         // compressed length
         // uncompressed length
         putLong(ze.getCrc(), buf, CFH_CRC_OFFSET);
         if (ze.getCompressedSize() >= ZIP64_MAGIC
                 || ze.getSize() >= ZIP64_MAGIC) {
             ZipLong.ZIP64_MAGIC.putLong(buf, CFH_COMPRESSED_SIZE_OFFSET);
             ZipLong.ZIP64_MAGIC.putLong(buf, CFH_ORIGINAL_SIZE_OFFSET);
         } else {
             putLong(ze.getCompressedSize(), buf, CFH_COMPRESSED_SIZE_OFFSET);
             putLong(ze.getSize(), buf, CFH_ORIGINAL_SIZE_OFFSET);
         }
 
         putShort(nameLen, buf, CFH_FILENAME_LENGTH_OFFSET);
 
         // extra field length
         putShort(extra.length, buf, CFH_EXTRA_LENGTH_OFFSET);
 
         putShort(commentLen, buf, CFH_COMMENT_LENGTH_OFFSET);
 
         // disk number start
         System.arraycopy(ZERO, 0, buf, CFH_DISK_NUMBER_OFFSET, SHORT);
 
         // internal file attributes
         putShort(ze.getInternalAttributes(), buf, CFH_INTERNAL_ATTRIBUTES_OFFSET);
 
         // external file attributes
         putLong(ze.getExternalAttributes(), buf, CFH_EXTERNAL_ATTRIBUTES_OFFSET);
 
         // relative offset of LFH
         putLong(Math.min(lfhOffset, ZIP64_MAGIC), buf, CFH_LFH_OFFSET);
 
         // file name
         System.arraycopy(name.array(), name.arrayOffset(), buf, CFH_FILENAME_OFFSET, nameLen);
 
         int extraStart = CFH_FILENAME_OFFSET + nameLen;
         System.arraycopy(extra, 0, buf, extraStart, extra.length);
 
-        int commentStart = extraStart + commentLen;
+        int commentStart = extraStart + extra.length;
 
         // file comment
         System.arraycopy(commentB.array(), commentB.arrayOffset(), buf, commentStart, commentLen);
         return buf;
     }
\ No newline at end of file
","yet another potential AIOBException in zip package

Bug found and fix provided by Earl Hood
",Buggy
ant,6044.json,e2a62c3179e855f7e102af8701aff81d6ba3c7e8,"@@ -1,56 +1,55 @@
         public int read(char[] cbuf, int off, int len)
             throws IOException {
 
             int amountRead = 0;
             while (pos < sourceFiles.size() || (needAddSeparator)) {
                 if (needAddSeparator) {
                     cbuf[off] = eolString.charAt(lastPos++);
                     if (lastPos >= eolString.length()) {
                         lastPos = 0;
                         needAddSeparator = false;
                         pos++;
                     }
                     len--;
                     off++;
                     amountRead++;
                     if (len == 0) {
                         return amountRead;
                     }
                     continue;
                 }
-
                 int nRead = getReader().read(cbuf, off, len);
                 if (nRead == -1 || nRead == 0) {
                     reader.close();
                     reader = null;
                     if (fixLastLine && isMissingEndOfLine()) {
                         needAddSeparator = true;
                         lastPos = 0;
                     } else {
                         pos++;
                     }
                 } else {
                     if (fixLastLine) {
                         for (int i = nRead;
                                  i > (nRead - lastChars.length);
                                  --i) {
                             if (i < 0) {
                                 break;
                             }
-                            addLastChar(cbuf[off + i]);
+                            addLastChar(cbuf[off + i - 1]);
                         }
                     }
                     len -= nRead;
                     off += nRead;
                     amountRead += nRead;
                     if (len == 0) {
                         return amountRead;
                     }
                 }
             }
             if (amountRead == 0) {
                 return -1;
             } else {
                 return amountRead;
             }
         }
\ No newline at end of file
","Fix off-by-one error in concat with fixlastline=""yes""
PR: 25464
Obtained from: wang liang


git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@275773 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
ant,8293.json,feb03ce2d86cb52fbe8ce55b6b74dfe2536924b1,"@@ -1,5 +1,5 @@
-    protected Object clone() throws CloneNotSupportedException {
+    public Object clone() throws CloneNotSupportedException {
         Assertions that = (Assertions) super.clone();
         that.assertionList = (ArrayList) assertionList.clone();
         return that;
     }
\ No newline at end of file
","added cloning support; bug #27218


git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@276160 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
ant,4097.json,84d3e4a158b155664d401f0d8b57124504532b74,"@@ -1,3 +1,11 @@
     public void setGlib(String superGrammar) {
-        this.superGrammar = superGrammar;
+        String sg = null;
+        if (Os.isFamily(""dos"")) {
+            sg = superGrammar.replace('\\','/');
+        }
+        else
+        {
+            sg = superGrammar;
+        }
+        this.superGrammar = sg;
     }
\ No newline at end of file
","All the tests in ANTLRTest.java involving a super-grammar file were failing on Windows.
This change fixes the problem.


git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@274716 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
ant,8414.json,08413ada31e6a9e9dbed3073158d17123d5028e0,"@@ -1,4 +1,6 @@
     private boolean hasPatterns(PatternSet ps) {
-        return ps.getIncludePatterns(getProject()).length > 0
-            || ps.getExcludePatterns(getProject()).length > 0;
+        String[] includePatterns = ps.getIncludePatterns(getProject());
+        String[] excludePatterns = ps.getExcludePatterns(getProject());
+        return (includePatterns != null && includePatterns.length > 0)
+            || (includePatterns != null && excludePatterns.length > 0);
     }
\ No newline at end of file
","Fix Bug 42397: NPE in <path><files refid>

git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@540055 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
ant,7366.json,2a5857c384ef5a9e02b4264be44bf67f3a584d57,"@@ -1,48 +1,48 @@
     public PlanarImage executeDrawOperation() {
         log(""\tCreating Rectangle w="" + width + "" h="" + height + "" arcw=""
             + arcwidth + "" arch="" + archeight);
         BufferedImage bi = new BufferedImage(width, height, BufferedImage.TYPE_4BYTE_ABGR_PRE);
 
         Graphics2D graphics = (Graphics2D) bi.getGraphics();
 
         if (!stroke.equals(""transparent"")) {
             BasicStroke bStroke = new BasicStroke(stroke_width);
             graphics.setColor(ColorMapper.getColorByName(stroke));
             graphics.setStroke(bStroke);
 
             if ((arcwidth != 0) || (archeight != 0)) {
                 graphics.drawRoundRect(0, 0, width, height, arcwidth, archeight);
             } else {
                 graphics.drawRect(0, 0, width, height);
             }
         }
 
         if (!fill.equals(""transparent"")) {
             graphics.setColor(ColorMapper.getColorByName(fill));
             if ((arcwidth != 0) || (archeight != 0)) {
                 graphics.fillRoundRect(stroke_width, stroke_width,
                     width - (stroke_width * 2), height - (stroke_width * 2),
                     arcwidth, archeight);
             } else {
                 graphics.fillRect(stroke_width, stroke_width,
                     width - (stroke_width * 2), height - (stroke_width * 2));
             }
         }
 
 
         final int size = instructions.size();
         for (int i = 0; i < size; i++) {
             ImageOperation instr = ((ImageOperation) instructions.elementAt(i));
             if (instr instanceof DrawOperation) {
                 PlanarImage img = ((DrawOperation) instr).executeDrawOperation();
                 graphics.drawImage(img.getAsBufferedImage(), null, 0, 0);
             } else if (instr instanceof TransformOperation) {
-                graphics = (Graphics2D) bi.getGraphics();
                 PlanarImage image
                     = ((TransformOperation) instr)
                     .executeTransformOperation(PlanarImage.wrapRenderedImage(bi));
                 bi = image.getAsBufferedImage();
+                graphics = (Graphics2D) bi.getGraphics();
             }
         }
         return PlanarImage.wrapRenderedImage(bi);
     }
\ No newline at end of file
","port image type bug fixes from Java8 refactoring in master
",Buggy
ant,9982.json,869b123c0437855adde003d242e4e084e8b35731,"@@ -1,30 +1,31 @@
     public File normalize(final String path) {
         Stack s = new Stack();
         String[] dissect = dissect(path);
         s.push(dissect[0]);
 
         StringTokenizer tok = new StringTokenizer(dissect[1], File.separator);
         while (tok.hasMoreTokens()) {
             String thisToken = tok.nextToken();
             if (""."".equals(thisToken)) {
                 continue;
             } else if ("".."".equals(thisToken)) {
                 if (s.size() < 2) {
-                    throw new BuildException(""Cannot resolve path "" + path);
+                    // Cannot resolve it, so skip it.
+                    return new File(path);
                 }
                 s.pop();
             } else { // plain component
                 s.push(thisToken);
             }
         }
         StringBuffer sb = new StringBuffer();
         for (int i = 0; i < s.size(); i++) {
             if (i > 1) {
                 // not before the filesystem root and not after it, since root
                 // already contains one
                 sb.append(File.separatorChar);
             }
             sb.append(s.elementAt(i));
         }
         return new File(sb.toString());
     }
\ No newline at end of file
","#40281: ""Cannot resolve path"" error thrown gratuitously.


git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@432379 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
ant,7113.json,2fbb2e62ab0d3d323a75c6baf00a2e675c7fd6f5,"@@ -1,46 +1,55 @@
     protected void slowScan() {
         synchronized (slowScanLock) {
             if (haveSlowResults) {
                 return;
             }
             if (slowScanning) {
                 while (slowScanning) {
                     try {
                         slowScanLock.wait();
                     } catch (InterruptedException e) {
                     }
                 }
                 return;
             }
             slowScanning = true;
         }
         try {
             synchronized (this) {
 
+                // set in/excludes to reasonable defaults if needed:
+                boolean nullIncludes = (includes == null);
+                includes = nullIncludes ? new String[] {""**""} : includes;
+                boolean nullExcludes = (excludes == null);
+                excludes = nullExcludes ? new String[0] : excludes;
+
                 String[] excl = new String[dirsExcluded.size()];
                 dirsExcluded.copyInto(excl);
         
                 String[] notIncl = new String[dirsNotIncluded.size()];
                 dirsNotIncluded.copyInto(notIncl);
         
                 for (int i = 0; i < excl.length; i++) {
                     if (!couldHoldIncluded(excl[i])) {
                         scandir(new File(basedir, excl[i]),
                                 excl[i] + File.separator, false);
                     }
                 }
                 for (int i = 0; i < notIncl.length; i++) {
                     if (!couldHoldIncluded(notIncl[i])) {
                         scandir(new File(basedir, notIncl[i]),
                                 notIncl[i] + File.separator, false);
                     }
                 }
+                clearCaches();
+                includes = nullIncludes ? null : includes;
+                excludes = nullExcludes ? null : excludes;
             }
         } finally {
             synchronized (slowScanLock) {
                 haveSlowResults = true;
                 slowScanning = false;
                 slowScanLock.notifyAll();
             }
         }
     }
\ No newline at end of file
","Not 100% sure this fixes the entire bug, but it eliminates NPEs for me.
PR: 34722


git-svn-id: https://svn.apache.org/repos/asf/ant/core/trunk@278219 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
ant,9433.json,fef3ea39f8bd474add292bb6437df6cbd22e1ba7,"@@ -1,47 +1,49 @@
     private static void buildJrePackages() {
         jrePackages = new Vector<String>();
         switch(javaVersionNumber) {
             case VERSION_1_9:
             case VERSION_1_8:
             case VERSION_1_7:
+                jrePackages.addElement(""jdk"");
+                // fall through
             case VERSION_1_6:
             case VERSION_1_5:
                 //In Java1.5, the apache stuff moved.
                 jrePackages.addElement(""com.sun.org.apache"");
                 //fall through.
             case VERSION_1_4:
                 if (javaVersionNumber == VERSION_1_4) {
                     jrePackages.addElement(""org.apache.crimson"");
                     jrePackages.addElement(""org.apache.xalan"");
                     jrePackages.addElement(""org.apache.xml"");
                     jrePackages.addElement(""org.apache.xpath"");
                 }
                 jrePackages.addElement(""org.ietf.jgss"");
                 jrePackages.addElement(""org.w3c.dom"");
                 jrePackages.addElement(""org.xml.sax"");
                 // fall through
             case VERSION_1_3:
                 jrePackages.addElement(""org.omg"");
                 jrePackages.addElement(""com.sun.corba"");
                 jrePackages.addElement(""com.sun.jndi"");
                 jrePackages.addElement(""com.sun.media"");
                 jrePackages.addElement(""com.sun.naming"");
                 jrePackages.addElement(""com.sun.org.omg"");
                 jrePackages.addElement(""com.sun.rmi"");
                 jrePackages.addElement(""sunw.io"");
                 jrePackages.addElement(""sunw.util"");
                 // fall through
             case VERSION_1_2:
                 jrePackages.addElement(""com.sun.java"");
                 jrePackages.addElement(""com.sun.image"");
                 // are there any here that we forgot?
                 // fall through
             case VERSION_1_1:
             default:
                 //things like sun.reflection, sun.misc, sun.net
                 jrePackages.addElement(""sun"");
                 jrePackages.addElement(""java"");
                 jrePackages.addElement(""javax"");
                 break;
         }
     }
\ No newline at end of file
","fix Bug 59556 - support ""jdk"" package for Java 7+

Patch based on Chris Hegarty (Oracle) work.
""jdk"" package has been introduced in JDK7 but is not known from Ant.
""jdk.net.Sockets"" has been chosen as test class because it is available in JDK7, JDK8 and JDK9.
",Buggy
lucene-solr,36661.json,d815a3608b2742dad7ed0c0b6233fdea1653c285,"@@ -1,33 +1,33 @@
   private final void count(List<MatchingDocs> matchingDocs) throws IOException {
     IntsRef scratch  = new IntsRef();
     for(MatchingDocs hits : matchingDocs) {
       OrdinalsReader.OrdinalsSegmentReader ords = ordinalsReader.getReader(hits.context);
       FixedBitSet bits = hits.bits;
     
       final int length = hits.bits.length();
       int doc = 0;
       while (doc < length && (doc = bits.nextSetBit(doc)) != -1) {
         ords.get(doc, scratch);
         for(int i=0;i<scratch.length;i++) {
-          ++counts[scratch.ints[i]];
+          counts[scratch.ints[scratch.offset+i]]++;
         }
         ++doc;
       }
     }
 
     // nocommit we could do this lazily instead:
 
     // Rollup any necessary dims:
     for(Map.Entry<String,FacetsConfig.DimConfig> ent : config.getDimConfigs().entrySet()) {
       String dim = ent.getKey();
       FacetsConfig.DimConfig ft = ent.getValue();
       if (ft.hierarchical && ft.multiValued == false) {
         int dimRootOrd = taxoReader.getOrdinal(new FacetLabel(dim));
         // It can be -1 if this field was declared in the
         // config but never indexed:
         if (dimRootOrd > 0) {
           counts[dimRootOrd] += rollup(children[dimRootOrd]);
         }
       }
     }
   }
\ No newline at end of file
","LUCENE-5339: migrate some more tests; fix 'ignores IntsRef.offset bug' in TaxoFacetCounts; add FacetTestCase.getFacetCounts

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/branches/lucene5339@1543506 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
lucene-solr,26469.json,4336de5e81d66e255abbface1bddf8c18e500a90,"@@ -1,16 +1,16 @@
   private void recordOffsetDiff(int inputLength, int outputLength) {
     if (inputLength == outputLength) {
       charCount += outputLength;
       return;
     }
     final int diff = inputLength - outputLength;
     final int cumuDiff = getLastCumulativeDiff();
     if (diff < 0) {
       for (int i = 1;  i <= -diff; ++i) {
         addOffCorrectMap(charCount + i, cumuDiff - i);
       }
     } else {
-      addOffCorrectMap(charCount + Math.min(1, outputLength), cumuDiff + diff);
+      addOffCorrectMap(charCount + outputLength, cumuDiff + diff);
     }
     charCount += outputLength;
   }
\ No newline at end of file
","LUCENE-5547: fix bug in offset correction

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1580829 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
lucene-solr,19683.json,748cb61e824feefe8a6ef0fb2735af183c4afd5a,"@@ -1,9 +1,9 @@
   public IndexOutput createOutput(String name, IOContext context)
       throws IOException {
     if (SEGMENTS_GEN.equals(name)) {
-      return NULL_WRITER;
+      return new NullIndexOutput();
     }
     HdfsFileWriter writer = new HdfsFileWriter(getFileSystem(), new Path(
         hdfsDirPath, name));
     return new HdfsIndexOutput(writer);
   }
\ No newline at end of file
","SOLR-4916: Fix bugs & usage of NullIndexOutput

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1502167 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
lucene-solr,50349.json,b8feb92271c62b3bc1c24e2e3610ecd1cf646eab,"@@ -1,54 +1,60 @@
-  public double surfaceDistance(final GeoPoint p1, final GeoPoint p2) {
-    final double latA = p1.getLatitude();
-    final double lonA = p1.getLongitude();
-    final double latB = p2.getLatitude();
-    final double lonB = p2.getLongitude();
+  public double surfaceDistance(final GeoPoint pt1, final GeoPoint pt2) {
+    final double L = pt2.getLongitude() - pt1.getLongitude();
+    final double U1 = Math.atan((1.0-flattening) * Math.tan(pt1.getLatitude()));
+    final double U2 = Math.atan((1.0-flattening) * Math.tan(pt2.getLatitude()));
 
-    final double L = lonB - lonA;
-    final double oF = 1.0 - this.flattening;
-    final double U1 = Math.atan(oF * Math.tan(latA));
-    final double U2 = Math.atan(oF * Math.tan(latB));
-    final double sU1 = Math.sin(U1);
-    final double cU1 = Math.cos(U1);
-    final double sU2 = Math.sin(U2);
-    final double cU2 = Math.cos(U2);
+    final double sinU1 = Math.sin(U1);
+    final double cosU1 = Math.cos(U1);
+    final double sinU2 = Math.sin(U2);
+    final double cosU2 = Math.cos(U2);
 
-    double sigma, sinSigma, cosSigma;
-    double cos2Alpha, cos2SigmaM;
-    
+    final double dCosU1CosU2 = cosU1 * cosU2;
+    final double dCosU1SinU2 = cosU1 * sinU2;
+
+    final double dSinU1SinU2 = sinU1 * sinU2;
+    final double dSinU1CosU2 = sinU1 * cosU2;
+
+
     double lambda = L;
-    double iters = 100;
+    double lambdaP = Math.PI * 2.0;
+    int iterLimit = 0;
+    double cosSqAlpha;
+    double sinSigma;
+    double cos2SigmaM;
+    double cosSigma;
+    double sigma;
+    double sinAlpha;
+    double C;
+    double sinLambda, cosLambda;
 
     do {
-      final double sinLambda = Math.sin(lambda);
-      final double cosLambda = Math.cos(lambda);
-      sinSigma = Math.sqrt((cU2 * sinLambda) * (cU2 * sinLambda) + (cU1 * sU2 - sU1 * cU2 * cosLambda)
-          * (cU1 * sU2 - sU1 * cU2 * cosLambda));
-      if (Math.abs(sinSigma) < Vector.MINIMUM_RESOLUTION)
+      sinLambda = Math.sin(lambda);
+      cosLambda = Math.cos(lambda);
+      sinSigma = Math.sqrt((cosU2*sinLambda) * (cosU2*sinLambda) +
+                                    (dCosU1SinU2 - dSinU1CosU2 * cosLambda) * (dCosU1SinU2 - dSinU1CosU2 * cosLambda));
+
+      if (sinSigma==0.0) {
         return 0.0;
-
-      cosSigma = sU1 * sU2 + cU1 * cU2 * cosLambda;
+      }
+      cosSigma = dSinU1SinU2 + dCosU1CosU2 * cosLambda;
       sigma = Math.atan2(sinSigma, cosSigma);
-      final double sinAlpha = cU1 * cU2 * sinLambda / sinSigma;
-      cos2Alpha = 1.0 - sinAlpha * sinAlpha;
-      cos2SigmaM = cosSigma - 2.0 * sU1 * sU2 / cos2Alpha;
+      sinAlpha = dCosU1CosU2 * sinLambda / sinSigma;
+      cosSqAlpha = 1.0 - sinAlpha * sinAlpha;
+      cos2SigmaM = cosSigma - 2.0 * dSinU1SinU2 / cosSqAlpha;
 
-      final double c = this.flattening * 0.625 * cos2Alpha * (4.0 + this.flattening * (4.0 - 3.0 * cos2Alpha));
-      final double lambdaP = lambda;
-      lambda = L + (1.0 - c) * this.flattening * sinAlpha * (sigma + c * sinSigma * (cos2SigmaM + c * cosSigma *
-          (-1.0 + 2.0 * cos2SigmaM * cos2SigmaM)));
-      if (Math.abs(lambda - lambdaP) < Vector.MINIMUM_RESOLUTION)
-        break;
-    } while (--iters > 0);
+      if (Double.isNaN(cos2SigmaM))
+        cos2SigmaM = 0.0;  // equatorial line: cosSqAlpha=0
+      C = flattening / 16.0 * cosSqAlpha * (4.0 + flattening * (4.0 - 3.0 * cosSqAlpha));
+      lambdaP = lambda;
+      lambda = L + (1.0 - C) * flattening * sinAlpha *
+        (sigma + C * sinSigma * (cos2SigmaM + C * cosSigma * (-1.0 + 2.0 * cos2SigmaM *cos2SigmaM)));
+    } while (Math.abs(lambda-lambdaP) > Vector.MINIMUM_RESOLUTION && ++iterLimit < 40);
 
-    if (iters == 0)
-      return 0.0;
+    final double uSq = cosSqAlpha * this.squareRatio;
+    final double A = 1.0 + uSq / 16384.0 * (4096.0 + uSq * (-768.0 + uSq * (320.0 - 175.0 * uSq)));
+    final double B = uSq / 1024.0 * (256.0 + uSq * (-128.0 + uSq * (74.0 - 47.0 * uSq)));
+    final double deltaSigma = B * sinSigma * (cos2SigmaM + B / 4.0 * (cosSigma * (-1.0 + 2.0 * cos2SigmaM * cos2SigmaM)-
+                                        B / 6.0 * cos2SigmaM * (-3.0 + 4.0 * sinSigma * sinSigma) * (-3.0 + 4.0 * cos2SigmaM * cos2SigmaM)));
 
-    final double uSq = cos2Alpha * this.squareRatio;
-    final double A = 1.0 + uSq * 0.00006103515625 * (4096.0 + uSq * (-768.0 + uSq * (320.0 - 175.0 * uSq)));
-    final double B = uSq * 0.0009765625 * (256.0 + uSq * (-128.0 + uSq * (74.0 - 47.0 * uSq)));
-    final double deltaSigma = B * sinSigma * (cos2SigmaM + B * 0.25 * (cosSigma * (-1.0 + 2.0 * cos2SigmaM * cos2SigmaM) - B * 0.16666666666666666666667 * cos2SigmaM
-            * (-3.0 + 4.0 * sinSigma * sinSigma) * (-3.0 + 4.0 * cos2SigmaM * cos2SigmaM)));
-
-    return this.c * A * (sigma - deltaSigma);
+    return c * A * (sigma - deltaSigma);
   }
\ No newline at end of file
","LUCENE-7139: fix bugs in geo3d's vincenty distance implementation
",Buggy
lucene-solr,8422.json,dfdd1b7363afa9e56a47fec7b92960468edd7763,"@@ -1,37 +1,37 @@
   public List<ZkCoreNodeProps> getReplicaProps(String collection,
       String shardId, String thisNodeName, String coreName, String stateFilter) {
     CloudState cloudState = this.cloudState;
     if (cloudState == null) {
       return null;
     }
     Map<String,Slice> slices = cloudState.getSlices(collection);
     if (slices == null) {
       throw new ZooKeeperException(ErrorCode.BAD_REQUEST,
           ""Could not find collection in zk: "" + collection + "" ""
               + cloudState.getCollections());
     }
     
     Slice replicas = slices.get(shardId);
     if (replicas == null) {
       throw new ZooKeeperException(ErrorCode.BAD_REQUEST, ""Could not find shardId in zk: "" + shardId);
     }
     
     Map<String,ZkNodeProps> shardMap = replicas.getShards();
     List<ZkCoreNodeProps> nodes = new ArrayList<ZkCoreNodeProps>(shardMap.size());
     String filterNodeName = thisNodeName + ""_"" + coreName;
     for (Entry<String,ZkNodeProps> entry : shardMap.entrySet()) {
       ZkCoreNodeProps nodeProps = new ZkCoreNodeProps(entry.getValue());
-      String coreNodeName = nodeProps.getNodeName() + ""_"" + coreName;
+      String coreNodeName = nodeProps.getNodeName() + ""_"" + nodeProps.getCoreName();
       if (cloudState.liveNodesContain(nodeProps.getNodeName()) && !coreNodeName.equals(filterNodeName)) {
         if (stateFilter == null || stateFilter.equals(nodeProps.getState())) {
           nodes.add(nodeProps);
         }
       }
     }
     if (nodes.size() == 0) {
       // no replicas - go local
       return null;
     }
 
     return nodes;
   }
\ No newline at end of file
","SOLR-3108: Error in SolrCloud's replica lookup code when replica's are hosted in same Solr instance (fix only)

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1242212 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
lucene-solr,10932.json,56476fb8c70486c21324879f1bd1efc79df92ffb,"@@ -1,16 +1,24 @@
   public Map<String, Metric> getMetrics() {
     final Map<String, Metric> metrics = new HashMap<>();
 
     try {
       final ObjectName on = new ObjectName(""java.lang:type=OperatingSystem"");
       // verify that it exists
-      mBeanServer.getMBeanInfo(on);
+      MBeanInfo info = mBeanServer.getMBeanInfo(on);
+      // collect valid attributes
+      Set<String> attributes = new HashSet<>();
+      for (MBeanAttributeInfo ai : info.getAttributes()) {
+        attributes.add(ai.getName());
+      }
       for (String metric : METRICS) {
-        metrics.put(metric, new JmxAttributeGauge(mBeanServer, on, metric));
+        // verify that an attribute exists before attempting to add it
+        if (attributes.contains(metric)) {
+          metrics.put(metric, new JmxAttributeGauge(mBeanServer, on, metric));
+        }
       }
     } catch (JMException ignored) {
       log.debug(""Unable to load OperatingSystem MBean"", ignored);
     }
 
     return metrics;
   }
\ No newline at end of file
","SOLR-9805 Fix assertion error on Windows where SystemLoadAverage is reported as -1.
Don't expose non-existent attributes.
",Buggy
lucene-solr,28559.json,f55c8d1247fa9183f90bf222e827727ba0dee481,"@@ -1,11 +1,11 @@
     public DocsAndPositionsEnum reset(int[] postings, byte[] payloadBytes) {
       this.postings = postings;
       upto = 0;
       skipPositions = 0;
       startOffset = -1;
       endOffset = -1;
       docID = -1;
       payloadLength = 0;
-      payload.bytes = payloadBytes;
+      this.payloadBytes = payloadBytes;
       return this;
     }
\ No newline at end of file
","fix bugs in DirectPF's lowFreq d-and-p-enum, set payload.bytes/offset/length in getPayload, also skip payload pointer correctly when scanning over deleted docs in nextDoc

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1364070 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
lucene-solr,2958.json,785bebbcbd8f77ccc6d75acf3fb3d42ee29770fc,"@@ -1,4 +1,4 @@
     public String mapSafeElement(String name) {
       String lowerName = name.toLowerCase(Locale.ROOT);
-      return lowerName.equals(""br"") ? null : lowerName;
+      return (lowerName.equals(""br"") || lowerName.equals(""body"")) ? null : lowerName;
     }
\ No newline at end of file
","SOLR-8981 remove ""don't test with java-9"" commands; fix bug introduced by TIKA-995 -- doubling of body elements in HTML tags; add copyright info for Jackcess.
",Buggy
lucene-solr,21433.json,c0e5935900ef5f0c65b006f3071d2132143dda58,"@@ -1,24 +1,25 @@
   public void init(NamedList args) {
 
-    String patternParam = args.remove(PATTERN_PARAM).toString();
+    Object patternParam = args.remove(PATTERN_PARAM);
 
     if(patternParam == null) {
       throw new SolrException(ErrorCode.SERVER_ERROR, 
                               ""Missing required init parameter: "" + PATTERN_PARAM);
     }
+    
     try {
-      pattern = Pattern.compile(patternParam);      
+      pattern = Pattern.compile(patternParam.toString());      
     } catch (PatternSyntaxException e) {
       throw new SolrException(ErrorCode.SERVER_ERROR, 
                               ""Invalid regex: "" + patternParam, e);
     }                                
 
-    String replacementParam = args.remove(REPLACEMENT_PARAM).toString();
+    Object replacementParam = args.remove(REPLACEMENT_PARAM);
     if(replacementParam == null) {
       throw new SolrException(ErrorCode.SERVER_ERROR, 
                               ""Missing required init parameter: "" + REPLACEMENT_PARAM);
     }
-    replacement = Matcher.quoteReplacement(replacementParam);
+    replacement = Matcher.quoteReplacement(replacementParam.toString());
 
     super.init(args);
   }
\ No newline at end of file
","fix a small bug around these null checks

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1357983 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
lucene-solr,48864.json,cd5b023219a4e7cd060e88799581704d15820edf,"@@ -1,11 +1,11 @@
     void mergeAt(int i) {
       assert stackSize > i + 1;
       final int l = runBase(i+1);
       final int pivot = runBase(i);
       final int h = runEnd(i);
       merge(l, pivot, h, pivot - l, h - pivot);
-      for (int j = 1; j <= i+1; ++j) {
+      for (int j = i + 1; j > 0; --j) {
         setRunEnd(j, runEnd(j-1));
       }
       --stackSize;
     }
\ No newline at end of file
","LUCENE-4839: Fix bug in SorterTemplate.timSort().


git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1457315 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
lucene-solr,38904.json,008bc74bebef96414f19118a267dbf982aba58b9,"@@ -1,30 +1,30 @@
     void add(int startOffset, int endOffset) {
       assert enumIdx == -1 : ""bad state"";
 
       // loop backwards since we expect a match at the end or close to it.  We expect O(1) not O(N).
       int pairIdx = numPairs - 1;
       for (; pairIdx >= 0; pairIdx--) {
         int iStartOffset = startOffsets[pairIdx];
         int iEndOffset = endOffsets[pairIdx];
         int cmp = Integer.compare(iStartOffset, startOffset);
         if (cmp == 0) {
           cmp = Integer.compare(iEndOffset, endOffset);
         }
         if (cmp == 0) {
           return; // we already have this offset-pair for this term
         } else if (cmp < 0) {
           break; //we will insert offsetPair to the right of pairIdx
         }
       }
       // pairIdx is now one position to the left of where we insert the new pair
       // shift right any pairs by one to make room
       final int shiftLen = numPairs - (pairIdx + 1);
       if (shiftLen > 0) {
-        System.arraycopy(startOffsets, pairIdx + 2, startOffsets, pairIdx + 3, shiftLen);
-        System.arraycopy(endOffsets, pairIdx + 2, endOffsets, pairIdx + 3, shiftLen);
+        System.arraycopy(startOffsets, pairIdx + 1, startOffsets, pairIdx + 2, shiftLen);
+        System.arraycopy(endOffsets, pairIdx + 1, endOffsets, pairIdx + 2, shiftLen);
       }
       // now we can place the offset pair
       startOffsets[pairIdx + 1] = startOffset;
       endOffsets[pairIdx + 1] = endOffset;
       numPairs++;
     }
\ No newline at end of file
","LUCENE-8365: Fix ArrayIndexOutOfBoundsException in UnifiedHighlighter

This fixes a ""off by one"" error in the UnifiedHighlighter's code that
is only triggered when two nested SpanNearQueries contain the same term.

Signed-off-by: Simon Willnauer <simonw@apache.org>
Closes #408
",Buggy
lucene-solr,2699.json,bee8d7ccb32bc23bd808f729493631b60a64bffb,"@@ -1,18 +1,9 @@
   public Comparator<Expression> comparator(final FacetSortDirection direction) {
     return (a, b) -> {
-      boolean aIsNull = a.getValue() == null;
-      boolean bIsNull = b.getValue() == null;
-
-      if (aIsNull && bIsNull) return 0;
-
-      if( direction == FacetSortDirection.ASCENDING ){ // nulls are last for ASC sort
-        return aIsNull ? 1
-          : bIsNull ? -1
-          : a.getValue().compareTo(b.getValue());
+      if( direction == FacetSortDirection.ASCENDING ){
+        return a.getValue().compareTo(b.getValue());
       } else {
-        return aIsNull ? -1
-          : bIsNull ? 1
-          : b.getValue().compareTo(a.getValue());
+        return b.getValue().compareTo(a.getValue());
       }
     };
   }
\ No newline at end of file
","Revert ""SOLR-9981: Performance improvements and bug fixes for the Analytics component""

This reverts commit a5dce163eb09dcc0eb7f7eb81d692bf3d19964a3.
",Buggy
lucene-solr,2699.json,a5dce163eb09dcc0eb7f7eb81d692bf3d19964a3,"@@ -1,9 +1,18 @@
   public Comparator<Expression> comparator(final FacetSortDirection direction) {
     return (a, b) -> {
-      if( direction == FacetSortDirection.ASCENDING ){
-        return a.getValue().compareTo(b.getValue());
+      boolean aIsNull = a.getValue() == null;
+      boolean bIsNull = b.getValue() == null;
+
+      if (aIsNull && bIsNull) return 0;
+
+      if( direction == FacetSortDirection.ASCENDING ){ // nulls are last for ASC sort
+        return aIsNull ? 1
+          : bIsNull ? -1
+          : a.getValue().compareTo(b.getValue());
       } else {
-        return b.getValue().compareTo(a.getValue());
+        return aIsNull ? -1
+          : bIsNull ? 1
+          : b.getValue().compareTo(a.getValue());
       }
     };
   }
\ No newline at end of file
","SOLR-9981: Performance improvements and bug fixes for the Analytics component
",Buggy
lucene-solr,5640.json,6e4924cbfc828506550fd27b0350e3f12c572746,"@@ -1,65 +1,65 @@
   private ResultSetValueSelector[] constructValueSelectors(ResultSetMetaData metadata) throws SQLException{
     ResultSetValueSelector[] valueSelectors = new ResultSetValueSelector[metadata.getColumnCount()];
     
     for(int columnIdx = 0; columnIdx < metadata.getColumnCount(); ++columnIdx){
       
       final int columnNumber = columnIdx + 1; // cause it starts at 1        
-      final String columnName = metadata.getColumnName(columnNumber);
+      final String columnName = metadata.getColumnLabel(columnNumber);
       String className = metadata.getColumnClassName(columnNumber);
       String typeName = metadata.getColumnTypeName(columnNumber);
             
       if(directSupportedTypes.contains(className)){
         valueSelectors[columnIdx] = new ResultSetValueSelector() {
           public Object selectValue(ResultSet resultSet) throws SQLException {
             Object obj = resultSet.getObject(columnNumber);
             if(resultSet.wasNull()){ return null; }
             return obj;
           }
           public String getColumnName() {
             return columnName;
           }
         };
       }
-      else if(Short.class.getName() == className){
+      else if(Short.class.getName().equals(className)) {
         valueSelectors[columnIdx] = new ResultSetValueSelector() {
           public Object selectValue(ResultSet resultSet) throws SQLException {
             Short obj = resultSet.getShort(columnNumber);
             if(resultSet.wasNull()){ return null; }
             return obj.longValue();
           }
           public String getColumnName() {
             return columnName;
           }
         };
       }
-      else if(Integer.class.getName() == className){
+      else if(Integer.class.getName().equals(className)) {
         valueSelectors[columnIdx] = new ResultSetValueSelector() {
           public Object selectValue(ResultSet resultSet) throws SQLException {
             Integer obj = resultSet.getInt(columnNumber);
             if(resultSet.wasNull()){ return null; }
             return obj.longValue();
           }
           public String getColumnName() {
             return columnName;
           }
         };
       }
-      else if(Float.class.getName() == className){
+      else if(Float.class.getName().equals(className)) {
         valueSelectors[columnIdx] = new ResultSetValueSelector() {
           public Object selectValue(ResultSet resultSet) throws SQLException {
             Float obj = resultSet.getFloat(columnNumber);
             if(resultSet.wasNull()){ return null; }
             return obj.doubleValue();
           }
           public String getColumnName() {
             return columnName;
           }
         };
       }
       else{
         throw new SQLException(String.format(Locale.ROOT, ""Unable to determine the valueSelector for column '%s' (col #%d) of java class '%s' and type '%s'"", columnName, columnNumber, className, typeName));
       }
     }
     
     return valueSelectors;
   }
\ No newline at end of file
","Update dependencies and fix minor errors
",Buggy
lucene-solr,26464.json,96150badce8234cac00a23c2d5da55545e0be958,"@@ -1,16 +1,24 @@
-  private int readInputToBuffer() throws IOException {
-    final int len = input.read(tmpBuffer);
-    if (len == -1) {
-      inputFinished = true;
-      return 0;
+  private void readInputToBuffer() throws IOException {
+    while (true) {
+      // CharacterUtils.fill is supplementary char aware
+      final boolean hasRemainingChars = CharacterUtils.fill(tmpBuffer, input);
+
+      assert tmpBuffer.getOffset() == 0;
+      inputBuffer.append(tmpBuffer.getBuffer(), 0, tmpBuffer.getLength());
+
+      if (hasRemainingChars == false) {
+        inputFinished = true;
+        break;
+      }
+
+      final int lastCodePoint = Character.codePointBefore(tmpBuffer.getBuffer(), tmpBuffer.getLength());
+      if (normalizer.isInert(lastCodePoint)) {
+        // we require an inert char so that we can normalize content before and
+        // after this character independently
+        break;
+      }
     }
-    inputBuffer.append(tmpBuffer, 0, len);
 
     // if checkedInputBoundary was at the end of a buffer, we need to check that char again
     checkedInputBoundary = Math.max(checkedInputBoundary - 1, 0);
-    // this loop depends on 'isInert' (changes under normalization) but looks only at characters.
-    // so we treat all surrogates as non-inert for simplicity
-    if (normalizer.isInert(tmpBuffer[len - 1]) && !Character.isSurrogate(tmpBuffer[len-1])) {
-      return len;
-    } else return len + readInputToBuffer();
   }
\ No newline at end of file
","LUCENE-7956: Fixed potential stack overflow error in ICUNormalizer2CharFilter.
",Buggy
lucene-solr,26464.json,63d67496cfae2cbe4611b294c18d285e89c8e254,"@@ -1,14 +1,16 @@
   private int readInputToBuffer() throws IOException {
     final int len = input.read(tmpBuffer);
     if (len == -1) {
       inputFinished = true;
       return 0;
     }
     inputBuffer.append(tmpBuffer, 0, len);
 
     // if checkedInputBoundary was at the end of a buffer, we need to check that char again
     checkedInputBoundary = Math.max(checkedInputBoundary - 1, 0);
-    if (normalizer.isInert(tmpBuffer[len - 1]) && !Character.isHighSurrogate(tmpBuffer[len-1])) {
+    // this loop depends on 'isInert' (changes under normalization) but looks only at characters.
+    // so we treat all surrogates as non-inert for simplicity
+    if (normalizer.isInert(tmpBuffer[len - 1]) && !Character.isSurrogate(tmpBuffer[len-1])) {
       return len;
     } else return len + readInputToBuffer();
   }
\ No newline at end of file
","fix bug in buffering logic of this charfilter

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1586473 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
lucene-solr,15099.json,07b37ff26becf214bae000dff08b9091d31327a8,"@@ -1,14 +1,12 @@
   private boolean predefinedPermissionAppliesToRequest(Permission predefinedPermission, AuthorizationContext context) {
-    if (context.getHandler() instanceof PermissionNameProvider) {
+    if (predefinedPermission.wellknownName == PermissionNameProvider.Name.ALL) {
+      return true; //'ALL' applies to everything!
+    } else if (! (context.getHandler() instanceof PermissionNameProvider)) {
+      return false; // We're not 'ALL', and the handler isn't associated with any other predefined permissions
+    } else {
       PermissionNameProvider handler = (PermissionNameProvider) context.getHandler();
       PermissionNameProvider.Name permissionName = handler.getPermissionName(context);
-      if (permissionName == null || !predefinedPermission.name.equals(permissionName.name)) {
-        return false;
-      }
-    } else {
-      //all is special. it can match any
-      if(predefinedPermission.wellknownName != PermissionNameProvider.Name.ALL) return false;
-    }
 
-    return true;
+      return permissionName != null && predefinedPermission.name.equals(permissionName.name);
+    }
   }
\ No newline at end of file
","SOLR-13355: Obey 'ALL' for handlers with other predefined perms

Prior to this commit, RuleBasedAuthorizationPlugin would check for the
predefined 'ALL' permission only when the endpoint being hit wasn't
associated with another predefined-permission.

This resulted in some very unintuitive behavior. For example, the
permission {name:all, role:admin} would correctly prevent a
role:foo user from accessing /admin/info/properties, but would allow
write access to /admin/authorization because of the SECURITY_EDIT
predefined perm associated with that endpoint.

This commit fixes this bug so that the 'all' permission is always
consulted whether or not the endpoint is associated with other predefined
permissions.
",Buggy
lucene-solr,14965.json,0857bb60d3bb5bd6d8d851ce2e01edd9bde310ea,"@@ -1,20 +1,21 @@
     public void refresh(SolrQueryRequest req, SolrQueryResponse rsp, PayloadObj<String> payload) {
       String p = payload.get();
       if (p == null) {
         payload.addError(""Package null"");
         return;
       }
       PackageLoader.Package pkg = coreContainer.getPackageLoader().getPackage(p);
       if (pkg == null) {
         payload.addError(""No such package: "" + p);
         return;
       }
-
+      //first refresh my own
+      packageLoader.notifyListeners(p);
       for (String s : coreContainer.getPackageStoreAPI().shuffledNodes()) {
         Utils.executeGET(coreContainer.getUpdateShardHandler().getDefaultHttpClient(),
             coreContainer.getZkController().zkStateReader.getBaseUrlForNodeName(s).replace(""/solr"", ""/api"") + ""/cluster/package?wt=javabin&omitHeader=true&refreshPackage="" + p,
             Utils.JAVABINCONSUMER);
       }
 
 
     }
\ No newline at end of file
","SOLR-13662, SOLR-13822: Fixing bug with refresh API, un-ignoring the test and new reference guide on Package Management
",Buggy
lucene-solr,19226.json,9e78be40c338005b75609a3b123778aea822bcf0,"@@ -1,7 +1,7 @@
   public void setNextReader(LeafReaderContext context) throws IOException {
-    if (globalDocValues instanceof MultiDocValues.MultiSortedDocValues) {
+    if (ordinalMap != null) {
       toGlobal = ordinalMap.getGlobalOrds(context.ord);
-      docValues = DocValues.getSorted(context.reader(), field);
     }
+    docValues = DocValues.getSorted(context.reader(), field);
     lastDocID = 0;
   }
\ No newline at end of file
","SOLR-11598: Fix bug while setting and resetting string doc-values while exporting documents
",Buggy
lucene-solr,38500.json,1d35bd0ea8beb635997c3cf131ded8ebe58d15a9,"@@ -1,9 +1,9 @@
   public void clearFieldsAfter(Calendar cal, int field) {
     int assertEra = -1;
     assert (assertEra = (((Calendar)cal.clone()).get(Calendar.ERA))) >= 0;//a trick to only get this if assert enabled
     //note: Calendar.ERA == 0;
-    for (int f = field+1; f <= Calendar.MILLISECOND; f++) {
+    for (int f = field + 1; f <= Calendar.MILLISECOND; f++) {
       cal.clear(f);
     }
-    assert ((Calendar)cal.clone()).get(Calendar.ERA) == assertEra : ""Calendar underflow"";
+    assert field + 1 == Calendar.ERA || ((Calendar)cal.clone()).get(Calendar.ERA) == assertEra : ""Calendar underflow"";
   }
\ No newline at end of file
","LUCENE-7278: DRPT: fix bug in assert statement
",Buggy
lucene-solr,13814.json,d7f397056bcb52564bf5cbffa96152aa74c0fa1f,"@@ -1,28 +1,29 @@
   public Query parse() throws SyntaxError {
     Query q = super.parse();
     if (!(q instanceof BooleanQuery)) {
       return q;
     }
     BooleanQuery obq = (BooleanQuery)q;
     Collection<Query> should = new ArrayList<Query>();
     Collection<BooleanClause> prohibOrReq = new ArrayList<BooleanClause>();
     BooleanQuery newq = new BooleanQuery();
 
     for (BooleanClause clause : obq.getClauses()) {
       if(clause.isProhibited() || clause.isRequired()) {
         prohibOrReq.add(clause);
       } else {
         BooleanQuery bq = new BooleanQuery();
         bq.add(clause);
         should.add(bq);
       }
     }
     if (should.size() > 0) {
       DisjunctionMaxQuery dmq = new DisjunctionMaxQuery(should, tie);
       newq.add(dmq, BooleanClause.Occur.SHOULD);
     }
     for(BooleanClause c : prohibOrReq) {
       newq.add(c);
     }
+    newq.setBoost(obq.getBoost());
     return newq;
   }
\ No newline at end of file
","SOLR-4785: Fixed bug with missing boost on toplevel query

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1486898 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
lucene-solr,20938.json,88eb9719fa0df2ed0477ec2bb9f20c8ab1644f85,"@@ -1,15 +1,15 @@
   private static boolean matchPath(String path, String name){
     List<String> pathSplit = StrUtils.splitSmart(path, '/');
     List<String> nameSplit = StrUtils.splitSmart(name, '/');
     for (int i = 0; i < nameSplit.size(); i++) {
       String s = nameSplit.get(i);
       String ps = pathSplit.size()>i ?  pathSplit.get(i) :null;
       if(ps == null) return false;
       if(s.equals(ps)) continue;
       if(""*"".equals(ps) && nameSplit.size()==i+1) return true;
       if(""**"".equals(ps)) return true;
       return false;
     }
-    return true;
+    return false;
 
   }
\ No newline at end of file
","SOLR-6365 bug fix matching wrong  name when it is a shorter prefix of path

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1649996 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
lucene-solr,46829.json,71c65184562499eba365d166fe3fabe0dbdc747b,"@@ -1,37 +1,37 @@
   public static final BinaryDocValues emptyBinary() {
     return new BinaryDocValues() {
       private int doc = -1;
       
       @Override
       public int advance(int target) {
         return doc = NO_MORE_DOCS;
       }
       
       @Override
       public boolean advanceExact(int target) throws IOException {
         doc = target;
-        return true;
+        return false;
       }
       
       @Override
       public int docID() {
         return doc;
       }
       
       @Override
       public int nextDoc() {
         return doc = NO_MORE_DOCS;
       }
       
       @Override
       public long cost() {
         return 0;
       }
 
       @Override
       public BytesRef binaryValue() {
         assert false;
         return null;
       }
     };
   }
\ No newline at end of file
","LUCENE-7462: Fix buggy advanceExact impl of empty binary doc values.
",Buggy
lucene-solr,21965.json,876573650b72adbf1ca005fe0f33607140c23841,"@@ -1,28 +1,28 @@
   public static SchemaField getAndCheckVersionField(IndexSchema schema) 
     throws SolrException {
-    final String errPrefix = VERSION_FIELD + ""field must exist in schema, using indexed=\""true\"" stored=\""true\"" and multiValued=\""false\"""";
+    final String errPrefix = VERSION_FIELD + "" field must exist in schema, using indexed=\""true\"" stored=\""true\"" and multiValued=\""false\"""";
     SchemaField sf = schema.getFieldOrNull(VERSION_FIELD);
 
     if (null == sf) {
       throw new SolrException
         (SolrException.ErrorCode.SERVER_ERROR, 
          errPrefix + "" ("" + VERSION_FIELD + "" does not exist)"");
     }
     if ( !sf.indexed() ) {
       throw new SolrException
         (SolrException.ErrorCode.SERVER_ERROR, 
          errPrefix + "" ("" + VERSION_FIELD + "" is not indexed"");
     }
     if ( !sf.stored() ) {
       throw new SolrException
         (SolrException.ErrorCode.SERVER_ERROR, 
          errPrefix + "" ("" + VERSION_FIELD + "" is not stored"");
     }
     if ( sf.multiValued() ) {
       throw new SolrException
         (SolrException.ErrorCode.SERVER_ERROR, 
          errPrefix + "" ("" + VERSION_FIELD + "" is multiValued"");
     }
     
     return sf;
   }
\ No newline at end of file
","SOLR-5259: Fix typo in error message when _version_ field is missing

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1525620 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
lucene-solr,17330.json,be813bd0aefcf480f854a05c7880494da5e8c8bf,"@@ -1,21 +1,45 @@
   public void validateRouteValue(AddUpdateCommand cmd) throws SolrException {
 
     final Instant docTimestamp =
         parseRouteKey(cmd.getSolrInputDocument().getFieldValue(getRouteField()));
 
     // FUTURE: maybe in some cases the user would want to ignore/warn instead?
     if (docTimestamp.isAfter(Instant.now().plusMillis(getMaxFutureMs()))) {
       throw new SolrException(BAD_REQUEST,
           ""The document's time routed key of "" + docTimestamp + "" is too far in the future given "" +
               ROUTER_MAX_FUTURE + ""="" + getMaxFutureMs());
     }
 
     // Although this is also checked later, we need to check it here too to handle the case in Dimensional Routed
     // aliases where one can legally have zero collections for a newly encountered category and thus the loop later
     // can't catch this.
-    Instant startTime = parseRouteKey(start);
+
+    // SOLR-13760 - we need to fix the date math to a specific instant when the first document arrives.
+    // If we don't do this DRA's with a time dimension have variable start times across the other dimensions
+    // and logic gets much to complicated, and depends too much on queries to zookeeper. This keeps life simpler.
+    // I have to admit I'm not terribly fond of the mutation during a validate method however.
+    Instant startTime;
+    try {
+      startTime = Instant.parse(start);
+    } catch (DateTimeParseException e) {
+      startTime = DateMathParser.parseMath(new Date(), start).toInstant();
+      SolrCore core = cmd.getReq().getCore();
+      ZkStateReader zkStateReader = core.getCoreContainer().getZkController().zkStateReader;
+      Aliases aliases = zkStateReader.getAliases();
+      Map<String, String> props = new HashMap<>(aliases.getCollectionAliasProperties(aliasName));
+      start = DateTimeFormatter.ISO_INSTANT.format(startTime);
+      props.put(ROUTER_START, start);
+
+      // This could race, but it only occurs when the alias is first used and the values produced
+      // should all be identical and who wins won't matter (baring cases of Date Math involving seconds,
+      // which is pretty far fetched). Putting this in a separate thread to ensure that any failed
+      // races don't cause documents to get rejected.
+      core.runAsync(() -> zkStateReader.aliasesManager.applyModificationAndExportToZk(
+          (a) -> aliases.cloneWithCollectionAliasProperties(aliasName, props)));
+
+    }
     if (docTimestamp.isBefore(startTime)) {
       throw new SolrException(BAD_REQUEST, ""The document couldn't be routed because "" + docTimestamp +
           "" is before the start time for this alias "" +start+"")"");
     }
   }
\ No newline at end of file
","SOLR-13760 - restore viability of date math in TRA start property (#879)

* SOLR-13760 - restore viability of date math in TRA start property by 
fixing the start date for time routed aliases
upon the receipt of the first document to avoid problems
with date math calculations required by DRA's
",Buggy
lucene-solr,11507.json,75e69c5198c02e6635eed274b03ea759ef1c4818,"@@ -1,19 +1,19 @@
     public void collect(int doc) throws IOException{
       int valuesDocID = leafOutcomeValue.docID();
       if (valuesDocID < doc) {
-        valuesDocID = leafOutcomeValue.advance(valuesDocID);
+        valuesDocID = leafOutcomeValue.advance(doc);
       }
       int outcome;
       if (valuesDocID == doc) {
         outcome = (int) leafOutcomeValue.longValue();
       } else {
         outcome = 0;
       }
 
       outcome = trainingParams.positiveLabel == outcome? 1 : 0;
       if (outcome == 1) {
         positiveDocsSet.set(context.docBase + doc);
       }
       docsSet.set(context.docBase+doc);
 
     }
\ No newline at end of file
","SOLR-9549: Fix bug in advancing docValues
",Buggy
lucene-solr,6041.json,e4d4e582a0049de34990fcff3df5fb220f14ee4b,"@@ -1,5 +1,13 @@
   public void open() throws IOException {
-    Map<String, List<Tuple>> lets = streamContext.getLets();
-    List<Tuple> tuples = lets.get(name);
-    tupleIterator = tuples.iterator();
+    Map<String, Object> lets = streamContext.getLets();
+    Object o = lets.get(name);
+    List l = null;
+    if(o instanceof List) {
+        l = (List)o;
+      if(l.get(0) instanceof Tuple) {
+        tupleIterator = l.iterator();
+      } else {
+        throw new IOException(""Get was not passed a list of tuples:""+o.getClass());
+      }
+    }
   }
\ No newline at end of file
","SOLR-10559: Fixed compilation error
",Buggy
lucene-solr,48392.json,05d62a357711d1e4e850a5d2fb7336bf0a7acf24,"@@ -1,7 +1,9 @@
   public static double haversinSortKey(double lat1, double lon1, double lat2, double lon2) {
     double x1 = lat1 * TO_RADIANS;
     double x2 = lat2 * TO_RADIANS;
     double h1 = 1 - cos(x1 - x2);
     double h2 = 1 - cos((lon1 - lon2) * TO_RADIANS);
-    return h1 + cos(x1) * cos(x2) * h2;
+    double h = h1 + cos(x1) * cos(x2) * h2;
+    // clobber crazy precision so subsequent rounding does not create ties.
+    return Double.longBitsToDouble(Double.doubleToRawLongBits(h) & 0xFFFFFFFFFFFFFFF8L);
   }
\ No newline at end of file
","LUCENE-7185: fix tie-breaker sort bug
",Buggy
lucene-solr,50327.json,97a5295f075d37b1a31c5e77e85f7a9934cae096,"@@ -1,5 +1,5 @@
   public double getLongitude() {
     if (Math.abs(x) < MINIMUM_RESOLUTION && Math.abs(y) < MINIMUM_RESOLUTION)
       return 0.0;
-    return Math.atan2(y,z);
+    return Math.atan2(y,x);
   }
\ No newline at end of file
","LUCENE-6487: Geo3D with WGS84 patch from Karl: fix bug in GeoPoint.getLongitude with test
from https://reviews.apache.org/r/34744/diff/raw/

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/branches/lucene6487@1682357 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
lucene-solr,22328.json,942750c33fc97c7f021c4831b61cb617f5cccf24,"@@ -1,69 +1,69 @@
     private long readWord(final int position) {
         if(position < 0) {
             throw new ArrayIndexOutOfBoundsException(position);
         }
 
         // First bit of the word
-        final long firstBitIndex = (position * wordLength);
+        final long firstBitIndex = ((long)position) * ((long)wordLength);
         final int firstByteIndex = (bytePadding + (int)(firstBitIndex / BITS_PER_BYTE));
         final int firstByteSkipBits = (int)(firstBitIndex % BITS_PER_BYTE);
 
         // Last bit of the word
         final long lastBitIndex = (firstBitIndex + wordLength - 1);
         final int lastByteIndex = (bytePadding + (int)(lastBitIndex / BITS_PER_BYTE));
         final int lastByteBitsToConsume;
 
         final int bitsAfterByteBoundary = (int)((lastBitIndex + 1) % BITS_PER_BYTE);
         // If the word terminates at the end of the last byte, consume the whole
         // last byte.
         if(bitsAfterByteBoundary == 0) {
             lastByteBitsToConsume = BITS_PER_BYTE;
         } else {
             // Otherwise, only consume what is necessary.
             lastByteBitsToConsume = bitsAfterByteBoundary;
         }
 
         if(lastByteIndex >= bytes.length) {
             throw new ArrayIndexOutOfBoundsException(""Word out of bounds of backing array."");
         }
 
         // Accumulator
         long value = 0;
 
         // --------------------------------------------------------------------
         // First byte
         final int bitsRemainingInFirstByte = (BITS_PER_BYTE - firstByteSkipBits);
         final int bitsToConsumeInFirstByte = Math.min(bitsRemainingInFirstByte, wordLength);
         long firstByte = (long)bytes[firstByteIndex];
 
         // Mask off the bits to skip in the first byte.
         final long firstByteMask = ((1L << bitsRemainingInFirstByte) - 1L);
         firstByte &= firstByteMask;
         // Right-align relevant bits of first byte.
         firstByte >>>= (bitsRemainingInFirstByte - bitsToConsumeInFirstByte);
 
         value |= firstByte;
 
         // If the first byte contains the whole word, short-circuit.
         if(firstByteIndex == lastByteIndex) {
             return value;
         }
 
         // --------------------------------------------------------------------
         // Middle bytes
         final int middleByteCount = (lastByteIndex - firstByteIndex - 1);
         for(int i=0; i<middleByteCount; i++) {
             final long middleByte = (bytes[firstByteIndex + i + 1] & BYTE_MASK);
             // Push middle byte onto accumulator.
             value <<= BITS_PER_BYTE;
             value |= middleByte;
         }
 
         // --------------------------------------------------------------------
         // Last byte
         long lastByte = (bytes[lastByteIndex] & BYTE_MASK);
         lastByte >>= (BITS_PER_BYTE - lastByteBitsToConsume);
         value <<= lastByteBitsToConsume;
         value |= lastByte;
         return value;
     }
\ No newline at end of file
","SOLR-7954: Fixed an integer overflow bug in the HyperLogLog code used by the 'cardinality' option of stats.field to prevent ArrayIndexOutOfBoundsException in a distributed search when a large precision is selected and a large number of values exist in each shard

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1697969 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
lucene-solr,21543.json,3c436362810e80ce036d8785eb03abbda2d10014,"@@ -1,42 +1,42 @@
   private static List<TypeMapping> parseTypeMappings(NamedList args) {
     List<TypeMapping> typeMappings = new ArrayList<TypeMapping>();
     List<Object> typeMappingsParams = args.getAll(TYPE_MAPPING_PARAM);
     for (Object typeMappingObj : typeMappingsParams) {
       if (null == typeMappingObj) {
         throw new SolrException(SERVER_ERROR, ""'"" + TYPE_MAPPING_PARAM + ""' init param cannot be null"");
       }
       if ( ! (typeMappingObj instanceof NamedList) ) {
         throw new SolrException(SERVER_ERROR, ""'"" + TYPE_MAPPING_PARAM + ""' init param must be a <lst>"");
       }
       NamedList typeMappingNamedList = (NamedList)typeMappingObj;
 
       Object fieldTypeObj = typeMappingNamedList.remove(FIELD_TYPE_PARAM);
       if (null == fieldTypeObj) {
         throw new SolrException(SERVER_ERROR,
             ""Each '"" + TYPE_MAPPING_PARAM + ""' <lst/> must contain a '"" + FIELD_TYPE_PARAM + ""' <str>"");
       }
       if ( ! (fieldTypeObj instanceof CharSequence)) {
         throw new SolrException(SERVER_ERROR, ""'"" + FIELD_TYPE_PARAM + ""' init param must be a <str>"");
       }
       if (null != typeMappingNamedList.get(FIELD_TYPE_PARAM)) {
         throw new SolrException(SERVER_ERROR,
-            ""Each '"" + TYPE_MAPPING_PARAM + ""' <lst/> must contain a '"" + FIELD_TYPE_PARAM + ""' <str>"");
+            ""Each '"" + TYPE_MAPPING_PARAM + ""' <lst/> may contain only one '"" + FIELD_TYPE_PARAM + ""' <str>"");
       }
       String fieldType = fieldTypeObj.toString();
 
       Collection<String> valueClasses
           = FieldMutatingUpdateProcessorFactory.oneOrMany(typeMappingNamedList, VALUE_CLASS_PARAM);
       if (valueClasses.isEmpty()) {
         throw new SolrException(SERVER_ERROR, 
             ""Each '"" + TYPE_MAPPING_PARAM + ""' <lst/> must contain at least one '"" + VALUE_CLASS_PARAM + ""' <str>"");
       }
       typeMappings.add(new TypeMapping(fieldType, valueClasses));
 
       if (0 != typeMappingNamedList.size()) {
         throw new SolrException(SERVER_ERROR, 
             ""Unexpected '"" + TYPE_MAPPING_PARAM + ""' init sub-param(s): '"" + typeMappingNamedList.toString() + ""'"");
       }
       args.remove(TYPE_MAPPING_PARAM);
     }
     return typeMappings;
   }
\ No newline at end of file
","SOLR-4894: fix error message

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1503275 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
lucene-solr,39255.json,33d18a0c599a5bc294f9503a6b8fa3e326f589a7,"@@ -1,114 +1,116 @@
   private void  setInternalDependencyProperties() {
     log(""Loading module dependencies from: "" + moduleDependenciesPropertiesFile, verboseLevel);
     Properties moduleDependencies = new Properties();
     try (InputStream inputStream = new FileInputStream(moduleDependenciesPropertiesFile);
          Reader reader = new InputStreamReader(inputStream, StandardCharsets.UTF_8)) {
       moduleDependencies.load(reader);
     } catch (FileNotFoundException e) {
       throw new BuildException(""Properties file does not exist: "" + moduleDependenciesPropertiesFile.getPath());
     } catch (IOException e) {
       throw new BuildException(""Exception reading properties file "" + moduleDependenciesPropertiesFile.getPath(), e);
     }
     Map<String,SortedSet<String>> testScopeDependencies = new HashMap<>();
     Map<String, String> testScopePropertyKeys = new HashMap<>();
     for (Map.Entry entry : moduleDependencies.entrySet()) {
       String newPropertyKey = (String)entry.getKey();
       StringBuilder newPropertyValue = new StringBuilder();
       String value = (String)entry.getValue();
       Matcher matcher = MODULE_DEPENDENCIES_COORDINATE_KEY_PATTERN.matcher(newPropertyKey);
       if ( ! matcher.matches()) {
         throw new BuildException(""Malformed module dependencies property key: '"" + newPropertyKey + ""'"");
       }
       String antProjectName = matcher.group(1);
       boolean isTest = null != matcher.group(2);
       String artifactName = antProjectToArtifactName(antProjectName);
       newPropertyKey = artifactName + (isTest ? "".internal.test"" : "".internal"") + "".dependencies""; // Add "".internal""
       if (isTest) {
         testScopePropertyKeys.put(artifactName, newPropertyKey);
       }
       if (null == value || value.isEmpty()) {
         allProperties.setProperty(newPropertyKey, """");
         Map<String,SortedSet<String>> scopedDependencies
             = isTest ? testScopeDependencies : internalCompileScopeDependencies;
         scopedDependencies.put(artifactName, new TreeSet<String>());
       } else {
         // Lucene analysis modules' build dirs do not include hyphens, but Solr contribs' build dirs do
         String origModuleDir = antProjectName.replace(""analyzers-"", ""analysis/"");
+        // Exclude the module's own build output, in addition to UNWANTED_INTERNAL_DEPENDENCIES
         Pattern unwantedInternalDependencies = Pattern.compile
-            (""(?:lucene/build/|solr/build/(?:contrib/)?)"" + origModuleDir + ""|"" + UNWANTED_INTERNAL_DEPENDENCIES);
+            (""(?:lucene/build/|solr/build/(?:contrib/)?)"" + origModuleDir + ""/"" // require dir separator 
+             + ""|"" + UNWANTED_INTERNAL_DEPENDENCIES);
         SortedSet<String> sortedDeps = new TreeSet<>();
         for (String dependency : value.split("","")) {
           matcher = SHARED_EXTERNAL_DEPENDENCIES_PATTERN.matcher(dependency);
           if (matcher.find()) {
             String otherArtifactName = matcher.group(1);
             boolean isTestScope = null != matcher.group(2) && matcher.group(2).length() > 0;
             otherArtifactName = otherArtifactName.replace('/', '-');
             otherArtifactName = otherArtifactName.replace(""lucene-analysis"", ""lucene-analyzers"");
             otherArtifactName = otherArtifactName.replace(""solr-contrib-solr-"", ""solr-"");
             otherArtifactName = otherArtifactName.replace(""solr-contrib-"", ""solr-"");
             if ( ! otherArtifactName.equals(artifactName)) {
               Map<String,Set<String>> sharedDeps
                   = isTest ? interModuleExternalTestScopeDependencies : interModuleExternalCompileScopeDependencies;
               Set<String> sharedSet = sharedDeps.get(artifactName);
               if (null == sharedSet) {
                 sharedSet = new HashSet<>();
                 sharedDeps.put(artifactName, sharedSet);
               }
               if (isTestScope) {
                 otherArtifactName += "":test"";
               }
               sharedSet.add(otherArtifactName);
             }
           }
           matcher = unwantedInternalDependencies.matcher(dependency);
           if (matcher.find()) {
             continue;  // skip external (/(test-)lib/), and non-jar and unwanted (self) internal deps
           }
           String artifactId = dependencyToArtifactId(newPropertyKey, dependency);
           String groupId = ""org.apache."" + artifactId.substring(0, artifactId.indexOf('-'));
           String coordinate = groupId + ':' + artifactId;
           sortedDeps.add(coordinate);
         }
         if (isTest) {  // Don't set test-scope properties until all compile-scope deps have been seen
           testScopeDependencies.put(artifactName, sortedDeps);
         } else {
           internalCompileScopeDependencies.put(artifactName, sortedDeps);
           for (String dependency : sortedDeps) {
             int splitPos = dependency.indexOf(':');
             String groupId = dependency.substring(0, splitPos);
             String artifactId = dependency.substring(splitPos + 1);
             appendDependencyXml(newPropertyValue, groupId, artifactId, ""    "", null, false, false, null, null);
           }
           if (newPropertyValue.length() > 0) {
             newPropertyValue.setLength(newPropertyValue.length() - 1); // drop trailing newline
           }
           allProperties.setProperty(newPropertyKey, newPropertyValue.toString());
         }
       }
     }
     // Now that all compile-scope dependencies have been seen, include only those test-scope
     // dependencies that are not also compile-scope dependencies.
     for (Map.Entry<String,SortedSet<String>> entry : testScopeDependencies.entrySet()) {
       String module = entry.getKey();
       SortedSet<String> testDeps = entry.getValue();
       SortedSet<String> compileDeps = internalCompileScopeDependencies.get(module);
       if (null == compileDeps) {
         throw new BuildException(""Can't find compile scope dependencies for module "" + module);
       }
       StringBuilder newPropertyValue = new StringBuilder();
       for (String dependency : testDeps) {
         // modules with separate compile-scope and test-scope POMs need their compile-scope deps
         // included in their test-scope deps.
         if (modulesWithSeparateCompileAndTestPOMs.contains(module) || ! compileDeps.contains(dependency)) {
           int splitPos = dependency.indexOf(':');
           String groupId = dependency.substring(0, splitPos);
           String artifactId = dependency.substring(splitPos + 1);
           appendDependencyXml(newPropertyValue, groupId, artifactId, ""    "", null, true, false, null, null);
         }
       }
       if (newPropertyValue.length() > 0) {
         newPropertyValue.setLength(newPropertyValue.length() - 1); // drop trailing newline
       }
       allProperties.setProperty(testScopePropertyKeys.get(module), newPropertyValue.toString());
     }
   }
\ No newline at end of file
","LUCENE-6607: Fix spatial3d module's Maven config - include dependency interpolation sites, make packaging jar instead of pom, don't skip deploy phase, etc.; and fix GetMavenDependenciesTask to exclude a module's build artifacts only if the build dir fully matches, rather than a prefix (this bug caused lucene-spatial's test dependency on the lucene-spatial3d jar to be left out of the generated POM, because lucene/build/spatial3d matched the regex for lucene-spatial's build output dir: 'lucene/build/spatial', i.e. with no dir separator)

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1690842 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
lucene-solr,46217.json,4cfc012bfa66d31b129495b258b5537663f37a10,"@@ -1,4 +1,7 @@
   public IndexWriterConfig setCodec(Codec codec) {
+    if (codec == null) {
+      throw new NullPointerException();
+    }
     this.codec = codec;
     return this;
   }
\ No newline at end of file
","fix test bug (and fix IWC to fail immediately if you do this)

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/branches/lucene4547@1439519 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
lucene-solr,49999.json,a14972d7ae2357ab7150909332a04c9a1a94474c,"@@ -1,3 +1,3 @@
     int docId() {
-      return doc > 1 ? NumericDocValues.NO_MORE_DOCS : doc;
+      return doc > 0 ? NumericDocValues.NO_MORE_DOCS : doc;
     }
\ No newline at end of file
","LUCENE-8055: MemoryIndex.MemoryDocValuesIterator returns 2 documents instead of 1

Fixes a bug if there is a DV field in the MemoryIndex the
`MemoryIndex.MemoryDocValuesIterator` will return 2 documents instead of 1.
",Buggy
lucene-solr,5155.json,ebd130b7e2720a4a5cfc3c542461f61932caadf0,"@@ -1,44 +1,54 @@
   public Tuple read() throws IOException {
 
     if(finished) {
       Map<String,Object> m = new HashMap<>();
       m.put(""EOF"", true);
       return new Tuple(m);
     } else {
       finished = true;
       Map<String, Object> values = new HashMap<>();
 
-      String plot= stringParams.get(""type"");
-      StreamEvaluator xvalues = evaluatorParams.get(""x"");
-      StreamEvaluator yvalues = evaluatorParams.get(""y"");
+      // add all string based params
+      // these could come from the context, or they will just be treated as straight strings
+      for(Entry<String,String> param : stringParams.entrySet()){
+        if(streamContext.getLets().containsKey(param.getValue())){
+          values.put(param.getKey(), streamContext.getLets().get(param.getValue()));
+        }
+        else{
+          values.put(param.getKey(), param.getValue());
+        }
+      }
 
-      List<Number> y = (List<Number>)yvalues.evaluateOverContext();
-      List<Number> x = null;
+      // add all evaluators
+      for(Entry<String,StreamEvaluator> param : evaluatorParams.entrySet()){
+        values.put(param.getKey(), param.getValue().evaluateOverContext());
+      }
 
-      if(xvalues == null) {
+      List<Number> y = (List<Number>)values.get(""y"");
+      List<Number> x = (List<Number>)values.get(""x"");
+
+      if(x == null) {
         //x is null so add a sequence
         x = new ArrayList();
         for(int i=0; i<y.size(); i++) {
           x.add(i+1);
         }
-      } else {
-        x = (List<Number>) xvalues.evaluateOverContext();
       }
 
       List<List<Number>> xy = new ArrayList();
       for(int i=0; i<x.size(); i++) {
         List<Number> pair = new ArrayList();
         pair.add(x.get(i));
         pair.add(y.get(i));
         xy.add(pair);
       }
 
-      values.put(""plot"", plot);
+      values.put(""plot"", values.get(""type""));
       values.put(""data"", xy);
 
       Tuple tup = new Tuple(values);
       tup.fieldLabels = fieldLabels;
       tup.fieldNames = fieldNames;
       return tup;
     }
   }
\ No newline at end of file
","SOLR-10802: Fix problem with variable assignment
",Buggy
lucene-solr,7768.json,e81dd4e870d2a9b27e1f4366e92daa6dba054da8,"@@ -1,5 +1,6 @@
     public boolean isNodeAlive(String node) {
-      if (zkClientClusterStateProvider != null && zkClientClusterStateProvider.getLiveNodes().contains(node))
-        return true;
+      if (zkClientClusterStateProvider != null) {
+        return zkClientClusterStateProvider.getLiveNodes().contains(node);
+      }
       return true;
     }
\ No newline at end of file
","SOLR-12977: fixed bug
",Buggy
lucene-solr,13947.json,9cfba4a728e38a7e6c59c60a377420abc769be46,"@@ -1,39 +1,45 @@
   public static QParser getParser(String qstr, String parserName, boolean allowLocalParams, SolrQueryRequest req) throws SyntaxError {
     // SolrParams localParams = QueryParsing.getLocalParams(qstr, req.getParams());
     if (parserName == null) {
       parserName = QParserPlugin.DEFAULT_QTYPE;//""lucene""
     }
     String stringIncludingLocalParams = qstr;
     ModifiableSolrParams localParams = null;
     SolrParams globalParams = req.getParams();
     boolean valFollowedParams = true;
     int localParamsEnd = -1;
 
     if (allowLocalParams && qstr != null && qstr.startsWith(QueryParsing.LOCALPARAM_START)) {
       localParams = new ModifiableSolrParams();
       localParamsEnd = QueryParsing.parseLocalParams(qstr, 0, localParams, globalParams);
 
       String val = localParams.get(QueryParsing.V);
       if (val != null) {
         // val was directly specified in localParams via v=<something> or v=$arg
         valFollowedParams = false;
         //TODO if remainder of query string after '}' is non-empty, then what? Throw error? Fall back to lucene QParser?
       } else {
         // use the remainder of the string as the value
         valFollowedParams = true;
         val = qstr.substring(localParamsEnd);
         localParams.set(QueryParsing.V, val);
       }
 
       parserName = localParams.get(QueryParsing.TYPE,parserName);
-      qstr = localParams.get(""v"");
+      qstr = localParams.get(QueryParsing.V);
     }
 
     QParserPlugin qplug = req.getCore().getQueryPlugin(parserName);
+    if (qplug == null) {
+      // there should a way to include parameter for which parsing failed
+      throw new SolrException(SolrException.ErrorCode.BAD_REQUEST,
+          ""invalid query parser '"" + parserName + (stringIncludingLocalParams == null?
+              ""'"": ""' for query '"" + stringIncludingLocalParams + ""'""));
+    }
     QParser parser =  qplug.createParser(qstr, localParams, req.getParams(), req);
 
     parser.stringIncludingLocalParams = stringIncludingLocalParams;
     parser.valFollowedParams = valFollowedParams;
     parser.localParamsEnd = localParamsEnd;
     return parser;
   }
\ No newline at end of file
","SOLR-13187: Fix NPE when invalid qParser is specified

* When non-existent qParser is specified return 400 error code
* SOLR-13197: Fix NPE when createQParser is called in StatsField
",Buggy
lucene-solr,47147.json,2d422a995af8132e3d39d5ef576216a3105c457a,"@@ -1,9 +1,14 @@
   public void close() throws IOException {
     try (final OutputStream o = os) {
       // We want to make sure that os.flush() was running before close:
       // BufferedOutputStream may ignore IOExceptions while flushing on close().
-      // TODO: this is no longer an issue in Java 8:
-      // http://hg.openjdk.java.net/jdk8/tl/jdk/rev/759aa847dcaf
-      o.flush();
+      // We keep this also in Java 8, although it claims to be fixed there,
+      // because there are more bugs around this! See:
+      // # https://bugs.openjdk.java.net/browse/JDK-7015589
+      // # https://bugs.openjdk.java.net/browse/JDK-8054565
+      if (!flushedOnClose) {
+        flushedOnClose = true; // set this BEFORE calling flush!
+        o.flush();
+      }
     }
   }
\ No newline at end of file
","LUCENE-6152: Fix double close bug in OutputStreamIndexOutput

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1648724 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
lucene-solr,5763.json,8dddd88d3054596b7afb536429b42792145fdffe,"@@ -1,51 +1,49 @@
   protected void constructStreams() throws IOException {
 
     try {
 
       ZkStateReader zkStateReader = cloudSolrClient.getZkStateReader();
       ClusterState clusterState = zkStateReader.getClusterState();
 
       //System.out.println(""Connected to zk an got cluster state."");
 
       Collection<Slice> slices = clusterState.getActiveSlices(this.collection);
 
       if(slices == null) {
-
-        String colLower = this.collection.toLowerCase(Locale.getDefault());
         //Try case insensitive match
         for(String col : clusterState.getCollections()) {
-          if(col.toLowerCase(Locale.getDefault()).equals(colLower)) {
+          if(col.equalsIgnoreCase(this.collection)) {
             slices = clusterState.getActiveSlices(col);
             break;
           }
         }
 
         if(slices == null) {
           throw new Exception(""Collection not found:"" + this.collection);
         }
       }
 
       params.put(""distrib"",""false""); // We are the aggregator.
 
       for(Slice slice : slices) {
         Collection<Replica> replicas = slice.getReplicas();
         List<Replica> shuffler = new ArrayList();
         for(Replica replica : replicas) {
           shuffler.add(replica);
         }
 
         Collections.shuffle(shuffler, new Random());
         Replica rep = shuffler.get(0);
         ZkCoreNodeProps zkProps = new ZkCoreNodeProps(rep);
         String url = zkProps.getCoreUrl();
         SolrStream solrStream = new SolrStream(url, params);
         if(streamContext != null) {
           solrStream.setStreamContext(streamContext);
         }
         solrStream.setFieldMappings(this.fieldMappings);
         solrStreams.add(solrStream);
       }
     } catch (Exception e) {
       throw new IOException(e);
     }
   }
\ No newline at end of file
","Fix more locale bugs in SQL handler ans streams
",Buggy
lucene-solr,21252.json,ad453aeeda705e120fb53ba5e8c607cb0a13d85d,"@@ -1,10 +1,10 @@
   private void ensureLog() {
     if (tlog == null) {
-      String newLogName = String.format(Locale.ENGLISH, ""%s.%019d"", TLOG_NAME, id);
+      String newLogName = String.format(Locale.ENGLISH, LOG_FILENAME_PATTERN, TLOG_NAME, id);
       try {
         tlog = new TransactionLog(new File(tlogDir, newLogName), globalStrings);
       } catch (IOException e) {
         throw new SolrException(SolrException.ErrorCode.SERVER_ERROR, ""Can't open new tlog!"", e);
       }
     }
   }
\ No newline at end of file
","SOLR-3206: fixed the test, will follow up with a root problem fix too.

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1297927 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
lucene-solr,23008.json,da832d4f3aa2e87cf1947ef4373977778ea6d2e0,"@@ -1,30 +1,30 @@
       public Map.Entry<String, String> next() {
         if (!hasNext()) {
           throw new NoSuchElementException();
         }
 
         if (headerValue == null || !headerValue.hasMoreElements()) {
           headerName = headerNameIt.nextElement();
           headerValue = request.getHeaders(headerName);
         }
 
         String key = headerName;
         String val = headerValue.nextElement();
 
-        return new Map.Entry<>() {
+        return new Map.Entry<String, String>() {
           @Override
           public String getKey() {
             return key;
           }
 
           @Override
           public String getValue() {
             return val;
           }
 
           @Override
           public String setValue(String value) {
             throw new UnsupportedOperationException();
           }
         };
       }
\ No newline at end of file
","SOLR-13434: Fixes problem on Java 8 build
",Buggy
lucene-solr,22004.json,9374fcc6e91c841772fd6d26a7599abcd01dba38,"@@ -1,8 +1,8 @@
   public Query rewrite(IndexReader reader) throws IOException {
     Query rewritten = in.rewrite(reader);
     if (rewritten != in) {
-      return new DeleteByQueryWrapper(in, schema);
+      return new DeleteByQueryWrapper(rewritten, schema);
     } else {
       return this;
     }
   }
\ No newline at end of file
","LUCENE-5666: fix rewrite bug

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/branches/lucene5666@1594418 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
lucene-solr,12659.json,30de6c512ae51391159b28e0250a9482f12690c7,"@@ -1,23 +1,24 @@
   public LeafCollector getLeafCollector(AtomicReaderContext context) throws IOException {
     if (SortingMergePolicy.isSorted(context.reader(), sort)) {
       // segment is sorted, can early-terminate
       return new FilterLeafCollector(super.getLeafCollector(context)) {
+        private int numCollected;
 
         @Override
         public void collect(int doc) throws IOException {
           super.collect(doc);
           if (++numCollected >= numDocsToCollect) {
             throw new CollectionTerminatedException();
           }
         }
 
         @Override
         public boolean acceptsDocsOutOfOrder() {
           return false;
         }
 
       };
     } else {
       return super.getLeafCollector(context);
     }
   }
\ No newline at end of file
","LUCENE-5623: fix bug in earlyterminatingcollector, fix test to be reproducible and more evil

git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1588953 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
jna,352.json,af1ef9330f4ef7d4f3618d5c4edc8e49b2b4862a,"@@ -1,5 +1,5 @@
-    public static final String getPrivateProfileString(final String appName, final String keyName, final String defaultValue, final String fileName) {
+    public static final String getPrivateProfileString(final String lpAppName, final String lpKeyName, final String lpDefault, final String lpFileName) {
         final char buffer[] = new char[1024];
         Kernel32.INSTANCE.GetPrivateProfileString(appName, keyName, defaultValue, buffer, new DWORD(buffer.length), fileName);
         return Native.toString(buffer);
     }
\ No newline at end of file
","fix javadoc errors/warnings
",Buggy
jna,3664.json,fce337b823bcc6130313cd71740b053abf681368,"@@ -1,7 +1,7 @@
     public void read() {
         boolean returnWide = original instanceof WString[];
         for (int si=0;si < original.length;si++) {
             String s = getPointer(si * Pointer.SIZE).getString(0, wide);
-            original[si] = returnWide ? new WString(s) : s; 
+            original[si] = returnWide ? new WString(s) : (Object)s; 
         }
     }
\ No newline at end of file
","Fix 1.4 compile error

git-svn-id: https://svn.java.net/svn/jna~svn/trunk@294 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80
",Buggy
jna,3945.json,563931750bb0f5af89da6d55030bdfd4c8854906,"@@ -1,3 +1,3 @@
     public int hashCode() {
-        return callFlags + options.hashCode() + peer.hashCode();
+        return callFlags + options.hashCode() + super.hashCode();
     }
\ No newline at end of file
","fix compiler error

git-svn-id: https://svn.java.net/svn/jna~svn/trunk@1143 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80
",Buggy
jna,4035.json,40f00b1dcba4c24b37452d05cb3118bdbc1480f3,"@@ -1,29 +1,31 @@
     public void setValue(long value) {
         long truncated = value;
         switch (size) {
         case 1:
             truncated = (byte) value;
             this.value = new Byte((byte) value);
             break;
         case 2:
             truncated = (short) value;
             this.value = new Short((short) value);
             break;
         case 4:
             truncated = (int) value;
             this.value = new Integer((int) value);
             break;
         case 8:
             this.value = new Long(value);
             break;
         default:
             throw new IllegalArgumentException(""Unsupported size: "" + size);
         }
-        long mask = (-1L >> size * 8) << (size * 8);
-        if ((value < 0 && truncated != value)
-            || (value >= 0 && (mask & value) != 0)) {
-            throw new IllegalArgumentException(""Argument (0x""
-                + Long.toHexString(value) + "") exceeds native capacity (""
-                + size + "" bytes)"");
+        if (size < 8) {
+            long mask = ~((1L << (size*8)) - 1);
+            if ((value < 0 && truncated != value)
+                    || (value >= 0 && (mask & value) != 0)) {
+                throw new IllegalArgumentException(""Argument value 0x""
+                        + Long.toHexString(value) + "" exceeds native capacity (""
+                        + size + "" bytes) mask=0x"" + Long.toHexString(mask));
+            }
         }
     }
\ No newline at end of file
","Fix bug checking IntegerType limits

git-svn-id: https://svn.java.net/svn/jna~svn/trunk@391 2f8a963e-d2e4-e7d0-97bf-ccb7fcea9d80
",Buggy
spring-framework,28571.json,582864802e49f0cc47575be00194e4194d7b1dc5,"@@ -1,8 +1,11 @@
 	public ModelMap getModel() {
 		if (useDefaultModel()) {
 			return this.defaultModel;
 		}
 		else {
-			return (this.redirectModel != null) ? this.redirectModel : new ModelMap();
+			if (this.redirectModel == null) {
+				this.redirectModel = new ModelMap();
+			}
+			return this.redirectModel;
 		}
 	}
\ No newline at end of file
","Ensure RedirectModel is initialized

This commit fixes an old bug in ModelAndViewContainer where getModel
returns a new ModelMap instance that isn't saved and re-used.

Issue: SPR-14045
",Buggy
spring-framework,5833.json,ee95f171c8a934080421e802fa6868843af1c45f,"@@ -1,4 +1,4 @@
 	public PropertySources getAppliedPropertySources() throws IllegalStateException {
-		Assert.state(this.appliedPropertySources != null, ""PropertySources have not get been applied"");
+		Assert.state(this.appliedPropertySources != null, ""PropertySources have not yet been applied"");
 		return this.appliedPropertySources;
 	}
\ No newline at end of file
","Update PropertySourcesPlaceholderConfigurer.java

Fix the error message when PropertySources are not applied",Buggy
spring-framework,20130.json,7e799295e55f5e5984a1040a016169ea0883bc2d,"@@ -1,10 +1,10 @@
 	public HttpInputMessage beforeBodyRead(HttpInputMessage request, MethodParameter parameter,
-			Type targetType, Class<? extends HttpMessageConverter<?>> converterType) {
+			Type targetType, Class<? extends HttpMessageConverter<?>> converterType) throws IOException {
 
 		for (RequestBodyAdvice advice : getMatchingAdvice(parameter, RequestBodyAdvice.class)) {
 			if (advice.supports(parameter, targetType, converterType)) {
 				request = advice.beforeBodyRead(request, parameter, targetType, converterType);
 			}
 		}
 		return request;
 	}
\ No newline at end of file
","Fix compile error
",Buggy
spring-framework,24540.json,f084b632864685d8e65d0cdfa719a813824fc59f,"@@ -1,31 +1,36 @@
 	private static String decodeHeaderFieldParam(String input) {
 		Assert.notNull(input, ""Input String should not be null"");
 		int firstQuoteIndex = input.indexOf('\'');
 		int secondQuoteIndex = input.indexOf('\'', firstQuoteIndex + 1);
 		// US_ASCII
 		if (firstQuoteIndex == -1 || secondQuoteIndex == -1) {
 			return input;
 		}
 		Charset charset = Charset.forName(input.substring(0, firstQuoteIndex));
 		Assert.isTrue(UTF_8.equals(charset) || ISO_8859_1.equals(charset),
 				""Charset should be UTF-8 or ISO-8859-1"");
 		byte[] value = input.substring(secondQuoteIndex + 1, input.length()).getBytes(charset);
 		ByteArrayOutputStream bos = new ByteArrayOutputStream();
 		int index = 0;
 		while (index < value.length) {
 			byte b = value[index];
 			if (isRFC5987AttrChar(b)) {
 				bos.write((char) b);
 				index++;
 			}
-			else if (b == '%') {
-				char[] array = { (char)value[index + 1], (char)value[index + 2]};
-				bos.write(Integer.parseInt(String.valueOf(array), 16));
+			else if (b == '%' && index < value.length - 2) {
+				char[] array = new char[]{(char) value[index + 1], (char) value[index + 2]};
+				try {
+					bos.write(Integer.parseInt(String.valueOf(array), 16));
+				}
+				catch (NumberFormatException ex) {
+					throw new IllegalArgumentException(INVALID_HEADER_FIELD_PARAMETER_FORMAT, ex);
+				}
 				index+=3;
 			}
 			else {
-				throw new IllegalArgumentException(""Invalid header field parameter format (as defined in RFC 5987)"");
+				throw new IllegalArgumentException(INVALID_HEADER_FIELD_PARAMETER_FORMAT);
 			}
 		}
 		return new String(bos.toByteArray(), charset);
 	}
\ No newline at end of file
","Fix ""array index out of bounds"" problem reported by LGTM.com
",Buggy
sonarqube,18348.json,9b57d0b379935e053ef050b0379c65fc32810bc1,"@@ -1,3 +1,3 @@
   public boolean isEnabled() {
-    return getRule().isEnabled();
+    return getRule()!=null && getRule().isEnabled();
   }
\ No newline at end of file
","Fix bug on deprecated profiles
",Buggy
sonarqube,4866.json,56963334491068e70db0695c7fc36d9c40bfca9a,"@@ -1,6 +1,7 @@
   private void checkNoOtherMetricWithTargetKey(DbSession dbSession, MetricDto metricInDb, MetricDto template) {
-    MetricDto metricWithTargetKey = dbClient.metricDao().selectNullableByKey(dbSession, template.getKey());
+    String targetKey = template.getKey();
+    MetricDto metricWithTargetKey = dbClient.metricDao().selectNullableByKey(dbSession, targetKey);
     if (isMetricFoundInDb(metricWithTargetKey) && !metricInDb.getId().equals(metricWithTargetKey.getId())) {
-      throw new ServerException(HttpURLConnection.HTTP_CONFLICT, ""A me metric exists with the key: "" + metricInDb.getKey());
+      throw new ServerException(HttpURLConnection.HTTP_CONFLICT, String.format(""The key '%s' is already used by an existing metric."", targetKey));
     }
   }
\ No newline at end of file
","SONAR-6572 WS metrics/update fix error message when updating with an existing key
",Buggy
sonarqube,4786.json,7e1ea5d43a0fd5231baddfc22bc4c76209622968,"@@ -1,14 +1,12 @@
   public void define(WebService.NewController controller) {
     WebService.NewAction action = controller.createAction(""uninstall"")
       .setPost(true)
       .setDescription(""Uninstalls the plugin specified by its key."" +
         ""<br/>"" +
-        ""Plugin information is retrieved from Update Center."" +
-        ""<br/>"" +
-        ""Requires user to be authenticated with Administer System permissions"")
+        ""Requires user to be authenticated with Administer System permissions."")
       .setHandler(this);
 
     action.createParam(PARAM_KEY)
       .setDescription(""The key identifying the plugin to uninstall"")
       .setRequired(true);
   }
\ No newline at end of file
","SONAR-6380 fix error in action description
",Buggy
sonarqube,15877.json,51f8fa984e4a2c11ededba97e6b2c0a2fe29bb02,"@@ -1,8 +1,8 @@
   public String toString() {
     return Objects.toStringHelper(this)
       .add(""key"", qpKey)
       .add(""name"", qpName)
       .add(""language"", languageKey)
-      .add(""rulesUpdatedAt"", rulesUpdatedAt)
+      .add(""rulesUpdatedAt"", rulesUpdatedAt.getTime())
       .toString();
   }
\ No newline at end of file
","fix some coverage flaws
",Buggy
sonarqube,20277.json,5e5fc1731d0e99ab4a457fb9eeee121f342d1f33,"@@ -1,7 +1,7 @@
   static String[] getListFromProperty(Map<String, String> properties, String key) {
     String propValue = properties.get(key);
     if (propValue != null) {
-      return DefaultConfiguration.parseAsCsv(ProjectDefinition.SOURCES_PROPERTY, propValue);
+      return DefaultConfiguration.parseAsCsv(key, propValue);
     }
     return new String[0];
   }
\ No newline at end of file
","SONAR-10122 fix misleading error message for multivalue properties

when parsing fails in ProjectReactor
it concerns only sonar.sources, sonar.tests and sonar.modules
",Buggy
sonarqube,1092.json,e1ecfa7d65c33df5ee054e57e2b5d696da038154,"@@ -1,12 +1,10 @@
   public TokenQueue chunk(Reader reader) {
-    CodeReaderConfiguration codeReaderConfiguration = new CodeReaderConfiguration();
-    codeReaderConfiguration.setBufferCapacity(BUFFER_CAPACITY);
-    CodeReader code = new CodeReader(reader, codeReaderConfiguration);
+    CodeReader code = new CodeReader(reader);
     TokenQueue queue = new TokenQueue();
     try {
       channelDispatcher.consume(code, queue);
       return queue;
     } catch (Exception e) {
       throw new DuplicationsException(""Unable to lex source code at line : "" + code.getLinePosition() + "" and column : "" + code.getColumnPosition(), e);
     }
   }
\ No newline at end of file
","SONAR-2923 and SONAR-2632: Fixed some side-effect compilations error in other modules
",Buggy
voldemort,8473.json,a8fa1f7a2beb35aa81fc82167eb061901506d6ac,"@@ -1,21 +1,17 @@
     public static long copyLarge(Reader input, Writer output, long limit) throws IOException {
         char[] buffer = new char[DEFAULT_BUFFER_SIZE];
         long count = 0;
         int n = 0;
         long remaining = limit;
         while(remaining > 0) {
-            if(remaining > DEFAULT_BUFFER_SIZE) {
-                n = input.read(buffer);
-            } else {
-                char[] remainingbuffer = new char[(int) remaining];
-                n = input.read(remainingbuffer);
-            }
+            n = (remaining > DEFAULT_BUFFER_SIZE) ? input.read(buffer)
+                                                 : input.read(buffer, 0, (int) remaining);
             if(n == -1) {
                 break;
             }
             output.write(buffer, 0, n);
             count += n;
             remaining -= n;
         }
         return count;
     }
\ No newline at end of file
","fix bug in last read
",Buggy
voldemort,10824.json,6980fd513d4c6545813e2294f5ac10afaa3bcbb6,"@@ -1,26 +1,29 @@
     public HintedHandoffStrategy updateHintedHandoffStrategy(StoreDefinition storeDef,
                                                              Cluster cluster) {
         if(HintedHandoffStrategyType.CONSISTENT_STRATEGY.toDisplay()
                                                         .compareTo(storeDef.getHintedHandoffStrategyType()
                                                                            .toDisplay()) == 0) {
             Integer hintPrefListSize = storeDef.getHintPrefListSize();
+
+            // Default value for hint pref list size = replication factor
             if(null == hintPrefListSize) {
-                if(cluster.getNumberOfNodes() > 6)
-                    hintPrefListSize = cluster.getNumberOfNodes() / 2;
+                if(cluster.getNumberOfNodes() == storeDef.getReplicationFactor())
+                    hintPrefListSize = storeDef.getReplicationFactor() - 1;
                 else
-                    hintPrefListSize = cluster.getNumberOfNodes();
+                    hintPrefListSize = storeDef.getReplicationFactor();
             }
+
             return new ConsistentHandoffStrategy(cluster,
                                                  hintPrefListSize,
                                                  enableZoneRouting,
                                                  clientZoneId);
         } else if(HintedHandoffStrategyType.TO_ALL_STRATEGY.toDisplay()
                                                            .compareTo(storeDef.getHintedHandoffStrategyType()
                                                                               .toDisplay()) == 0) {
             return new HandoffToAllStrategy(cluster, enableZoneRouting, clientZoneId);
         } else {
             throw new VoldemortException(""HintedHandoffStrategyType:""
                                          + storeDef.getHintedHandoffStrategyType()
                                          + "" not handled by "" + this.getClass());
         }
     }
\ No newline at end of file
","Fixed another bug in Consistent strategy + Updated stores.xml so as to get EndToEnd Test running
",Buggy
voldemort,9755.json,97bfa6751eba8afb13bfc801afa47d2b6bd9af1d,"@@ -1,3 +1,3 @@
     public double get99thWaitTimeMs() {
-        return this.histogramWaitMs.getQuantile(0.99);
+        return (double) (this.histogramWaitNs.getQuantile(0.99)) / Time.NS_PER_MS;
     }
\ No newline at end of file
","Fixed bug and verified monitoring feature of q99th wait time
",Buggy
voldemort,9005.json,c07b777533cdbdfe4042258dbf44f2d9d51e3bc0,"@@ -1,286 +1,283 @@
     public void run() {
         Object message = messageEvent.getMessage();
         if(message instanceof CoordinatorStoreClientRequest) {
             CoordinatorStoreClientRequest storeClientRequestObject = (CoordinatorStoreClientRequest) message;
             this.requestObject = storeClientRequestObject.getRequestObject();
             this.storeClient = storeClientRequestObject.getStoreClient();
 
             // This shouldn't ideally happen.
             if(this.requestObject != null) {
 
                 switch(requestObject.getOperationType()) {
                     case VoldemortOpCode.GET_METADATA_OP_CODE:
                         if(logger.isDebugEnabled()) {
                             logger.debug(""GET Metadata request received."");
                         }
 
                         try {
 
                             String queryStoreName = ByteUtils.getString(this.requestObject.getKey()
                                                                                           .get(),
                                                                         ""UTF-8"");
                             StoreDefinition storeDef = StoreDefinitionUtils.getStoreDefinitionWithName(this.coordinatorMetadata.getStoresDefs(),
                                                                                                        queryStoreName);
                             String serializerInfoXml = RestUtils.constructSerializerInfoXml(storeDef);
                             GetMetadataResponseSender metadataResponseSender = new GetMetadataResponseSender(messageEvent,
                                                                                                              serializerInfoXml.getBytes());
 
                             metadataResponseSender.sendResponse(this.coordinatorPerfStats,
                                                                 true,
                                                                 this.requestObject.getRequestOriginTimeInMs());
                             if(logger.isDebugEnabled()) {
                                 logger.debug(""GET Metadata successful !"");
                             }
                         } catch(Exception e) {
                             /*
                              * We might get InsufficientOperationalNodes
                              * exception due to a timeout, thus creating
                              * confusion in the root cause. Hence explicitly
                              * check for timeout.
                              */
                             if(System.currentTimeMillis() >= (this.requestObject.getRequestOriginTimeInMs() + this.requestObject.getRoutingTimeoutInMs())) {
                                 RestErrorHandler.writeErrorResponse(this.messageEvent,
                                                                     REQUEST_TIMEOUT,
                                                                     ""GET METADATA request timed out: ""
                                                                             + e.getMessage());
+                            } else {
+                                getErrorHandler.handleExceptions(messageEvent, e);
                             }
-
-                            getErrorHandler.handleExceptions(messageEvent, e);
                         }
                         break;
 
                     case VoldemortOpCode.GET_OP_CODE:
                         if(logger.isDebugEnabled()) {
                             logger.debug(""GET request received."");
                         }
 
                         try {
                             boolean keyExists = false;
                             List<Versioned<byte[]>> versionedValues = this.storeClient.getWithCustomTimeout(this.requestObject);
                             if(versionedValues == null || versionedValues.size() == 0) {
                                 if(this.requestObject.getValue() != null) {
                                     if(versionedValues == null) {
                                         versionedValues = new ArrayList<Versioned<byte[]>>();
                                     }
                                     versionedValues.add(this.requestObject.getValue());
                                     keyExists = true;
 
                                 }
                             } else {
                                 keyExists = true;
                             }
 
                             if(keyExists) {
                                 GetResponseSender responseConstructor = new GetResponseSender(messageEvent,
                                                                                               requestObject.getKey(),
                                                                                               versionedValues,
                                                                                               this.storeClient.getStoreName());
                                 responseConstructor.sendResponse(this.coordinatorPerfStats,
                                                                  true,
                                                                  this.requestObject.getRequestOriginTimeInMs());
                                 if(logger.isDebugEnabled()) {
                                     logger.debug(""GET successful !"");
                                 }
 
                             } else {
                                 RestErrorHandler.writeErrorResponse(this.messageEvent,
                                                                     NOT_FOUND,
                                                                     ""Requested Key does not exist"");
                             }
 
                         } catch(Exception e) {
                             /*
                              * We might get InsufficientOperationalNodes
                              * exception due to a timeout, thus creating
                              * confusion in the root cause. Hence explicitly
                              * check for timeout.
                              */
                             if(System.currentTimeMillis() >= (this.requestObject.getRequestOriginTimeInMs() + this.requestObject.getRoutingTimeoutInMs())) {
                                 RestErrorHandler.writeErrorResponse(this.messageEvent,
                                                                     REQUEST_TIMEOUT,
                                                                     ""GET request timed out: ""
                                                                             + e.getMessage());
+                            } else {
+                                getErrorHandler.handleExceptions(messageEvent, e);
                             }
-
-                            getErrorHandler.handleExceptions(messageEvent, e);
                         }
                         break;
 
                     case VoldemortOpCode.GET_ALL_OP_CODE:
                         if(logger.isDebugEnabled()) {
                             logger.debug(""GET ALL request received."");
                         }
 
                         try {
                             Map<ByteArray, List<Versioned<byte[]>>> versionedResponses = this.storeClient.getAllWithCustomTimeout(this.requestObject);
                             if(versionedResponses == null
                                || versionedResponses.values().size() == 0) {
                                 logger.error(""Error when doing getall. Keys do not exist."");
 
                                 RestErrorHandler.writeErrorResponse(this.messageEvent,
                                                                     NOT_FOUND,
                                                                     ""Error when doing getall. Keys do not exist."");
                             } else {
                                 GetAllResponseSender responseConstructor = new GetAllResponseSender(messageEvent,
                                                                                                     versionedResponses,
                                                                                                     this.storeClient.getStoreName());
                                 responseConstructor.sendResponse(this.coordinatorPerfStats,
                                                                  true,
                                                                  this.requestObject.getRequestOriginTimeInMs());
 
                                 if(logger.isDebugEnabled()) {
                                     logger.debug(""GET ALL successful !"");
                                 }
 
                             }
 
                         } catch(Exception e) {
                             /*
                              * We might get InsufficientOperationalNodes
                              * exception due to a timeout, thus creating
                              * confusion in the root cause. Hence explicitly
                              * check for timeout.
                              */
                             if(System.currentTimeMillis() >= (this.requestObject.getRequestOriginTimeInMs() + this.requestObject.getRoutingTimeoutInMs())) {
                                 RestErrorHandler.writeErrorResponse(this.messageEvent,
                                                                     REQUEST_TIMEOUT,
                                                                     ""GET ALL request timed out: ""
                                                                             + e.getMessage());
+                            } else {
+                                getErrorHandler.handleExceptions(messageEvent, e);
                             }
-
-                            getErrorHandler.handleExceptions(messageEvent, e);
                         }
                         break;
 
                     // TODO: Implement this in the next pass
                     case VoldemortOpCode.GET_VERSION_OP_CODE:
 
                         if(logger.isDebugEnabled()) {
                             logger.debug(""Incoming get version request"");
                         }
 
                         try {
 
                             if(logger.isDebugEnabled()) {
                                 logger.debug(""GET versions request successful !"");
                             }
 
                         } catch(Exception e) {
                             /*
                              * We might get InsufficientOperationalNodes
                              * exception due to a timeout, thus creating
                              * confusion in the root cause. Hence explicitly
                              * check for timeout.
                              */
                             if(System.currentTimeMillis() >= (this.requestObject.getRequestOriginTimeInMs() + this.requestObject.getRoutingTimeoutInMs())) {
                                 RestErrorHandler.writeErrorResponse(this.messageEvent,
                                                                     REQUEST_TIMEOUT,
                                                                     ""GET VERSION request timed out: ""
                                                                             + e.getMessage());
+                            } else {
+                                getVersionErrorHandler.handleExceptions(messageEvent, e);
                             }
-
-                            getVersionErrorHandler.handleExceptions(messageEvent, e);
                         }
                         break;
 
                     case VoldemortOpCode.PUT_OP_CODE:
                         if(logger.isDebugEnabled()) {
                             logger.debug(""PUT request received."");
                         }
 
                         try {
                             VectorClock successfulPutVC = null;
 
                             if(this.requestObject.getValue() != null) {
                                 successfulPutVC = ((VectorClock) this.storeClient.putVersionedWithCustomTimeout(this.requestObject)).clone();
                             } else {
                                 successfulPutVC = ((VectorClock) this.storeClient.putWithCustomTimeout(this.requestObject)).clone();
                             }
 
                             PutResponseSender responseConstructor = new PutResponseSender(messageEvent,
                                                                                           successfulPutVC,
                                                                                           this.storeClient.getStoreName(),
                                                                                           this.requestObject.getKey());
                             responseConstructor.sendResponse(this.coordinatorPerfStats,
                                                              true,
                                                              this.requestObject.getRequestOriginTimeInMs());
 
                             if(logger.isDebugEnabled()) {
                                 logger.debug(""PUT successful !"");
                             }
 
                         } catch(Exception e) {
                             /*
                              * We might get InsufficientOperationalNodes
                              * exception due to a timeout, thus creating
                              * confusion in the root cause. Hence explicitly
                              * check for timeout.
                              */
                             if(System.currentTimeMillis() >= (this.requestObject.getRequestOriginTimeInMs() + this.requestObject.getRoutingTimeoutInMs())) {
                                 RestErrorHandler.writeErrorResponse(this.messageEvent,
                                                                     REQUEST_TIMEOUT,
                                                                     ""PUT request timed out: ""
                                                                             + e.getMessage());
+                            } else {
+                                putErrorHandler.handleExceptions(messageEvent, e);
                             }
-
-                            putErrorHandler.handleExceptions(messageEvent, e);
                         }
 
                         break;
 
                     case VoldemortOpCode.DELETE_OP_CODE:
                         if(logger.isDebugEnabled()) {
                             logger.debug(""Incoming delete request"");
                         }
 
                         try {
                             boolean isDeleted = this.storeClient.deleteWithCustomTimeout(this.requestObject);
                             if(isDeleted) {
                                 DeleteResponseSender responseConstructor = new DeleteResponseSender(messageEvent,
                                                                                                     this.storeClient.getStoreName(),
                                                                                                     this.requestObject.getKey());
                                 responseConstructor.sendResponse(this.coordinatorPerfStats,
                                                                  true,
                                                                  this.requestObject.getRequestOriginTimeInMs());
 
                                 if(logger.isDebugEnabled()) {
                                     logger.debug(""DELETE request successful !"");
                                 }
 
                             } else {
                                 logger.error(""Requested Key with the specified version does not exist"");
                                 RestErrorHandler.writeErrorResponse(this.messageEvent,
                                                                     NOT_FOUND,
                                                                     ""Requested Key with the specified version does not exist"");
                             }
 
                         } catch(Exception e) {
 
                             /*
                              * We might get InsufficientOperationalNodes
                              * exception due to a timeout, thus creating
                              * confusion in the root cause. Hence explicitly
                              * check for timeout.
                              */
                             if(System.currentTimeMillis() >= (this.requestObject.getRequestOriginTimeInMs() + this.requestObject.getRoutingTimeoutInMs())) {
                                 RestErrorHandler.writeErrorResponse(this.messageEvent,
                                                                     REQUEST_TIMEOUT,
                                                                     ""DELETE request timed out: ""
                                                                             + e.getMessage());
+                            } else {
+                                deleteErrorHandler.handleExceptions(messageEvent, e);
                             }
-
-                            deleteErrorHandler.handleExceptions(messageEvent, e);
                         }
                         break;
 
                     default:
                         System.err.println(""Illegal operation."");
                         return;
-
                 }
 
             }
-
         }
-
     }
\ No newline at end of file
","fix duplicate error message bug and add large value size test for coordinator
",Buggy
voldemort,7694.json,d1b041d2e3ef3148bfcfae07d6e2609a5aa0ac45,"@@ -1,33 +1,33 @@
     public VAdminProto.UpdateMetadataPairResponse handleUpdateMetadataPair(VAdminProto.UpdateMetadataPairRequest request) {
         VAdminProto.UpdateMetadataPairResponse.Builder response = VAdminProto.UpdateMetadataPairResponse.newBuilder();
         try {
             ByteArray clusterKey = ProtoUtils.decodeBytes(request.getClusterKey());
             ByteArray storesKey = ProtoUtils.decodeBytes(request.getStoresKey());
             String clusterKeyString = ByteUtils.getString(clusterKey.get(), ""UTF-8"");
             String storesKeyString = ByteUtils.getString(storesKey.get(), ""UTF-8"");
 
             if(MetadataStore.METADATA_KEYS.contains(clusterKeyString)
                && MetadataStore.METADATA_KEYS.contains(storesKeyString)) {
 
                 Versioned<byte[]> clusterVersionedValue = ProtoUtils.decodeVersioned(request.getClusterValue());
                 Versioned<byte[]> storesVersionedValue = ProtoUtils.decodeVersioned(request.getStoresValue());
 
                 metadataStore.writeLock.lock();
                 try {
                     logger.info(""Updating metadata for keys '"" + clusterKeyString + ""'"" + "" and '""
                                 + storesKeyString + ""'"");
                     metadataStore.put(clusterKey, clusterVersionedValue, null);
-                    metadataStore.put(storesKey, storesVersionedValue, null);
+                    metadataStore.updateStoreDefinitions(storesVersionedValue);
                     logger.info(""Successfully updated metadata for keys '"" + clusterKeyString + ""'""
                                 + "" and '"" + storesKeyString + ""'"");
                 } finally {
                     metadataStore.writeLock.unlock();
                 }
             }
         } catch(VoldemortException e) {
             response.setError(ProtoUtils.encodeError(errorCodeMapper, e));
             logger.error(""handleUpdateMetadataPair failed for request("" + request.toString() + "")"",
                          e);
         }
         return response.build();
     }
\ No newline at end of file
","Bug fix in RebalanceRebootstrapConsistencyTest and AdminServiceRequestHandler. Adding wrapper for updateRemoteStoreDefList in AdminClient
",Buggy
voldemort,7656.json,1f057d7e3c68dc4d67387a5485ac6793d3feb8b7,"@@ -1,31 +1,33 @@
     public VAdminProto.RebalanceStateChangeResponse handleRebalanceStateChange(VAdminProto.RebalanceStateChangeRequest request) {
-
         VAdminProto.RebalanceStateChangeResponse.Builder response = VAdminProto.RebalanceStateChangeResponse.newBuilder();
 
-        try {
-            // Retrieve all values first
-            List<RebalancePartitionsInfo> rebalancePartitionsInfo = Lists.newArrayList();
-            for(RebalancePartitionInfoMap map: request.getRebalancePartitionInfoListList()) {
-                rebalancePartitionsInfo.add(ProtoUtils.decodeRebalancePartitionInfoMap(map));
+        synchronized(rebalancer) {
+            try {
+                // Retrieve all values first
+                List<RebalancePartitionsInfo> rebalancePartitionsInfo = Lists.newArrayList();
+                for(RebalancePartitionInfoMap map: request.getRebalancePartitionInfoListList()) {
+                    rebalancePartitionsInfo.add(ProtoUtils.decodeRebalancePartitionInfoMap(map));
+                }
+
+                Cluster cluster = new ClusterMapper().readCluster(new StringReader(request.getClusterString()));
+
+                boolean swapRO = request.getSwapRo();
+                boolean changeClusterMetadata = request.getChangeClusterMetadata();
+                boolean changeRebalanceState = request.getChangeRebalanceState();
+                boolean rollback = request.getRollback();
+
+                rebalancer.rebalanceStateChange(cluster,
+                                                rebalancePartitionsInfo,
+                                                swapRO,
+                                                changeClusterMetadata,
+                                                changeRebalanceState,
+                                                rollback);
+            } catch(VoldemortException e) {
+                response.setError(ProtoUtils.encodeError(errorCodeMapper, e));
+                logger.error(""handleRebalanceStateChange failed for request("" + request.toString()
+                             + "")"", e);
             }
-
-            Cluster cluster = new ClusterMapper().readCluster(new StringReader(request.getClusterString()));
-
-            boolean swapRO = request.getSwapRo();
-            boolean changeClusterMetadata = request.getChangeClusterMetadata();
-            boolean changeRebalanceState = request.getChangeRebalanceState();
-            boolean rollback = request.getRollback();
-
-            rebalancer.rebalanceStateChange(cluster,
-                                            rebalancePartitionsInfo,
-                                            swapRO,
-                                            changeClusterMetadata,
-                                            changeRebalanceState,
-                                            rollback);
-        } catch(VoldemortException e) {
-            response.setError(ProtoUtils.encodeError(errorCodeMapper, e));
-            logger.error(""handleRebalanceStateChange failed for request("" + request.toString()
-                         + "")"", e);
         }
+
         return response.build();
     }
\ No newline at end of file
","fix two concurrency bugs during the termination of donor-based rebalancing
",Buggy
voldemort,6967.json,9f2e07c6e18984df4d2428dd51accd37534e9a68,"@@ -1,11 +1,12 @@
     public void stop() {
         logger.info(""Stopping "" + getType().getDisplayName());
         synchronized(this) {
             if(!isStarted()) {
                 logger.info(""The service is already stopped, ignoring duplicate attempt."");
+                return;
             }
 
             stopInner();
             isStarted.set(false);
         }
     }
\ No newline at end of file
","Fixed the re-introduction of BindExceptions upon start up of some recently added tests:

All of the following tests directly used the method ServerTestUtils.startVoldemortServer
  test/unit/voldemort/client/ClientRegistryTest.java
  test/unit/voldemort/client/AdminFetchTest.java
  test/unit/voldemort/client/EndToEndRebootstrapTest.java
  test/unit/voldemort/store/system/AsyncMetadataVersionManagerTest.java
  test/unit/voldemort/store/system/SystemStoreTest.java

This method of starting Voldemort servers is susceptible to
BindException errors. Unless something very fancy is being done, the
method ServerTestUtils.startVoldemortCluster should be used to start a
cluster within a test.

test/unit/voldemort/client/ClientRegistryTest.java extended from
TestCase. This is a ""Junit3"" idiom that we should not use in new
tests. The Junit4 approach to tests relies solely on annotation.
",Buggy
voldemort,8213.json,46a5b4d7e916e3fe0a9a77659599d74709f18c2d,"@@ -1,55 +1,56 @@
     private void write(DataOutputStream output, Object object, Object type) throws IOException {
         try {
             if(type instanceof Map) {
                 if(object != null && !(object instanceof Map))
                     throw new SerializationException(""Expected Map, but got "" + object.getClass()
                                                      + "": "" + object);
                 writeMap(output, (Map<String, Object>) object, (Map<String, Object>) type);
             } else if(type instanceof List) {
                 if(object != null && !(object instanceof List))
                     throw new SerializationException(""Expected List but got "" + object.getClass()
                                                      + "": "" + object);
                 writeList(output, (List<Object>) object, (List<Object>) type);
             } else if(type instanceof JsonTypes) {
                 JsonTypes jsonType = (JsonTypes) type;
                 switch(jsonType) {
                     case STRING:
                         writeString(output, (String) object);
                         break;
                     case INT8:
                         writeInt8(output, (Byte) object);
                         break;
                     case INT16:
                         writeInt16(output, coerceToShort(object));
                         break;
                     case INT32:
                         writeInt32(output, coerceToInteger(object));
                         break;
                     case INT64:
                         writeInt64(output, coerceToLong(object));
                         break;
                     case FLOAT32:
                         writeFloat32(output, coerceToFloat(object));
                         break;
                     case FLOAT64:
                         writeFloat64(output, coerceToDouble(object));
                         break;
                     case DATE:
                         writeDate(output, coerceToDate(object));
                         break;
                     case BYTES:
                         writeBytes(output, (byte[]) object);
                         break;
                     case BOOLEAN:
                         writeBoolean(output, (Boolean) object);
+                        break;
                     default:
                         throw new SerializationException(""Unknown type: "" + type);
                 }
             }
         } catch(ClassCastException e) {
             // simpler than doing every test
             throw new SerializationException(""Expected type "" + type
                                              + "" but got object of incompatible type ""
                                              + object.getClass().getName() + ""."");
         }
     }
\ No newline at end of file
","Fix serialization bug with writing boolean values--missing break in case statement.
",Buggy
voldemort,9151.json,ff128a8ad5de83bc55b8cec80d7775e61816e4e6,"@@ -1,16 +1,21 @@
     public List<Versioned<T>> resolveConflicts(List<Versioned<T>> items) {
+        List<ClockEntry> maxClock = null;
         if(items.size() <= 1) {
             return items;
         } else {
             Versioned<T> max = items.get(0);
             long maxTime = ((VectorClock) items.get(0).getVersion()).getTimestamp();
+            maxClock = ((VectorClock) items.get(0).getVersion()).getEntries();
             for(Versioned<T> versioned: items) {
                 VectorClock clock = (VectorClock) versioned.getVersion();
                 if(clock.getTimestamp() > maxTime) {
                     max = versioned;
                     maxTime = ((VectorClock) versioned.getVersion()).getTimestamp();
                 }
+                maxClock = VectorClock.maxClockList(maxClock, clock.getEntries());
             }
-            return Collections.singletonList(max);
+            Versioned<T> maxTimeClockVersioned = new Versioned<T>(max.getValue(),
+                                                                  new VectorClock(maxClock, maxTime));
+            return Collections.singletonList(maxTimeClockVersioned);
         }
     }
\ No newline at end of file
","TimeBasedInconsistency resolover bug fix
",Buggy
voldemort,11028.json,c3773f409dffb3761aaeba6811d3ed6836263987,"@@ -1,15 +1,15 @@
     public static void validateUserStoreNamesOnNode(AdminClient adminClient,
                                                  Integer nodeId,
                                                  List<String> storeNames) {
         List<StoreDefinition> storeDefList = adminClient.metadataMgmtOps.getRemoteStoreDefList(nodeId)
                                                                         .getValue();
-        List<String> storeNameList = Lists.newArrayList();
+        Map<String, Boolean> existingStoreNames = new HashMap<String, Boolean>();
         for(StoreDefinition storeDef: storeDefList) {
-            storeNameList.add(storeDef.getName());
+          existingStoreNames.put(storeDef.getName(), true);
         }
         for(String storeName: storeNames) {
-            if(!storeNameList.contains(storeName)) {
+            if(!Boolean.TRUE.equals(existingStoreNames.get(storeName))) {
                 Utils.croak(""Store "" + storeName + "" does not exist!"");
             }
         }
     }
\ No newline at end of file
","Fix a vadmin error
",Buggy
voldemort,755.json,0548406c86c8ed3af48c0a59586f8dd03d3aefdd,"@@ -1,11 +1,10 @@
             public void nodeUnavailable(Node node) {
                 if(logger.isInfoEnabled())
-                    logger.info(""Node "" + node
-                                + "" has been marked as unavailable, destroying socket pool"");
+                    logger.info(node + "" has been marked as unavailable, destroying socket pool"");
 
                 // Kill the socket pool for this node...
                 SocketDestination destination = new SocketDestination(node.getHost(),
                                                                       node.getSocketPort(),
                                                                       config.getRequestFormatType());
                 socketPool.close(destination);
             }
\ No newline at end of file
","Fixed inconsistent error message.
",Buggy
voldemort,151.json,a36d1fe39e88e79875bef39bc0ce10419d8cbcf2,"@@ -1,8 +1,8 @@
-    private AdminClient createAdminClient(String url, boolean fetchAllStoresXml) {
+    private AdminClient createAdminClient(String url, boolean fetchAllStoresXml, int connectionTimeoutSec, int socketTimeoutSec) {
         ClientConfig config = new ClientConfig().setBootstrapUrls(url)
-                .setConnectionTimeout(15,TimeUnit.SECONDS)
+                .setConnectionTimeout(connectionTimeoutSec ,TimeUnit.SECONDS)
                 .setFetchAllStoresXmlInBootstrap(fetchAllStoresXml);
 
-        AdminClientConfig adminConfig = new AdminClientConfig().setAdminSocketTimeoutSec(60);
+        AdminClientConfig adminConfig = new AdminClientConfig().setAdminSocketTimeoutSec(socketTimeoutSec);
         return new AdminClient(adminConfig, config);
     }
\ No newline at end of file
","Made admin connection/socket timeout configurable in BnP.

Also changed the default socket timeout to 180 seconds.

This fixes the following problem: when a node is unreachable and
completely shut down, requests to it will time out, which takes
60 seconds. When BnP notices this, it will reach one of the live
nodes in the cluster and ask it to deal with the failure. The
live node will try to talk to the dead node, which will also
take 60 seconds to time out. By the time the live node decides
that the dead node is unreachable, and responds to the BnP job,
the BnP job will have already timed out. Then, the BnP job will
think that the HandleFailedFetchRequest could not complete
successfully (even though it did in fact complete successfully)
and BnP HA will be aborted.

The solution is that the BnP job's socket timeout must be greater
than the server's default connection timeout.

This was not an issue before when we had insanely long time outs,
but those time outs have been reduced considerably in commit
34debd34c5896b6c2a01b1012e89dd1a3a0a0242. This is likely when we
regressed on the handling of this failure mode.
",Buggy
voldemort,132.json,da4a1bf5015df49a9e8ba867a90d4dab7f0ba194,"@@ -1,29 +1,29 @@
-    public static void main(String[] args) {
+    public static void main(String[] args) throws Exception {
         // Validate arguments
         if (args.length < 1) {
             logger.error(""Please provide a job config file name as the argument to this script."");
             System.exit(1);
         }
         String fileName = args[0];
 
         // Load config
         logger.info(""Extracting config properties out of: "" + fileName);
         Props props = null;
         try {
             props = new Props(null, fileName);
         } catch (IOException e) {
             logger.error(""Exception while reading config file!"", e);
             System.exit(1);
         }
 
         // Run job
         VoldemortBuildAndPushJob job = new VoldemortBuildAndPushJob(""shell-job"", props);
         try {
             job.run();
         } catch (Exception e) {
             logger.error(""Exception while running BnP job!"", e);
             System.exit(1);
         }
         logger.info(""BnP job finished successfully (:"");
         System.exit(0);
     }
\ No newline at end of file
","Fixed a compilation error introduced by last commit. (#468)

",Buggy
voldemort,9849.json,41cf6a7204e1b9821833bf9f6022f61abd10f007,"@@ -1,17 +1,17 @@
     private VectorClock readVersion(String key) {
         try {
             File versionFile = new File(getVersionDirectory(), key);
             if(!versionFile.exists()) {
                 // bootstrap file save default clock as version.
-                VectorClock clock = new VectorClock();
+                VectorClock clock = new VectorClock(0);
                 writeVersion(key, clock);
                 return clock;
             } else {
                 // read the version file and return version.
                 String hexCode = FileUtils.readFileToString(versionFile, ""UTF-8"");
                 return new VectorClock(Hex.decodeHex(hexCode.toCharArray()));
             }
         } catch(Exception e) {
             throw new VoldemortException(""Failed to read Version for Key:"" + key, e);
         }
     }
\ No newline at end of file
","fixed a bug that throws exceptions for some tests
",Buggy
cassandra,15770.json,3740f815c21254bd625ad1cbe8d47aa657727a83,"@@ -1,26 +1,29 @@
     public boolean maybeWaitForArchiving(String name)
     {
         Future<?> f = archivePending.remove(name);
         if (f == null)
             return true; // archiving disabled
 
         try
         {
             f.get();
         }
         catch (InterruptedException e)
         {
             throw new AssertionError(e);
         }
         catch (ExecutionException e)
         {
-            if (e.getCause() instanceof IOException)
+            if (e.getCause() instanceof RuntimeException)
             {
-                logger.error(""Looks like the archiving of file {} failed earlier, cassandra is going to ignore this segment for now."", name);
-                return false;
+                if (e.getCause().getCause() instanceof IOException)
+                {
+                    logger.error(""Looks like the archiving of file {} failed earlier, cassandra is going to ignore this segment for now."", name, e.getCause().getCause());
+                    return false;
+                }
             }
             throw new RuntimeException(e);
         }
 
         return true;
     }
\ No newline at end of file
","Fix bugs in commit log archiving startup behavior

patch by Ariel Weisberg; reviewed by Branimir Lambov for CASSANDRA-10593
",Buggy
cassandra,5689.json,02030dd658e6ca0cdb8987fd72e0454066e1b6d6,"@@ -1,4 +1,7 @@
     public boolean contains(T position)
     {
-        return Range.contains(left, right, position) || left.equals(position);
+        // Range.contains doesnt work correctly if left == right because for
+        // Range that means a wrapping range that select the whole ring. So we
+        // must explicitely handle this case
+        return left.equals(position) || (!left.equals(right) && Range.contains(left, right, position));
     }
\ No newline at end of file
","Fix LCS bug with sstables containing only 1 row

patch by slebresne; reviewed by jbellis for CASSANDRA-4411
",Buggy
cassandra,13729.json,967a2cfe179548835d5e8c1640889420ce0d40ce,"@@ -1,13 +1,13 @@
     private void updateCrc()
     {
-        if (crcPosition == buffer.position() | crcUpdateDisabled)
+        if (crcPosition == buffer.position() || crcUpdateDisabled)
             return;
 
         assert crcPosition >= 0 && crcPosition < buffer.position();
 
         ByteBuffer unprocessed = buffer.duplicate();
         unprocessed.position(crcPosition)
                    .limit(buffer.position());
 
         crc.update(unprocessed);
     }
\ No newline at end of file
","8630: fixed coverity defects
",Buggy
cassandra,14898.json,50c1987265f8ddaf5032a7ace07b2462aba4f09b,"@@ -1,38 +1,38 @@
     static Set<List<String>> getCompactionBuckets(List<String> files, long min)
     {
-    	Map<List<String>, Long> buckets = new NonBlockingHashMap<List<String>, Long>();
+    	Map<List<String>, Long> buckets = new ConcurrentHashMap<List<String>, Long>();
     	for(String fname : files)
     	{
     		File f = new File(fname);
     		long size = f.length();
 
     		boolean bFound = false;
             // look for a bucket containing similar-sized files:
             // group in the same bucket if it's w/in 50% of the average for this bucket,
             // or this file and the bucket are all considered ""small"" (less than `min`)
             for (List<String> bucket : buckets.keySet())
     		{
                 long averageSize = buckets.get(bucket);
                 if ((size > averageSize/2 && size < 3*averageSize/2)
                     || ( size < min && averageSize < min))
     			{
                     // remove and re-add because adding changes the hash
                     buckets.remove(bucket);
     				averageSize = (averageSize + size) / 2 ;
                     bucket.add(fname);
                     buckets.put(bucket, averageSize);
     				bFound = true;
     				break;
     			}
     		}
             // no similar bucket found; put it in a new one
     		if(!bFound)
     		{
                 ArrayList<String> bucket = new ArrayList<String>();
                 bucket.add(fname);
                 buckets.put(bucket, size);
     		}
     	}
 
         return buckets.keySet();
     }
\ No newline at end of file
","fix getCompactionBuckets -- something is broken in NonBlockingHashMap when removing and re-adding the same collection mid-iteration; it ends up with multiple references to that collection.  going back to ConcurrentHashMap fixes the problem.  (any additional overhead from CHM is negligible here.)  patch by jbellis; reviewed by Eric Evans for #57

git-svn-id: https://svn.apache.org/repos/asf/incubator/cassandra/trunk@764004 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
cassandra,6678.json,7b083a4e083442cb6e6bf34735753c6103d88654,"@@ -1,8 +1,6 @@
     public static void rescheduleFailedTasks()
     {
-        for (SnapshotDeletingTask task : failedTasks)
-        {
-            failedTasks.remove(task);
+        Runnable task;
+        while ( null != (task = failedTasks.poll()))
             ScheduledExecutors.nonPeriodicTasks.submit(task);
-        }
     }
\ No newline at end of file
","Fix coverity errors with SSTableDeletingTask and SnapshotDeletingtask

Patch by jmckenzie; reviewed by stefania for CASSANDRA-10222
",Buggy
cassandra,9236.json,2a656e6bd5e1f5ac8161b65a211dd8bed74b7def,"@@ -1,10 +1,10 @@
     private MerkleTree getMerkleTree(Token t)
     {
         for (Range<Token> range : merkleTrees.keySet())
         {
             if (range.contains(t))
                 return merkleTrees.get(range);
         }
 
-        return null;
+        throw new AssertionError(""Expected tree for token "" + t);
     }
\ No newline at end of file
","Fixed coverity defects
Reviewed by Marcus Olsson for CASSANDRA-5220
",Buggy
cassandra,20480.json,6991556e431a51575744248a4c484270c4f918c9,"@@ -1,4 +1,4 @@
     public static void truncate()
     {
-        ALL.forEach(table -> getSchemaCFS(table).truncateBlocking());
+        ALL.reverse().forEach(table -> getSchemaCFS(table).truncateBlocking());
     }
\ No newline at end of file
","Fix startup problems due to schema tables not completely flushed

patch by Stefania Alborghetti; reviewed by Aleksey Yeschenko for CASSANDRA-12213.
",Buggy
cassandra,17609.json,0f977c597a6b70984de96bcc49474acdb12ad2ea,"@@ -1,24 +1,24 @@
     public int compare(Composite c1, Composite c2)
     {
         // This method assumes that simple composites never have an EOC != NONE. This assumption
         // stands in particular on the fact that a Composites.EMPTY never has a non-NONE EOC. If
         // this ever change, we'll need to update this.
 
         if (isByteOrderComparable)
         {
             // toByteBuffer is always cheap for simple types, and we keep virtual method calls to a minimum:
             // hasRemaining will always be inlined, as will most of the call-stack for BBU.compareUnsigned
             ByteBuffer b1 = c1.toByteBuffer();
             ByteBuffer b2 = c2.toByteBuffer();
             if (!b1.hasRemaining() || !b2.hasRemaining())
                 return b1.hasRemaining() ? 1 : (b2.hasRemaining() ? -1 : 0);
             return ByteBufferUtil.compareUnsigned(b1, b2);
         }
 
         boolean c1isEmpty = c1.isEmpty();
         boolean c2isEmpty = c2.isEmpty();
         if (c1isEmpty || c2isEmpty)
-            return c1isEmpty ? 1 : (c2isEmpty ? -1 : 0);
+            return !c1isEmpty ? 1 : (!c2isEmpty ? -1 : 0);
 
         return type.compare(c1.get(0), c2.get(0));
     }
\ No newline at end of file
","Fix CellName comparison bugs

Patch by tjake; reviewed by bes for CASSANDRA-7227
",Buggy
cassandra,16419.json,653dcc63e0f6b0c5b3c3592beb1e0dd3bc1ee0cf,"@@ -1,4 +1,4 @@
     public Long compose(ByteBuffer bytes)
     {
-        return ByteBufferUtil.toLong(bytes);
+        return CounterContext.instance().total(bytes);
     }
\ No newline at end of file
","fix merge problem with CHANGES.txt, use right call in AbstractCommutativeType.compose()

git-svn-id: https://svn.apache.org/repos/asf/cassandra/trunk@1082155 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
jgit,9755.json,d2600693bd5fb8bda20bae41467132668caa1e14,"@@ -1,34 +1,40 @@
 	private static RebaseTodoLine parseLine(byte[] buf, int tokenBegin,
 			int lineEnd) {
 		RebaseTodoLine.Action action = null;
 		AbbreviatedObjectId commit = null;
 
 		int nextSpace = RawParseUtils.next(buf, tokenBegin, ' ');
 		int tokenCount = 0;
-		while (tokenCount < 3 && nextSpace < lineEnd) {
+		while (tokenCount < 3 && nextSpace <= lineEnd) {
 			switch (tokenCount) {
 			case 0:
 				String actionToken = new String(buf, tokenBegin,
 						nextSpace - tokenBegin - 1, UTF_8);
 				tokenBegin = nextSpace;
 				action = RebaseTodoLine.Action.parse(actionToken);
 				if (action == null)
 					return null; // parsing failed
 				break;
 			case 1:
 				nextSpace = RawParseUtils.next(buf, tokenBegin, ' ');
-				String commitToken = new String(buf, tokenBegin,
-						nextSpace - tokenBegin - 1, UTF_8);
+				String commitToken;
+				if (nextSpace > lineEnd + 1) {
+					commitToken = new String(buf, tokenBegin,
+							lineEnd - tokenBegin + 1, UTF_8);
+				} else {
+					commitToken = new String(buf, tokenBegin,
+							nextSpace - tokenBegin - 1, UTF_8);
+				}
 				tokenBegin = nextSpace;
 				commit = AbbreviatedObjectId.fromString(commitToken);
 				break;
 			case 2:
 				return new RebaseTodoLine(action, commit,
 						RawParseUtils.decode(buf, tokenBegin, 1 + lineEnd));
 			}
 			tokenCount++;
 		}
 		if (tokenCount == 2)
 			return new RebaseTodoLine(action, commit, """"); //$NON-NLS-1$
 		return null;
 	}
\ No newline at end of file
","Fix off-by-one error in RebaseTodoFile when reading a todo file

Commit messages of length 1 were not read. 'lineEnd' is the offset
of the last character in the line before the terminating LF or CR-LF,
and 'nextSpace' is actually the offset of the character _after_ the
next space. With a one-character commit message, nextSpace == lineEnd.

The code also assumes the commit message to be optional, but actually
failed in that case because it read beyond the line ending. Fix that,
too.

Add a test case for reading a todo file.

Bug: 546245
Change-Id: I368d63615930ea2398a6230e756442fd88870654
Signed-off-by: Thomas Wolf <thomas.wolf@paranor.ch>",Buggy
jgit,9755.json,4feace2b9ecb90fe591c4317403f6d8e6309287e,"@@ -1,32 +1,34 @@
 	private static RebaseTodoLine parseLine(byte[] buf, int tokenBegin,
 			int lineEnd) {
 		RebaseTodoLine.Action action = null;
 		AbbreviatedObjectId commit = null;
 
 		int nextSpace = RawParseUtils.next(buf, tokenBegin, ' ');
 		int tokenCount = 0;
 		while (tokenCount < 3 && nextSpace < lineEnd) {
 			switch (tokenCount) {
 			case 0:
 				String actionToken = new String(buf, tokenBegin, nextSpace
 						- tokenBegin - 1);
 				tokenBegin = nextSpace;
 				action = RebaseTodoLine.Action.parse(actionToken);
 				if (action == null)
 					return null; // parsing failed
 				break;
 			case 1:
 				nextSpace = RawParseUtils.next(buf, tokenBegin, ' ');
 				String commitToken = new String(buf, tokenBegin, nextSpace
 						- tokenBegin - 1);
 				tokenBegin = nextSpace;
 				commit = AbbreviatedObjectId.fromString(commitToken);
 				break;
 			case 2:
 				return new RebaseTodoLine(action, commit, RawParseUtils.decode(
 						buf, tokenBegin, 1 + lineEnd));
 			}
 			tokenCount++;
 		}
+		if (tokenCount == 2)
+			return new RebaseTodoLine(action, commit, """"); //$NON-NLS-1$
 		return null;
 	}
\ No newline at end of file
","Fix parsing Rebase todo lines when commit message is missing

Bug: 422253
Change-Id: I9739b16c91d2df31a481360a712d3479a4eeee2e
Signed-off-by: Stefan Lay <stefan.lay@sap.com>",Buggy
jgit,168.json,846ef78a02edceb99940d7aa92dcd2462a85c602,"@@ -1,24 +1,24 @@
 	private RefTree rebuild(RefDatabase refdb) throws IOException {
 		RefTree tree = RefTree.newEmptyTree();
 		List<org.eclipse.jgit.internal.storage.reftree.Command> cmds
 			= new ArrayList<>();
 
 		Ref head = refdb.exactRef(HEAD);
 		if (head != null) {
 			cmds.add(new org.eclipse.jgit.internal.storage.reftree.Command(
 					null,
 					head));
 		}
 
 		for (Ref r : refdb.getRefs(RefDatabase.ALL).values()) {
-			if (r.getName().equals(txnCommitted)
+			if (r.getName().equals(txnCommitted) || r.getName().equals(HEAD)
 					|| r.getName().startsWith(txnNamespace)) {
 				continue;
 			}
 			cmds.add(new org.eclipse.jgit.internal.storage.reftree.Command(
 					null,
 					db.peel(r)));
 		}
 		tree.apply(cmds);
 		return tree;
 	}
\ No newline at end of file
","Fix RebuildRefTree trying to add HEAD twice to RefTree

14dfa70520 fixed the problem that HEAD wasn't added to the reftree when
rebuilding the reftree in an empty repository where HEAD isn't yet
resolvable. Since non-resolvable refs are filtered out by
RefDatabase.getRefs(ALL) we have to add HEAD to the reftree explicitly
in this special case.

This fix resulted in another bug: rebuilding the reftree in a repository
which has a resolvable HEAD failed with a DirCacheNameConflictException
in RefTree.apply(). If HEAD is resolvable RefDatabase.getRefs(ALL) does
not filter out HEAD. This results in two identical CREATE commands for
HEAD which RefTree.apply() refuses to execute.

Fix this by no longer creating a duplicate CREATE command for HEAD.

See: I46cbc2611b9ae683ef7319dc46af277925dfaee5
Change-Id: I58dd6bcdef88820aa7de29761d43e2edfa18fcbe
Signed-off-by: Matthias Sohn <matthias.sohn@sap.com>",Buggy
jgit,8367.json,ec97912762754ee88f1af5ed80e993c545778242,"@@ -1,26 +1,26 @@
 	public int match(final RawCharSequence rcs) {
 		final int needleLen = needle.length;
 		final byte first = needle[0];
 
 		final byte[] text = rcs.buffer;
 		int matchPos = rcs.startPtr;
 		final int maxPos = rcs.endPtr - needleLen;
 
-		OUTER: for (; matchPos < maxPos; matchPos++) {
+		OUTER: for (; matchPos <= maxPos; matchPos++) {
 			if (neq(first, text[matchPos])) {
-				while (++matchPos < maxPos && neq(first, text[matchPos])) {
+				while (++matchPos <= maxPos && neq(first, text[matchPos])) {
 					/* skip */
 				}
-				if (matchPos == maxPos)
+				if (matchPos > maxPos)
 					return -1;
 			}
 
-			int si = ++matchPos;
+			int si = matchPos + 1;
 			for (int j = 1; j < needleLen; j++, si++) {
 				if (neq(needle[j], text[si]))
 					continue OUTER;
 			}
-			return matchPos - 1;
+			return matchPos;
 		}
 		return -1;
 	}
\ No newline at end of file
","Fix multiple bugs in RawSubStringPattern used by MessageRevFilter

* Match at end of input was not handled correctly.
* When more than one character matched but not all, the next character
  was not considered as a match start (e.g. pattern ""abab"" didn't match
  input ""abaabab"").

Bug: 409144
Change-Id: Ia44682c618bfbb927f5567c194227421d222a160
Signed-off-by: Matthias Sohn <matthias.sohn@sap.com>",Buggy
jgit,6829.json,5e44bfa3ad462e1220426492c53606c6a643a970,"@@ -1,6 +1,10 @@
 	private boolean isNoNewlineAtEndOfFile(FileHeader fh) {
-		HunkHeader lastHunk = fh.getHunks().get(fh.getHunks().size() - 1);
+		List<? extends HunkHeader> hunks = fh.getHunks();
+		if (hunks == null || hunks.isEmpty()) {
+			return false;
+		}
+		HunkHeader lastHunk = hunks.get(hunks.size() - 1);
 		RawText lhrt = new RawText(lastHunk.getBuffer());
-		return lhrt.getString(lhrt.size() - 1).equals(
-				""\\ No newline at end of file""); //$NON-NLS-1$
+		return lhrt.getString(lhrt.size() - 1)
+				.equals(""\\ No newline at end of file""); //$NON-NLS-1$
 	}
\ No newline at end of file
","Fix ApplyCommand which doesn't work if patch adds empty file

Bug: 548219
Change-Id: Ibb32132a38e54508a24489322da58ddfd80a1d9a
Signed-off-by: Anton Khodos <khodosanton@gmail.com>
Signed-off-by: Matthias Sohn <matthias.sohn@sap.com>",Buggy
jgit,9865.json,3e2ec7e5e81a489a326d872aa0670119ff2c1152,"@@ -1,8 +1,8 @@
 	public int compareTo(LfsPointer o) {
 		int x = getOid().compareTo(o.getOid());
 		if (x != 0) {
 			return x;
 		}
 
-		return (int) (getSize() - o.getSize());
+		return Long.compare(getSize(), o.getSize());
 	}
\ No newline at end of file
","Fix BadComparable error flagged by error prone

Running recent error prone version complaining on that code:

LfsPointer.java:171: error: [BadComparable] Possible sign flip from
narrowing conversion
		return (int) (getSize() - o.getSize());
		       ^
    (see https://errorprone.info/bugpattern/BadComparable)
  Did you mean 'return Long.compare(getSize(), o.getSize());'?

Bug: 562756
Change-Id: I0522f1025319a9290c448a064fbafdb4b16d1d59
Signed-off-by: David Ostrovsky <david@ostrovsky.org>
",Buggy
jgit,7605.json,56ee8117802a672e80011ee07ea6b253a5b7d0a9,"@@ -1,13 +1,17 @@
 	public boolean isPathSuffix(final byte[] p, final int pLen) {
 		final AbstractTreeIterator t = currentHead;
 		final byte[] c = t.path;
 		final int cLen = t.pathLen;
-		int ci;
 
-		for (ci = 1; ci < cLen && ci < pLen; ci++) {
-			if (c[cLen-ci] != p[pLen-ci])
+		for (int i = 1; i <= pLen; i++) {
+			// Pattern longer than current path
+			if (i > cLen)
+				return false;
+			// Current path doesn't match pattern
+			if (c[cLen - i] != p[pLen - i])
 				return false;
 		}
 
+		// Whole pattern tested -> matches
 		return true;
 	}
\ No newline at end of file
","Fix bugs in TreeWalk#isPathSuffix used by PathSuffixFilter

* It didn't check the first character in the pattern due to a off-by-one
  error. Spotted by James Roper.
* It returned true even when pattern was longer than current path, e.g.
  it returned that "".txt"" is suffix of ""txt"".

Bug: 411999
Change-Id: I9fbcd68a11fb57cc49956b70c387a47271a0424f
Signed-off-by: Robin Stocker <robin@nibor.org>
",Buggy
jgit,7675.json,5b55498b16267102b021a47b3a7c0bdbfae63e71,"@@ -1,5 +1,3 @@
 	protected byte[] idSubmodule(final Entry e) {
-		if (repository == null)
-			return idSubmodule(getDirectory(), e);
-		return super.idSubmodule(e);
+		return idSubmodule(getDirectory(), e);
 	}
\ No newline at end of file
","Fix FileTreeIterator.idSubmodule(Entry)

FileTreeIterator was calling by mistake
WorkingTreeIterator.idSubmodule(Entry). Instead it should always compute
idSubmodule on its own.

Change-Id: Id1b988aded06939b1d7edd2671e34bf756896c0e
",Buggy
jgit,4217.json,e60b9e1879f8774e1afe07be4224605045f49eec,"@@ -1,8 +1,9 @@
 	private long getEffectiveRacyThreshold() {
 		long timestampResolution = fileStoreAttributeCache
 				.getFsTimestampResolution().toNanos();
 		long minRacyInterval = fileStoreAttributeCache.getMinimalRacyInterval()
 				.toNanos();
-		// add a 30% safety margin
-		return Math.max(timestampResolution, minRacyInterval) * 13 / 10;
+		long max = Math.max(timestampResolution, minRacyInterval);
+		// safety margin: factor 2.5 below 100ms otherwise 1.25
+		return max < 100_000_000L ? max * 5 / 2 : max * 5 / 4;
 	}
\ No newline at end of file
","FileSnapshot: fix bug with timestamp thresholding

Increase the safety factor to 2.5x for extra safety if max of measured
timestamp resolution and measured minimal racy threshold is < 100ms, use
1.25 otherwise since for large filesystem resolution values the
influence of finite resolution of the system clock should be negligible.

Before, not yet using the newly introduced minRacyThreshold measurement,
the threshold was 1.1x FS resolution, and we could issue the
following sequence of events,

  start
  create-file
  read-file (currentTime)
  end

which had the following timestamps:

  create-file 1564589081998
  start 1564589082002
  read 1564589082003
  end 1564589082004

In this case, the difference between create-file and read is 5ms,
which exceeded the 4ms FS resolution, even though the events together
took just 2ms of runtime.

Reproduce with:
  bazel test --runs_per_test=100 \
    //org.eclipse.jgit.test:org_eclipse_jgit_internal_storage_file_FileSnapshotTest

The file system timestamp resolution is 4ms in this case.

This code assumes that the kernel and the JVM use the same clock that
is synchronized with the file system clock. This seems plausible,
given the resolution of System.currentTimeMillis() and the latency for
a gettimeofday system call (typically ~1us), but it would be good to
justify this with specifications.

Also cover a source of flakiness: if the test runs under extreme load,
then we could have

  start
  create-file
  <long delay>
  read
  end

which would register as an unmodified file. Avoid this by skipping the
test if end-start is too big.

[msohn]:
- downported from master to stable-5.1
- skip test if resolution is below 10ms
- adjust safety factor to 1.25 for resolutions above 100ms

Change-Id: I87d2cf035e01c44b7ba8364c410a860aa8e312ef
Signed-off-by: Han-Wen Nienhuys <hanwen@google.com>
Signed-off-by: Matthias Sohn <matthias.sohn@sap.com>
",Buggy
jgit,5424.json,35b01dac4c81542b195169e3b7365c12a165232c,"@@ -1,45 +1,41 @@
 	public void fillTo(final int highMark) throws MissingObjectException,
 			IncorrectObjectTypeException, IOException {
 		if (walker == null || size > highMark)
 			return;
 
-		Generator p = walker.pending;
-		RevCommit c = p.next();
+		RevCommit c = walker.next();
 		if (c == null) {
-			walker.pending = EndGenerator.INSTANCE;
 			walker = null;
 			return;
 		}
 		enter(size, (E) c);
 		add((E) c);
-		p = walker.pending;
 
 		while (size <= highMark) {
 			int index = size;
 			Block s = contents;
 			while (index >> s.shift >= BLOCK_SIZE) {
 				s = new Block(s.shift + BLOCK_SHIFT);
 				s.contents[0] = contents;
 				contents = s;
 			}
 			while (s.shift > 0) {
 				final int i = index >> s.shift;
 				index -= i << s.shift;
 				if (s.contents[i] == null)
 					s.contents[i] = new Block(s.shift - BLOCK_SHIFT);
 				s = (Block) s.contents[i];
 			}
 
 			final Object[] dst = s.contents;
 			while (size <= highMark && index < BLOCK_SIZE) {
-				c = p.next();
+				c = walker.next();
 				if (c == null) {
-					walker.pending = EndGenerator.INSTANCE;
 					walker = null;
 					return;
 				}
 				enter(size++, (E) c);
 				dst[index++] = c;
 			}
 		}
 	}
\ No newline at end of file
","Fix RevCommitList to work with subclasses of RevWalk

Bug: 321502
Change-Id: Ic4bc49a0da90234271aea7c0a4e344a1c3620cfc
Signed-off-by: Matthias Sohn <matthias.sohn@sap.com>",Buggy
jgit,5825.json,b07db609089749ed49a7f0b1fb3841a8f74110c2,"@@ -1,13 +1,16 @@
 	static int count(String s, char c, boolean ignoreFirstLast) {
 		int start = 0;
 		int count = 0;
-		while (true) {
+		int length = s.length();
+		while (start < length) {
 			start = s.indexOf(c, start);
-			if (start == -1)
+			if (start == -1) {
 				break;
-			if (!ignoreFirstLast || (start != 0 && start != s.length()))
+			}
+			if (!ignoreFirstLast || (start != 0 && start != length - 1)) {
 				count++;
+			}
 			start++;
 		}
 		return count;
 	}
\ No newline at end of file
","Fix off-by-one error in Strings.count()

Change-Id: I0667b1624827d1cf0cc1b81f86c7bb44eafd68a7
Signed-off-by: Thomas Wolf <thomas.wolf@paranor.ch>",Buggy
jgit,6619.json,51a5cc7f1a1033664ee2fb760ed217b665b12b34,"@@ -1,6 +1,6 @@
 	private static int findForwardLine(IntList lines, int idx, int ptr) {
 		final int end = lines.size() - 2;
-		while (idx < end && lines.get(idx + 2) <= ptr)
+		while (idx < end && lines.get(idx + 2) < ptr)
 			idx++;
 		return idx;
 	}
\ No newline at end of file
","Fix diff when first text is the start of the other

The problem occurred when the first text ends in the middle
of the last line of the other text and the first text has no
end of line.

Bug: 344975
Change-Id: I1f0dd9f8062f2148a7c1341c9122202e082ad19d
Signed-off-by: Robin Rosenberg <robin.rosenberg@dewire.com>
",Buggy
jgit,6447.json,e0e52cb0110a908959f7df13c5e66bf911bad74f,"@@ -1,6 +1,6 @@
 	private boolean result(Candidate n) throws IOException {
 		n.beginResult(revPool);
 		outCandidate = n;
 		outRegion = n.regionList;
-		return true;
+		return outRegion != null;
 	}
\ No newline at end of file
","Fix NPE in BlameGenerator.getSourceStart()

Bug: 499543
Change-Id: I99f6ebb1c3ceea20e8ca093acbe824c9f0362d45
Signed-off-by: Matthias Sohn <matthias.sohn@sap.com>",Buggy
jgit,6994.json,0505657d6a7dd4575a64ddfb5c0928870fe5843b,"@@ -1,9 +1,9 @@
 	public CommitCommand setAll(boolean all) {
 		checkCallable();
-		if (!only.isEmpty())
+		if (all && !only.isEmpty())
 			throw new JGitInternalException(MessageFormat.format(
 					JGitText.get().illegalCombinationOfArguments, ""--all"", //$NON-NLS-1$
 					""--only"")); //$NON-NLS-1$
 		this.all = all;
 		return this;
 	}
\ No newline at end of file
","commit command: allow to specify path(s) argument(s)

This fixes the command below:

jgit commit a -m ""added file a""

which currently fails with:

org.eclipse.jgit.api.errors.JGitInternalException: The combination of
arguments --all and --only is not allowed

Bug: 484973
Change-Id: I37a4ccd68101a66520ef99110f7aa0cbdcc8beba
Signed-off-by: Andrey Loskutov <loskutov@gmx.de>
",Buggy
jgit,7416.json,e56d50a94bfe60663bd589da61e07b9461f2c5f7,"@@ -1,22 +1,22 @@
 	private static String composeSquashMessage(boolean isSquash,
 			RevCommit commitToPick, String currSquashMessage, int count) {
 		StringBuilder sb = new StringBuilder();
 		String ordinal = getOrdinal(count);
 		sb.setLength(0);
 		sb.append(""# This is a combination of "").append(count)
 				.append("" commits.\n"");
+		// Add the previous message without header (i.e first line)
+		sb.append(currSquashMessage.substring(currSquashMessage.indexOf(""\n"") + 1));
+		sb.append(""\n"");
 		if (isSquash) {
 			sb.append(""# This is the "").append(count).append(ordinal)
 					.append("" commit message:\n"");
 			sb.append(commitToPick.getFullMessage());
 		} else {
 			sb.append(""# The "").append(count).append(ordinal)
 					.append("" commit message will be skipped:\n# "");
 			sb.append(commitToPick.getFullMessage().replaceAll(""([\n\r])"",
 					""$1# ""));
 		}
-		// Add the previous message without header (i.e first line)
-		sb.append(""\n"");
-		sb.append(currSquashMessage.substring(currSquashMessage.indexOf(""\n"") + 1));
 		return sb.toString();
 	}
\ No newline at end of file
","Interactive rebase: Fix order of commit messages on squash

Bug: 431214
Change-Id: I295bfdc5751545b046d7fe7efc3f8b39ab4f5415
Signed-off-by: Stefan Lay <stefan.lay@sap.com>
Signed-off-by: Robin Rosennberg <robin.rosenberg@dewire.com>
",Buggy
jgit,7416.json,8339a07e8314d6a40e15252bcc736a46c0aca0ea,"@@ -1,22 +1,22 @@
 	private static String composeSquashMessage(boolean isSquash,
 			RevCommit commitToPick, String currSquashMessage, int count) {
 		StringBuilder sb = new StringBuilder();
 		String ordinal = getOrdinal(count);
 		sb.setLength(0);
 		sb.append(""# This is a combination of "").append(count)
 				.append("" commits.\n"");
 		if (isSquash) {
 			sb.append(""# This is the "").append(count).append(ordinal)
 					.append("" commit message:\n"");
 			sb.append(commitToPick.getFullMessage());
 		} else {
 			sb.append(""# The "").append(count).append(ordinal)
 					.append("" commit message will be skipped:\n# "");
-			sb.append(commitToPick.getFullMessage().replaceAll(""([\n\r]+)"",
+			sb.append(commitToPick.getFullMessage().replaceAll(""([\n\r])"",
 					""$1# ""));
 		}
 		// Add the previous message without header (i.e first line)
 		sb.append(""\n"");
 		sb.append(currSquashMessage.substring(currSquashMessage.indexOf(""\n"") + 1));
 		return sb.toString();
 	}
\ No newline at end of file
","Fix FIXUP error for blank lines in interactive rebase

Empty lines of discarded commit messages were added to the commit
message because they were not commented out properly.

Bug: 422246
Change-Id: I263e8a6b30a3392d8b4f09c0695505068a0a485d
Signed-off-by: Stefan Lay <stefan.lay@sap.com>",Buggy
jgit,9377.json,325cb35ccd6108eaf9e6c3ec6343ca6988f10a21,"@@ -1,6 +1,8 @@
 	private ObjectId idFor(int objType, byte[] raw) {
 		if (skipList != null) {
-			return new ObjectInserter.Formatter().idFor(objType, raw);
+			try (ObjectInserter.Formatter fmt = new ObjectInserter.Formatter()) {
+				return fmt.idFor(objType, raw);
+			}
 		}
 		return null;
 	}
\ No newline at end of file
","[infer] Fix resource leak in ObjectChecker

Bug: 509385
Change-Id: I6b6ff5b721d959eb0708003a40c8f97d6826ac46
Signed-off-by: Matthias Sohn <matthias.sohn@sap.com>",Buggy
weka,20283.json,8215c432375cb2ff1bbda2825426fa0535b77834,"@@ -1,25 +1,13 @@
-  public EventSetDescriptor [] getEventSetDescriptors() {
+  public EventSetDescriptor[] getEventSetDescriptors() {
     try {
-      EventSetDescriptor [] esds = 
-      { new EventSetDescriptor(DataSource.class, 
-                               ""dataSet"", 
-                               DataSourceListener.class, 
-                               ""acceptDataSet""),
-        new EventSetDescriptor(DataSource.class, 
-                               ""instance"", 
-                               InstanceListener.class, 
-                               ""acceptInstance""),
-        new EventSetDescriptor(TrainingSetProducer.class, 
-                               ""trainingSet"", 
-                               TrainingSetListener.class, 
-                               ""acceptTrainingSet""),
-        new EventSetDescriptor(TestSetProducer.class, 
-                               ""testSet"", 
-                               TestSetListener.class, 
-                               ""acceptTestSet"")  };
+      EventSetDescriptor[] esds = {
+        new EventSetDescriptor(DataSource.class, ""dataSet"",
+          DataSourceListener.class, ""acceptDataSet""),
+        new EventSetDescriptor(DataSource.class, ""instance"",
+          InstanceListener.class, ""acceptInstance""), };
       return esds;
     } catch (Exception ex) {
       ex.printStackTrace();
     }
     return null;
   }
\ No newline at end of file
","Fixed a bug in the specification of event types produced by Appender and in the routine that determines whether a particular event type can be generated at a given point in time.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@10150 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,26539.json,88c70a2f184a0b7b2d27a48ebc04083d0d800049,"@@ -1,3 +1,6 @@
   public static List<String> getAllMetricNames() {
-    return Evaluation.getAllEvaluationMetricNames();
+    List<String> metrics = getBuiltInMetricNames();
+    metrics.addAll(getPluginMetricNames());
+
+    return metrics;
   }
\ No newline at end of file
","Fixed a bug in the getAllMetricNames() method.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@10919 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,20282.json,289721c0795b80e42b2664ffaa47dfab08f7ceac,"@@ -1,6 +1,7 @@
   private String statusMessagePrefix() {
     return getCustomName() + ""$"" + hashCode() + ""|""
-    + ((m_Filter instanceof OptionHandler) 
+    + ((m_Filter instanceof OptionHandler &&
+        Utils.joinOptions(((OptionHandler)m_Filter).getOptions()).length() > 0) 
         ? Utils.joinOptions(((OptionHandler)m_Filter).getOptions()) + ""|""
             : """");
   }
\ No newline at end of file
","Fixed a minor status logging bug.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@4797 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,19858.json,06022e54131102f3817c490551c2babc818ef2e2,"@@ -1,47 +1,49 @@
   protected void newFlow() {
     m_newFlowBut.setEnabled(false);
 
     String user = m_viewer.getUser();
     String password = m_viewer.getPassword();
     String uRL = m_viewer.getURL();
     String query = m_viewer.getQuery();
 
     if (query == null) {
       query = """";
     }
 
     try {
       DatabaseLoader dbl = new DatabaseLoader();
       dbl.setUser(user);
       dbl.setPassword(password);
       dbl.setUrl(uRL);
       dbl.setQuery(query);
 
       BeanContextSupport bc = new BeanContextSupport();
       bc.setDesignTime(true);
 
       Loader loaderComp = new Loader();
       bc.add(loaderComp);
       loaderComp.setLoader(dbl);
 
       KnowledgeFlowApp singleton = KnowledgeFlowApp.getSingleton();
       m_mainPerspective.addTab(""DBSource"");
-      /*
-       * BeanInstance beanI = new
-       * BeanInstance(m_mainPerspective.getBeanLayout(m_mainPerspective
-       * .getNumTabs() - 1), loaderComp, 50, 50, m_mainPerspective.getNumTabs()
-       * - 1);
-       */
-      Vector<Object> beans = BeanInstance.getBeanInstances(m_mainPerspective
-        .getNumTabs() - 1);
-      Vector<BeanConnection> connections = BeanConnection
-        .getConnections(m_mainPerspective.getNumTabs() - 1);
-      singleton.integrateFlow(beans, connections, true, false);
+
+      // The process of creating a BeanInstance integrates will result
+      // in it integrating itself into the flow in the specified tab
+      new BeanInstance(m_mainPerspective.getBeanLayout(m_mainPerspective
+        .getNumTabs() - 1), loaderComp, 50, 50,
+        m_mainPerspective.getNumTabs()
+        - 1);
+
+      // Vector<Object> beans = BeanInstance.getBeanInstances(m_mainPerspective
+      // .getNumTabs() - 1);
+      // Vector<BeanConnection> connections = BeanConnection
+      // .getConnections(m_mainPerspective.getNumTabs() - 1);
+      // singleton.integrateFlow(beans, connections, true, false);
       singleton.setActivePerspective(0); // switch back to the main perspective
 
       m_newFlowBut.setEnabled(true);
 
     } catch (Exception ex) {
       ex.printStackTrace();
     }
   }
\ No newline at end of file
","Fixed a bug where the code that creates the DatabaseLoader component when the new flow button is pressed got accidently commented out.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@11286 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,5643.json,a6289b3f0cf2a2301bce6c1a9f33e7f522996b43,"@@ -1,24 +1,28 @@
   protected Instance mergeInstances(Instance source, Instance dest) {
 
     Instances outputFormat = outputFormatPeek();
     double[] vals = new double[outputFormat.numAttributes()];
     for(int i = 0; i < vals.length; i++) {
       if ((i != outputFormat.classIndex()) && (m_SelectedCols.isInRange(i))) {
         if (source != null) {
           vals[i] = source.value(i);
         } else {
           vals[i] = Utils.missingValue();
         }
       } else {
         vals[i] = dest.value(i);
       }
     }
     Instance inst = null;
     if (dest instanceof SparseInstance) {
       inst = new SparseInstance(dest.weight(), vals);
     } else {
       inst = new DenseInstance(dest.weight(), vals);
     }
-    inst.setDataset(dest.dataset());
+    // inst.setDataset(dest.dataset());
+    // push() sets the dataset to the output format, however, if
+    // a preview transformation is being done then push() does not
+    // get called, so set the output format correctly here.
+    inst.setDataset(outputFormat);
     return inst;
   }
\ No newline at end of file
","Fixed a bug that affected the structure (dataset) assigned to a transformed instance when doing a preview transformation

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@13412 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,31430.json,ac9fe6291a2243cdf039b445dd9190343c4c6d51,"@@ -1,18 +1,13 @@
   public final Matrix transpose() {
 
     int nr = m_Elements.length, nc = m_Elements[0].length;
-    Matrix b;
-    try {
-      b = (Matrix)clone();
-    } catch (CloneNotSupportedException ex) {
-      b = new Matrix(nr, nc);
-    }
+    Matrix b = new Matrix(nc, nr);
 
     for(int i = 0;i < nc; i++) {
       for(int j = 0; j < nr; j++) {
 	b.m_Elements[i][j] = m_Elements[j][i];
       }
     }
 
     return b;
   }
\ No newline at end of file
","Fixed the matrix transpose problem introduced with last checkin.


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@773 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,30779.json,a24ded419dad69fad9e5bdfca523043e633de4a1,"@@ -1,32 +1,34 @@
     public Instance nextElement(Instances dataset) {
       Instance	result;
       
       result = null;
       
       if (isIncremental()) {
 	// is there still an instance in the buffer?
 	if (m_IncrementalBuffer != null) {
 	  result              = m_IncrementalBuffer;
 	  m_IncrementalBuffer = null;
 	}
 	else {
 	  try {
 	    result = m_Loader.getNextInstance(dataset);
 	  }
 	  catch (Exception e) {
 	    e.printStackTrace();
 	    result = null;
 	  }
 	}
       }
       else {
 	if (m_BatchCounter < m_BatchBuffer.numInstances()) {
 	  result = m_BatchBuffer.instance(m_BatchCounter);
 	  m_BatchCounter++;
 	}
       }
 
-      result.setDataset(dataset);
+      if (result != null) {
+        result.setDataset(dataset);
+      }
       
       return result;
     }
\ No newline at end of file
","Fixed a bug where a null pointer could get dereferenced in the nextElement() method of DataSource.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@6417 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,14864.json,8ed966e4e1e65cf3ca1691aac3767c74ad03ae50,"@@ -1,214 +1,211 @@
   public int[] search (ASEvaluation ASEval, Instances data)
     throws Exception {
     m_totalEvals = 0;
     if (!(ASEval instanceof SubsetEvaluator)) {
       throw  new Exception(ASEval.getClass().getName() 
 			   + "" is not a "" 
 			   + ""Subset evaluator!"");
     }
 
     if (ASEval instanceof UnsupervisedSubsetEvaluator) {
       m_hasClass = false;
-    }
-    else {
+    } else {
       m_hasClass = true;
       m_classIndex = data.classIndex();
     }
 
     SubsetEvaluator ASEvaluator = (SubsetEvaluator)ASEval;
     m_numAttribs = data.numAttributes();
     int i, j;
     int best_size = 0;
     int size = 0;
     int done;
     int sd = m_searchDirection;
     BitSet best_group, temp_group;
     int stale;
     double best_merit;
     double merit;
     boolean z;
     boolean added;
     Link2 tl;
     Hashtable lookup = new Hashtable(m_cacheSize * m_numAttribs);
     int insertCount = 0;
     int cacheHits = 0;
     LinkedList2 bfList = new LinkedList2(m_maxStale);
     best_merit = -Double.MAX_VALUE;
     stale = 0;
     best_group = new BitSet(m_numAttribs);
 
     m_startRange.setUpper(m_numAttribs-1);
     if (!(getStartSet().equals(""""))) {
       m_starting = m_startRange.getSelection();
     }
     // If a starting subset has been supplied, then initialise the bitset
     if (m_starting != null) {
       for (i = 0; i < m_starting.length; i++) {
 	if ((m_starting[i]) != m_classIndex) {
 	  best_group.set(m_starting[i]);
 	}
       }
 
       best_size = m_starting.length;
       m_totalEvals++;
-    }
-    else {
+    } else {
       if (m_searchDirection == SELECTION_BACKWARD) {
 	setStartSet(""1-last"");
 	m_starting = new int[m_numAttribs];
 
 	// init initial subset to all attributes
 	for (i = 0, j = 0; i < m_numAttribs; i++) {
 	  if (i != m_classIndex) {
 	    best_group.set(i);
 	    m_starting[j++] = i;
 	  }
 	}
 
 	best_size = m_numAttribs - 1;
 	m_totalEvals++;
       }
     }
 
     // evaluate the initial subset
     best_merit = ASEvaluator.evaluateSubset(best_group);
     // add the initial group to the list and the hash table
     Object [] best = new Object[1];
     best[0] = best_group.clone();
     bfList.addToList(best, best_merit);
     BitSet tt = (BitSet)best_group.clone();
     String hashC = tt.toString();
-    lookup.put(hashC, """");
+    lookup.put(hashC, new Double(best_merit));
 
     while (stale < m_maxStale) {
       added = false;
 
       if (m_searchDirection == SELECTION_BIDIRECTIONAL) {
 	// bi-directional search
-	  done = 2;
-	  sd = SELECTION_FORWARD;
-	}
-      else {
+        done = 2;
+        sd = SELECTION_FORWARD;
+      } else {
 	done = 1;
       }
 
       // finished search?
       if (bfList.size() == 0) {
 	stale = m_maxStale;
 	break;
       }
 
       // copy the attribute set at the head of the list
       tl = bfList.getLinkAt(0);
       temp_group = (BitSet)(tl.getData()[0]);
       temp_group = (BitSet)temp_group.clone();
       // remove the head of the list
       bfList.removeLinkAt(0);
       // count the number of bits set (attributes)
       int kk;
 
       for (kk = 0, size = 0; kk < m_numAttribs; kk++) {
 	if (temp_group.get(kk)) {
 	  size++;
 	}
       }
 
       do {
 	for (i = 0; i < m_numAttribs; i++) {
 	  if (sd == SELECTION_FORWARD) {
 	    z = ((i != m_classIndex) && (!temp_group.get(i)));
-	  }
-	  else {
+	  } else {
 	    z = ((i != m_classIndex) && (temp_group.get(i)));
 	  }
-
+          
 	  if (z) {
 	    // set the bit (attribute to add/delete)
 	    if (sd == SELECTION_FORWARD) {
 	      temp_group.set(i);
 	      size++;
-	    }
-	    else {
+	    } else {
 	      temp_group.clear(i);
 	      size--;
 	    }
 
 	    /* if this subset has been seen before, then it is already 
 	       in the list (or has been fully expanded) */
 	    tt = (BitSet)temp_group.clone();
 	    hashC = tt.toString();
+	    
 	    if (lookup.containsKey(hashC) == false) {
 	      merit = ASEvaluator.evaluateSubset(temp_group);
 	      m_totalEvals++;
-
-	      if (m_debug) {
-		System.out.print(""Group: "");
-		printGroup(tt, m_numAttribs);
-		System.out.println(""Merit: "" + merit);
-	      }
-
-	      // is this better than the best?
-	      if (sd == SELECTION_FORWARD) {
-		z = ((merit - best_merit) > 0.00001);
-	      }
-	      else {
-		if (merit == best_merit) {
-		  z = (size < best_size);
-		} else {
-		  z = (merit >  best_merit);
-		} 
-	      }
-
-	      if (z) {
-		added = true;
-		stale = 0;
-		best_merit = merit;
-		//		best_size = (size + best_size);
-		best_size = size;
-		best_group = (BitSet)(temp_group.clone());
-	      }
-
+	      
+	      // insert this one in the hashtable
 	      if (insertCount > m_cacheSize * m_numAttribs) {
 		lookup = new Hashtable(m_cacheSize * m_numAttribs);
 		insertCount = 0;
 	      }
-	      // insert this one in the list and in the hash table
-	      Object [] add = new Object[1];
-	      add[0] = tt.clone();
-	      bfList.addToList(add, merit);
 	      hashC = tt.toString();
-	      lookup.put(hashC, """");
-	      insertCount++;
+    	      lookup.put(hashC, new Double(merit));
+    	      insertCount++;
 	    } else {
-	      cacheHits++;
+	      merit = ((Double)lookup.get(hashC)).doubleValue();
+	      cacheHits++;  
+	    }
+	    
+	    // insert this one in the list
+	    Object[] add = new Object[1];
+	    add[0] = tt.clone();
+	    bfList.addToList(add, merit);
+	    
+	    if (m_debug) {
+	      System.out.print(""Group: "");
+	      printGroup(tt, m_numAttribs);
+	      System.out.println(""Merit: "" + merit);
+	    }
+
+	    // is this better than the best?
+	    if (sd == SELECTION_FORWARD) {
+	      z = ((merit - best_merit) > 0.00001);
+	    } else {
+	      if (merit == best_merit) {
+		z = (size < best_size);
+	      } else {
+		z = (merit >  best_merit);
+	      } 
+	    }
+
+	    if (z) {
+	      added = true;
+	      stale = 0;
+	      best_merit = merit;
+	      //		best_size = (size + best_size);
+	      best_size = size;
+	      best_group = (BitSet)(temp_group.clone());
 	    }
 
 	    // unset this addition(deletion)
 	    if (sd == SELECTION_FORWARD) {
 	      temp_group.clear(i);
 	      size--;
-	    }
-	    else {
+	    } else {
 	      temp_group.set(i);
 	      size++;
 	    }
 	  }
 	}
 
 	if (done == 2) {
 	  sd = SELECTION_BACKWARD;
 	}
 
 	done--;
       } while (done > 0);
 
       /* if we haven't added a new attribute subset then full expansion 
 	 of this node hasen't resulted in anything better */
       if (!added) {
 	stale++;
       }
     }
 
     m_bestMerit = best_merit;
     return  attributeList(best_group);
   }
\ No newline at end of file
","Added Martin Guetlein's bug fix for merit caching


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@4162 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,14864.json,89300e74cf24e09a676e8b2c132e4381f57905ac,"@@ -1,208 +1,216 @@
   public int[] search (ASEvaluation ASEval, Instances data)
     throws Exception {
     m_totalEvals = 0;
     if (!(ASEval instanceof SubsetEvaluator)) {
       throw  new Exception(ASEval.getClass().getName() 
 			   + "" is not a "" 
 			   + ""Subset evaluator!"");
     }
 
     if (ASEval instanceof UnsupervisedSubsetEvaluator) {
       m_hasClass = false;
     }
     else {
       m_hasClass = true;
       m_classIndex = data.classIndex();
     }
 
     SubsetEvaluator ASEvaluator = (SubsetEvaluator)ASEval;
     m_numAttribs = data.numAttributes();
     int i, j;
     int best_size = 0;
     int size = 0;
     int done;
     int sd = m_searchDirection;
     int evals = 0;
     BitSet best_group, temp_group;
     int stale;
     double best_merit;
     boolean ok = true;
     double merit;
     boolean z;
     boolean added;
     Link2 tl;
     Hashtable lookup = new Hashtable(m_cacheSize * m_numAttribs);
     int insertCount = 0;
     int cacheHits = 0;
     LinkedList2 bfList = new LinkedList2(m_maxStale);
     best_merit = -Double.MAX_VALUE;
     stale = 0;
     best_group = new BitSet(m_numAttribs);
 
     m_startRange.setUpper(m_numAttribs-1);
     if (!(getStartSet().equals(""""))) {
       m_starting = m_startRange.getSelection();
     }
     // If a starting subset has been supplied, then initialise the bitset
     if (m_starting != null) {
       for (i = 0; i < m_starting.length; i++) {
 	if ((m_starting[i]) != m_classIndex) {
 	  best_group.set(m_starting[i]);
 	}
       }
 
       best_size = m_starting.length;
       m_totalEvals++;
     }
     else {
       if (m_searchDirection == SELECTION_BACKWARD) {
 	setStartSet(""1-last"");
 	m_starting = new int[m_numAttribs];
 
 	// init initial subset to all attributes
 	for (i = 0, j = 0; i < m_numAttribs; i++) {
 	  if (i != m_classIndex) {
 	    best_group.set(i);
 	    m_starting[j++] = i;
 	  }
 	}
 
 	best_size = m_numAttribs - 1;
 	m_totalEvals++;
       }
     }
 
     // evaluate the initial subset
     best_merit = ASEvaluator.evaluateSubset(best_group);
     // add the initial group to the list and the hash table
     Object [] best = new Object[1];
     best[0] = best_group.clone();
     bfList.addToList(best, best_merit);
     BitSet tt = (BitSet)best_group.clone();
     String hashC = tt.toString();
     lookup.put(hashC, """");
 
     while (stale < m_maxStale) {
       added = false;
 
       if (m_searchDirection == SELECTION_BIDIRECTIONAL) {
 	// bi-directional search
 	  done = 2;
 	  sd = SELECTION_FORWARD;
 	}
       else {
 	done = 1;
       }
 
       // finished search?
       if (bfList.size() == 0) {
 	stale = m_maxStale;
 	break;
       }
 
       // copy the attribute set at the head of the list
       tl = bfList.getLinkAt(0);
       temp_group = (BitSet)(tl.getData()[0]);
       temp_group = (BitSet)temp_group.clone();
       // remove the head of the list
       bfList.removeLinkAt(0);
       // count the number of bits set (attributes)
       int kk;
 
       for (kk = 0, size = 0; kk < m_numAttribs; kk++) {
 	if (temp_group.get(kk)) {
 	  size++;
 	}
       }
 
       do {
 	for (i = 0; i < m_numAttribs; i++) {
 	  if (sd == SELECTION_FORWARD) {
 	    z = ((i != m_classIndex) && (!temp_group.get(i)));
 	  }
 	  else {
 	    z = ((i != m_classIndex) && (temp_group.get(i)));
 	  }
 
 	  if (z) {
 	    // set the bit (attribute to add/delete)
 	    if (sd == SELECTION_FORWARD) {
 	      temp_group.set(i);
+	      size++;
 	    }
 	    else {
 	      temp_group.clear(i);
+	      size--;
 	    }
 
 	    /* if this subset has been seen before, then it is already 
 	       in the list (or has been fully expanded) */
 	    tt = (BitSet)temp_group.clone();
 	    hashC = tt.toString();
 	    if (lookup.containsKey(hashC) == false) {
 	      merit = ASEvaluator.evaluateSubset(temp_group);
 	      m_totalEvals++;
 
 	      if (m_debug) {
 		System.out.print(""Group: "");
 		printGroup(tt, m_numAttribs);
 		System.out.println(""Merit: "" + merit);
 	      }
 
 	      // is this better than the best?
 	      if (sd == SELECTION_FORWARD) {
 		z = ((merit - best_merit) > 0.00001);
 	      }
 	      else {
-		z = ((merit >= best_merit) && ((size) < best_size));
+		if (merit == best_merit) {
+		  z = (size < best_size);
+		} else {
+		  z = (merit >  best_merit);
+		} 
 	      }
 
 	      if (z) {
 		added = true;
 		stale = 0;
 		best_merit = merit;
 		//		best_size = (size + best_size);
 		best_size = size;
 		best_group = (BitSet)(temp_group.clone());
 	      }
 
 	      if (insertCount > m_cacheSize * m_numAttribs) {
 		lookup = new Hashtable(m_cacheSize * m_numAttribs);
 		insertCount = 0;
 	      }
 	      // insert this one in the list and in the hash table
 	      Object [] add = new Object[1];
 	      add[0] = tt.clone();
 	      bfList.addToList(add, merit);
 	      hashC = tt.toString();
 	      lookup.put(hashC, """");
 	      insertCount++;
 	    } else {
 	      cacheHits++;
 	    }
 
 	    // unset this addition(deletion)
 	    if (sd == SELECTION_FORWARD) {
 	      temp_group.clear(i);
+	      size--;
 	    }
 	    else {
 	      temp_group.set(i);
+	      size++;
 	    }
 	  }
 	}
 
 	if (done == 2) {
 	  sd = SELECTION_BACKWARD;
 	}
 
 	done--;
       } while (done > 0);
 
       /* if we haven't added a new attribute subset then full expansion 
 	 of this node hasen't resulted in anything better */
       if (!added) {
 	stale++;
       }
     }
 
     m_bestMerit = best_merit;
     return  attributeList(best_group);
   }
\ No newline at end of file
","Fixed bug in backward mode


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@2250 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,14864.json,316eaac24eb968e7441b31b4e54c4ba10926a75a,"@@ -1,191 +1,189 @@
   public int[] search (int[] startSet, ASEvaluation ASEval, Instances data)
     throws Exception
   {
     if (!(ASEval instanceof SubsetEvaluator)) {
       throw  new Exception(ASEval.getClass().getName() 
 			   + "" is not a "" 
 			   + ""Subset evaluator!"");
     }
 
     if (startSet != null) {
       m_starting = startSet;
     }
 
     if (ASEval instanceof UnsupervisedSubsetEvaluator) {
       m_hasClass = false;
     }
     else {
       m_hasClass = true;
       m_classIndex = data.classIndex();
     }
 
     SubsetEvaluator ASEvaluator = (SubsetEvaluator)ASEval;
     m_numAttribs = data.numAttributes();
     int i, j;
     int best_size = 0;
     int size = 0;
     int done;
     int sd = m_searchDirection;
     int evals = 0;
     BitSet best_group, temp_group;
     int stale;
     double best_merit;
     boolean ok = true;
     double merit;
     boolean z;
     boolean added;
     Link2 tl;
     Hashtable lookup = new Hashtable((int)(200.0*m_numAttribs*1.5));
     LinkedList2 bfList = new LinkedList2(m_maxStale);
     best_merit = -Double.MAX_VALUE;
     stale = 0;
     best_group = new BitSet(m_numAttribs);
 
     // If a starting subset has been supplied, then initialise the bitset
     if (m_starting != null) {
       for (i = 0; i < m_starting.length; i++) {
 	if ((m_starting[i]) != m_classIndex) {
 	  best_group.set(m_starting[i]);
 	}
       }
 
-      // evaluate the initial set
-      best_merit = ASEvaluator.evaluateSubset(best_group);
       best_size = m_starting.length;
       m_totalEvals++;
     }
     else {if (m_searchDirection == -1) {
       m_starting = new int[m_numAttribs];
 
       // init initial subset to all attributes
       for (i = 0, j = 0; i < m_numAttribs; i++) {
 	if (i != m_classIndex) {
 	  best_group.set(i);
 	  m_starting[j++] = i;
 	}
       }
 
-      // evaluate the initial set
-      best_merit = ASEvaluator.evaluateSubset(best_group);
       best_size = m_numAttribs - 1;
       m_totalEvals++;
     }
     }
 
+    // evaluate the initial subset
+    best_merit = ASEvaluator.evaluateSubset(best_group);
     // add the initial group to the list and the hash table
     bfList.addToList(best_group, best_merit);
     BitSet tt = (BitSet)best_group.clone();
     lookup.put(tt, """");
 
     while (stale < m_maxStale) {
       added = false;
 
       if (m_searchDirection == 0) // bi-directional search
 	{
 	  done = 2;
 	  sd = 1;
 	}
       else {
 	done = 1;
       }
 
       // finished search?
       if (bfList.size() == 0) {
 	stale = m_maxStale;
 	break;
       }
 
       // copy the attribute set at the head of the list
       tl = bfList.getLinkAt(0);
       temp_group = (BitSet)(tl.getGroup().clone());
       // remove the head of the list
       bfList.removeLinkAt(0);
       // count the number of bits set (attributes)
       int kk;
 
       for (kk = 0, size = 0; kk < m_numAttribs; kk++) {
 	if (temp_group.get(kk)) {
 	  size++;
 	}
       }
 
       do {
 	for (i = 0; i < m_numAttribs; i++) {
 	  if (sd == 1) {
 	    z = ((i != m_classIndex) && (!temp_group.get(i)));
 	  }
 	  else {
 	    z = ((i != m_classIndex) && (temp_group.get(i)));
 	  }
 
 	  if (z) {
 	    // set the bit (attribute to add/delete)
 	    if (sd == 1) {
 	      temp_group.set(i);
 	    }
 	    else {
 	      temp_group.clear(i);
 	    }
 
 	    /* if this subset has been seen before, then it is already 
 	       in the list (or has been fully expanded) */
 	    tt = (BitSet)temp_group.clone();
 
 	    if (lookup.containsKey(tt) == false) {
 	      merit = ASEvaluator.evaluateSubset(temp_group);
 	      m_totalEvals++;
 
 	      if (m_debug) {
 		System.out.print(""Group: "");
 		printGroup(tt, m_numAttribs);
 		System.out.println(""Merit: "" + merit);
 	      }
 
 	      // is this better than the best?
 	      if (sd == 1) {
 		z = ((merit - best_merit) > 0.00001);
 	      }
 	      else {
 		z = ((merit >= best_merit) && ((size + sd) < best_size));
 	      }
 
 	      if (z) {
 		added = true;
 		stale = 0;
 		best_merit = merit;
 		best_size = (size + best_size);
 		best_group = (BitSet)(temp_group.clone());
 	      }
 
 	      // insert this one in the list and in the hash table
 	      bfList.addToList(tt, merit);
 	      lookup.put(tt, """");
 	    }
 
 	    // unset this addition(deletion)
 	    if (sd == 1) {
 	      temp_group.clear(i);
 	    }
 	    else {
 	      temp_group.set(i);
 	    }
 	  }
 	}
 
 	if (done == 2) {
 	  sd = -1;
 	}
 
 	done--;
       } while (done > 0);
 
       /* if we haven't added a new attribute subset then full expansion 
 	 of this node hasen't resulted in anything better */
       if (!added) {
 	stale++;
       }
     }
 
     m_bestMerit = best_merit;
     return  attributeList(best_group);
   }
\ No newline at end of file
","Fixed small bug in evaluation of an empty subset.


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@169 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,20981.json,6c77ccd674985be37160a0788865e371bf1cb5e1,"@@ -1,49 +1,53 @@
   private void saveLayout(int tabIndex, boolean showDialog) {
     // m_loadB.setEnabled(false);
     // m_saveB.setEnabled(false);
     java.awt.Color bckC = getBackground();
 
     File sFile = m_mainKFPerspective.getFlowFile(tabIndex);
     int returnVal = JFileChooser.APPROVE_OPTION;
+    boolean shownDialog = false;
 
     if (showDialog || sFile.getName().equals(""-NONE-"")) {
       returnVal = m_FileChooser.showSaveDialog(this);
+      shownDialog = true;
     }
 
     if (returnVal == JFileChooser.APPROVE_OPTION) {
       // temporarily remove this panel as a property changle listener from
       // each bean
 
       Vector beans = BeanInstance.getBeanInstances(tabIndex);
       detachFromLayout(beans);
 
-      // determine filename
-      sFile = m_FileChooser.getSelectedFile();
+      // determine filename (if necessary)
+      if (shownDialog) {
+        sFile = m_FileChooser.getSelectedFile();
+      }
 
       // add extension if necessary
       if (m_FileChooser.getFileFilter() == m_KfFilter) {
         if (!sFile.getName().toLowerCase().endsWith(FILE_EXTENSION)) {
           sFile = new File(sFile.getParent(), sFile.getName() + FILE_EXTENSION);
         }
       } else if (m_FileChooser.getFileFilter() == m_KOMLFilter) {
         if (!sFile.getName().toLowerCase().endsWith(KOML.FILE_EXTENSION + ""kf"")) {
           sFile = new File(sFile.getParent(), sFile.getName()
               + KOML.FILE_EXTENSION + ""kf"");
         }
       } else if (m_FileChooser.getFileFilter() == m_XStreamFilter) {
         if (!sFile.getName().toLowerCase()
             .endsWith(XStream.FILE_EXTENSION + ""kf"")) {
           sFile = new File(sFile.getParent(), sFile.getName()
               + XStream.FILE_EXTENSION + ""kf"");
         }
       } else if (m_FileChooser.getFileFilter() == m_XMLFilter) {
         if (!sFile.getName().toLowerCase().endsWith(FILE_EXTENSION_XML)) {
           sFile = new File(sFile.getParent(), sFile.getName()
               + FILE_EXTENSION_XML);
         }
       }
 
       saveLayout(sFile, m_mainKFPerspective.getCurrentTabIndex(), false);
       m_mainKFPerspective.setFlowFile(tabIndex, sFile);
     }
   }
\ No newline at end of file
","Fixed a bug where a tab would get saved with the filename associated with another tab

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@9860 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,37320.json,24265153c621e05ff04b8fd1e06a4dfd6a63950a,"@@ -1,12 +1,13 @@
   public void addStepOutputListener(StepOutputListener listener,
     String outputConnectionName) {
     List<StepOutputListener> listenersForConnectionType =
       m_outputListeners.get(outputConnectionName);
     if (listenersForConnectionType == null) {
       listenersForConnectionType = new ArrayList<StepOutputListener>();
+      m_outputListeners.put(outputConnectionName, listenersForConnectionType);
     }
 
     if (!listenersForConnectionType.contains(listener)) {
       listenersForConnectionType.add(listener);
     }
   }
\ No newline at end of file
","Fixed a bug in the step output listener framework

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@12498 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,21662.json,ac1cf6e094d4d41b6cff6e286f9abb0cdd58e95b,"@@ -1,9 +1,9 @@
   public void addObject(String name, Object o) {
     String nameCopy = name;
     int i = 0;
-    while (m_Results.containsKey(nameCopy)) {
+    while (m_Objs.containsKey(nameCopy)) {
       nameCopy = name + ""_"" + i++;
     }
 
     m_Objs.put(nameCopy, o);
   }
\ No newline at end of file
","Fixed bug, introduced in the last change, that affected accessing of objects stored against results

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@13734 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,32460.json,c3cf13ff2162159996a765cb4fcfb11c86359d6e,"@@ -1,23 +1,23 @@
   private static void initStemmers() {
     Vector<String> classnames;
     int i;
 
     if (m_Stemmers != null) {
       return;
     }
 
     m_Stemmers = new Vector<String>();
 
     if (!m_Present) {
       return;
     }
 
     classnames = GenericObjectEditor.getClassnames(SNOWBALL_PROGRAM);
     // try dynamic discovery if not in props file
     if (classnames.size() == 0) {
       classnames = ClassDiscovery.find(SNOWBALL_PROGRAM, PACKAGE_EXT);
-      for (i = 0; i < classnames.size(); i++) {
-        m_Stemmers.add(getStemmerName(classnames.get(i).toString()));
-      }
+    }
+    for (i = 0; i < classnames.size(); i++) {
+      m_Stemmers.add(getStemmerName(classnames.get(i).toString()));
     }
   }
\ No newline at end of file
","Fixed a bug that prevented snowball classes from being found when static entries in GenericObjectEditor.props are being used (instead of dynamic class discovery)

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@13430 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,24188.json,639ea63bec73dc387b27664947c01effdfc97c4c,"@@ -1,153 +1,153 @@
   public String toStringMatrix() {
     StringBuffer    result;
     String[][]      cells;
     int             i;
     int             j;
     int             n;
     int             k;
     int             size;
     String          line;
     int             indexBase;
     int             indexSecond;
     StringBuffer    head;
     StringBuffer    body;
     StringBuffer    foot;
     int[]           startMeans;
     int[]           startSigs;
     int             maxLength;
 
     result     = new StringBuffer();
     head       = new StringBuffer();
     body       = new StringBuffer();
     foot       = new StringBuffer();
     cells      = toArray();
     startMeans = new int[getColCount()];
     startSigs  = new int[getColCount() - 1];
     maxLength  = 0;
 
     // pad numbers
     for (n = 1; n < cells[0].length; n++) {
       size = getColSize(cells, n, true, true);
       for (i = 1; i < cells.length - 1; i++)
         cells[i][n] = padString(cells[i][n], size, true);
     }
 
     // index of base column in array
     indexBase = 1;
     if (getShowStdDev())
       indexBase++;
 
     // index of second column in array
     indexSecond = indexBase + 1;
     if (getShowStdDev())
       indexSecond++;
 
     // output data (without ""(v/ /*)"")
     j = 0;
     k = 0;
     for (i = 1; i < cells.length - 1; i++) {
       line = """";
       
       for (n = 0; n < cells[0].length; n++) {
         // record starts
         if (i == 1) {
           if (isMean(n)) {
             startMeans[j] = line.length();
             j++;
           }
 
           if (isSignificance(n)) {
             startSigs[k] = line.length();
             k++;
           }
         }
         
         if (n == 0) {
           line += padString(cells[i][n], getRowNameWidth());
-          line += padString(""("" + Utils.doubleToString(getCount(i-1), 0) + "")"", 
+          line += padString(""("" + Utils.doubleToString(getCount(getDisplayRow(i-1)), 0) + "")"", 
                         getCountWidth(), true);
         }
         else {
           // additional space before means
           if (isMean(n))
             line += ""  "";
 
           // print cell
           if (getShowStdDev()) {
             if (isMean(n - 1)) {
               if (!cells[i][n].trim().equals(""""))              
                 line += ""("" + cells[i][n] + "")"";
               else
                 line += "" "" + cells[i][n] + "" "";
             }
             else
               line += "" "" + cells[i][n];
           }
           else {
             line += "" "" + cells[i][n];
           }
         }
 
         // add separator after base column
         if (n == indexBase)
           line += "" |"";
       }
 
       // record overall length
       if (i == 1)
         maxLength = line.length();
       
       body.append(line + ""\n"");
     }
 
     // column names
     line = padString(cells[0][0], startMeans[0]);
     i    = -1;
     for (n = 1; n < cells[0].length; n++) {
       if (isMean(n)) {
         i++;
 
         if (i == 0)
           line = padString(line, startMeans[i] - getCountWidth());
         else if (i == 1)
           line = padString(line, startMeans[i] - "" |"".length());
         else if (i > 1)
           line = padString(line, startMeans[i]);
         
         if (i == 1)
           line += "" |"";
         
         line += "" "" + cells[0][n];
       }
     }
     line = padString(line, maxLength);
     head.append(line + ""\n"");
     head.append(line.replaceAll(""."", ""-"") + ""\n"");
     body.append(line.replaceAll(""."", ""-"") + ""\n"");
 
     // output wins/losses/ties
     if (getColCount() > 1) {
       line = padString(cells[cells.length - 1][0], startMeans[1]-2, true) + "" |"";
       i    = 0;
       for (n = 1; n < cells[cells.length - 1].length; n++) {
         if (isSignificance(n)) {
           line = padString(
                   line, startSigs[i] + 1 - cells[cells.length - 1][n].length());
           line += "" "" + cells[cells.length - 1][n];
           i++;
         }
       }
       line = padString(line, maxLength);
     }
     else {
       line = padString(cells[cells.length - 1][0], line.length() - 2) + "" |"";
     }
     foot.append(line + ""\n"");
     
     // assemble output
     result.append(head.toString());
     result.append(body.toString());
     result.append(foot.toString());
 
     return result.toString();
   }
\ No newline at end of file
","Fixed bug in ResultMatrixPlainText, which meant that displayed counts could be out of line with corresponding dataset and results. Changed TTesters to not throw an exception when missing values are encountered.


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@2816 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,17500.json,d109992d4145875b41832b4a599e8cc7b7e5d4a2,"@@ -1,71 +1,74 @@
   protected void setNumeric() {
     m_isNumeric = true;
     /*      m_maxC = mxC;
 	    m_minC = mnC; */
 
     double min=Double.POSITIVE_INFINITY;
     double max=Double.NEGATIVE_INFINITY;
     double value;
 
     for (int i=0;i<m_Instances.numInstances();i++) {
       if (!m_Instances.instance(i).isMissing(m_cIndex)) {
 	value = m_Instances.instance(i).value(m_cIndex);
 	if (value < min) {
 	  min = value;
 	}
 	if (value > max) {
 	  max = value;
 	}
       }
     }
      
+    // handle case where all values are missing
+    if (min == Double.POSITIVE_INFINITY) min = max = 0.0;
+
     m_minC = min; m_maxC = max;
 
     int whole = (int)Math.abs(m_maxC);
     double decimal = Math.abs(m_maxC) - whole;
     int nondecimal;
     nondecimal = (whole > 0) 
       ? (int)(Math.log(whole) / Math.log(10))
       : 1;
     
     m_precisionC = (decimal > 0) 
       ? (int)Math.abs(((Math.log(Math.abs(m_maxC)) / 
 				      Math.log(10))))+2
       : 1;
     if (m_precisionC > VisualizeUtils.MAX_PRECISION) {
       m_precisionC = 1;
     }
 
     String maxStringC = Utils.doubleToString(m_maxC,
 					     nondecimal+1+m_precisionC
 					     ,m_precisionC);
     if (m_labelMetrics != null) {
       m_HorizontalPad = m_labelMetrics.stringWidth(maxStringC);
     }
 
     whole = (int)Math.abs(m_minC);
     decimal = Math.abs(m_minC) - whole;
     nondecimal = (whole > 0) 
       ? (int)(Math.log(whole) / Math.log(10))
       : 1;
     
      m_precisionC = (decimal > 0) 
        ? (int)Math.abs(((Math.log(Math.abs(m_minC)) / 
 				      Math.log(10))))+2
       : 1;
      if (m_precisionC > VisualizeUtils.MAX_PRECISION) {
        m_precisionC = 1;
      }
     
      maxStringC = Utils.doubleToString(m_minC,
 				       nondecimal+1+m_precisionC
 				       ,m_precisionC);
      if (m_labelMetrics != null) {
        if (m_labelMetrics.stringWidth(maxStringC) > m_HorizontalPad) {
 	 m_HorizontalPad = m_labelMetrics.stringWidth(maxStringC);
        }
      }
 
     setOn(true);
     this.repaint();
   }
\ No newline at end of file
","Fixed bug caused when all numeric values are missing.


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@1219 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,31181.json,feacc664ba9b84371e98b74802bc9f6a36edcff4,"@@ -1,19 +1,19 @@
   public String[] getOptions() {
 
     Vector<String> result = new Vector<String>();
 
     result.add(""-R"");
     result.add(getAttributeIndices());
 
     if (getInvertSelection()) {
       result.add(""-V"");
     }
 
-    result.add(""F"");
+    result.add(""-F"");
     result.add("""" + getFilterSpec());
 
-    result.add(""D"");
+    result.add(""-D"");
     result.add("""" + getDistanceSpec());
 
     return result.toArray(new String[result.size()]);
   }
\ No newline at end of file
","Small bug fix in getOptions().

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@11186 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,36114.json,f20281f569296add23cdf098a2ef5d7c1c9101a3,"@@ -1,31 +1,31 @@
   public static boolean hasInterface(Class intf, Class cls) {
     Class[]       intfs;
     int           i;
     boolean       result;
     Class         currentclass;
     
     result       = false;
     currentclass = cls;
     do {
       // check all the interfaces, this class implements
       intfs = currentclass.getInterfaces();
       for (i = 0; i < intfs.length; i++) {
         if (intfs[i].equals(intf)) {
           result = true;
           break;
         }
       }
 
       // get parent class
       if (!result) {
         currentclass = currentclass.getSuperclass();
         
-        // topmost class reached?
-        if (currentclass.equals(Object.class))
+        // topmost class reached or no superclass?
+        if ( (currentclass == null) || (currentclass.equals(Object.class)) )
           break;
       }
     } 
     while (!result);
       
     return result;
   }
\ No newline at end of file
","fixed bug with interfaces (return null as superclass)


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@2976 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,36431.json,a91eb3b6273ee2b25218e3fd6a1520a0f11b6e6e,"@@ -1,17 +1,18 @@
   public void stepInit() throws WekaException {
     m_isReset = true;
+    m_streamingData = null;
 
     // see if the specified downstream steps are connected
     m_validTrueStep =
       getStepManager().getOutgoingConnectedStepWithName(
         environmentSubstitute(m_customNameOfTrueStep)) != null;
     m_validFalseStep =
       getStepManager().getOutgoingConnectedStepWithName(
         environmentSubstitute(m_customNameOfFalseStep)) != null;
 
     m_incomingStructure = null;
 
     if (m_expressionString == null || m_expressionString.length() == 0) {
       throw new WekaException(""No expression defined!"");
     }
   }
\ No newline at end of file
","Fixed a small bug in FlowByExpression - object holding streaming data output did not get set to null in reset() method

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@13301 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,29966.json,a5e2d1ef0f62ebac46d095c840ea7ff4a9145b48,"@@ -1,172 +1,192 @@
   public static void main(String[] args) {
     try {
       if (args.length == 0 || args[0].equalsIgnoreCase(""-h"") ||
           args[0].equalsIgnoreCase(""-help"")) {
-        System.err.println(""Usage:\n\tweka.Run [-no-scan | -no-load] <scheme name [scheme options]>"");
+        System.err.println(""Usage:\n\tweka.Run [-no-scan] [-no-load] <scheme name [scheme options]>"");
         System.exit(1);
       }
+      boolean noScan = false;
+      boolean noLoad = false;
       if (args[0].equals(""-list-packages"")) {
         weka.core.WekaPackageManager.loadPackages(true);
         System.exit(0);
-      } else if (!args[0].equals(""-no-load"")) {
+      } else if (args[0].equals(""-no-load"")) {
+        noLoad = true;
+        if (args.length > 1) {
+          if (args[1].equals(""-no-scan"")) {
+            noScan = true;
+          }
+        }
+      } else if (args[0].equals(""-no-scan"")) {
+        noScan = true;
+        if (args.length > 1) {
+          if (args[1].equals(""-no-load"")) {
+            noLoad = true;
+          }
+        }
+      }
+      
+      if (!noLoad) {
         weka.core.WekaPackageManager.loadPackages(false);
       }
       
+      int schemeIndex = 0;
+      if (noLoad && noScan) {
+        schemeIndex = 2;
+      } else if (noLoad || noScan) {
+        schemeIndex = 1;
+      }
+      
       String schemeToRun = null;
       String[] options = null;
-      if (args[0].equals(""-no-scan"") || args[0].equals(""-no-load"")) {
-        if (args.length < 2) {
-          System.err.println(""No scheme name given."");
-          System.exit(1);
-        }
-        schemeToRun = args[1];
-        options = new String[args.length - 2];
-        if (options.length > 0) {
-          System.arraycopy(args, 2, options, 0, options.length);
-        }
-      } else {
-        // scan packages for matches
-        schemeToRun = args[0];
-        options = new String[args.length - 1];
-        if (options.length > 0) {
-          System.arraycopy(args, 1, options, 0, options.length);
-        }
-
-        ArrayList<String> matches = weka.core.ClassDiscovery.find(args[0]);
+      
+      if (schemeIndex >= args.length) {
+        System.err.println(""No scheme name given."");
+        System.exit(1);
+      }
+      schemeToRun = args[schemeIndex];
+      options = new String[args.length - schemeIndex - 1];
+      if (options.length > 0) {
+        System.arraycopy(args, schemeIndex + 1, options, 0, options.length);
+      }
+      
+           
+      if (!noScan) {     
+        ArrayList<String> matches = weka.core.ClassDiscovery.find(schemeToRun);
         ArrayList<String> prunedMatches = new ArrayList<String>();
         // prune list for anything that isn't a runnable scheme      
         for (int i = 0; i < matches.size(); i++) {
           try {
             Object scheme = java.beans.Beans.instantiate((new Run()).getClass().getClassLoader(),
                 matches.get(i));          
             if (scheme instanceof weka.classifiers.Classifier ||
                 scheme instanceof weka.clusterers.Clusterer ||
                 scheme instanceof weka.associations.Associator ||
                 scheme instanceof weka.attributeSelection.ASEvaluation ||
                 scheme instanceof weka.filters.Filter) {
               prunedMatches.add(matches.get(i));
             }
           } catch (Exception ex) {
             // ignore any classes that we can't instantiate due to no no-arg constructor
           }
         }
 
         if (prunedMatches.size() == 0) {
-          System.err.println(""Can't find scheme "" + args[0] + "", or it is not runnable."");
+          System.err.println(""Can't find scheme "" + schemeToRun + "", or it is not runnable."");
           System.exit(1);
         } else if (prunedMatches.size() > 1) {
           java.io.BufferedReader br = 
             new java.io.BufferedReader(new java.io.InputStreamReader(System.in));
           boolean done = false;
           while (!done) {
             System.out.println(""Select a scheme to run, or <return> to exit:"");
             for (int i = 0; i < prunedMatches.size(); i++) {
               System.out.println(""\t"" + (i+1) + "") "" + prunedMatches.get(i));
             }
             System.out.print(""\nEnter a number > "");
             String choice = null;
             int schemeNumber = 0;
             try {
               choice = br.readLine();
               if (choice.equals("""")) {
                 System.exit(0);
               } else {
                 schemeNumber = Integer.parseInt(choice);
                 schemeNumber--;
                 if (schemeNumber >= 0 && schemeNumber < prunedMatches.size()) {
                   schemeToRun = prunedMatches.get(schemeNumber);
                   done = true;
                 }
               }
             } catch (java.io.IOException ex) {
               // ignore
             }
           }
         } else {
           schemeToRun = prunedMatches.get(0);
         }
       }
 
       Object scheme = null;
       try {
         scheme = java.beans.Beans.instantiate((new Run()).getClass().getClassLoader(),
             schemeToRun);
       } catch (Exception ex) {
         System.err.println(schemeToRun + "" is not runnable!"");
         System.exit(1);
       }
       // now see which interfaces/classes this scheme implements/extends
       ArrayList<SchemeType> types = new ArrayList<SchemeType>();      
       if (scheme instanceof weka.classifiers.Classifier) {
         types.add(SchemeType.CLASSIFIER);
       }
       if (scheme instanceof weka.clusterers.Clusterer) {
         types.add(SchemeType.CLUSTERER);
       }
       if (scheme instanceof weka.associations.Associator) {
         types.add(SchemeType.ASSOCIATOR);
       }
       if (scheme instanceof weka.attributeSelection.ASEvaluation) {
         types.add(SchemeType.ATTRIBUTE_SELECTION);
       }
       if (scheme instanceof weka.filters.Filter) {
         types.add(SchemeType.FILTER);
       }
       
       SchemeType selectedType = null;
       if (types.size() == 0) {
         System.err.println("""" + schemeToRun + "" is not runnable!"");
         System.exit(1);
       }
       if (types.size() == 1) {
         selectedType = types.get(0);
       } else {
         java.io.BufferedReader br = 
           new java.io.BufferedReader(new java.io.InputStreamReader(System.in));
         boolean done = false;
         while (!done) {
           System.out.println("""" + schemeToRun + "" can be executed as any of the following:"");
           for (int i = 0; i < types.size(); i++) {
             System.out.println(""\t"" + (i+1) + "") "" + types.get(i));
           }
           System.out.print(""\nEnter a number > "");
           String choice = null;
           int typeNumber = 0;
           try {
             choice = br.readLine();
             if (choice.equals("""")) {
               System.exit(0);
             } else {
               typeNumber = Integer.parseInt(choice);
               typeNumber--;
               if (typeNumber >= 0 && typeNumber < types.size()) {
                 selectedType = types.get(typeNumber);
                 done = true;
               }
             }
           } catch (java.io.IOException ex) {
             // ignore
           }
         }
       }
             
       if (selectedType == SchemeType.CLASSIFIER) {
         weka.classifiers.AbstractClassifier.runClassifier((weka.classifiers.Classifier)scheme, options);
       } else if (selectedType == SchemeType.CLUSTERER) {
         weka.clusterers.AbstractClusterer.runClusterer((weka.clusterers.Clusterer)scheme, options);
       } else if (selectedType == SchemeType.ATTRIBUTE_SELECTION) {
         weka.attributeSelection.ASEvaluation.runEvaluator((weka.attributeSelection.ASEvaluation)scheme, options);
       } else if (selectedType == SchemeType.ASSOCIATOR) {
         weka.associations.AbstractAssociator.runAssociator((weka.associations.Associator)scheme, options);
       } else if (selectedType == SchemeType.FILTER) {
         weka.filters.Filter.runFilter((weka.filters.Filter)scheme, options);
       }
     } 
     catch (Exception e) {
       if (    ((e.getMessage() != null) && (e.getMessage().indexOf(""General options"") == -1))
 	   || (e.getMessage() == null) )
 	e.printStackTrace();
       else
 	System.err.println(e.getMessage());
     }
   }
\ No newline at end of file
","Fixed a bug that prevented the -no-scan and -no-load options to be used at the same time.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@6676 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,6813.json,017098ae02f2d6bdf3fb5d25b0d3ccedd8c46b7e,"@@ -1,28 +1,35 @@
   protected static Vector instanceToVector(Instance toProcess, int classIndex) {
     if (toProcess instanceof SparseInstance) {
       int classModifier = classIndex >= 0 ? 1 : 0;
+      if (classModifier > 0) {
+        double classValue = toProcess.classValue();
+        if (classValue == 0) {
+          classModifier = 0; // class is sparse
+        }
+      }
       SparseInstance toProcessSparse = ((SparseInstance) toProcess);
       int[] indices = new int[toProcessSparse.numValues() - classModifier];
       double[] values = new double[toProcessSparse.numValues() - classModifier];
       int index = 0;
       for (int i = 0; i < toProcessSparse.numValues(); i++) {
         if (toProcessSparse.index(i) != classIndex) {
           indices[index] = toProcessSparse.index(i);
           values[index++] = toProcessSparse.valueSparse(i);
         }
       }
-      return Vectors.sparse(toProcess.numValues(), indices, values);
+      return Vectors.sparse(
+        toProcess.numAttributes() - (classIndex >= 0 ? 1 : 0), indices, values);
     } else {
       if (classIndex < 0) {
         return Vectors.dense(toProcess.toDoubleArray());
       }
       double[] independent = new double[toProcess.numAttributes() - 1];
       int index = 0;
       for (int i = 0; i < toProcess.numAttributes(); i++) {
         if (i != classIndex) {
           independent[index++] = toProcess.value(i);
         }
       }
       return Vectors.dense(independent);
     }
   }
\ No newline at end of file
","Fixed a bug in sparse instance to sparse Vector conversion.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@14868 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,1604.json,a3134adec9386c387ea691ca59e46a35f35f858d,"@@ -1,175 +1,179 @@
   public void buildClassifier(Instances data) throws Exception {
     // can classifier handle the data?
     getCapabilities().testWithFail(data);
 
     m_errorsFromR = new ArrayList<String>();
 
     if (m_modelHash == null) {
       m_modelHash = """" + hashCode();
     }
 
     data = new Instances(data);
     data.deleteWithMissingClass();
 
     if (data.numInstances() == 0 || data.numAttributes() == 1) {
       if (data.numInstances() == 0) {
         System.err
           .println(""No instances with non-missing class - using ZeroR model"");
       } else {
         System.err.println(""Only the class attribute is present in ""
           + ""the data - using ZeroR model"");
       }
       m_zeroR = new ZeroR();
       m_zeroR.buildClassifier(data);
       return;
     }
 
     // remove useless attributes
     m_removeUseless = new RemoveUseless();
     m_removeUseless.setInputFormat(data);
     data = Filter.useFilter(data, m_removeUseless);
 
     if (!m_dontReplaceMissingValues) {
       m_missingFilter = new ReplaceMissingValues();
       m_missingFilter.setInputFormat(data);
       data = Filter.useFilter(data, m_missingFilter);
     }
 
     data = handleZeroFrequencyNominalValues(data);
 
     m_serializedModel = null;
 
     if (!m_initialized) {
       init();
 
       if (!m_mlrAvailable) {
         throw new Exception(
           ""MLR is not available for some reason - can't continue!"");
       }
     } else {
       // unload and then reload MLR to try and clear any errors/inconsistent
       // state
       reloadMLR();
     }
 
     m_baseLearnerLibraryAvailable = false;
     loadBaseLearnerLibrary();
     if (!m_baseLearnerLibraryAvailable) {
       throw new Exception(""Library ""
         + MLRClassifier.TAGS_LEARNER[m_rLearner].getIDStr() + "" for learner ""
         + MLRClassifier.TAGS_LEARNER[m_rLearner].getReadable()
         + "" is not available for some reason - can't continue!"");
     }
 
     RSession eng = null;
     eng = RSession.acquireSession(this);
     eng.setLog(this, m_logger);
     eng.clearConsoleBuffer(this);
 
+    // Change to a temporary directory where we have write access
+    // in case an mlr scheme tries to write a local file
+    eng.parseAndEval(this, ""setwd(tempdir())"");
+
     // Set seed for random number generator in R in a data-dependent manner
     eng.parseAndEval(this,
       ""set.seed("" + data.getRandomNumberGenerator(getSeed()).nextInt() + "")"");
 
     // clean up any previous model
     // suffix model identifier with hashcode of this object
     eng.parseAndEval(this, ""remove(weka_r_model"" + m_modelHash + "")"");
 
     // transfer training data into a data frame in R
     Object[] result = RUtils.instancesToDataFrame(eng, this, data, ""mlr_data"");
     m_cleanedAttNames = (String[])result[0];
     m_cleanedAttValues = (String[][])result[1];
 
     try {
       String mlrIdentifier =
         MLRClassifier.TAGS_LEARNER[m_rLearner].getReadable();
 
       if (data.classAttribute().isNumeric()
         && mlrIdentifier.startsWith(""classif"")) {
         throw new Exception(""Training instances has a numeric class but ""
           + ""selected R learner is a classifier!"");
       } else if (data.classAttribute().isNominal()
         && mlrIdentifier.startsWith(""regr"")) {
         throw new Exception(""Training instances has a nominal class but ""
           + ""selected R learner is a regressor!"");
       }
 
       m_errorsFromR.clear();
       // make classification/regression task
       String taskString = null;
       if (data.classAttribute().isNominal()) {
         taskString = ""task <- makeClassifTask(data = mlr_data, target = \""""
           + m_cleanedAttNames[data.classIndex()] + ""\"")"";
       } else {
         taskString = ""task <- makeRegrTask(data = mlr_data, target = \""""
           + m_cleanedAttNames[data.classIndex()] + ""\"")"";
       }
 
       if (m_Debug) {
         System.err.println(""Prediction task: "" + taskString);
       }
 
       eng.parseAndEval(this, taskString);
       // eng.parseAndEval(this, ""print(task)"");
       checkForErrors();
 
       m_schemeProducesProbs = schemeProducesProbabilities(mlrIdentifier, eng);
 
       String probs =
         (data.classAttribute().isNominal() && m_schemeProducesProbs)
           ? "", predict.type = \""prob\"""" : """";
       String learnString = null;
       if (m_schemeOptions != null && m_schemeOptions.length() > 0) {
         learnString = ""l <- makeLearner(\"""" + mlrIdentifier + ""\"""" + probs
           + "", "" + m_schemeOptions + "")"";
       } else {
         learnString =
           ""l <- makeLearner(\"""" + mlrIdentifier + ""\"""" + probs + "")"";
       }
 
       if (m_Debug) {
         System.err.println(""Make a learner object: "" + learnString);
       }
 
       eng.parseAndEval(this, learnString);
       checkForErrors();
 
       // eng.parseAndEval(this, ""print(l)"");
 
       // train model
       eng.parseAndEval(this,
         ""weka_r_model"" + m_modelHash + "" <- train(l, task)"");
 
       checkForErrors();
 
       // get the model for serialization
       REXP serializedRModel = eng.parseAndEval(this,
         ""serialize(weka_r_model"" + m_modelHash + "", NULL)"");
 
       checkForErrors();
 
       m_modelText = new StringBuffer();
 
       // get the textual representation
       eng.parseAndEval(this,
         ""print(getLearnerModel(weka_r_model"" + m_modelHash + ""))"");
       m_modelText.append(eng.getConsoleBuffer(this));
 
       // now try and serialize the model
       XStream xs = new XStream();
       String xml = xs.toXML(serializedRModel);
       if (xml != null && xml.length() > 0) {
         m_serializedModel = new StringBuffer();
         m_serializedModel.append(xml);
       }
     } catch (Exception ex) {
       ex.printStackTrace();
       // remove R training data frame after completion
       eng.parseAndEval(this, ""remove(mlr_data)"");
       RSession.releaseSession(this);
 
       throw new Exception(ex.getMessage());
     }
 
     eng.parseAndEval(this, ""remove(mlr_data)"");
     RSession.releaseSession(this);
   }
\ No newline at end of file
","Fixed problem for learning algorithms such as xgboost that create files. Now MLRClassifier creates and uses a temporary directory.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@14368 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,23659.json,04f417158535105b2ada4d2cb15709a24d2924e2,"@@ -1,125 +1,125 @@
   public String toStringMatrix() {
     StringBuffer    result;
     String[][]      cells;
     int             i;
     int             j;
     int             n;
     int             size;
 
     result  = new StringBuffer();
     cells   = toArray();
 
     result.append(  ""\\begin{table}[thb]\n\\caption{\\label{labelname}""
                   + ""Table Caption}\n"");
     if (!getShowStdDev())
       result.append(""\\footnotesize\n"");
     else
       result.append(""\\scriptsize\n"");
 
     // output the column alignment characters
     // one for the dataset name and one for the comparison column
     if (!getShowStdDev()) {
       result.append(  ""{\\centering \\begin{tabular}{""
                     + ""l""                     // dataset
                     + """"                      // separator
                     + ""r""                     // mean
                     );
     } else {
       // dataset, mean, std dev
       result.append(  ""{\\centering \\begin{tabular}{"" 
                     + ""l""                     // dataset
                     + """"                      // separator
                     + ""r""                     // mean
                     + ""@{\\hspace{0cm}}""      // separator
                     + ""c""                     // +/-
                     + ""@{\\hspace{0cm}}""      // separator
                     + ""r""                     // stddev
                     );
     }
 
     for (j = 1; j < getColCount(); j++) {
       if (getColHidden(j))
         continue;
       if (!getShowStdDev())
         result.append(  ""r""                   // mean
                       + ""@{\\hspace{0.1cm}}""  // separator
                       + ""c""                   // significance
                       );
       else 
         result.append(  ""r""                   // mean
                       + ""@{\\hspace{0cm}}""    // separator
                       + ""c""                   // +/-
                       + ""@{\\hspace{0cm}}""    // separator
                       + ""r""                   // stddev
                       + ""@{\\hspace{0.1cm}}""  // separator
                       + ""c""                   // significance
                       );
     }
     result.append(""}\n\\\\\n\\hline\n"");
     if (!getShowStdDev())
-      result.append(""Dataset & "" + getColName(0));
+      result.append(""Dataset & "" + cells[0][1]);
     else
-      result.append(""Dataset & \\multicolumn{3}{c}{"" + getColName(0) + ""}"");
+      result.append(""Dataset & \\multicolumn{3}{c}{"" + cells[0][1] + ""}"");
 
     // now do the column names (numbers)
-    for (j = 1; j < getColCount(); j++) {
-      if (getColHidden(j))
+    for (j = 2; j < cells[0].length; j++) {
+      if (!isMean(j))
         continue;
       if (!getShowStdDev())
-        result.append(""& "" + getColName(j) + "" & "");
+        result.append(""& "" + cells[0][j] + "" & "");
       else
-        result.append(""& \\multicolumn{4}{c}{"" + getColName(j) + ""} "");
+        result.append(""& \\multicolumn{4}{c}{"" + cells[0][j] + ""} "");
     }
     result.append(""\\\\\n\\hline\n"");
 
     // change ""_"" to ""-"" in names
     for (i = 1; i < cells.length; i++)
       cells[i][0] = cells[i][0].replace('_', '-');
 
     // pad numbers
     for (n = 1; n < cells[0].length; n++) {
       size = getColSize(cells, n);
       for (i = 1; i < cells.length; i++)
         cells[i][n] = padString(cells[i][n], size, true);
     }
 
     // output data (w/o wins/ties/losses)
     for (i = 1; i < cells.length - 1; i++) {
       for (n = 0; n < cells[0].length; n++) {
         if (n == 0) {
           result.append(padString(cells[i][n], getRowNameWidth()));
         }
         else {
           if (getShowStdDev()) {
             if (isMean(n - 1)) {
               if (!cells[i][n].trim().equals(""""))
                 result.append("" & $\\pm$ & "");
               else
                 result.append("" &       & "");
             }
             else
               result.append("" & "");
           }
           else {
             result.append("" & "");
           }
           result.append(cells[i][n]);
         }
       }
       
       result.append(""\\\\\n"");
     }
 
     result.append(""\\hline\n\\multicolumn{"" + cells[0].length + ""}{c}{$\\circ$, $\\bullet$""
 		  +"" statistically significant improvement or degradation}""
 		  +""\\\\\n\\end{tabular} "");
     if (!getShowStdDev())     
       result.append(""\\footnotesize "");
     else
       result.append(""\\scriptsize "");
     
     result.append(""\\par}\n\\end{table}""
 		  +""\n"");
      
     return result.toString();
   }
\ No newline at end of file
","fixed bug with column names (weren't in the correct order)


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@2393 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,36869.json,1a86d86af7ad235af95da7469c4252a5adf77d13,"@@ -1,27 +1,29 @@
   protected void checkPendingStreaming() throws WekaException {
     try {
       m_streamingFilter.batchFinished();
       Instances structureCopy =
         m_streamingFilter.getOutputFormat().stringFreeStructure();
       while (m_streamingFilter.numPendingOutput() > 0) {
         getStepManager().throughputUpdateStart();
         Instance filteredI = m_streamingFilter.output();
         if (m_stringAttsPresent) {
           for (int i = 0; i < filteredI.numAttributes(); i++) {
-            String val = filteredI.stringValue(i);
-            structureCopy.attribute(i).setStringValue(val);
-            filteredI.setValue(i, 0);
+            if (filteredI.attribute(i).isString() && ! filteredI.isMissing(i)) {
+              String val = filteredI.stringValue(i);
+              structureCopy.attribute(i).setStringValue(val);
+              filteredI.setValue(i, 0);
+            }
           }
           filteredI.setDataset(structureCopy);
         }
         m_incrementalData
           .setPayloadElement(StepManager.CON_INSTANCE, filteredI);
         if (!isStopRequested()) {
           getStepManager().outputData(m_incrementalData);
         }
         getStepManager().throughputUpdateEnd();
       }
     } catch (Exception ex) {
       throw new WekaException(ex);
     }
   }
\ No newline at end of file
","Fixed a small bug in processing of string attributes

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@13321 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,29259.json,a01e554f4dee170f439264d96f61f10c13bb316c,"@@ -1,58 +1,58 @@
   public double[] pairwiseCoupling(double[][] n, double[][] r) {
 
     // Initialize p and u array
     double[] p = new double[r.length];
     for (int i =0; i < p.length; i++) {
       p[i] = 1.0 / (double)p.length;
     }
     double[][] u = new double[r.length][r.length];
     for (int i = 0; i < r.length; i++) {
       for (int j = i + 1; j < r.length; j++) {
 	u[i][j] = 0.5;
       }
     }
 
     // firstSum doesn't change
     double[] firstSum = new double[p.length];
     for (int i = 0; i < p.length; i++) {
       for (int j = i + 1; j < p.length; j++) {
 	firstSum[i] += n[i][j] * r[i][j];
 	firstSum[j] += n[i][j] * (1 - r[i][j]);
       }
     }
 
     // Iterate until convergence
     boolean changed;
     do {
       changed = false;
       double[] secondSum = new double[p.length];
       for (int i = 0; i < p.length; i++) {
 	for (int j = i + 1; j < p.length; j++) {
 	  secondSum[i] += n[i][j] * u[i][j];
 	  secondSum[j] += n[i][j] * (1 - u[i][j]);
 	}
       }
       for (int i = 0; i < p.length; i++) {
-	if (firstSum[i] == 0) {
+	if ((firstSum[i] == 0) || (secondSum[i] == 0)) {
 	  if (p[i] > 0) {
 	    changed = true;
 	  }
 	  p[i] = 0;
 	} else {
 	  double factor = firstSum[i] / secondSum[i];
 	  double pOld = p[i];
 	  p[i] *= factor;
 	  if (Math.abs(pOld - p[i]) > 1.0e-3) {
 	    changed = true;
 	  }
 	}
       }
       Utils.normalize(p);
       for (int i = 0; i < r.length; i++) {
 	for (int j = i + 1; j < r.length; j++) {
 	  u[i][j] = p[i] / (p[i] + p[j]);
 	}
       }
     } while (changed);
     return p;
   }
\ No newline at end of file
","Fixed division by zero problem in pairwise coupling


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@1430 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,5830.json,4e28ba24b34efd31ec6954aa8312a90cd500ce2a,"@@ -1,12 +1,12 @@
   public void stepInit() throws WekaException {
     if ((m_encodedForecaster == null || m_encodedForecaster.equals(""-NONE-"")) &&
-      m_fileName == null || isEmpty(m_fileName.toString())) {
+      (m_fileName == null || isEmpty(m_fileName.toString()))) {
       throw new WekaException(""No forecaster specified!"");
     }
 
     m_isReset = true;
     m_isStreaming = false;
     m_overlayData = null;
     m_bufferedPrimeData = null;
     m_streamingData = new Data(StepManager.CON_INSTANCE);
   }
\ No newline at end of file
","Fixed a bug that prevented initialization to complete successfully when the model being used is serialized into the metadata for the step

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@13349 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,25919.json,92304dbdd06bfcf597e16639d7f8b1656d4269d9,"@@ -1,3 +1,4 @@
   public void setComputeAttributeImportance(boolean computeAttributeImportance) {
     m_computeAttributeImportance = computeAttributeImportance;
+    ((RandomTree)m_Classifier).setComputeImpurityDecreases(computeAttributeImportance);
   }
\ No newline at end of file
","Fixed another small bug in option setting

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@13190 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,10363.json,e68621d5b0b175c4b155cb383a8c007a83d10875,"@@ -1,8 +1,8 @@
   public String globalInfo() {
-    return ""Iteratively fits a regression model by attempting to minimize absolute error, based on""
+    return ""Iteratively fits a regression model by attempting to minimize absolute error, using""
             + ""a base learner that minimizes weighted squared error.\n\n""
             + ""Weights are bounded from below by 1.0 / Utils.SMALL.\n\n""
             + ""Resamples data based on weights if base learner is not a WeightedInstancesHandler.\n\n""
       +""For more information see:\n\n""
       + getTechnicalInformation().toString();
   }
\ No newline at end of file
","Updated Javadoc in IterativeAbsoluteErrorRegression. Fixed bug in globalInfo().

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@12364 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,12909.json,1e5d54bb479e458b94b035c9d201dae6a4aec513,"@@ -1,45 +1,48 @@
   public void updateDefaultList() {
     
     ((ModelList.SortedListModel) m_ModelList.getModel()).clear();
     
     String ensemblePackageString = getPackageName();
     
     int index = m_DefaultFilesComboBox.getSelectedIndex();
     
     Vector classifiers = null;
     
     LibrarySerialization serialization;
     try {
       
       serialization = new LibrarySerialization();
       
       String defaultFileString = ensemblePackageString
       + m_DefaultFileNames[index].trim() + "".model.xml"";
       
       //System.out.println(defaultFileString);
-      
-      InputStream is = ClassLoader.getSystemResourceAsStream(defaultFileString);
+    
+      ClassLoader thisLoader = getClass().getClassLoader();
+      // InputStream is = ClassLoader.getSystemResourceAsStream(defaultFileString);
+      InputStream is = thisLoader.getResourceAsStream(defaultFileString);
       
       if (is == null) {
 	File f = new File(defaultFileString);
 	if (f.exists()) {
 	  System.out.println(""file existed: "" + f.getPath());
 	} else {
 	  System.out.println(""file didn't exist: "" + f.getPath());
 	}
 	
       }
       
-      classifiers = (Vector) serialization.read(ClassLoader.getSystemResourceAsStream(defaultFileString));
+      // classifiers = (Vector) serialization.read(ClassLoader.getSystemResourceAsStream(defaultFileString));
+      classifiers = (Vector) serialization.read(thisLoader.getResourceAsStream(defaultFileString));
       
       for (Iterator it = classifiers.iterator(); it.hasNext();) {
 	EnsembleLibraryModel model = m_ListModelsPanel.getLibrary().createModel((Classifier) it.next());
 	model.testOptions();
 	((ModelList.SortedListModel) m_ModelList.getModel()).add(model);
       }
       
     } catch (Exception e) {
       // TODO Auto-generated catch block
       e.printStackTrace();
     }
   }
\ No newline at end of file
","Fixed a bug that was preventing a property file from being loaded correctly

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@14340 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,21385.json,1f61d35aae476dd90e8166897219ea0c8128e978,"@@ -1,173 +1,173 @@
   public void actionPerformed(ActionEvent e) {
     
     //JMenuItem m = (JMenuItem)e.getSource();
     
     if (e.getActionCommand() == null) {
       if (m_scaling == 0) {
 	repaint();
       }
       else {
 	animateScaling(m_nViewPos, m_nViewSize, m_scaling);
       }
     }
     else if (e.getActionCommand().equals(""Fit to Screen"")) {
       
       Dimension np = new Dimension();
       Dimension ns = new Dimension();
 
       getScreenFit(np, ns);
 
       animateScaling(np, ns, 10);
       
     }
     else if (e.getActionCommand().equals(""Center on Top Node"")) {
       
       int tpx = (int)(m_topNode.getCenter() * m_viewSize.width);   //calculate
       //the top nodes postion but don't adjust for where 
       int tpy = (int)(m_topNode.getTop() * m_viewSize.height);     //view is
       
       
       
       Dimension np = new Dimension(getSize().width / 2 - tpx, 
 				   getSize().width / 6 - tpy);
       
       animateScaling(np, m_viewSize, 10);
       
     }
     else if (e.getActionCommand().equals(""Auto Scale"")) {
       autoScale();  //this will figure the best scale value 
       //keep the focus on the middle of the screen and call animate
     }
     else if (e.getActionCommand().equals(""Visualize The Node"")) {
       //send the node data to the visualizer 
       if (m_focusNode >= 0) {
 	Instances inst;
 	if ((inst = m_nodes[m_focusNode].m_node.getInstances()) != null) {
 	  VisualizePanel pan = new VisualizePanel();
 	  pan.setInstances(inst);
 	  JFrame nf = new JFrame();
 	  nf.setSize(400, 300);
 	  nf.getContentPane().add(pan);
 	  nf.setVisible(true);
 	}
 	else {
 	  JOptionPane.showMessageDialog(this, ""Sorry, there is no "" + 
-					""availble Instances data for "" +
+					""available Instances data for "" +
 					""this Node."", ""Sorry!"",
 					JOptionPane.WARNING_MESSAGE); 
 	}
       }
       else {
 	JOptionPane.showMessageDialog(this, ""Error, there is no "" + 
 				      ""selected Node to perform "" +
 				      ""this operation on."", ""Error!"",
 				      JOptionPane.ERROR_MESSAGE); 
       }
     }
     else if (e.getActionCommand().equals(""Create Child Nodes"")) {
       if (m_focusNode >= 0) {
 	if (m_listener != null) {
 	  //then send message to the listener
 	  m_listener.userCommand(new TreeDisplayEvent
 	    (TreeDisplayEvent.ADD_CHILDREN, 
 	     m_nodes[m_focusNode].m_node.getRefer()));
 	}
 	else {
 	  JOptionPane.showMessageDialog(this, ""Sorry, there is no "" + 
 					""available Decision Tree to "" +
 					""perform this operation on."",
 					""Sorry!"", 
 					JOptionPane.WARNING_MESSAGE);
 	}
       }
       else {
 	JOptionPane.showMessageDialog(this, ""Error, there is no "" +
 				      ""selected Node to perform this "" +
 				      ""operation on."", ""Error!"",
 				      JOptionPane.ERROR_MESSAGE);
       }
     }
     else if (e.getActionCommand().equals(""Remove Child Nodes"")) {
       if (m_focusNode >= 0) {
 	if (m_listener != null) {
 	  //then send message to the listener
 	  m_listener.userCommand(new 
 	    TreeDisplayEvent(TreeDisplayEvent.REMOVE_CHILDREN, 
 			     m_nodes[m_focusNode].m_node.getRefer()));
 	}
 	else {
 	  JOptionPane.showMessageDialog(this, ""Sorry, there is no "" + 
 					""available Decsion Tree to "" +
 					""perform this operation on."",
 					""Sorry!"", 
 					JOptionPane.WARNING_MESSAGE);
 	}
       }
       else {
 	JOptionPane.showMessageDialog(this, ""Error, there is no "" +
 				      ""selected Node to perform this "" +
 				      ""operation on."", ""Error!"",
 				      JOptionPane.ERROR_MESSAGE);
       }
     }
     else if (e.getActionCommand().equals(""classify_child"")) {
       if (m_focusNode >= 0) {
 	if (m_listener != null) {
 	  //then send message to the listener
 	  m_listener.userCommand(new TreeDisplayEvent
 	    (TreeDisplayEvent.CLASSIFY_CHILD, 
 	     m_nodes[m_focusNode].m_node.getRefer()));
 	}
 	else {
 	  JOptionPane.showMessageDialog(this, ""Sorry, there is no "" + 
 					""available Decsion Tree to "" +
 					""perform this operation on."",
 					""Sorry!"", 
 					JOptionPane.WARNING_MESSAGE);
 	}
       }
       else {
 	JOptionPane.showMessageDialog(this, ""Error, there is no "" +
 				      ""selected Node to perform this "" +
 				      ""operation on."", ""Error!"",
 				      JOptionPane.ERROR_MESSAGE);
       }
     }
     else if (e.getActionCommand().equals(""send_instances"")) {
       if (m_focusNode >= 0) {
 	if (m_listener != null) {
 	  //then send message to the listener
 	  m_listener.userCommand(new TreeDisplayEvent
 	    (TreeDisplayEvent.SEND_INSTANCES, 
 	     m_nodes[m_focusNode].m_node.getRefer()));
 	}
 	else {
 	  JOptionPane.showMessageDialog(this, ""Sorry, there is no "" + 
 					""available Decsion Tree to "" +
 					""perform this operation on."",
 					""Sorry!"", 
 					JOptionPane.WARNING_MESSAGE);
 	}
       }
       else {
 	JOptionPane.showMessageDialog(this, ""Error, there is no "" +
 				      ""selected Node to perform this "" +
 				      ""operation on."", ""Error!"",
 				      JOptionPane.ERROR_MESSAGE);
       }
     }
     else if (e.getActionCommand().equals(""Accept The Tree"")) {
       if (m_listener != null) {
 	//then send message to the listener saying that the tree is done
 	m_listener.userCommand(new TreeDisplayEvent(TreeDisplayEvent.ACCEPT,
 						  null));
       }
       else {
 	JOptionPane.showMessageDialog(this, ""Sorry, there is no "" +
 				      ""available Decision Tree to "" +
 				      ""perform this operation on."",
 				      ""Sorry!"", 
 				      JOptionPane.WARNING_MESSAGE);
       }
     }
   }
\ No newline at end of file
","fixed typo in error message


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@3733 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,26536.json,8a6133c51b18360a896a4e959c47ff6c31ed9425,"@@ -1,16 +1,12 @@
   protected void initializeWithPluginMetrics() {
     m_pluginMetrics.clear();
     List<AbstractEvaluationMetric> pluginMetrics = m_eval.getPluginMetrics();
     if (pluginMetrics != null && pluginMetrics.size() > 0) {
       for (AbstractEvaluationMetric m : pluginMetrics) {
-        if (m instanceof InformationRetrievalEvaluationMetric) {
-          List<String> statNames = m.getStatisticNames();
-          for (String s : statNames) {
-            m_pluginMetrics.put(s.toLowerCase(), m);
-          }
-        } else {
-          m_pluginMetrics.put(m.getMetricName().toLowerCase(), m);
+        List<String> statNames = m.getStatisticNames();
+        for (String s : statNames) {
+          m_pluginMetrics.put(s.toLowerCase(), m);
         }
       }
     }
   }
\ No newline at end of file
","Fixed a small bug in the initializeWithPluginMetrics() method.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@10890 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,21345.json,f05e160a2290644b91f34152ee153ba21fa688bd,"@@ -1,9 +1,21 @@
     public void setValueAt(Object aValue,
 			   int rowIndex,
 			   int columnIndex) {
 
       //      double value = ((Double) aValue).doubleValue();
       //      m_matrix.setElement(rowIndex, columnIndex, value);
-      m_matrix.setCell(rowIndex, columnIndex, aValue);
+      // try to parse it as a double first
+      Double val;
+      try {
+        val = new Double(((String)aValue));
+        double value = val.doubleValue();
+      } catch (Exception ex) {
+        val = null;
+      }
+      if (val == null) {
+        m_matrix.setCell(rowIndex, columnIndex, aValue);
+      } else {
+        m_matrix.setCell(rowIndex, columnIndex, val);
+      }
       fireTableCellUpdated(rowIndex, columnIndex);
     }
\ No newline at end of file
","Fixed problem with setting cost values


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@3268 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,32633.json,5bf47271c53b258212fcf284bc65101b75cd4309,"@@ -1,45 +1,45 @@
   protected static void loadPackageDirectory(File directory, boolean verbose)
       throws Exception {
     File[] contents = directory.listFiles();
 
     // make sure that jar files and lib directory get processed first
     for (int i = 0; i < contents.length; i++) {
       if (contents[i].isFile() && contents[i].getPath().endsWith("".jar"")) {
         if (verbose) {
           System.out.println(""[Weka] loading "" + contents[i].getPath());
         }
         ClassloaderUtil.addFile(contents[i].getPath());
       } else if (contents[i].isDirectory()
           && contents[i].getName().equalsIgnoreCase(""lib"")) {
         // add any jar files in the lib directory to the classpath
         loadPackageDirectory(contents[i], verbose);
       }
     }
 
     // now any auxilliary files
     for (int i = 0; i < contents.length; i++) {
       if (contents[i].isFile() && contents[i].getPath().endsWith(""Beans.props"")) {
         // KnowledgeFlow plugin -- add the Beans.props file to the list of
         // bean plugin props
 
         KnowledgeFlowApp.addToPluginBeanProps(contents[i]);
         KnowledgeFlowApp.disposeSingleton();
 
       } else if (contents[i].isFile()
           && contents[i].getPath().endsWith(""Explorer.props"")) {
         // Explorer tabs plugin
         // process the keys in the properties file and append/add values
         processExplorerProps(contents[i]);
       } else if (contents[i].isFile()
           && contents[i].getPath().endsWith(""GUIEditors.props"")) {
         // Editor for a particular component
         processGUIEditorsProps(contents[i]);
       } else if (contents[i].isFile()
           && contents[i].getPath().endsWith(""GenericPropertiesCreator.props"")) {
         processGenericPropertiesCreatorProps(contents[i]);
       } else if (contents[i].isFile()
-          && contents[i].getParent().endsWith(""PluginManager.props"")) {
+          && contents[i].getPath().endsWith(""PluginManager.props"")) {
         processPluginManagerProps(contents[i]);
       }
     }
   }
\ No newline at end of file
","Fixed a bug in the processing of PluginManager.props files.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@9314 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,30120.json,4223a444b35556add50503527e26b24f82ea6784,"@@ -1,6 +1,6 @@
   public Instances trainCV(int numFolds, int numFold, Random random) {
 
-    Instances train = trainCV(numFold, numFold);
+    Instances train = trainCV(numFolds, numFold);
     train.randomize(random);
     return train;
   }
\ No newline at end of file
","Fixed a bug that I just introduced with my new code.


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@1850 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,20457.json,0fb7be37516d2f841ec1d8dc7949967049dd41f9,"@@ -1,5 +1,10 @@
   public void setText(String text) {
     m_currentContents = text;
-    m_combo.setSelectedItem(m_currentContents);
+    java.awt.Component theEditor = m_combo.getEditor().getEditorComponent();
+    if (theEditor instanceof JTextField) {
+      ((JTextField)theEditor).setText(text);
+    } else {
+      m_combo.setSelectedItem(m_currentContents);
+    }
     m_support.firePropertyChange("""", null, null);
   }
\ No newline at end of file
","Fixed a bug in setting the value of the field.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@8116 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,36417.json,5887d72aa9c3dc9d14f09c98ea60b54b3ea4a75c,"@@ -1,31 +1,40 @@
   public void processSecondary(Integer setNum, Integer maxSetNum, Data data,
     PairedDataHelper<weka.classifiers.Classifier> helper) throws WekaException {
 
     // trained classifier for this set number
     weka.classifiers.Classifier classifier =
       helper.getIndexedPrimaryResult(setNum);
 
     // test data
     Instances testSplit = data.getPrimaryPayload();
 
+    if (m_trainedClassifierHeader != null
+      && !testSplit.equalHeaders(m_trainedClassifierHeader)) {
+      if (!(m_trainedClassifier instanceof InputMappedClassifier)) {
+        throw new WekaException(
+          ""Structure of incoming data does not match ""
+            + ""that of the trained classifier"");
+      }
+    }
+
     // paired training data
     Instances trainingSplit =
       helper.getIndexedValueFromNamedStore(""trainingSplits"", setNum);
 
     getStepManager().logBasic(
       ""Dispatching model for set "" + setNum + "" out of "" + maxSetNum
         + "" to output"");
 
     Data batchClassifier =
       new Data(StepManager.CON_BATCH_CLASSIFIER, classifier);
     batchClassifier.setPayloadElement(StepManager.CON_AUX_DATA_TRAININGSET,
       trainingSplit);
     batchClassifier.setPayloadElement(StepManager.CON_AUX_DATA_TESTSET,
       testSplit);
     batchClassifier.setPayloadElement(StepManager.CON_AUX_DATA_SET_NUM, setNum);
     batchClassifier.setPayloadElement(StepManager.CON_AUX_DATA_MAX_SET_NUM,
       maxSetNum);
     batchClassifier
       .setPayloadElement(StepManager.CON_AUX_DATA_LABEL, getName());
     getStepManager().outputData(batchClassifier);
   }
\ No newline at end of file
","Fixed a bug where the Classifier step was not checking for compatible structure structure between training and test sets in the case where the classifier is not an InputMappedClassifier

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@14678 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,36360.json,a415ad7bb7e75ba3cda722d4c62bd27c01db961e,"@@ -1,78 +1,84 @@
   protected void createOffscreenPlot(Data data) {
     List<Instances> offscreenPlotData = new ArrayList<Instances>();
     Instances predictedI = data.getPrimaryPayload();
+    boolean colorSpecified = false;
 
-    if (predictedI.classIndex() >= 0 && predictedI.classAttribute().isNominal()) {
+    String additional = m_additionalOptions;
+    if (m_additionalOptions.length() > 0) {
+      additional = environmentSubstitute(additional);
+    }
+
+    if (!additional.contains(""-color"")
+      && m_offscreenRendererName.contains(""Weka Chart Renderer"")) {
+      // for WekaOffscreenChartRenderer only
+      if (additional.length() > 0) {
+        additional += "","";
+      }
+      if (predictedI.classIndex() >= 0) {
+        additional += ""-color="" + predictedI.classAttribute().name();
+      } else {
+        additional += ""-color=/last"";
+      }
+    } else {
+      colorSpecified = true;
+    }
+
+    if (predictedI.classIndex() >= 0 && predictedI.classAttribute().isNominal()
+      && !colorSpecified) {
       // set up multiple series - one for each class
       Instances[] classes = new Instances[predictedI.numClasses()];
       for (int i = 0; i < predictedI.numClasses(); i++) {
         classes[i] = new Instances(predictedI, 0);
         classes[i].setRelationName(predictedI.classAttribute().value(i));
       }
       for (int i = 0; i < predictedI.numInstances(); i++) {
         Instance current = predictedI.instance(i);
         classes[(int) current.classValue()].add((Instance) current.copy());
       }
       for (Instances classe : classes) {
         offscreenPlotData.add(classe);
       }
     } else {
       offscreenPlotData.add(new Instances(predictedI));
     }
 
     List<String> options = new ArrayList<String>();
-    String additional = m_additionalOptions;
-    if (m_additionalOptions.length() > 0) {
-      additional = environmentSubstitute(additional);
-    }
-
-    if (additional.contains(""-color"")) {
-      // for WekaOffscreenChartRenderer only
-      if (additional.length() > 0) {
-        additional += "","";
-      }
-      if (predictedI.classIndex() >= 0) {
-        additional += ""-color="" + predictedI.classAttribute().name();
-      } else {
-        additional += ""-color=/last"";
-      }
-    }
 
     String[] optionsParts = additional.split("","");
     for (String p : optionsParts) {
       options.add(p.trim());
     }
 
     // only need the x-axis (used to specify the attribute to plot)
     String xAxis = m_xAxis;
     xAxis = environmentSubstitute(xAxis);
 
     String width = m_width;
     String height = m_height;
     int defWidth = 500;
     int defHeight = 400;
     width = environmentSubstitute(width);
     height = environmentSubstitute(height);
 
     defWidth = Integer.parseInt(width);
     defHeight = Integer.parseInt(height);
 
     try {
       getStepManager().logDetailed(""Creating image"");
       BufferedImage osi =
         m_offscreenRenderer.renderHistogram(defWidth, defHeight,
           offscreenPlotData, xAxis, options);
 
       Data imageData = new Data(StepManager.CON_IMAGE, osi);
       String relationName = predictedI.relationName();
       if (relationName.length() > 10) {
         relationName = relationName.substring(0, 10);
       }
       imageData.setPayloadElement(StepManager.CON_AUX_DATA_TEXT_TITLE,
         relationName + "":"" + m_xAxis);
       getStepManager().outputData(imageData);
     } catch (Exception e1) {
       e1.printStackTrace();
     }
 
   }
\ No newline at end of file
","Fixed a few bugs in offscreen rendering that affected stacked histograms

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@13327 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,9851.json,64d54abda520da9b2297ed56047ce86beda812b4,"@@ -1,113 +1,117 @@
   protected void makeTree(FastVector BestFirstElements, BFTree root,
       Instances train, Instances test, FastVector modelError, int[][] sortedIndices,
       double[][] weights, double[][][] dists, double[] classProbs, double totalWeight,
       double[] branchProps, int minNumObj, boolean useHeuristic, boolean useGini, boolean useErrorRate)
   throws Exception {
 
     if (BestFirstElements.size()==0) return;
 
     ///////////////////////////////////////////////////////////////////////
     // All information about the node to split (first BestFirst object in
     // BestFirstElements)
     FastVector firstElement = (FastVector)BestFirstElements.elementAt(0);
 
     // node to split
     //BFTree nodeToSplit = (BFTree)firstElement.elementAt(0);
 
     // split attribute
     Attribute att = (Attribute)firstElement.elementAt(1);
 
     // info of split value or split string
     double splitValue = Double.NaN;
     String splitStr = null;
     if (att.isNumeric())
       splitValue = ((Double)firstElement.elementAt(2)).doubleValue();
     else {
       splitStr=((String)firstElement.elementAt(2)).toString();
     }
 
     // the best gini gain or information of this node
     double gain = ((Double)firstElement.elementAt(3)).doubleValue();
     ///////////////////////////////////////////////////////////////////////
 
     if (totalWeight < 2*minNumObj || branchProps[0]==0
 	|| branchProps[1]==0) {
       // remove the first element
       BestFirstElements.removeElementAt(0);
       makeLeaf(train);
+      if (BestFirstElements.size() == 0) {
+        return;
+      }
+
       BFTree nextSplitNode = (BFTree)
       ((FastVector)BestFirstElements.elementAt(0)).elementAt(0);
       nextSplitNode.makeTree(BestFirstElements, root, train, test, modelError,
 	  nextSplitNode.m_SortedIndices, nextSplitNode.m_Weights,
 	  nextSplitNode.m_Dists, nextSplitNode.m_ClassProbs,
 	  nextSplitNode.m_TotalWeight, nextSplitNode.m_Props, minNumObj,
 	  useHeuristic, useGini, useErrorRate);
       return;
 
     }
 
     // If gini gain or information gain is 0, make all nodes in the BestFirstElements leaf nodes
     // because these node sorted descendingly according to gini gain or information gain.
     // (namely, gini gain or information gain of all nodes in BestFirstEelements is 0).
     if (gain==0) {
       for (int i=0; i<BestFirstElements.size(); i++) {
 	FastVector element = (FastVector)BestFirstElements.elementAt(i);
 	BFTree node = (BFTree)element.elementAt(0);
 	node.makeLeaf(train);
       }
       BestFirstElements.removeAllElements();
     }
 
     // gini gain or information gain is not 0
     else {
       // remove the first element
       BestFirstElements.removeElementAt(0);
       m_Attribute = att;
       if (att.isNumeric()) m_SplitValue = splitValue;
       else m_SplitString = splitStr;
 
       int[][][] subsetIndices = new int[2][train.numAttributes()][0];
       double[][][] subsetWeights = new double[2][train.numAttributes()][0];
 
       splitData(subsetIndices, subsetWeights, m_Attribute,
 	  m_SplitValue, m_SplitString,
 	  sortedIndices, weights, train);
 
       // if split will generate node(s) which has total weights less than m_minNumObj,
       // do not split
       int attIndex = att.index();
       if (subsetIndices[0][attIndex].length<minNumObj ||
 	  subsetIndices[1][attIndex].length<minNumObj) {
 	makeLeaf(train);
       }
 
       // split the node and cauculate error rate of this temporary tree
       else {
 	m_isLeaf = false;
 	m_Attribute = att;
 
 	makeSuccessors(BestFirstElements,train,subsetIndices,
 	    subsetWeights,dists, m_Attribute, useHeuristic, useGini);
 	for (int i=0; i<2; i++){
 	  m_Successors[i].makeLeaf(train);
 	}
 
 	Evaluation eval = new Evaluation(test);
 	eval.evaluateModel(root, test);
 	double error;
 	if (useErrorRate) error = eval.errorRate();
 	else error = eval.rootMeanSquaredError();
 	modelError.addElement(new Double(error));
       }
 
       if (BestFirstElements.size()!=0) {
 	FastVector nextSplitElement = (FastVector)BestFirstElements.elementAt(0);
 	BFTree nextSplitNode = (BFTree)nextSplitElement.elementAt(0);
 	nextSplitNode.makeTree(BestFirstElements, root, train, test, modelError,
 	    nextSplitNode.m_SortedIndices, nextSplitNode.m_Weights,
 	    nextSplitNode.m_Dists, nextSplitNode.m_ClassProbs,
 	    nextSplitNode.m_TotalWeight, nextSplitNode.m_Props, minNumObj,
 	    useHeuristic, useGini,useErrorRate);
       }
     }
   }
\ No newline at end of file
","Fixed null pntr exception due to the fact that BFTree's recursion depended on a bug in FastVector


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@4237 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,28572.json,563360413e272237a4f3fe3033b8e50dfb132e27,"@@ -1,12 +1,18 @@
 	void replaceAtt(int nTargetNode, String sName, FastVector values) {
 		Attribute newAtt = new Attribute(sName, values);
 		if (m_Instances.classIndex() == nTargetNode) {
 			m_Instances.setClassIndex(-1);
-			m_Instances.insertAttributeAt(newAtt, nTargetNode);
+			/*m_Instances.insertAttributeAt(newAtt, nTargetNode);
 			m_Instances.deleteAttributeAt(nTargetNode + 1);
+			m_Instances.setClassIndex(nTargetNode); */
+			
+			m_Instances.deleteAttributeAt(nTargetNode);
+			m_Instances.insertAttributeAt(newAtt, nTargetNode);
 			m_Instances.setClassIndex(nTargetNode);
 		} else {
-			m_Instances.insertAttributeAt(newAtt, nTargetNode);
-			m_Instances.deleteAttributeAt(nTargetNode + 1);
+			/*m_Instances.insertAttributeAt(newAtt, nTargetNode);
+			m_Instances.deleteAttributeAt(nTargetNode + 1); */
+		        m_Instances.deleteAttributeAt(nTargetNode);
+		        m_Instances.insertAttributeAt(newAtt, nTargetNode);
 		}
 	} // replaceAtt
\ No newline at end of file
","Fixed a bug (caused indirectly by the change that disallows attributes with the same name in a set of instances) whereby an exception was generated by actions that mutated the values at a node.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@7834 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,20177.json,b5bafa7c1b1d4a69d3060a9be3b02c4b280127b9,"@@ -1,10 +1,11 @@
   public static void addPlugin(String interfaceName, String name, 
       String concreteType) {
     if (PLUGINS.get(interfaceName) == null) {
       Map<String, String> pluginsOfInterfaceType = 
         new TreeMap<String, String>();
       pluginsOfInterfaceType.put(name, concreteType);
+      PLUGINS.put(interfaceName, pluginsOfInterfaceType);      
     } else {
       PLUGINS.get(interfaceName).put(name, concreteType);
     }
   }
\ No newline at end of file
","Fixed a bug in the plugin registering mechanism.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@7629 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,21148.json,bad512e53bc1d955e4847e14296af551c9f28459,"@@ -1,50 +1,50 @@
   public void acceptDataSet(DataSetEvent e) {
 
     m_busy = true;
     if (m_log != null) {
       m_log.statusMessage(statusMessagePrefix() + ""Processing batch..."");
     }
 
     try {
       makeOutputStructure(new Instances(e.getDataSet(), 0));
     } catch (Exception ex) {
       String msg = statusMessagePrefix()
         + ""ERROR: unable to create output instances structure."";
       if (m_log != null) {
         m_log.statusMessage(msg);
         m_log.logMessage(""[SubstringLabeler] "" + ex.getMessage());
       }
       stop();
 
       ex.printStackTrace();
       m_busy = false;
       return;
     }
 
     Instances toProcess = e.getDataSet();
 
     for (int i = 0; i < toProcess.numInstances(); i++) {
       Instance current = toProcess.instance(i);
       Instance result = null;
       try {
         result = m_matches.makeOutputInstance(current, true);
       } catch (Exception ex) {
         ex.printStackTrace();
       }
 
       if (result != null) {
         // m_outputStructure.add(result);
         m_matches.getOutputStructure().add(result);
       }
     }
 
     if (m_log != null) {
       m_log.statusMessage(statusMessagePrefix() + ""Finished."");
     }
 
     // notify listeners
-    DataSetEvent d = new DataSetEvent(this, m_matches.getInputStructure());
+    DataSetEvent d = new DataSetEvent(this, m_matches.getOutputStructure());
     notifyDataListeners(d);
 
     m_busy = false;
   }
\ No newline at end of file
","Fixed a bug in batch mode

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@11956 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,36953.json,aeff9067d2f9056edfc89df194af976e07e4bd40,"@@ -1,105 +1,106 @@
   public void processIncoming(Data data) throws WekaException {
     Object modelToSave = null;
     Instances modelHeader = null;
     Integer setNum = null;
     Integer maxSetNum = null;
 
     if (data.getConnectionName().equals(StepManager.CON_INCREMENTAL_CLASSIFIER)) {
       if (m_incrementalHeader == null
         && !getStepManager().isStreamFinished(data)) {
         m_incrementalHeader =
           ((Instance) data
             .getPayloadElement(StepManager.CON_AUX_DATA_TEST_INSTANCE))
             .dataset();
       }
       if (getStepManager().isStreamFinished(data)
         || (m_incrementalSaveSchedule > 0
           && m_counter % m_incrementalSaveSchedule == 0 && m_counter > 0)) {
         modelToSave =
           (weka.classifiers.Classifier) data
             .getPayloadElement(StepManager.CON_INCREMENTAL_CLASSIFIER);
+        modelHeader = m_incrementalHeader;
       }
     } else {
       modelToSave = data.getPayloadElement(data.getConnectionName());
       modelHeader =
         (Instances) data
           .getPayloadElement(StepManager.CON_AUX_DATA_TRAININGSET);
       setNum =
         (Integer) data.getPayloadElement(StepManager.CON_AUX_DATA_SET_NUM);
       maxSetNum =
         (Integer) data.getPayloadElement(StepManager.CON_AUX_DATA_MAX_SET_NUM);
       if (modelHeader == null) {
         modelHeader =
           (Instances) data.getPayloadElement(StepManager.CON_AUX_DATA_TESTSET);
       }
     }
 
     if (modelToSave != null) {
       if (modelToSave instanceof UpdateableBatchProcessor) {
         try {
           // make sure model cleans up before saving
           ((UpdateableBatchProcessor) modelToSave).batchFinished();
         } catch (Exception ex) {
           throw new WekaException(ex);
         }
       }
 
       if (modelHeader != null) {
         modelHeader = new Instances(modelHeader, 0);
       }
 
       getStepManager().processing();
       String prefix = getStepManager().environmentSubstitute(m_filenamePrefix);
       String relationName =
         m_includeRelationName && modelHeader != null ? modelHeader
           .relationName() : """";
       String setSpec =
         maxSetNum != null && setNum != null ? ""_"" + setNum + ""_"" + maxSetNum
           + ""_"" : """";
 
       String modelName = modelToSave.getClass().getCanonicalName();
       modelName =
         modelName.substring(modelName.lastIndexOf(""."") + 1, modelName.length());
       String filename = """" + prefix + relationName + setSpec + modelName;
       filename = sanitizeFilename(filename);
 
       String dirName =
         getStepManager().environmentSubstitute(m_directory.toString());
       File tempFile = new File(dirName);
       filename = tempFile.getAbsolutePath() + File.separator + filename;
 
       getStepManager().logBasic(
         ""Saving model "" + modelToSave.getClass().getCanonicalName() + "" to ""
           + filename + "".model"");
       getStepManager().statusMessage(
         ""Saving model: "" + modelToSave.getClass().getCanonicalName());
 
       ObjectOutputStream oos = null;
       try {
         oos =
           new ObjectOutputStream(new BufferedOutputStream(new FileOutputStream(
             new File(filename + "".model""))));
         oos.writeObject(modelToSave);
         if (modelHeader != null) {
           oos.writeObject(modelHeader);
         }
         oos.close();
       } catch (Exception ex) {
         throw new WekaException(ex);
       } finally {
         if (data.getConnectionName() != StepManager.CON_INCREMENTAL_CLASSIFIER
           || getStepManager().isStreamFinished(data)) {
           getStepManager().finished();
         }
         if (oos != null) {
           try {
             oos.close();
           } catch (Exception ex) {
             throw new WekaException(ex);
           }
         }
       }
     }
 
     m_counter++;
   }
\ No newline at end of file
","Fixed a bug where the training data header was not getting saved for incremental models

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@13175 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,9988.json,ff62ff2731fed53f3db748855b97c8c08a893dca,"@@ -1,19 +1,19 @@
   protected synchronized void trimZeroDistances(Neighborhood n) {    
-    int index = 0;
+    int index = n.m_neighbors.numInstances();
     for (int i = 0; i < n.m_neighbors.numInstances(); i++) {
       if (n.m_distances[i] > 0) {
         index = i;
         break;
       }
     }
     
     if (index > 0) {
       // trim zero distances
       for (int i = 0; i < index; i++) {
         n.m_neighbors.remove(0);
       }
       double[] newDist = new double[n.m_distances.length - index];
       System.arraycopy(n.m_distances, index, newDist, 0, newDist.length);
       n.m_distances = newDist;
     }
   }
\ No newline at end of file
","Fixed a bug in trimZeroDistances()

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@9723 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,18815.json,0cd35ea8a7783c8ca9d16a71fc888af2d82c3e90,"@@ -1,69 +1,74 @@
   public static void main(String[] args) {
+
+    weka.core.logging.Logger.log(weka.core.logging.Logger.Level.INFO,
+      ""Logging started"");
+    WekaPackageManager.loadPackages(false, true, true);
+
     try {
       LookAndFeel.setLookAndFeel(WorkbenchDefaults.APP_ID,
         WorkbenchDefaults.APP_ID + "".lookAndFeel"", WorkbenchDefaults.LAF);
     } catch (IOException ex) {
       ex.printStackTrace();
     }
     weka.gui.GenericObjectEditor.determineClasses();
 
     try {
       if (System.getProperty(""os.name"").contains(""Mac"")) {
         System.setProperty(""apple.laf.useScreenMenuBar"", ""true"");
       }
       m_workbench = new WorkbenchApp();
       final javax.swing.JFrame jf =
         new javax.swing.JFrame(""Weka "" + m_workbench.getApplicationName());
       jf.getContentPane().setLayout(new java.awt.BorderLayout());
 
       Image icon =
         Toolkit.getDefaultToolkit().getImage(
           WorkbenchApp.class.getClassLoader().getResource(
             ""weka/gui/weka_icon_new_48.png""));
       jf.setIconImage(icon);
 
       jf.getContentPane().add(m_workbench, BorderLayout.CENTER);
       jf.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);
       jf.pack();
       m_workbench.showMenuBar(jf);
       jf.setSize(1024, 768);
       jf.setVisible(true);
 
       if (args.length == 1) {
         System.err.println(""Loading instances from "" + args[0]);
         AbstractFileLoader loader = ConverterUtils.getLoaderForFile(args[0]);
         loader.setFile(new File(args[0]));
         m_workbench.getPerspectiveManager().getMainPerspective()
           .setInstances(loader.getDataSet());
       }
 
       Thread memMonitor = new Thread() {
         @Override
         public void run() {
           while (true) {
             // try {
             // System.out.println(""Before sleeping."");
             // Thread.sleep(10);
 
             if (m_Memory.isOutOfMemory()) {
               // clean up
               jf.dispose();
               m_workbench = null;
               System.gc();
 
               // display error
               System.err.println(""\ndisplayed message:"");
               m_Memory.showOutOfMemory();
               System.err.println(""\nexiting"");
               System.exit(-1);
             }
           }
         }
       };
 
       memMonitor.setPriority(Thread.MAX_PRIORITY);
       memMonitor.start();
     } catch (Exception ex) {
       ex.printStackTrace();
     }
   }
\ No newline at end of file
","Fixed a weird class loading bug that affected loading RPlugin

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@15118 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,30927.json,95a3f1d8e4e0087ec7760ebed797b134337b1feb,"@@ -1,31 +1,32 @@
   protected static String makeOptionStr(AbstractFileLoader loader) {
     StringBuffer result;
     Option option;
 
     result = new StringBuffer(""\nUsage:\n"");
     result.append(""\t"" + loader.getClass().getName().replaceAll("".*\\."", """"));
-    if (loader instanceof OptionHandler) {
-      result.append("" [options]"");
-    }
     result.append("" <"");
     String[] ext = loader.getFileExtensions();
     for (int i = 0; i < ext.length; i++) {
       if (i > 0) {
         result.append("" | "");
       }
       result.append(""file"" + ext[i]);
     }
-    result.append("">\n"");
+    result.append("">"");
+    if (loader instanceof OptionHandler) {
+      result.append("" [options]"");
+    }
+    result.append(""\n"");
 
     if (loader instanceof OptionHandler) {
       result.append(""\nOptions:\n\n"");
       Enumeration<Option> enm = ((OptionHandler) loader).listOptions();
       while (enm.hasMoreElements()) {
         option = enm.nextElement();
         result.append(option.synopsis() + ""\n"");
         result.append(option.description() + ""\n"");
       }
     }
 
     return result.toString();
   }
\ No newline at end of file
","Fixed output bug in command-line help: file name needs to be given *before* options.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@12103 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,12790.json,bfb54a334c1bdae9044c51ab3cd1319734e8cab4,"@@ -1,98 +1,100 @@
     public void buildClusterer(Instances data) throws Exception
   {
     reset();
     meanInstance = new DenseInstance(data.numAttributes());
     for (int i = 0; i < data.numAttributes(); i++)
       meanInstance.setValue(i, data.meanOrMode(i));
     numInstances = data.numInstances();
 
     kMeans.setDistanceFunction(distanceFunction);
     kMeans.setMaxIterations(maxIterations);
     //    kMeans.setInitializeUsingKMeansPlusPlusMethod(initializeWithKMeansPlusPlus);
-    kMeans.setInitializationMethod(new weka.core.SelectedTag(SimpleKMeans.KMEANS_PLUS_PLUS, SimpleKMeans.TAGS_SELECTION));
+    if (initializeWithKMeansPlusPlus) {
+      kMeans.setInitializationMethod(new weka.core.SelectedTag(SimpleKMeans.KMEANS_PLUS_PLUS, SimpleKMeans.TAGS_SELECTION));
+    }
 
     /**
      * step 1: iterate over all restarts and possible k values, record CH-scores
      */
     Random r = new Random(m_Seed);
     double meanCHs[] = new double[maxNumClusters + 1 - minNumClusters];
     double maxCHs[] = new double[maxNumClusters + 1 - minNumClusters];
     int maxSeed[] = new int[maxNumClusters + 1 - minNumClusters];
 
     for (int i = 0; i < restarts; i++)
       {
         if (printDebug)
           System.out.println(""cascade> restarts: "" + (i + 1) + "" / "" + restarts);
 
         for (int k = minNumClusters; k <= maxNumClusters; k++)
           {
             if (printDebug)
               System.out.print(""cascade>  k:"" + k + "" "");
 
             int seed = r.nextInt();
             kMeans.setSeed(seed);
             kMeans.setNumClusters(k);
             kMeans.buildClusterer(data);
             double ch = getCalinskiHarabasz();
 
             int index = k - minNumClusters;
             meanCHs[index] = (meanCHs[index] * i + ch) / (double) (i + 1);
             if (i == 0 || ch > maxCHs[index])
               {
                 maxCHs[index] = ch;
                 maxSeed[index] = seed;
               }
 
             if (printDebug)
               System.out.println("" CH:"" + df.format(ch) + ""  W:""
                                  + df.format(kMeans.getSquaredError() / (double) (numInstances - kMeans.getNumClusters()))
                                  + "" (unweighted:"" + df.format(kMeans.getSquaredError()) + "")  B:""
                                  + df.format(getSquaredErrorBetweenClusters() / (double) (kMeans.getNumClusters() - 1))
                                  + "" (unweighted:"" + df.format(getSquaredErrorBetweenClusters()) + "") "");
           }
       }
     if (printDebug)
       {
         String s = ""cascade> max CH: [ "";
         for (int i = 0; i < maxSeed.length; i++)
           s += df.format(maxCHs[i]) + "" "";
         System.out.println(s + ""]"");
       }
     String s = ""cascade> mean CH: [ "";
     for (int i = 0; i < maxSeed.length; i++)
       s += df.format(meanCHs[i]) + "" "";
 
     finalMeanCH = s + ""]"";
     //    System.out.println(s + ""]"");
 
     /**
      * step 2: select k with best mean CH-score; select seed for max CH score for this k
      */
     int bestK = -1;
     double maxCH = -1;
     for (int k = minNumClusters; k <= maxNumClusters; k++)
       {
         int index = k - minNumClusters;
         if (bestK == -1 || meanCHs[index] > maxCH)
           {
             maxCH = meanCHs[index];
             bestK = k;
           }
       }
     if (manuallySelectNumClusters)
       {
         int selectedK = selectKManually(meanCHs, bestK);
         if (selectedK != -1)
           bestK = selectedK;
       }
     int bestSeed = maxSeed[bestK - minNumClusters];
 
     finalBestK = bestK;
     finalBestSeed = bestSeed;
     //    System.out.println(""cascade> k (yields highest mean CH): "" + bestK);
     //    System.out.println(""cascade> seed (highest CH for k="" + bestK + "") : "" + bestSeed);
 
     kMeans.setSeed(bestSeed);
     kMeans.setNumClusters(bestK);
     kMeans.buildClusterer(data);
   }
\ No newline at end of file
","Fixed a small bug introduced with the last change.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@10457 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,31032.json,4ab412e6138508ec825027ffab22b044aedd6a09,"@@ -1,9 +1,11 @@
   private void initTokenizer(StreamTokenizer tokenizer) {
     tokenizer.resetSyntax();         
     tokenizer.whitespaceChars(0, (' '-1));    
     tokenizer.wordChars(' ','\u00FF');
     tokenizer.whitespaceChars(',',',');
     tokenizer.whitespaceChars('\t','\t');
     tokenizer.commentChar('%');
+    tokenizer.quoteChar('""');
+    tokenizer.quoteChar('\'');
     tokenizer.eolIsSignificant(true);
   }
\ No newline at end of file
","Fixed bug introduced in r4914, where handling of quoted strings got deleted.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@5150 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,28754.json,4718fad5f7d375b9878d9d345d7cefc62c223c70,"@@ -1,25 +1,26 @@
   protected synchronized void completedClassifier(int iteration,
       boolean success) {
-    m_completed++;
 
     if (!success) {
       m_failed++;
       if (m_Debug) {
         System.err.println(""Iteration "" + iteration + "" failed!"");
       }
+    } else {
+      m_completed++;
     }
 
     if (m_completed + m_failed == m_Classifiers.length) {
       if (m_failed > 0) {
         if (m_Debug) {
           System.err.println(""Problem building classifiers - some iterations failed."");
         }
       }
 
       // have to shut the pool down or program executes as a server
       // and when running from the command line does not return to the
       // prompt
       m_executorPool.shutdown();
       block(false);
     }
   }
\ No newline at end of file
","Fixed a bug that prevented the sum of completed and failed classifiers from equaling the total number of classifiers when failures occur. This bug only affected the case when one or more failures occurred.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@6266 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,36601.json,2b4d1e40b90f0675df910618594260c237945fec,"@@ -1,3 +1,3 @@
-  public boolean getStepMustRunSingleThreaded() {
+  public boolean stepMustRunSingleThreaded() {
     return getStepManager().getStepMustRunSingleThreaded();
   }
\ No newline at end of file
","Fixed a bug that could cause Knowledge Flow files to fail to load. This was inadvertently introduced with the single threaded executor addition

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@13700 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,1770.json,81174005aadc513eaeddade0fcb41f7c02f7cf21,"@@ -1,106 +1,107 @@
   protected void makeTree(Instances data, int totalInstances,
     int[][] sortedIndices, double[][] weights, double[] classProbs,
     double totalWeight, double minNumObj, boolean useHeuristic)
     throws Exception {
 
     // if no instances have reached this node (normally won't happen)
     if (totalWeight == 0) {
       m_Attribute = null;
       m_ClassValue = Utils.missingValue();
       m_Distribution = new double[data.numClasses()];
       return;
     }
 
     m_totalTrainInstances = totalInstances;
     m_isLeaf = true;
+    m_Successors = null;
 
     m_ClassProbs = new double[classProbs.length];
     m_Distribution = new double[classProbs.length];
     System.arraycopy(classProbs, 0, m_ClassProbs, 0, classProbs.length);
     System.arraycopy(classProbs, 0, m_Distribution, 0, classProbs.length);
     if (Utils.sum(m_ClassProbs) != 0) {
       Utils.normalize(m_ClassProbs);
     }
 
     // Compute class distributions and value of splitting
     // criterion for each attribute
     double[][][] dists = new double[data.numAttributes()][0][0];
     double[][] props = new double[data.numAttributes()][0];
     double[][] totalSubsetWeights = new double[data.numAttributes()][2];
     double[] splits = new double[data.numAttributes()];
     String[] splitString = new String[data.numAttributes()];
     double[] giniGains = new double[data.numAttributes()];
 
     // for each attribute find split information
     for (int i = 0; i < data.numAttributes(); i++) {
       Attribute att = data.attribute(i);
       if (i == data.classIndex()) {
         continue;
       }
       if (att.isNumeric()) {
         // numeric attribute
         splits[i] = numericDistribution(props, dists, att, sortedIndices[i],
           weights[i], totalSubsetWeights, giniGains, data);
       } else {
         // nominal attribute
         splitString[i] = nominalDistribution(props, dists, att,
           sortedIndices[i], weights[i], totalSubsetWeights, giniGains, data,
           useHeuristic);
       }
     }
 
     // Find best attribute (split with maximum Gini gain)
     int attIndex = Utils.maxIndex(giniGains);
     m_Attribute = data.attribute(attIndex);
 
     m_train = new Instances(data, sortedIndices[attIndex].length);
     for (int i = 0; i < sortedIndices[attIndex].length; i++) {
       Instance inst = data.instance(sortedIndices[attIndex][i]);
       Instance instCopy = (Instance) inst.copy();
       instCopy.setWeight(weights[attIndex][i]);
       m_train.add(instCopy);
     }
 
     // Check if node does not contain enough instances, or if it can not be
     // split,
     // or if it is pure. If does, make leaf.
     if (totalWeight < 2 * minNumObj || giniGains[attIndex] == 0
       || props[attIndex][0] == 0 || props[attIndex][1] == 0) {
       makeLeaf(data);
     }
 
     else {
       m_Props = props[attIndex];
       int[][][] subsetIndices = new int[2][data.numAttributes()][0];
       double[][][] subsetWeights = new double[2][data.numAttributes()][0];
 
       // numeric split
       if (m_Attribute.isNumeric()) {
         m_SplitValue = splits[attIndex];
       } else {
         m_SplitString = splitString[attIndex];
       }
 
       splitData(subsetIndices, subsetWeights, m_Attribute, m_SplitValue,
         m_SplitString, sortedIndices, weights, data);
 
       // If split of the node results in a node with less than minimal number of
       // isntances,
       // make the node leaf node.
       if (subsetIndices[0][attIndex].length < minNumObj
         || subsetIndices[1][attIndex].length < minNumObj) {
         makeLeaf(data);
         return;
       }
 
       // Otherwise, split the node.
       m_isLeaf = false;
       m_Successors = new SimpleCart[2];
       for (int i = 0; i < 2; i++) {
         m_Successors[i] = new SimpleCart();
         m_Successors[i].makeTree(data, m_totalTrainInstances, subsetIndices[i],
           subsetWeights[i], dists[attIndex][i],
           totalSubsetWeights[attIndex][i], minNumObj, useHeuristic);
       }
     }
   }
\ No newline at end of file
","Fixed problem where unprune() step caused root node to not be labeled a leaf when it really is a leaf. This only caused problems when unpruned tree consists of a single node that is a leaf node.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@10490 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,17814.json,34abf3851dd64f8c49bdd8875debb6ec45310dc5,"@@ -1,27 +1,33 @@
   public void setInstancesFromFileQ() {
     
 //     if (m_IOThread == null) {
       int returnVal = m_FileChooser.showOpenDialog(this);
       if (returnVal == JFileChooser.APPROVE_OPTION) {
 	File selected = m_FileChooser.getSelectedFile();
 	
 	try
 	{
 	java.io.Reader r = new java.io.BufferedReader(
 				new java.io.FileReader(selected));
 	Instances i = new Instances(r);
 	setInstances(i);
 	
 	//dataFileLabel.setText(selected.getName());
-	dataFileLabel.setText(i.relationName());
+	String relationName = i.relationName();
+	String truncatedN = relationName;
+	if (relationName.length() > 25) {
+	  truncatedN = relationName.substring(0, 25) + ""..."";
+	}
+	dataFileLabel.setText(truncatedN);
+	dataFileLabel.setToolTipText(relationName);
 	} catch (Exception e)
 	{
 		JOptionPane.showMessageDialog(this,""Can't load at this time,\n""
 				    + ""currently busy with other IO"",
 				    ""Load Instances"",
 				    JOptionPane.WARNING_MESSAGE);
 		    e.printStackTrace();
 	
 	}
       }
   }
\ No newline at end of file
","Fixed a bug that caused a widget layout problem when loading a dataset with a long relation name.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@6482 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,24248.json,3a2501745298eb32d9cb3350d07eb15e93716bb9,"@@ -1,13 +1,19 @@
   public void calculateDerived() {
 
     mean = Double.NaN;
     stdDev = Double.NaN;
     if (count > 0) {
       mean = sum / count;
+      stdDev = Double.POSITIVE_INFINITY;
       if (count > 1) {
 	stdDev = sumSq - (sum * sum) / count;
 	stdDev /= (count - 1);
+        if (stdDev < 0) {
+          System.err.println(""Warning: stdDev value = "" + stdDev 
+                             + "" -- rounded to zero."");
+          stdDev = 0;
+        }
 	stdDev = Math.sqrt(stdDev);
       }
     }
   }
\ No newline at end of file
","Fixed some NaN problems with Std Devs.


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@714 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,23181.json,2e12f8aa73f943180eb6c082e92698d3281baf35,"@@ -1,8 +1,23 @@
   protected void updateCapabilitiesFilter(Capabilities filter) {
     if (filter == null) {
       m_AssociatorEditor.setCapabilitiesFilter(new Capabilities(null));
       return;
     }
     
     m_AssociatorEditor.setCapabilitiesFilter(filter);
+    
+    m_StartBut.setEnabled(true);
+    // Check capabilities
+    Capabilities currentFilter = m_AssociatorEditor.getCapabilitiesFilter();
+    Associator associator = (Associator) m_AssociatorEditor.getValue();
+    Capabilities currentSchemeCapabilities =  null;
+    if (associator != null && currentFilter != null && 
+        (associator instanceof CapabilitiesHandler)) {
+      currentSchemeCapabilities = ((CapabilitiesHandler)associator).getCapabilities();
+      
+      if (!currentSchemeCapabilities.supportsMaybe(currentFilter) &&
+          !currentSchemeCapabilities.supports(currentFilter)) {
+        m_StartBut.setEnabled(false);
+      }
+    }
   }
\ No newline at end of file
","Fixed a bug where the enabled/disabled state of the start button was not being updated when a new data set was set on this panel.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@5384 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,21328.json,be43f6517961a36acbbc66eeb4fe2bc861f6c154,"@@ -1,8 +1,13 @@
   public Object getValue() {
     String path = getAsText();
     if (path != null && path.length() > 0) {
       return new File(path);
     }
 
-    return new File(""."");
+    JFileChooser embeddedEditor = (JFileChooser) m_fileEditor.getCustomEditor();
+    if (embeddedEditor.getFileSelectionMode() == JFileChooser.DIRECTORIES_ONLY) {
+      return new File(""."");
+    } else {
+      return new File("""");
+    }
   }
\ No newline at end of file
","Fixed a bug where '.' was returned when the field was empty in the case where the editor has been configured for files only (rather than directories)

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@13132 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,6470.json,bae2e9e85c74323389279cac539860e8b88d49d2,"@@ -1,27 +1,26 @@
             public void run() {
               PythonSession session;
-              m_executeScriptBut.setEnabled(false);
               try {
                 session = PythonSession.acquireSession(PythonPanel.this);
-                m_logPanel.statusMessage(""Executing script..."");
                 List<String> outAndErr =
                   session.executeScript(m_scriptEditor.getText(),
                     m_debug.isSelected());
                 if (outAndErr.get(0).length() > 0) {
                   logMessage(outAndErr.get(0), null);
                 }
                 if (outAndErr.get(1).length() > 0) {
                   throw new WekaException(outAndErr.get(1));
                 }
                 refreshVarList(session);
                 checkDebug(session);
                 m_logPanel.statusMessage(""OK"");
               } catch (WekaException ex) {
                 ex.printStackTrace();
                 logMessage(null, ex);
                 m_logPanel.statusMessage(""An error occurred. See log."");
               } finally {
                 PythonSession.releaseSession(PythonPanel.this);
                 m_executeScriptBut.setEnabled(true);
+                revalidate();
               }
             }
\ No newline at end of file
","Fixed a refresh bug that affected the variables list

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@11810 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,31459.json,3b4b438af6d33017965dabcd7943e5de02464e2c,"@@ -1,29 +1,29 @@
   void forceDeleteAttributeAt(int position) {
 
     int index = locateIndex(position);
 
     m_NumAttributes--;
     if ((index >= 0) && (m_Indices[index] == position)) {
       int[] tempIndices = new int[m_Indices.length - 1];
       double[] tempValues = new double[m_AttValues.length - 1];
       System.arraycopy(m_Indices, 0, tempIndices, 0, index);
       System.arraycopy(m_AttValues, 0, tempValues, 0, index);
       for (int i = index; i < m_Indices.length - 1; i++) {
 	tempIndices[i] = m_Indices[i + 1] - 1;
 	tempValues[i] = m_AttValues[i + 1];
       }
       m_Indices = tempIndices;
       m_AttValues = tempValues;
     } else {
       int[] tempIndices = new int[m_Indices.length];
       double[] tempValues = new double[m_AttValues.length];
       System.arraycopy(m_Indices, 0, tempIndices, 0, index + 1);
       System.arraycopy(m_AttValues, 0, tempValues, 0, index + 1);
-      for (int i = index + 1; i < m_Indices.length - 1; i++) {
+      for (int i = index + 1; i < m_Indices.length; i++) {
 	tempIndices[i] = m_Indices[i] - 1;
 	tempValues[i] = m_AttValues[i];
       }
       m_Indices = tempIndices;
       m_AttValues = tempValues;
     }
   }
\ No newline at end of file
","Fixed bug in SparseInstance in forceAttributeDelete.


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@1236 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,29293.json,64d11bc2714c068b7bdba2410a82a0d50c430b55,"@@ -1,24 +1,24 @@
   public void setOptions(String[] options) throws Exception {
     String tmpStr;
 
     tmpStr = Utils.getOption('R', options);
     if (tmpStr.length() != 0) {
       setCombinationRule(new SelectedTag(tmpStr, TAGS_RULES));
     } else {
       setCombinationRule(new SelectedTag(AVERAGE_RULE, TAGS_RULES));
     }
 
     m_classifiersToLoad.clear();
     while (true) {
       String loadString = Utils.getOption('P', options);
       if (loadString.length() == 0) {
         break;
       }
 
       m_classifiersToLoad.add(loadString);
     }
 
-    setDoNotPrintModels(Utils.getFlag(""-do-not-print"", options));
+    setDoNotPrintModels(Utils.getFlag(""do-not-print"", options));
 
     super.setOptions(options);
   }
\ No newline at end of file
","Fixed an option handling bug

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@13518 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,9850.json,feaeb8e65657f876489351748361cd4cbc9a7fe5,"@@ -1,104 +1,107 @@
   protected boolean makeTree(FastVector BestFirstElements, BFTree root,
       Instances train, int[][] sortedIndices, double[][] weights,
       double[][][] dists, double[] classProbs, double totalWeight,
       double[] branchProps, int minNumObj, boolean useHeuristic, boolean useGini)
   throws Exception {
 
     if (BestFirstElements.size()==0) return false;
 
     ///////////////////////////////////////////////////////////////////////
     // All information about the node to split (first BestFirst object in
     // BestFirstElements)
     FastVector firstElement = (FastVector)BestFirstElements.elementAt(0);
 
     // node to split
     BFTree nodeToSplit = (BFTree)firstElement.elementAt(0);
 
     // split attribute
     Attribute att = (Attribute)firstElement.elementAt(1);
 
     // info of split value or split string
     double splitValue = Double.NaN;
     String splitStr = null;
     if (att.isNumeric())
       splitValue = ((Double)firstElement.elementAt(2)).doubleValue();
     else {
       splitStr=((String)firstElement.elementAt(2)).toString();
     }
 
     // the best gini gain or information gain of this node
     double gain = ((Double)firstElement.elementAt(3)).doubleValue();
     ///////////////////////////////////////////////////////////////////////
 
     // If no enough data to split for this node or this node can not be split find next node to split.
     if (totalWeight < 2*minNumObj || branchProps[0]==0
 	|| branchProps[1]==0) {
       // remove the first element
       BestFirstElements.removeElementAt(0);
       nodeToSplit.makeLeaf(train);
+      if (BestFirstElements.size() == 0) {
+        return false;
+      }
       BFTree nextNode = (BFTree)
       ((FastVector)BestFirstElements.elementAt(0)).elementAt(0);
       return root.makeTree(BestFirstElements, root, train,
 	  nextNode.m_SortedIndices, nextNode.m_Weights, nextNode.m_Dists,
 	  nextNode.m_ClassProbs, nextNode.m_TotalWeight,
 	  nextNode.m_Props, minNumObj, useHeuristic, useGini);
     }
 
     // If gini gain or information is 0, make all nodes in the BestFirstElements leaf nodes
     // because these node sorted descendingly according to gini gain or information gain.
     // (namely, gini gain or information gain of all nodes in BestFirstEelements is 0).
     if (gain==0) {
       for (int i=0; i<BestFirstElements.size(); i++) {
 	FastVector element = (FastVector)BestFirstElements.elementAt(i);
 	BFTree node = (BFTree)element.elementAt(0);
 	node.makeLeaf(train);
       }
       BestFirstElements.removeAllElements();
       return false;
     }
 
     else {
       // remove the first element
       BestFirstElements.removeElementAt(0);
       nodeToSplit.m_Attribute = att;
       if (att.isNumeric()) nodeToSplit.m_SplitValue = splitValue;
       else nodeToSplit.m_SplitString = splitStr;
 
       int[][][] subsetIndices = new int[2][train.numAttributes()][0];
       double[][][] subsetWeights = new double[2][train.numAttributes()][0];
 
       splitData(subsetIndices, subsetWeights, nodeToSplit.m_Attribute,
 	  nodeToSplit.m_SplitValue, nodeToSplit.m_SplitString,
 	  nodeToSplit.m_SortedIndices, nodeToSplit.m_Weights, train);
 
       // if split will generate node(s) which has total weights less than m_minNumObj,
       // do not split
       int attIndex = att.index();
       if (subsetIndices[0][attIndex].length<minNumObj ||
 	  subsetIndices[1][attIndex].length<minNumObj) {
 
 	nodeToSplit.makeLeaf(train);
 	BFTree nextNode = (BFTree)
 	((FastVector)BestFirstElements.elementAt(0)).elementAt(0);
 	return root.makeTree(BestFirstElements, root, train,
 	    nextNode.m_SortedIndices, nextNode.m_Weights, nextNode.m_Dists,
 	    nextNode.m_ClassProbs, nextNode.m_TotalWeight,
 	    nextNode.m_Props, minNumObj, useHeuristic, useGini);
       }
 
       // split the node
       else {
 	nodeToSplit.m_isLeaf = false;
 	nodeToSplit.m_Attribute = att;
 
 	nodeToSplit.makeSuccessors(BestFirstElements,train,subsetIndices,
 	    subsetWeights,dists, nodeToSplit.m_Attribute,useHeuristic,useGini);
 
 	for (int i=0; i<2; i++){
 	  nodeToSplit.m_Successors[i].makeLeaf(train);
 	}
 
 	return true;
       }
     }
   }
\ No newline at end of file
","Fixed a bug that would occur occasionally when PREPRUNING was selected

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@6949 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,27361.json,84effa0146bd9bb228110c26aaf7a40f959c9043,"@@ -1,3 +1,3 @@
-  public double [][] coefficents() {
+  public double [][] coefficients() {
     return m_Par;
   }
\ No newline at end of file
","Fixed spelling mistake in method to get coefficients :-)


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@4337 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,13928.json,83d877a74c163b3242c845bd9ecc4d2857ef2fa1,"@@ -1,33 +1,37 @@
   public double[] distributionForInstance(Instance instance) throws Exception {
 
     int [] arrIdc = new int[m_BaseClassifiers.length+1];
     arrIdc[m_BaseClassifiers.length]=m_MetaFormat.numAttributes()-1;
     double [] classProbs = new double[m_BaseFormat.numClasses()];
     Instance newInst;
     double sum=0;
 
     for (int i = 0; i<m_MetaClassifiers.length; i++) {
       for (int j = 0; j<m_BaseClassifiers.length; j++)
           arrIdc[j]=m_BaseFormat.numClasses()*j+i;
 
-      m_attrFilter.setAttributeIndicesArray(arrIdc);
+      m_makeIndicatorFilter.setAttributeIndex("""" + (m_MetaFormat.classIndex() + 1));
+      m_makeIndicatorFilter.setNumeric(true);
       m_makeIndicatorFilter.setValueIndex(i);
-
+      m_makeIndicatorFilter.setInputFormat(m_MetaFormat);
       m_makeIndicatorFilter.input(metaInstance(instance));
       m_makeIndicatorFilter.batchFinished();
       newInst = m_makeIndicatorFilter.output();
+
+      m_attrFilter.setAttributeIndicesArray(arrIdc);
+      m_attrFilter.setInvertSelection(true);
       m_attrFilter.setInputFormat(m_makeIndicatorFilter.getOutputFormat());
       m_attrFilter.input(newInst);
       m_attrFilter.batchFinished();
       newInst = m_attrFilter.output();
 
       classProbs[i]=m_MetaClassifiers[i].classifyInstance(newInst);
       if (classProbs[i]>1) { classProbs[i]=1; }
       if (classProbs[i]<0) { classProbs[i]=0; }
       sum+= classProbs[i];
     }
 
     if (sum!=0) Utils.normalize(classProbs,sum);
 
     return classProbs;
   }
\ No newline at end of file
","Fixed problem resulting from changing Range.java


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@1815 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,18243.json,5e2b216f64dbf04497ebd70c8db41a5f21e4ae37,"@@ -1,83 +1,86 @@
   protected void setInstancesFromDBaseQuery() {
 
     try {
       if (m_InstanceQuery == null) {
 	m_InstanceQuery = new InstanceQuery();
       }
       String dbaseURL = m_InstanceQuery.getDatabaseURL();
       String username = m_InstanceQuery.getUsername();
       String passwd = m_InstanceQuery.getPassword();
       /*dbaseURL = (String) JOptionPane.showInputDialog(this,
 					     ""Enter the database URL"",
 					     ""Query Database"",
 					     JOptionPane.PLAIN_MESSAGE,
 					     null,
 					     null,
 					     dbaseURL);*/
      
       
       
       DatabaseConnectionDialog dbd= new DatabaseConnectionDialog(null,dbaseURL,username);
       dbd.setVisible(true);
       
       //if (dbaseURL == null) {
       if (dbd.getReturnValue()==JOptionPane.CLOSED_OPTION) {
 	m_FromLab.setText(""Cancelled"");
 	return;
       }
       dbaseURL=dbd.getURL();
       username=dbd.getUsername();
       passwd=dbd.getPassword();
       m_InstanceQuery.setDatabaseURL(dbaseURL);
       m_InstanceQuery.setUsername(username);
       m_InstanceQuery.setPassword(passwd);
       m_InstanceQuery.setDebug(dbd.getDebug());
       
       m_InstanceQuery.connectToDatabase();
       if (!m_InstanceQuery.experimentIndexExists()) {
 	System.err.println(""not found"");
 	m_FromLab.setText(""No experiment index"");
+        m_InstanceQuery.disconnectFromDatabase();
 	return;
       }
       System.err.println(""found"");
       m_FromLab.setText(""Getting experiment index"");
       Instances index = m_InstanceQuery.retrieveInstances(""SELECT * FROM ""
 				       + InstanceQuery.EXP_INDEX_TABLE);
       if (index.numInstances() == 0) {
 	m_FromLab.setText(""No experiments available"");
+        m_InstanceQuery.disconnectFromDatabase();
 	return;	
       }
       m_FromLab.setText(""Got experiment index"");
 
       DefaultListModel lm = new DefaultListModel();
       for (int i = 0; i < index.numInstances(); i++) {
 	lm.addElement(index.instance(i).toString());
       }
       JList jl = new JList(lm);
       jl.setSelectedIndex(0);
       int result;
       // display dialog only if there's not just one result!
       if (jl.getModel().getSize() != 1) {
         ListSelectorDialog jd = new ListSelectorDialog(null, jl);
         result = jd.showDialog();
       }
       else {
         result = ListSelectorDialog.APPROVE_OPTION;
       }
       if (result != ListSelectorDialog.APPROVE_OPTION) {
 	m_FromLab.setText(""Cancelled"");
+        m_InstanceQuery.disconnectFromDatabase();
 	return;
       }
       Instance selInst = index.instance(jl.getSelectedIndex());
       Attribute tableAttr = index.attribute(InstanceQuery.EXP_RESULT_COL);
       String table = InstanceQuery.EXP_RESULT_PREFIX
 	+ selInst.toString(tableAttr);
       setInstancesFromDatabaseTable(table);
       
     } catch (Exception ex) {
        // 1. print complete stacktrace
        ex.printStackTrace();
        // 2. print message in panel
        m_FromLab.setText(""Problem reading database: '"" + ex.getMessage() + ""'"");
     }
   }
\ No newline at end of file
","Fixed a couple of bugs where database connection was not being closed if close/cancel was pressed. Thanks to Miryam Gomez and Raquel Porras for the bug fix


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@4243 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,19592.json,54c6ebfe7355bada5df3972c74469299c98fc417,"@@ -1,80 +1,82 @@
   protected void updateChart(double [] dataPoint) {
-    int iwidth = m_plotPanel.getWidth();
-    int iheight = m_plotPanel.getHeight();
+    //    int iwidth = m_plotPanel.getWidth();
+    //    int iheight = m_plotPanel.getHeight();
+    int iwidth = m_osi.getWidth(this);
+    int iheight = m_osi.getHeight(this);
 
     //    System.err.println(dataPoint[0]);
     if (dataPoint.length-1 != m_previousY.length) {
       m_previousY = new double [dataPoint.length-1];
       //      m_plotCount = 0;
       for (int i = 0; i < dataPoint.length-1; i++) {
 	m_previousY[i] = convertToPanelY(0);
       }
     }
 
     Graphics osg = m_osi.getGraphics();
     
     Graphics g = m_plotPanel.getGraphics();
 
     // paint the old scale onto the plot if a scale update has occured
     if (m_yScaleUpdate) {
       String maxVal = numToString(m_oldMax);
       String minVal = numToString(m_oldMin);
       String midVal = numToString((m_oldMax - m_oldMin) / 2.0);
       if (m_labelMetrics == null) {
 	m_labelMetrics = g.getFontMetrics(m_labelFont);
       }
       osg.setFont(m_labelFont);
       int wmx = m_labelMetrics.stringWidth(maxVal);
       int wmn = m_labelMetrics.stringWidth(minVal);
       int wmd = m_labelMetrics.stringWidth(midVal);
 
       int hf = m_labelMetrics.getAscent();
       osg.setColor(m_colorList[m_colorList.length-1]);
       osg.drawString(maxVal, iwidth-wmx, hf-2);
       osg.drawString(midVal, iwidth-wmd, (iheight / 2)+(hf / 2));
       osg.drawString(minVal, iwidth-wmn, iheight-1);
       m_yScaleUpdate = false;
       System.err.println(""Here"");
     }
 
     osg.copyArea(m_refreshWidth,0,iwidth-m_refreshWidth,
 		 iheight,-m_refreshWidth,0);
     osg.setColor(Color.black);
     osg.fillRect(iwidth-m_refreshWidth,0, iwidth, iheight);
 
     double pos;
     for (int i = 0; i < dataPoint.length-1; i++) {
       osg.setColor(m_colorList[(i % m_colorList.length)]);
       pos = convertToPanelY(dataPoint[i]);
       osg.drawLine(iwidth-m_refreshWidth, (int)m_previousY[i], 
 		   iwidth-1, (int)pos);
       m_previousY[i] = pos;
       if (dataPoint[dataPoint.length-1] % m_xValFreq == 0) {
 	// draw the actual y value onto the plot for this curve
 	String val = numToString(dataPoint[i]);
 	if (m_labelMetrics == null) {
 	  m_labelMetrics = g.getFontMetrics(m_labelFont);
 	}
 	int hf = m_labelMetrics.getAscent();
 	if (pos - hf < 0) {
 	  pos += hf;
 	}
 	int w = m_labelMetrics.stringWidth(val);
 	osg.setFont(m_labelFont);
 	osg.drawString(val, iwidth-w, (int)pos);
       }
     }
     
     // last element in the data point array contains the data point number
     if (dataPoint[dataPoint.length-1] % m_xValFreq == 0) {
 
       String xVal = """"+(int)dataPoint[dataPoint.length-1];
       osg.setColor(m_colorList[m_colorList.length-1]);
       int w = m_labelMetrics.stringWidth(xVal);
       osg.setFont(m_labelFont);
       osg.drawString(xVal, iwidth-w, iheight - 1);
     }
     g.drawImage(m_osi,0,0,m_plotPanel);
     //    System.err.println(""Finished"");
     //    m_plotCount++;
   }
\ No newline at end of file
","Fixed scrolling problem under java 1.4 on Linux


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@1484 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,30975.json,32ee55c07bd6bb0d5afd27817fc05d405bd35c4f,"@@ -1,50 +1,67 @@
   public void writeIncremental(Instance inst) throws IOException {
     int writeMode = getWriteMode();
     Instances structure = getInstances();
 
     if (getRetrieval() == BATCH || getRetrieval() == NONE) {
       throw new IOException(""Batch and incremental saving cannot be mixed."");
     }
 
     if (writeMode == WAIT) {
       if (structure == null) {
         setWriteMode(CANCEL);
         if (inst != null) {
-          throw new IOException(
-            ""Structure (header Information) has to be set "" + ""in advance"");
+          throw new IOException(""Structure (header Information) has to be set ""
+            + ""in advance"");
         }
       } else {
-        m_dictionaryBuilder.reset();
-        try {
-          m_dictionaryBuilder.setup(structure);
-        } catch (Exception ex) {
-          throw new IOException(ex);
-        }
-        setWriteMode(WRITE);
+        setWriteMode(STRUCTURE_READY);
       }
       writeMode = getWriteMode();
     }
+    if (writeMode == CANCEL) {
+      cancel();
+    }
+
+    if (writeMode == STRUCTURE_READY) {
+      m_dictionaryBuilder.reset();
+      try {
+        m_dictionaryBuilder.setup(structure);
+      } catch (Exception ex) {
+        throw new IOException(ex);
+      }
+      setWriteMode(WRITE);
+      writeMode = getWriteMode();
+    }
 
     if (writeMode == WRITE) {
       if (structure == null) {
         throw new IOException(""No instances information available."");
       }
 
       if (inst != null) {
         m_dictionaryBuilder.processInstance(inst);
       } else {
+        try {
+          m_dictionaryBuilder.finalizeDictionary();
+        } catch (Exception e) {
+          throw new IOException(e);
+        }
         if (retrieveFile() == null && getWriter() == null) {
           if (getSaveBinaryDictionary()) {
             throw new IOException(
               ""Can't output binary dictionary to standard out!"");
           }
           m_dictionaryBuilder.saveDictionary(System.out);
         } else {
-          m_dictionaryBuilder.saveDictionary(getWriter());
+          if (getSaveBinaryDictionary()) {
+            m_dictionaryBuilder.saveDictionary(m_binaryStream);
+          } else {
+            m_dictionaryBuilder.saveDictionary(getWriter());
+          }
         }
 
         resetStructure();
         resetWriter();
       }
     }
   }
\ No newline at end of file
","Fixed a bug in incremental mode

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@12690 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,20298.json,2de75b28460973901afd12db84cb5288c20a8918,"@@ -1,24 +1,23 @@
   private void setupRendererOptsTipText(JLabel optsLab) {
     String renderer = m_rendererCombo.getSelectedItem().toString();
     if (renderer.equalsIgnoreCase(""weka chart renderer"")) {
       // built-in renderer
       WekaOffscreenChartRenderer rcr = new WekaOffscreenChartRenderer();
       String tipText = rcr.optionsTipTextHTML();
       tipText = tipText.replace(""<html>"", ""<html>Comma separated list of options:<br>"");
       optsLab.setToolTipText(tipText);
     } else {
       try {
-        Object rendererO = PluginManager.getPluginInstance(""weka.gui.beans.OffscreenChartRender"",
+        Object rendererO = PluginManager.getPluginInstance(""weka.gui.beans.OffscreenChartRenderer"",
             renderer);
 
         if (rendererO != null) {
           String tipText = ((OffscreenChartRenderer)rendererO).optionsTipTextHTML();
           if (tipText != null && tipText.length() > 0) {
             optsLab.setToolTipText(tipText);
           }
         }
       } catch (Exception ex) {
-
       }
     }
   }
\ No newline at end of file
","Fixed a bug in the routine that sets the tool tip for additional options in plugin renderers.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@7690 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,17871.json,e62dd28a920a99053a89d45c44b4520741764624,"@@ -1,91 +1,92 @@
   public static void main (String [] args) {
     try {
       if (args.length < 8) {
 	System.err.println(""Usage : BoundaryPanel <dataset> ""
 			   +""<class col> <xAtt> <yAtt> ""
 			   +""<base> <# loc/pixel> <kernel bandwidth> ""
 			   +""<display width> ""
 			   +""<display height> <classifier ""
 			   +""[classifier options]>"");
 	System.exit(1);
       }
       final javax.swing.JFrame jf = 
 	new javax.swing.JFrame(""Weka classification boundary visualizer"");
       jf.getContentPane().setLayout(new BorderLayout());
 
       System.err.println(""Loading instances from : ""+args[0]);
       java.io.Reader r = new java.io.BufferedReader(
 			 new java.io.FileReader(args[0]));
       final Instances i = new Instances(r);
       i.setClassIndex(Integer.parseInt(args[1]));
 
       //      bv.setClassifier(new Logistic());
       final int xatt = Integer.parseInt(args[2]);
       final int yatt = Integer.parseInt(args[3]);
       int base = Integer.parseInt(args[4]);
       int loc = Integer.parseInt(args[5]);
 
       int bandWidth = Integer.parseInt(args[6]);
       int panelWidth = Integer.parseInt(args[7]);
       int panelHeight = Integer.parseInt(args[8]);
 
       final String classifierName = args[9];
       final BoundaryPanel bv = new BoundaryPanel(panelWidth,panelHeight);
       bv.addActionListener(new ActionListener() {
 	  public void actionPerformed(ActionEvent e) {
 	    String classifierNameNew = 
 	      classifierName.substring(classifierName.lastIndexOf('.')+1, 
 				       classifierName.length());
 	    bv.saveImage(classifierNameNew+""_""+i.relationName()
 			 +""_X""+xatt+""_Y""+yatt+"".jpg"");
 	  }
 	});
 
       jf.getContentPane().add(bv, BorderLayout.CENTER);
       jf.setSize(bv.getMinimumSize());
       //      jf.setSize(200,200);
       jf.addWindowListener(new java.awt.event.WindowAdapter() {
 	  public void windowClosing(java.awt.event.WindowEvent e) {
 	    jf.dispose();
 	    System.exit(0);
 	  }
 	});
 
       jf.pack();
       jf.setVisible(true);
       //      bv.initialize();
       bv.repaint();
       
 
       String [] argsR = null;
       if (args.length > 10) {
+	System.err.println(""""+(args.length-10));
 	argsR = new String [args.length-10];
-	for (int j = 9; j < args.length; j++) {
+	for (int j = 10; j < args.length; j++) {
 	  argsR[j-10] = args[j];
 	}
       }
       Classifier c = Classifier.forName(args[9], argsR);
       KDDataGenerator dataGen = new KDDataGenerator();
       dataGen.setKernelBandwidth(bandWidth);
       bv.setDataGenerator(dataGen);
       bv.setNumSamplesPerRegion(loc);
       bv.setGeneratorSamplesBase(base);
       bv.setClassifier((DistributionClassifier)c);
       bv.setTrainingData(i);
       bv.setXAttribute(xatt);
       bv.setYAttribute(yatt);
 
       try {
 	// try and load a color map if one exists
 	FileInputStream fis = new FileInputStream(""colors.ser"");
 	ObjectInputStream ois = new ObjectInputStream(fis);
 	FastVector colors = (FastVector)ois.readObject();
 	bv.setColors(colors);	
       } catch (Exception ex) {
 	System.err.println(""No color map file"");
       }
       bv.start();
     } catch (Exception ex) {
       ex.printStackTrace();
     }
   }
\ No newline at end of file
","Fixed bug in main method


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@1588 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,30018.json,044bb44ae261d7619c1f9d9616f4e996330d7043,"@@ -1,77 +1,75 @@
   protected List<String> checkForNativeLibs(Package toLoad, File packageDir) {
     List<String> jarsForClassloaderToIgnore = new ArrayList<>();
 
     if (toLoad.getPackageMetaDataElement(""NativeLibs"") != null) {
       String nativeLibs =
         toLoad.getPackageMetaDataElement(""NativeLibs"").toString();
       if (nativeLibs.length() > 0) {
         String[] jarsWithLibs = nativeLibs.split("";"");
         for (String entry : jarsWithLibs) {
           String[] jarAndEntries = entry.split("":"");
           if (jarAndEntries.length != 2) {
             System.err
               .println(""Was expecting two entries for native lib spec - ""
                 + ""jar:comma-separated lib paths"");
             continue;
           }
           String jarPath = jarAndEntries[0].trim();
           String[] libPathsInJar = jarAndEntries[1].split("","");
           List<String> libsToInstall = new ArrayList<>();
-          List<String> libsToAddToPath = new ArrayList<>();
           // look at named libs and check if they are already in
           // $WEKA_HOME/native-libs - don't extract a second time, but DO
           // add entries to java.library.path
           for (String lib : libPathsInJar) {
             String libName = lib.trim().replace(""\\"", ""/"");
             if (!nativeLibInstalled(libName.substring(
               libName.lastIndexOf(""/"") + 1, libName.length()))) {
-              libsToInstall.add(libName);
+              libsToInstall.add(libName.substring(
+                libName.lastIndexOf(""/"") + 1, libName.length()));
             }
-            libsToAddToPath.add(libName.substring(libName.lastIndexOf(""/"") + 1,
-              libName.length()));
           }
 
           if (libsToInstall.size() > 0) {
             try {
               installNativeLibs(packageDir, jarPath, libsToInstall);
             } catch (IOException e) {
               e.printStackTrace();
             }
           }
           /*
            * if (libsToAddToPath.size() > 0) {
            * addNativeLibsToLibsProp(libsToAddToPath); }
            */
         }
       }
     }
 
     // now check to see if there is a native loader to inject into the
     // root class loader
     if (toLoad.getPackageMetaDataElement(""InjectLoader"") != null) {
       String injectDetails =
         toLoad.getPackageMetaDataElement(""InjectLoader"").toString();
       String[] entries = injectDetails.split("";"");
 
       for (String entry : entries) {
         String jarPath = entry.trim();
         boolean rootClassLoader = false;
         if (jarPath.startsWith(""root|"")) {
           jarPath = jarPath.replace(""root|"", """");
           rootClassLoader = true;
         }
         String ignoreJar = jarPath.replace(""\\"", ""/"");
         ignoreJar = ignoreJar.substring(ignoreJar.lastIndexOf(""/"") + 1);
 
         jarsForClassloaderToIgnore.add(ignoreJar);
         try {
           WekaPackageClassLoaderManager.injectAllClassesInJar(new File(
             packageDir.toString() + File.separator + jarPath.trim()));
         } catch (Exception e) {
           e.printStackTrace();
         }
       }
     }
 
     return jarsForClassloaderToIgnore;
   }
\ No newline at end of file
","Fixed a bug in the native lib installation routine

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@13561 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,3629.json,34ee50c28e6d5f6dc2ea9bff29e6d09545fb601e,"@@ -1,38 +1,38 @@
   public void start() throws WekaException {
     if (getStepManager().numIncomingConnections() == 0) {
       getStepManager().processing();
       ClassLoader orig = Thread.currentThread().getContextClassLoader();
       try {
         String jobName = ""WekaKF:"" + m_runningJob.getJobName();
         Thread.currentThread()
           .setContextClassLoader(this.getClass().getClassLoader());
 
         List<StepManager> outConns =
           getStepManager().getOutgoingConnections().get(""success"");
         if (outConns != null) {
           for (StepManager manager : outConns) {
             jobName += ""+"" + ((AbstractSparkJob) ((StepManagerImpl) manager)
               .getManagedStep()).getUnderlyingJob().getJobName();
           }
         }
         m_runningJob.setJobName(jobName);
         getStepManager()
           .logBasic(""Starting Spark job as start point: "" + jobName);
 
         // we are a start point. Assumption is that we're the *only* start point
         // as things will break down if there are more than one.
         try {
           m_sparkLogAppender = m_runningJob.initJob(null);
         } catch (Exception ex) {
-          ex.printStackTrace();
+          m_runningJob = null;
           throw new WekaException(ex);
         }
         m_currentContext = m_runningJob.getSparkContext();
         m_cachingStrategy = m_runningJob.getCachingStrategy();
         m_outputDirectory = m_runningJob.getSparkJobConfig().getOutputDir();
       } finally {
         Thread.currentThread().setContextClassLoader(orig);
       }
       runJob();
     }
   }
\ No newline at end of file
","Fixed a bug that prevented spark step options from being altered after a job had been run and suffered a failure

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@12960 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,29409.json,c06f15670aa5dc47487a677160a087b8ab2d869a,"@@ -1,3 +1,3 @@
   public String getRevision() {
-    return RevisionUtils.extract(""$Revision: 1.1 $"");
+    return RevisionUtils.extract(""$Revision$"");
   }
\ No newline at end of file
","Fixed a bug introduced by the improvements in derived fields where field definitions for inputs were not being set correctly.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@5028 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,25760.json,b63980e747df9f6abe802dfdf83f00c171dec0ea,"@@ -1,17 +1,25 @@
     protected double[][] getCoefficients(){
 	double[][] coefficients = new double[m_numClasses][m_numericDataHeader.numAttributes() + 1];
 	for (int j = 0; j < m_numClasses; j++) {
 	    //go through simple regression functions and add their coefficient to the coefficient of
 	    //the attribute they are built on.
 	    for (int i = 0; i < m_numRegressions; i++) {
 		
 		double slope = m_regressions[j][i].getSlope();
 		double intercept = m_regressions[j][i].getIntercept();
 		int attribute = m_regressions[j][i].getAttributeIndex();
 		
 		coefficients[j][0] += intercept;
 		coefficients[j][attribute + 1] += slope;
 	    }
 	}
+        
+        // Need to multiply all coefficients by (J-1) / J
+        for (int j = 0; j < coefficients.length; j++) {
+          for (int i = 0; i < coefficients[0].length; i++) {
+            coefficients[j][i] *= (double)(m_numClasses - 1) / (double)m_numClasses;
+          }
+        }
+
 	return coefficients;
     }
\ No newline at end of file
","Fixed bug in output of coefficients and intercept: they needed to be multiplied by (J-1)/J, where J is the number of classes. This affected LMT and SimpleLogistic.


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@3930 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,10869.json,d7b954bf6ad31fcb8c1e3fd0ed630c511674efa0,"@@ -1,103 +1,105 @@
     protected Instances determineOutputFormat(Instances inputFormat) throws Exception {
 
         // Sample subset of instances
         Filter filter = Filter.makeCopy(getFilter());
         filter.setInputFormat(inputFormat);
         m_Sample = Filter.useFilter(inputFormat, filter);
 
         // Compute kernel-based matrices for subset
         m_Kernel = Kernel.makeCopy(m_Kernel);
         m_Kernel.buildKernel(m_Sample);
         int m = m_Sample.numInstances();
         int n = inputFormat.numInstances();
         Matrix khatM = new UpperSymmDenseMatrix(m);
         for (int i = 0; i < m; i++) {
             for (int j = i; j < m; j++) {
                 khatM.set(i, j, m_Kernel.eval(i, j, m_Sample.instance(i)));
             }
         }
         m_Kernel.clean();
 
         if (m_Debug) {
             Matrix kbM = new DenseMatrix(n, m);
             for (int i = 0; i < n; i++) {
                 for (int j = 0; j < m; j++) {
                     kbM.set(i, j, m_Kernel.eval(-1, j, inputFormat.instance(i)));
                 }
             }
 
             // Calculate SVD of kernel matrix
             SVD svd = SVD.factorize(khatM);
 
             double[] singularValues = svd.getS();
             Matrix sigmaI = new UpperSymmDenseMatrix(m);
             for (int i = 0; i < singularValues.length; i++) {
                 if (singularValues[i] > SMALL) {
                     sigmaI.set(i, i, 1.0 / singularValues[i]);
                 }
             }
 
             System.err.println(""U :\n"" + svd.getU());
             System.err.println(""Vt :\n"" + svd.getVt());
             System.err.println(""Reciprocal of singular values :\n"" + sigmaI);
 
             Matrix pseudoInverse = svd.getU().mult(sigmaI, new DenseMatrix(m,m)).mult(svd.getVt(), new DenseMatrix(m,m));
 
             // Compute reduced-rank version
             Matrix khatr = kbM.mult(pseudoInverse, new DenseMatrix(n, m)).mult(kbM.transpose(new DenseMatrix(m, n)), new DenseMatrix(n,n));
 
             System.err.println(""Reduced rank matrix: \n"" + khatr);
         }
 
         // Compute weighting matrix
         if (getUseSVD()) {
             SVD svd = SVD.factorize(khatM);
             double[] e = svd.getS();
             Matrix dhatr = new UpperSymmDenseMatrix(e.length);
             for (int i = 0; i < e.length; i++) {
                 if (Math.sqrt(e[i]) > SMALL) {
                     dhatr.set(i, i, 1.0 / Math.sqrt(e[i]));
                 }
             }
             if (m_Debug) {
                 System.err.println(""U matrix :\n"" + svd.getU());
                 System.err.println(""Vt matrix :\n"" + svd.getVt());
                 System.err.println(""Singluar values \n"" + Utils.arrayToString(svd.getS()));
                 System.err.println(""Reciprocal of square root of singular values :\n"" + dhatr);
             }
             m_WeightingMatrix = dhatr.mult(svd.getVt(), new DenseMatrix(m,m));
         } else {
 
             SymmDenseEVD evd = SymmDenseEVD.factorize(khatM);
             double[] e = evd.getEigenvalues();
             Matrix dhatr = new UpperSymmDenseMatrix(e.length);
             for (int i = 0; i < e.length; i++) {
                 if (Math.sqrt(e[i]) > SMALL) {
                     dhatr.set(i, i, 1.0 / Math.sqrt(e[i]));
                 }
             }
             if (m_Debug) {
                 System.err.println(""Eigenvector matrix :\n"" + evd.getEigenvectors());
                 System.err.println(""Eigenvalues \n"" + Utils.arrayToString(evd.getEigenvalues()));
                 System.err.println(""Reciprocal of square root of eigenvalues :\n"" + dhatr);
             }
             m_WeightingMatrix = dhatr.mult(evd.getEigenvectors().transpose(), new DenseMatrix(m,m));
         }
 
         if (m_Debug) {
             System.err.println(""Weighting matrix: \n"" + m_WeightingMatrix);
         }
 
         // Construct header for output format
         boolean hasClass = (inputFormat.classIndex() >= 0);
         ArrayList<Attribute> atts = new ArrayList<Attribute>(m + ((hasClass) ? 1 : 0));
         for (int i = 0; i < m; i++) {
             atts.add(new Attribute(""z"" + (i + 1)));
         }
         if (hasClass) {
             atts.add((Attribute) inputFormat.classAttribute().copy());
         }
         Instances d = new Instances(inputFormat.relationName(), atts, 0);
-        d.setClassIndex(d.numAttributes() - 1);
+        if (hasClass) {
+          d.setClassIndex(d.numAttributes() - 1);
+        }
         return d;
     }
\ No newline at end of file
","Bug fix: class index in output was set to last attribute even if input data did not have class.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@14365 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,10869.json,ff769b98dbd0a017a91ca677f90dc3750b239511,"@@ -1,67 +1,87 @@
     protected Instances determineOutputFormat(Instances inputFormat) throws Exception {
 
         // Sample subset of instances
         Filter filter = Filter.makeCopy(getFilter());
         filter.setInputFormat(inputFormat);
         m_Sample = Filter.useFilter(inputFormat, filter);
 
         // Compute kernel-based matrices for subset
         m_Kernel = Kernel.makeCopy(m_Kernel);
         m_Kernel.buildKernel(m_Sample);
         int m = m_Sample.numInstances();
         int n = inputFormat.numInstances();
         double[][] khat = new double[m][m];
         for (int i = 0; i < m; i++) {
             for (int j = i; j < m; j++) {
                 khat[i][j] = m_Kernel.eval(i, j, m_Sample.instance(i));
                 khat[j][i] = khat[i][j];
             }
         }
         Matrix khatM = new Matrix(khat);
-        /*double[][] kb = new double[m][n];
-        for (int i = 0; i < m; i++) {
-            for (int j = i; j < n; j++) {
-                kb[i][j] = m_Kernel.eval(-1, i, inputFormat.instance(i));
+
+        if (m_Debug) {
+            double[][] kb = new double[n][m];
+            for (int i = 0; i < n; i++) {
+                for (int j = 0; j < m; j++) {
+                    kb[i][j] = m_Kernel.eval(-1, j, inputFormat.instance(i));
+                }
             }
-        }
-        Matrix kbM = new Matrix(kb).transpose();*/
+            Matrix kbM = new Matrix(kb);
 
-        // Calculate SVD of kernel matrix
-        SingularValueDecomposition svd = new SingularValueDecomposition(new Matrix(khat));
+            // Calculate SVD of kernel matrix
+            SingularValueDecomposition svd = new SingularValueDecomposition(new Matrix(khat));
 
-        double[] singularValues = svd.getSingularValues();
-        Matrix sigmaI = new Matrix(m,m);
-        for (int i = 0; i < singularValues.length; i++) {
-            sigmaI.set(i, i, 1.0 / singularValues[i]);
+            double[] singularValues = svd.getSingularValues();
+            Matrix sigmaI = new Matrix(m, m);
+            for (int i = 0; i < singularValues.length; i++) {
+                if (singularValues[i] > 1e-6) {
+                    sigmaI.set(i, i, 1.0 / singularValues[i]);
+                }
+            }
+
+            System.out.println(""U :\n"" + svd.getU());
+            System.out.println(""V :\n"" + svd.getV());
+            System.out.println(""Reciprocal of singular values :\n"" + sigmaI);
+
+            Matrix pseudoInverse = svd.getV().times(sigmaI).times(svd.getU().transpose());
+
+            // Compute reduced-rank version
+            Matrix khatr = kbM.times(pseudoInverse).times(kbM.transpose());
+
+            System.out.println(""Reduced rank matrix: \n"" + khatr);
         }
 
-        m_WeightingMatrix = sigmaI.times(svd.getV().transpose());
-
-
-        /* Matrix pseudoInverse = svd.getV().transpose().times(sigmaI).times(svd.getU().transpose());
-
-        // Compute reduced-rank version
-        Matrix khatr = kbM.times(pseudoInverse).times(kbM.transpose());
-
-        // Get eigenvalues and eigenvectors of reduced-rank matrix
-        EigenvalueDecomposition evd = new EigenvalueDecomposition(khatr);
+        // Get eigenvalues and eigenvectors
+        EigenvalueDecomposition evd = new EigenvalueDecomposition(khatM);
         double[] e = evd.getRealEigenvalues();
         Matrix dhatr = new Matrix(e.length, e.length);
         for (int i  = 0; i < e.length; i++) {
-            dhatr.set(i, i, 1./Math.sqrt(e[i]));
+            dhatr.set(i, i, 1.0/Math.sqrt(e[i]));
         }
-        m_WeightingMatrix = dhatr.times(evd.getV()); */
+        if (m_Debug) {
+            System.out.println(""Eigenvector matrix :\n"" + evd.getV());
+            System.out.println(""Eigenvalue matrix \n"" + evd.getD());
+            System.out.println(""Reciprocal of square root of eigenvalues :\n"" + dhatr);
+        }
+
+        //System.out.println(""Reconstructed matrix: \n"" + evd.getV().times(evd.getD()).times(evd.getV().inverse())
+
+        m_WeightingMatrix = dhatr.times(evd.getV().transpose());
+
+        if (m_Debug) {
+            System.out.println(""Weighting matrix: \n"" + m_WeightingMatrix);
+        }
 
         // Construct header for output format
         boolean hasClass = (inputFormat.classIndex() >= 0);
         ArrayList<Attribute> atts = new ArrayList<Attribute>(m + ((hasClass) ? 1 : 0));
         for (int i = 0; i < m; i++) {
             atts.add(new Attribute(""z"" + (i + 1)));
         }
         if (hasClass) {
             atts.add((Attribute) inputFormat.classAttribute().copy());
         }
         Instances d = new Instances("""", atts, 0);
         d.setClassIndex(d.numAttributes() - 1);
         return d;
     }
\ No newline at end of file
","Several bug fixes.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@12516 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,18657.json,c9a6740cbebd93b5978b7e993e314995eb4db94f,"@@ -1,17 +1,27 @@
   public void insertInstance(int index, boolean notify) {
     if (!m_IgnoreChanges) {
       addUndoPoint();
     }
     double[] vals = new double[m_Data.numAttributes()];
+
+    // set any string or relational attribute values to missing
+    // in the new instance, just in case this is the very first
+    // instance in the dataset.
+    for (int i = 0; i < m_Data.numAttributes(); i++) {
+      if (m_Data.attribute(i).isString()
+        || m_Data.attribute(i).isRelationValued()) {
+        vals[i] = Utils.missingValue();
+      }
+    }
     Instance toAdd = new DenseInstance(1.0, vals);
     if (index < 0) {
       m_Data.add(toAdd);
     } else {
       m_Data.add(index, toAdd);
     }
     if (notify) {
       notifyListener(new TableModelEvent(this, m_Data.numInstances() - 1,
         m_Data.numInstances() - 1, TableModelEvent.ALL_COLUMNS,
         TableModelEvent.INSERT));
     }
   }
\ No newline at end of file
","Fixed a bug in the insertion of new instances. Now sets the value of relational and string attributes in the new instance to missing, just in case the new instance is the very first one in the dataset

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@12708 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,33458.json,b7e34d731ed42ab40ad353a159d93fb4247a9bc9,"@@ -1,24 +1,26 @@
   public String substitute(String source) throws Exception {
     // Grab each variable out of the string
     int index = source.indexOf(""${"");
 
     while (index >= 0) {
       index += 2;
       int endIndex = source.indexOf('}');
       if (endIndex >= 0 && endIndex > index +1) {
         String key = source.substring(index, endIndex);
 
         // look this sucker up
         String replace = m_envVars.get(key);
         if (replace != null) {
           String toReplace = ""${"" + key + ""}"";
           source = source.replace(toReplace, replace);
         } else {
           throw new Exception(""[Environment] Variable "" 
                               + key + "" doesn't seem to be set."");
         }
+      } else {
+        break;
       }
       index = source.indexOf(""${"");
     }
     return source;
   }
\ No newline at end of file
","Fixed a bug that caused an infinite loop in substitute(). Now uses a TreeMap instead of a HashMap so that keys are kept in sorted order.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@5368 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,24845.json,ceb6ad5f19eef0a321d4c4ad851a2bba76e1ebb0,"@@ -1,5 +1,4 @@
   public String globalInfo() {
     return ""Hierarchical clustering class.\n""
-      + ""Implements a number of classic agglomorative (i.e. bottom up) hierarchical clustering methods""
-      + ""based on ."";
+      + ""Implements a number of classic agglomerative (i.e., bottom up) hierarchical clustering methods."";
   }
\ No newline at end of file
","Fixed bug in globalInfo() method.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@13174 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,15454.json,be743132c9f71754ed911dce8ed0a797b9314166,"@@ -1,18 +1,18 @@
   public Enumeration<Option> listOptions() {
 
     Vector<Option> newVector = new Vector<Option>(1);
 
     newVector
       .addElement(new Option(
-        ""\tNew field specification (name@type@value).\n""
+        ""\tNew field specification (name@type:value).\n""
           + ""\t Environment variables may be used for any/all parts of the\n""
           + ""\tspecification. Type can be one of (numeric, nominal, string or date).\n""
           + ""\tThe value for date be a specific date string or the special string\n""
           + ""\t\""now\"" to indicate the current date-time. A specific date format\n""
           + ""\tstring for parsing specific date values can be specified by suffixing\n""
           + ""\tthe type specification - e.g. \""myTime@date:MM-dd-yyyy@08-23-2009\"".""
           + ""This option may be specified multiple times"", ""A"", 1,
         ""-A <name@type@value>""));
 
     return newVector.elements();
   }
\ No newline at end of file
","Fixed a bug in the help info for the -A option

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@13337 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,15454.json,611c95b4ddf959002e0360d9c109a532143b3d2c,"@@ -1,18 +1,18 @@
   public Enumeration<Option> listOptions() {
 
     Vector<Option> newVector = new Vector<Option>(1);
 
     newVector
       .addElement(new Option(
         ""\tNew field specification (name@type@value).\n""
           + ""\t Environment variables may be used for any/all parts of the\n""
           + ""\tspecification. Type can be one of (numeric, nominal, string or date).\n""
           + ""\tThe value for date be a specific date string or the special string\n""
           + ""\t\""now\"" to indicate the current date-time. A specific date format\n""
           + ""\tstring for parsing specific date values can be specified by suffixing\n""
           + ""\tthe type specification - e.g. \""myTime@date:MM-dd-yyyy@08-23-2009\"".""
           + ""This option may be specified multiple times"", ""A"", 1,
-        ""-A <name:type:value>""));
+        ""-A <name@type@value>""));
 
     return newVector.elements();
   }
\ No newline at end of file
","Fixed an error in the listOptions output

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@12731 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,26007.json,6fcd46acab99a453150b3418dc7da518be7033d2,"@@ -1,43 +1,43 @@
   private String ruleToString() {
     StringBuffer text = new StringBuffer();
 
     if (m_splitAtts.length > 0) {
       text.append(""IF\n"");
 
       for (int i = m_splitAtts.length - 1; i >= 0; i--) {
 	text.append(""\t"" + m_covered.attribute(m_splitAtts[i]).name() + "" "");
 
 	if (m_relOps[i] == 0) {
 	  text.append(""<= "");
 	} else {
 	  text.append(""> "");
 	} 
 
 	text.append(Utils.doubleToString(m_splitVals[i], 1, 3) + ""\n"");
       } 
 
       text.append(""THEN\n"");
     } 
 
     if (m_ruleModel != null) {
       try {
 	text.append(m_ruleModel.printNodeLinearModel());
 	text.append("" ["" + m_numCovered/*m_covered.numInstances()*/);
 
 	if (m_globalAbsDev > 0.0) {
 	  text.append(""/""+Utils.doubleToString((100 * 
 						   m_ruleModel.
 						   rootMeanSquaredError() / 
-						   m_globalAbsDev), 1, 3) 
+						   m_globalStdDev), 1, 3) 
 		      + ""%]\n\n"");
 	} else {
 	  text.append(""]\n\n"");
 	} 
       } catch (Exception e) {
 	return ""Can't print rule"";
       } 
     } 
     
     //    System.out.println(m_instances);
     return text.toString();
   } 
\ No newline at end of file
","Fixed bug in rule output. Second number in the brackets at a leaf now reports the rms error as a percentage of the global standard deviation.


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@3106 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,14982.json,e15ee656dfd1f2636611269ded7d3ce754f975c0,"@@ -1,80 +1,90 @@
   public int[] search (ASEvaluation ASEval, Instances data)
     throws Exception {
     int i, j;
 
     if (!(ASEval instanceof AttributeEvaluator)) {
       throw  new Exception(ASEval.getClass().getName() 
 			   + "" is not a"" 
 			   + ""Attribute evaluator!"");
     }
-    
-    if (ASEval instanceof AttributeTransformer) {
-      data = ((AttributeTransformer)ASEval).transformedHeader();
-    }
 
     m_numAttribs = data.numAttributes();
 
     if (ASEval instanceof UnsupervisedAttributeEvaluator) {
       m_hasClass = false;
     }
     else {
-      m_hasClass = true;
       m_classIndex = data.classIndex();
+      if (m_classIndex >= 0) {	
+	m_hasClass = true;
+      } else {
+	m_hasClass = false;
+      }
+    }
+
+    // get the transformed data and check to see if the transformer
+    // preserves a class index
+    if (ASEval instanceof AttributeTransformer) {
+      data = ((AttributeTransformer)ASEval).transformedHeader();
+      if (m_classIndex >= 0 && data.classIndex() >= 0) {
+	m_classIndex = data.classIndex();
+	m_hasClass = true;
+      }
     }
 
 
     m_startRange.setUpper(m_numAttribs - 1);
     if (!(getStartSet().equals(""""))) {
       m_starting = m_startRange.getSelection();
     }
     
     int sl=0;
     if (m_starting != null) {
       sl = m_starting.length;
     }
     if ((m_starting != null) && (m_hasClass == true)) {
       // see if the supplied list contains the class index
       boolean ok = false;
       for (i = 0; i < sl; i++) {
 	if (m_starting[i] == m_classIndex) {
 	  ok = true;
 	  break;
 	}
       }
       
       if (ok == false) {
 	sl++;
       }
     }
     else {
       if (m_hasClass == true) {
 	sl++;
       }
     }
 
 
     m_attributeList = new int[m_numAttribs - sl];
     m_attributeMerit = new double[m_numAttribs - sl];
 
     // add in those attributes not in the starting (omit list)
     for (i = 0, j = 0; i < m_numAttribs; i++) {
       if (!inStarting(i)) {
 	m_attributeList[j++] = i;
       }
     }
 
     AttributeEvaluator ASEvaluator = (AttributeEvaluator)ASEval;
 
     for (i = 0; i < m_attributeList.length; i++) {
       m_attributeMerit[i] = ASEvaluator.evaluateAttribute(m_attributeList[i]);
     }
 
     double[][] tempRanked = rankedAttributes();
     int[] rankedAttributes = new int[m_attributeList.length];
 
     for (i = 0; i < m_attributeList.length; i++) {
       rankedAttributes[i] = (int)tempRanked[i][0];
     }
 
     return  rankedAttributes;
   }
\ No newline at end of file
","Fixed a bug with handling class index when used with attribute transformers


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@2023 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,8085.json,908420a70784469c92b61a26142bb14cd748d5d5,"@@ -1,57 +1,59 @@
   public void finalizeTask() throws Exception {
     if (m_classifier == null) {
       throw new Exception(""No classifier has been set"");
     }
 
     if (m_classifier instanceof UpdateableClassifier
       && !m_batchTrainedIncremental) {
       // nothing to do except possibly down-sample predictions for
       // auc/prc
       if (m_predFrac > 0) {
         ((AggregateableEvaluationWithPriors) m_eval).prunePredictions(
           m_predFrac, m_seed);
       }
 
       return;
     }
 
     m_trainingHeader.compactify();
 
     Instances test = m_trainingHeader;
     Random r = new Random(m_seed);
     test.randomize(r);
     if (test.classAttribute().isNominal() && m_totalFolds > 1) {
       test.stratify(m_totalFolds);
     }
 
     if (m_totalFolds > 1 && m_foldNumber >= 1) {
       test = test.testCV(m_totalFolds, m_foldNumber - 1);
     }
 
     m_numTestInstances = test.numInstances();
 
-    if (m_classifier instanceof BatchPredictor) {
+    if (m_classifier instanceof BatchPredictor
+      && ((BatchPredictor) m_classifier)
+        .implementsMoreEfficientBatchPrediction()) {
 
       // this method always stores the predictions for AUC, so we need to get
-      // rid of them if we're note doing any AUC computation
+      // rid of them if we're not doing any AUC computation
       m_eval.evaluateModel(m_classifier, test);
-      if (m_predFrac < 0) {
+      if (m_predFrac <= 0) {
         ((AggregateableEvaluationWithPriors) m_eval).deleteStoredPredictions();
       }
     } else {
       for (int i = 0; i < test.numInstances(); i++) {
         if (m_predFrac > 0) {
           m_eval.evaluateModelOnceAndRecordPrediction(m_classifier,
             test.instance(i));
         } else {
           m_eval.evaluateModelOnce(m_classifier, test.instance(i));
         }
       }
     }
 
     // down-sample predictions for auc/prc
     if (m_predFrac > 0) {
       ((AggregateableEvaluationWithPriors) m_eval).prunePredictions(m_predFrac,
         m_seed);
     }
   }
\ No newline at end of file
","Fixed a bug (due to changes in BatchPredictor) that caused predictions for AUC, AUPRC to always be retained regardless of the user-specified fraction

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@12342 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,26472.json,aab16fcf5619d64b56a044bb7acaa276a2f2857b,"@@ -1,12 +1,15 @@
   public double matthewsCorrelationCoefficient(int classIndex) {
     double numTP = numTruePositives(classIndex);
     double numTN = numTrueNegatives(classIndex);
     double numFP = numFalsePositives(classIndex);
     double numFN = numFalseNegatives(classIndex);
     double n = (numTP * numTN) - (numFP * numFN);
     double d = (numTP + numFP) * (numTP + numFN) * (numTN + numFP)
         * (numTN + numFN);
     d = Math.sqrt(d);
+    if (d == 0) {
+      d = 1;
+    }
 
     return n / d;
   }
\ No newline at end of file
","Fixed a bug in the MCC calculation - MCC should be zero if the denominator of the calculation is zero.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@9101 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,32917.json,db5c23a0208b68d40384c60c377e2e204c0b098e,"@@ -1,17 +1,17 @@
   public void setOptions(String[] options) throws Exception {
-    String nnSearchClass = Utils.getOption('D', options);
+    String nnSearchClass = Utils.getOption('A', options);
     if(nnSearchClass.length() != 0) {
       String nnSearchClassSpec[] = Utils.splitOptions(nnSearchClass);
       if(nnSearchClassSpec.length == 0) { 
         throw new Exception(""Invalid DistanceFunction specification string.""); 
       }
       String className = nnSearchClassSpec[0];
       nnSearchClassSpec[0] = """";
 
       setDistanceFunction( (DistanceFunction)
-                            Utils.forName( NearestNeighbourSearch.class, 
+                            Utils.forName( DistanceFunction.class, 
                                            className, nnSearchClassSpec) );
     }
     else 
       this.setDistanceFunction(new EuclideanDistance());  
   }
\ No newline at end of file
","New Reorder filter. Improvement of docs for Copy filter. Improvements to ArffViewer. Bug fix in NearestNeighbourSearch option setting. All from Peter.


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@2325 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,15986.json,a67dbdf599b532b4d05eec72b79cc0a92a58bb0f,"@@ -1,27 +1,29 @@
   public boolean setInputFormat(Instances instanceInfo) throws Exception {
     
     super.setInputFormat(instanceInfo);
 
     int[] attsToDelete = new int[instanceInfo.numAttributes()];
     int numToDelete = 0;
     for (int i=0; i<instanceInfo.numAttributes(); i++) {
-      if (i == instanceInfo.classIndex()) continue; // skip class
+      if ((i == instanceInfo.classIndex() && !m_invert)) {
+	continue; // skip class
+      }
       if (instanceInfo.attribute(i).type() == m_attTypeToDelete)
 	attsToDelete[numToDelete++] = i;
     }
 
     int[] finalAttsToDelete = new int[numToDelete];
     System.arraycopy(attsToDelete, 0, finalAttsToDelete, 0, numToDelete);
     
     m_attributeFilter.setAttributeIndicesArray(finalAttsToDelete);
     m_attributeFilter.setInvertSelection(m_invert);
     
     boolean result = m_attributeFilter.setInputFormat(instanceInfo);
     Instances afOutputFormat = m_attributeFilter.getOutputFormat();
     
     // restore old relation name to hide attribute filter stamp
     afOutputFormat.setRelationName(instanceInfo.relationName());
 
     setOutputFormat(afOutputFormat);
     return result;
   }
\ No newline at end of file
","Fixed bug.


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@1805 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,10085.json,7d3176f1d203310d133e13abf01de23e6eb5784f,"@@ -1,7 +1,5 @@
-    public int[] postProcess(int[] attributeSet) {
+  public void clean() {
 
     // save memory
     m_trainInstances = new Instances(m_trainInstances, 0);
-
-    return attributeSet;
   }
\ No newline at end of file
","Fixed a bug when generating a ranking via GreedyStepwise

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@11854 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,30928.json,656caee9c08b0537064158bcef54389068beb1eb,"@@ -1,55 +1,57 @@
   public static void runFileLoader(AbstractFileLoader loader, String[] options) {
     // help request?
     try {
       String[] tmpOptions = options.clone();
       if (Utils.getFlag('h', tmpOptions)) {
         System.err.println(""\nHelp requested\n"" + makeOptionStr(loader));
         return;
       }
     } catch (Exception e) {
       // ignore it
     }
 
     if (options.length > 0) {
+      String fileName = options[0];
+      options[0] = """";
       if (loader instanceof OptionHandler) {
         // set options
         try {
           ((OptionHandler) loader).setOptions(options);
           // find file
           for (int i = 0; i < options.length; i++) {
             if (options[i].length() > 0) {
               options = new String[] { options[i] };
               break;
             }
           }
         } catch (Exception ex) {
           System.err.println(makeOptionStr(loader));
           System.exit(1);
         }
       }
 
       try {
-        loader.setFile(new File(options[0]));
+        loader.setFile(new File(fileName));
         // incremental
         if (loader instanceof IncrementalConverter) {
           Instances structure = loader.getStructure();
           System.out.println(structure);
           Instance temp;
           do {
             temp = loader.getNextInstance(structure);
             if (temp != null) {
               System.out.println(temp);
             }
           } while (temp != null);
         }
         // batch
         else {
           System.out.println(loader.getDataSet());
         }
       } catch (Exception ex) {
         ex.printStackTrace();
       }
     } else {
       System.err.println(makeOptionStr(loader));
     }
   }
\ No newline at end of file
","Bug fix: file name wasn't removed from options array.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@12104 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,21177.json,e137d2cd150f941d4ad96e9bcb3d3a27f7153b2e,"@@ -1,29 +1,33 @@
   protected int getIndexOfAttribute(Instances insts, String attName) {
     
+    if (attName == null) {
+      return -1;
+    }
+    
     // special first and last strings
     if (attName.equalsIgnoreCase(""/last"")) {
       return insts.numAttributes() - 1;
     }
     if (attName.equalsIgnoreCase(""/first"")) {
       return 0;
     }
     if (attName.startsWith(""/"")) {
       // try and parse remainder as a number
       String numS = attName.replace(""/"", """");
       try {
         int index = Integer.parseInt(numS);
         index--; // from 1-based to 0-based
         if (index >= 0 && index < insts.numAttributes()) {
           return index;
         }
       } catch (NumberFormatException e) {        
       }      
     }
     
     Attribute att = insts.attribute(attName);
     if (att != null) {
       return att.index();
     }
     
     return -1; // not found
   }  
\ No newline at end of file
","Small bug fix in the routine that finds attribute indexes.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@7639 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,20328.json,8e2c885e0e2766ce262502a0ba98b112379f314f,"@@ -1,24 +1,24 @@
   private void setupRendererOptsTipText(JLabel optsLab) {
     String renderer = m_rendererCombo.getSelectedItem().toString();
     if (renderer.equalsIgnoreCase(""weka chart renderer"")) {
       // built-in renderer
       WekaOffscreenChartRenderer rcr = new WekaOffscreenChartRenderer();
       String tipText = rcr.optionsTipTextHTML();
       tipText = tipText.replace(""<html>"", ""<html>Comma separated list of options:<br>"");
       optsLab.setToolTipText(tipText);
     } else {
       try {
-        Object rendererO = PluginManager.getPluginInstance(""weka.gui.beans.OffscreenChartRender"",
+        Object rendererO = PluginManager.getPluginInstance(""weka.gui.beans.OffscreenChartRenderer"",
             renderer);
 
         if (rendererO != null) {
           String tipText = ((OffscreenChartRenderer)rendererO).optionsTipTextHTML();
           if (tipText != null && tipText.length() > 0) {
             optsLab.setToolTipText(tipText);
           }
         }
       } catch (Exception ex) {
 
       }
     }
   }
\ No newline at end of file
","Fixed a bug in the routine that sets the tool tip for additional options in plugin renderers.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@7689 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,20328.json,68eef00749a6bf58cbca2344dd6f91e526407d21,"@@ -1,24 +1,24 @@
   private void setupRendererOptsTipText(JLabel optsLab) {
     String renderer = m_rendererCombo.getSelectedItem().toString();
     if (renderer.equalsIgnoreCase(""weka chart renderer"")) {
       // built-in renderer
       WekaOffscreenChartRenderer rcr = new WekaOffscreenChartRenderer();
       String tipText = rcr.optionsTipTextHTML();
-      tipText = tipText.replace(""<html>"", ""<html>Comma separate list of options:<br>"");
+      tipText = tipText.replace(""<html>"", ""<html>Comma separated list of options:<br>"");
       optsLab.setToolTipText(tipText);
     } else {
       try {
         Object rendererO = PluginManager.getPluginInstance(""weka.gui.beans.OffscreenChartRender"",
             renderer);
 
         if (rendererO != null) {
           String tipText = ((OffscreenChartRenderer)rendererO).optionsTipTextHTML();
           if (tipText != null && tipText.length() > 0) {
             optsLab.setToolTipText(tipText);
           }
         }
       } catch (Exception ex) {
 
       }
     }
   }
\ No newline at end of file
","Fixed a spelling mistake in a tooltip.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@7635 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,3145.json,d00cb09c5d77936fe79ca4e6697fc4b8dde11de4,"@@ -1,50 +1,51 @@
   protected List<Instances> initializeWithRandomCenters(
     JavaRDD<Instance> dataset, Instances headerWithSummary, int numRuns,
     int numClusters) throws IOException, DistributedWekaException {
 
     Instances headerNoSummary =
       CSVToARFFHeaderReduceTask.stripSummaryAtts(headerWithSummary);
 
     // sample all runs worth of initial centers in one hit
     // take twice as many as needed in case there are duplicates
     int seed = 1;
     if (!DistributedJobConfig.isEmpty(getRandomSeed())) {
       try {
         seed = Integer.parseInt(environmentSubstitute(getRandomSeed()));
       } catch (NumberFormatException e) {
         // don't complain
       }
     }
 
     // oversample for > 1 cluster per run, so that we have some options if there
     // are duplicates in the list. numClusters == 1 will be used when seeding
     // the k-means|| initialization process
+    int oversampleFactor = numClusters > 1 ? 2 : 1;
     List<Instance> centerList =
-      dataset.takeSample(true, numClusters > 1 ? 2 : 1 * numRuns * numClusters,
-        seed);
+      dataset.takeSample(true, oversampleFactor * numRuns * numClusters,
+                         seed);
 
     // make sure that start points and header have been through any filters
     KMeansMapTask forFilteringOnly = new KMeansMapTask();
     try {
       forFilteringOnly.setOptions(Utils
         .splitOptions(environmentSubstitute(getKMeansMapTaskOpts())));
 
       // initialize sketches
       headerNoSummary = forFilteringOnly.init(headerWithSummary);
 
       for (int i = 0; i < centerList.size(); i++) {
         Instance filtered = forFilteringOnly.applyFilters(centerList.get(i));
         centerList.set(i, filtered);
       }
 
     } catch (Exception ex) {
       logMessage(ex);
       throw new DistributedWekaException(ex);
     }
 
     List<Instances> centreCandidates =
       KMeansMapTask.assignStartPointsFromList(numRuns, numClusters, centerList,
         headerNoSummary);
 
     return centreCandidates;
   }
\ No newline at end of file
","Fixed a bug in the standard random initialization routine

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@11926 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,26979.json,483a2a5d5184c1590893885c0a1be41649ba25de,"@@ -1,113 +1,113 @@
   public String toString() {
 
     StringBuffer text = new StringBuffer();
     int printed = 0;
 	
     if ((m_alpha == null) && (m_sparseWeights == null)) {
       return ""SMOreg : No model built yet."";
     }
     try {
       text.append(""SMOreg\n\n"");
 	    
       text.append(""Kernel used : \n"");
       if(m_useRBF) {
 	text.append(""  RBF kernel : K(x,y) = e^-("" + m_gamma + ""* <x-y,x-y>^2)"");
       } else if (m_exponent == 1){
 	text.append(""  Linear Kernel : K(x,y) = <x,y>"");
       } else {
 	if (m_featureSpaceNormalization) {
 	  if (m_lowerOrder){
 	    text.append(""  Normalized Poly Kernel with lower order : K(x,y) = (<x,y>+1)^"" + m_exponent + ""/"" + 
 			""((<x,x>+1)^"" + m_exponent + ""*"" + ""(<y,y>+1)^"" + m_exponent + "")^(1/2)"");		    
 	  } else {
 	    text.append(""  Normalized Poly Kernel : K(x,y) = <x,y>^"" + m_exponent + ""/"" + ""(<x,x>^"" + 
 			m_exponent + ""*"" + ""<y,y>^"" + m_exponent + "")^(1/2)"");
 	  }
 	} else {
 	  if (m_lowerOrder){
 	    text.append(""  Poly Kernel with lower order : K(x,y) = (<x,y> + 1)^"" + m_exponent);
 	  } else {
 	    text.append(""  Poly Kernel : K(x,y) = <x,y>^"" + m_exponent);		
 	  }
 	}
       }
       text.append(""\n\n"");
 
       // display the linear transformation
       String trans = """";
       if (m_filterType == FILTER_STANDARDIZE) {
 	//text.append(""LINEAR TRANSFORMATION APPLIED : \n"");
 	trans = ""(standardized) "";
 	//text.append(trans + m_data.classAttribute().name() + ""  = "" + 
 	//	    m_Alin + "" * "" + m_data.classAttribute().name() + "" + "" + m_Blin + ""\n\n"");
       } else if (m_filterType == FILTER_NORMALIZE) {
 	//text.append(""LINEAR TRANSFORMATION APPLIED : \n"");
 	trans = ""(normalized) "";
 	//text.append(trans + m_data.classAttribute().name() + ""  = "" + 
 	//	    m_Alin + "" * "" + m_data.classAttribute().name() + "" + "" + m_Blin + ""\n\n"");
       }
 
       // If machine linear, print weight vector
       if (!m_useRBF && m_exponent == 1.0) {
 	text.append(""Machine Linear: showing attribute weights, "");
 	text.append(""not support vectors.\n"");
 		
 	// We can assume that the weight vector is stored in sparse
 	// format because the classifier has been built
 	text.append(trans + m_data.classAttribute().name() + "" =\n"");
 	for (int i = 0; i < m_sparseWeights.length; i++) {
-	  if (i != (int)m_classIndex) {
+	  if (m_sparseIndices[i] != (int)m_classIndex) {
 	    if (printed > 0) {
 	      text.append("" + "");
 	    } else {
 	      text.append(""   "");
 	    }
 	    text.append(Utils.doubleToString(m_sparseWeights[i], 12, 4) +
 			"" * "");
 	    if (m_filterType == FILTER_STANDARDIZE) {
 	      text.append(""(standardized) "");
 	    } else if (m_filterType == FILTER_NORMALIZE) {
 	      text.append(""(normalized) "");
 	    }
 	    if (!m_checksTurnedOff) {
 	      text.append(m_data.attribute(m_sparseIndices[i]).name()+""\n"");
 	    } else {
 	      text.append(""attribute with index "" + 
 			  m_sparseIndices[i] +""\n"");
 	    }
 	    printed++;
 	  }
 	}
       } else {
 	text.append(""Support Vector Expansion :\n"");
 	text.append(trans + m_data.classAttribute().name() + "" =\n"");
 	printed = 0;
 	for (int i = 0; i < m_alpha.length; i++) {
 	  double val = m_alpha[i] - m_alpha_[i];
 	  if (java.lang.Math.abs(val) < 1e-4)
 	    continue;
 	  if (printed > 0) {
 	    text.append("" + "");
 	  } else {
 	    text.append(""   "");		    
 	  }
 	  text.append(Utils.doubleToString(val, 12, 4) 
 		      + "" * K[X("" + i + ""), X]\n"");
 	  printed++;
 	}
       }
       if (m_b > 0) {
 	text.append("" + "" + Utils.doubleToString(m_b, 12, 4));
       } else {
 	text.append("" - "" + Utils.doubleToString(-m_b, 12, 4));
       }
       if (m_useRBF || m_exponent != 1.0) {
 	text.append(""\n\nNumber of support vectors: "" + printed);
       }
       text.append(""\n\nNumber of kernel evaluations: "" + m_kernel.numEvals()+ ""\n"");
     } catch (Exception e) {
       return ""Can't print the classifier."";
     }
 
     return text.toString();
   }
\ No newline at end of file
","Fixed bug in output of sparse linear machines (class index was not dealt with correctly (thanks, Bernhard)).


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@2091 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,28766.json,78f99a6107b459a31b5ab63e2f403eb841974e27,"@@ -1,14 +1,19 @@
   public double[] distributionForInstance(Instance instance) throws Exception {
 
     double[] dist = new double[instance.numClasses()];
     switch (instance.classAttribute().type()) {
     case Attribute.NOMINAL:
-      dist[(int)classifyInstance(instance)] = 1.0;
+      double classification = classifyInstance(instance);
+      if (Instance.isMissingValue(classification)) {
+	return dist;
+      } else {
+	dist[(int)classification] = 1.0;
+      }
       return dist;
     case Attribute.NUMERIC:
       dist[0] = classifyInstance(instance);
       return dist;
     default:
       return dist;
     }
   }    
\ No newline at end of file
","Fixed bug that caused incorrect handling of unclassified instances in distributionForInstance()


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@2006 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,28908.json,b842fc63d279fec85c6c091749c5a8b41f36f775,"@@ -1,25 +1,25 @@
   protected Instances metaFormat(Instances instances) throws Exception {
 
     FastVector attributes = new FastVector();
     Instances metaFormat;
     Attribute attribute;
     int i = 0;
 
     for (int k = 0; k < m_Classifiers.length; k++) {
       Classifier classifier = (Classifier) getClassifier(k);
       String name = classifier.getClass().getName();
       if (m_BaseFormat.classAttribute().isNumeric()) {
 	attributes.addElement(new Attribute(name));
       } else {
 	for (int j = 0; j < m_BaseFormat.classAttribute().numValues(); j++) {
 	  attributes.addElement(new Attribute(name + "":"" + 
 					      m_BaseFormat
 					      .classAttribute().value(j)));
 	}
       }
     }
-    attributes.addElement(m_BaseFormat.classAttribute());
+    attributes.addElement(m_BaseFormat.classAttribute().copy());
     metaFormat = new Instances(""Meta format"", attributes, 0);
     metaFormat.setClassIndex(metaFormat.numAttributes() - 1);
     return metaFormat;
   }
\ No newline at end of file
","Apply bug fix from Alexander K. Seewald <alexsee@oefai.at>


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@2237 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,4826.json,6809d47f9b4ddab9de675679cc0cd2f38a66799c,"@@ -1,104 +1,103 @@
   protected void display(ArrayList<Prediction> preds, Attribute classAtt,
     int classValue) {
 
     if (preds == null) {
       JOptionPane.showMessageDialog(null, ""No data available for display!"");
       return;
     }
 
     // Remove prediction objects where either the prediction or the actual value are missing
     ArrayList<Prediction> newPreds = new ArrayList<>();
     for (Prediction p : preds) {
       if (!Utils.isMissingValue(p.actual()) && !Utils
         .isMissingValue(p.predicted())) {
         newPreds.add(p);
       }
     }
     preds = newPreds;
 
     ArrayList<Attribute> attributes = new ArrayList<>(1);
     attributes.add(new Attribute(""class_prob""));
     Instances data =
       new Instances(""class_probabilities"", attributes, preds.size());
 
     for (int i = 0; i < preds.size(); i++) {
       double[] inst =
         { ((NominalPrediction) preds.get(i)).distribution()[classValue] };
       data.add(new DenseInstance(preds.get(i).weight(), inst));
     }
 
     try {
       Discretize d = new Discretize();
       d.setUseEqualFrequency(true);
       d.setBins(
         Integer.max(1, (int) Math.round(Math.sqrt(data.sumOfWeights()))));
       d.setUseBinNumbers(true);
       d.setInputFormat(data);
       data = Filter.useFilter(data, d);
 
       int numBins = data.attribute(0).numValues();
       double[] sumClassProb = new double[numBins];
       double[] sumTrueClass = new double[numBins];
       double[] sizeOfBin = new double[numBins];
       for (int i = 0; i < data.numInstances(); i++) {
         int binIndex = (int) data.instance(i).value(0);
         sizeOfBin[binIndex] += preds.get(i).weight();
         sumTrueClass[binIndex] +=
           preds.get(i).weight() * ((((int) preds.get(i).actual())
             == classValue) ? 1.0 : 0.0);
         sumClassProb[binIndex] +=
           preds.get(i).weight() * ((NominalPrediction) preds.get(i))
             .distribution()[classValue];
       }
 
       ArrayList<Attribute> atts = new ArrayList<>(1);
       atts.add(new Attribute(""average_class_prob""));
       atts.add(new Attribute(""average_true_class_value""));
 
       // Collect data for plotting, making sure that 0,0 and 1,1 are included as invisible points
       Instances cdata =
         new Instances(""calibration_curve_data"", atts, numBins + 2);
       int[] shapeType = new int[numBins + 2];
       boolean[] connectPoint = new boolean[numBins + 2];
       for (int i = 0; i < numBins; i++) {
         double[] v = new double[2];
         v[0] = sumClassProb[i] / sizeOfBin[i];
         v[1] = sumTrueClass[i] / sizeOfBin[i];
         cdata.add(new DenseInstance(sizeOfBin[i], v));
         shapeType[i] = Plot2D.PLUS_SHAPE;
         connectPoint[i] = true;
       }
       double[] zero = new double[2];
       double[] one = new double[2];
       one[0] = 1.0;
       one[1] = 1.0;
       cdata.add(new DenseInstance(0.0, zero));
       cdata.add(new DenseInstance(0.0, one));
       shapeType[shapeType.length - 2] =
         -2; // Hack to make sure that corner points are invisible
       shapeType[shapeType.length - 1] = -2;
 
       PlotData2D plotInfo = new PlotData2D(cdata);
       plotInfo.setConnectPoints(connectPoint);
       plotInfo.setShapeType(shapeType);
-      plotInfo.setPlotName(
-        ""\""Calibration curve for class value \"" + classAtt.value(classValue)"");
+      plotInfo.setPlotName(""Calibration curve for class value "" + classAtt.value(classValue));
       VisualizePanel vp = new VisualizePanel();
       vp.setName(
         ""Calibration curve (x: estimated probability, y: observed probability) for ""
           + classAtt.value(classValue) + "" based on"" + "" "" + numBins
           + "" equal-frequency bins"");
       vp.setMasterPlot(plotInfo);
 
       JFrame frame = new JFrame(
         ""Calibration curve (x: estimated probability, y: observed probability) for ""
           + classAtt.value(classValue) + "" based on"" + "" "" + numBins
           + "" equal-frequency bins"");
       frame.setSize(1024, 800);
       frame.setContentPane(vp);
       frame.setVisible(true);
 
     } catch (Exception ex) {
       ex.printStackTrace();
     }
   }
\ No newline at end of file
","Committed one small bug fix in name of Instances object. Removed one unnecessary import.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@14764 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,22844.json,0f8a283a8a350a9341d33f14127fb4d90fbe0b6c,"@@ -1,25 +1,40 @@
   protected void updateCapabilitiesFilter(Capabilities filter) {
     Instances 		tempInst;
     Capabilities 	filterClass;
 
     if (filter == null) {
       m_ClassifierEditor.setCapabilitiesFilter(new Capabilities(null));
       return;
     }
     
     if (!ExplorerDefaults.getInitGenericObjectEditorFilter())
       tempInst = new Instances(m_Instances, 0);
     else
       tempInst = new Instances(m_Instances);
     tempInst.setClassIndex(m_ClassCombo.getSelectedIndex());
 
     try {
       filterClass = Capabilities.forInstances(tempInst);
     }
     catch (Exception e) {
       filterClass = new Capabilities(null);
     }
     
     // set new filter
     m_ClassifierEditor.setCapabilitiesFilter(filterClass);
+    
+    // Check capabilities
+    m_StartBut.setEnabled(true);
+    Capabilities currentFilter = m_ClassifierEditor.getCapabilitiesFilter();
+    Classifier classifier = (Classifier) m_ClassifierEditor.getValue();
+    Capabilities currentSchemeCapabilities =  null;
+    if (classifier != null && currentFilter != null && 
+        (classifier instanceof CapabilitiesHandler)) {
+      currentSchemeCapabilities = ((CapabilitiesHandler)classifier).getCapabilities();
+      
+      if (!currentSchemeCapabilities.supportsMaybe(currentFilter) &&
+          !currentSchemeCapabilities.supports(currentFilter)) {
+        m_StartBut.setEnabled(false);
+      }
+    }
   }
\ No newline at end of file
","Fixed a bug where the enabled/disabled state of the start button was not being updated when a new data set was set on this panel.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@5382 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,15202.json,e6a516aae06f40c5da24d36795d1ee48b4688fb5,"@@ -1,11 +1,17 @@
   public void setOptions(String[] options) throws Exception {
     
     setAttributeIndices(Utils.getOption('R', options));
     setInvertSelection(Utils.getFlag('V', options));
-    setClassName(Utils.getOption('C', options));
-    setMethodName(Utils.getOption('M', options));
+    String classString = Utils.getOption('C', options);
+    if (classString.length() != 0) {
+      setClassName(classString);
+    }
+    String methodString = Utils.getOption('M', options);
+    if (methodString.length() != 0) {
+      setMethodName(methodString);
+    }
 
     if (getInputFormat() != null) {
       setInputFormat(getInputFormat());
     }
   }
\ No newline at end of file
","Fixed some option-handling bugs.


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@2193 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,23203.json,af433bd414a79a55cf517aeccf73cfc90d5c8089,"@@ -1,13 +1,14 @@
   public void setInstances(Instances inst) {
     m_Instances = inst;
     m_RelationNameLab.setText(m_Instances.relationName());
+    m_RelationNameLab.setToolTipText(m_Instances.relationName());
     m_NumInstancesLab.setText("""" + 
         ((m_showZeroInstancesAsUnknown && m_Instances.numInstances() == 0) 
             ? ""?"" 
             : """" + m_Instances.numInstances()));
     m_NumAttributesLab.setText("""" + m_Instances.numAttributes());
     m_sumOfWeightsLab.setText("""" + 
         ((m_showZeroInstancesAsUnknown && m_Instances.numInstances() == 0) 
             ? ""?"" 
             : """" + Utils.doubleToString(m_Instances.sumOfWeights(), 3)));
   }
\ No newline at end of file
","Fixed a bug where the relation name would overlap the attributes. Now sets the tip text for the relation name label to be equal to the relation name (so that the full relation name can be seen when the mouse hovers over the name on the panel).

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@7229 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,27297.json,334f1a26a1895da32f511cae40ee3143b87295d7,"@@ -1,18 +1,18 @@
   public double SVMOutput(Instance inst) throws Exception {
     
     double result = -m_b;
     // Is the machine linear?
     if (m_weights != null) {
       // Is weight vector stored in sparse format?
-      for (int i = 0; i < m_weights.length; i++) {
+      for (int i = 0; i < inst.numValues(); i++) {
 	if (inst.index(i) != m_classIndex) {
 	  result += m_weights[inst.index(i)] * inst.valueSparse(i);
 	}
       }
     } else {
       for (int i = m_supportVectors.getNext(-1); i != -1; i = m_supportVectors.getNext(i)) {
 	result += (m_alpha[i] - m_alphaStar[i]) * m_kernel.eval(-1, i, inst);
       }
     }
     return result;
   }
\ No newline at end of file
","Fixed bug where a loop a loop iteration was not correct for sparse instances.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@6621 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,9635.json,d31aa1c73607a81824ab967b78e8bf672d9c1a1b,"@@ -1,110 +1,110 @@
   protected void purgeTasks(long purgeInterval) {
     Date now = new Date();
     long nowMilli = now.getTime();
     boolean doPurge = false;
 
     List<WekaTaskEntry> taskList = m_taskMap.getTaskList();
     for (WekaTaskEntry t : taskList) {
       NamedTask task = m_taskMap.getTask(t);
       doPurge = false;
       if (!(task instanceof Scheduled)) {
         // Date lastExecuted = getExecutionTime(t);
         Date lastExecuted = t.getLastExecution();
         if (lastExecuted != null) {
           if (task.getTaskStatus().getExecutionStatus() == TaskStatusInfo.PROCESSING) {
             // don't purge executing tasks!!
             continue;
           }
           long milli = lastExecuted.getTime();
 
           // leave tasks that were sent to us from another server for twice as
           // long in
           // order to give the master a chance to tell us to purge them
           long pI =
             (t.getCameFromMaster() ? (purgeInterval * 2) : purgeInterval);
 
           if (nowMilli - milli > pI) {
             doPurge = true;
           }
         }
       } else {
         Date lastExecuted = t.getLastExecution();
         Date nextExecution =
           ((Scheduled) task).getSchedule().nextExecution(lastExecuted);
         if (nextExecution == null && lastExecuted != null) {
           long milli = lastExecuted.getTime();
 
           // leave tasks that were sent to us from another server for twice as
           // long in
           // order to give the master a chance to tell us to purge them
           long pI =
             (t.getCameFromMaster() ? (purgeInterval * 2) : purgeInterval);
 
           if (nowMilli - milli > pI) {
             doPurge = true;
           }
         }
       }
 
       if (doPurge) {
         PostMethod post = null;
         InputStream is = null;
 
         try {
           String url = ""http://"" + getHostname() + "":"" + getPort();
           url = url.replace("" "", ""%20"");
           url += PurgeTaskServlet.CONTEXT_PATH;
-          url += ""/?name="" + t.toString();
+	  url += ""/?name="" + URLEncoder.encode(t.toString(), ""UTF-8"");
           url += ""&client=Y"";
 
           post = new PostMethod(url);
           post.setDoAuthentication(true);
           post.addRequestHeader(new Header(""Content-Type"", ""text/plain""));
 
           // Get HTTP client
           HttpClient client =
             ConnectionManager.getSingleton().createHttpClient();
           ConnectionManager.addCredentials(client, m_username, m_password);
 
           // Execute request
           int result = client.executeMethod(post);
           // System.out.println(""[WekaServer] Response from master server : "" +
           // result);
           if (result == 401) {
             System.err.println(""[WekaServer] Unable to purge task""
               + "" - authentication required.\n"");
           } else {
             // the response
             is = post.getResponseBodyAsStream();
             ObjectInputStream ois = new ObjectInputStream(is);
             Object response = ois.readObject();
             if (response.toString().startsWith(WekaServlet.RESPONSE_ERROR)) {
               System.err.println(""[WekaServer] A problem occurred while ""
                 + ""trying to purge task ("" + t.toString() + ""): \n"" + ""\t""
                 + response.toString());
             } else {
               System.out.println(""[WekaServer] purged task: "" + t.toString());
             }
           }
         } catch (Exception ex) {
           System.err
             .println(""[WekaServer] A problem occurred while ""
               + ""trying to purge task ("" + t.toString() + ""): ""
               + ex.getMessage());
           ex.printStackTrace();
         } finally {
           if (is != null) {
             try {
               is.close();
             } catch (IOException e) {
               e.printStackTrace();
             }
           }
 
           if (post != null) {
             post.releaseConnection();
           }
         }
       }
     }
   }
\ No newline at end of file
","Fixed a bug in the purge task thread

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@12578 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,33400.json,a69dfab4b09e9d52542306b240900fdbfb951df3,"@@ -1,145 +1,146 @@
   private Instance vectorizeInstance(Instance input, int[] offsetHolder,
     boolean retainStringAttValuesInMemory) throws Exception {
 
     if (!m_inputContainsStringAttributes) {
       return input;
     }
 
     if (m_inputFormat == null) {
       throw new Exception(""No input format available. Call setup() and ""
         + ""make sure a dictionary has been built first."");
     }
 
     if (m_consolidatedDict == null) {
       throw new Exception(""Dictionary hasn't been built or consolidated yet!"");
     }
 
     int indexOffset = 0;
     int classIndex = m_outputFormat.classIndex();
     Map<Integer, double[]> contained = new TreeMap<Integer, double[]>();
     for (int i = 0; i < m_inputFormat.numAttributes(); i++) {
       if (!m_selectedRange.isInRange(i)) {
         if (!m_inputFormat.attribute(i).isString()
           && !m_inputFormat.attribute(i).isRelationValued()) {
 
           // add nominal and numeric directly
           if (input.value(i) != 0.0) {
             contained.put(indexOffset, new double[] { input.value(i) });
           }
         } else {
           if (input.isMissing(i)) {
             contained.put(indexOffset, new double[] { Utils.missingValue() });
           } else if (m_inputFormat.attribute(i).isString()) {
             String strVal = input.stringValue(i);
             if (retainStringAttValuesInMemory) {
               double strIndex =
                 m_outputFormat.attribute(indexOffset).addStringValue(strVal);
               contained.put(indexOffset, new double[] { strIndex });
             } else {
               m_outputFormat.attribute(indexOffset).setStringValue(strVal);
               contained.put(indexOffset, new double[] { 0 });
             }
           } else {
             // relational
             if (m_outputFormat.attribute(indexOffset).numValues() == 0) {
               Instances relationalHeader =
                 m_outputFormat.attribute(indexOffset).relation();
 
               // hack to defeat sparse instances bug
               m_outputFormat.attribute(indexOffset).addRelation(
                 relationalHeader);
             }
             int newIndex =
               m_outputFormat.attribute(indexOffset).addRelation(
                 input.relationalValue(i));
             contained.put(indexOffset, new double[] { newIndex });
           }
         }
         indexOffset++;
       }
     }
 
     offsetHolder[0] = indexOffset;
 
     // dictionary entries
     for (int i = 0; i < m_inputFormat.numAttributes(); i++) {
       if (m_selectedRange.isInRange(i) && !input.isMissing(i)) {
         m_tokenizer.tokenize(input.stringValue(i));
 
         while (m_tokenizer.hasMoreElements()) {
           String word = m_tokenizer.nextElement();
           if (m_lowerCaseTokens) {
             word = word.toLowerCase();
           }
           word = m_stemmer.stem(word);
 
           int[] idxAndDocCount = m_consolidatedDict.get(word);
           if (idxAndDocCount != null) {
             if (m_outputCounts) {
               double[] inputCount =
                 contained.get(idxAndDocCount[0] + indexOffset);
               if (inputCount != null) {
                 inputCount[0]++;
               } else {
                 contained.put(idxAndDocCount[0] + indexOffset,
                   new double[] { 1 });
               }
             } else {
               contained
                 .put(idxAndDocCount[0] + indexOffset, new double[] { 1 });
             }
           }
         }
       }
     }
 
     // TF transform
     if (m_TFTransform) {
       for (Map.Entry<Integer, double[]> e : contained.entrySet()) {
         int index = e.getKey();
         if (index >= indexOffset) {
           double[] val = e.getValue();
           val[0] = Math.log(val[0] + 1);
         }
       }
     }
 
     // IDF transform
     if (m_IDFTransform) {
       for (Map.Entry<Integer, double[]> e : contained.entrySet()) {
         int index = e.getKey();
         if (index >= indexOffset) {
           double[] val = e.getValue();
           String word = m_outputFormat.attribute(index).name();
+          word = word.substring(m_Prefix.length());
           int[] idxAndDocCount = m_consolidatedDict.get(word);
           if (idxAndDocCount == null) {
             throw new Exception(""This should never occur"");
           }
           if (idxAndDocCount.length != 2) {
             throw new Exception(""Can't compute IDF transform as document ""
               + ""counts are not available"");
           }
           val[0] = val[0] * Math.log(m_count / (double) idxAndDocCount[1]);
         }
       }
     }
 
     double[] values = new double[contained.size()];
     int[] indices = new int[contained.size()];
     int i = 0;
     for (Map.Entry<Integer, double[]> e : contained.entrySet()) {
       values[i] = e.getValue()[0];
       indices[i++] = e.getKey().intValue();
     }
 
     Instance inst =
       new SparseInstance(input.weight(), values, indices,
         m_outputFormat.numAttributes());
     inst.setDataset(m_outputFormat);
 
     if (m_normalize) {
       normalizeInstance(inst, indexOffset);
     }
 
     return inst;
   }
\ No newline at end of file
","Fixed a bug that affected the -P option when used in conjuction with the IDF transform

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@12931 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,3374.json,b97c9f7d4a47bf18c449215421f95140d8c6c5ea,"@@ -1,222 +1,222 @@
   public boolean runJobWithContext(JavaSparkContext sparkContext)
     throws IOException, DistributedWekaException {
 
     m_currentContext = sparkContext;
     setJobStatus(JobStatus.RUNNING);
     boolean success = false;
 
     if (m_env == null) {
       m_env = Environment.getSystemWide();
     }
 
     // Make sure that we save out to a subdirectory of the output
     // directory
     String outputPath = environmentSubstitute(m_sjConfig.getOutputDir());
     outputPath = addSubdirToPath(outputPath, OUTPUT_SUBDIR);
 
     JavaRDD<Instance> inputData = null;
     Instances headerWithSummary = null;
     if (getDataset(TRAINING_DATA) != null) {
       inputData = getDataset(TRAINING_DATA).getDataset();
       headerWithSummary = getDataset(TRAINING_DATA).getHeaderWithSummary();
       logMessage(""RDD<Instance> dataset provided: ""
         + inputData.partitions().size() + "" partitions."");
     }
 
     if (inputData == null && headerWithSummary == null) {
       logMessage(""[Randomly shuffle data] Invoking ARFF Job..."");
       m_arffHeaderJob.setEnvironment(m_env);
       m_arffHeaderJob.setLog(getLog());
       m_arffHeaderJob.setStatusMessagePrefix(m_statusMessagePrefix);
       m_arffHeaderJob.setCachingStrategy(getCachingStrategy());
 
       // header job necessary?
       success = m_arffHeaderJob.runJobWithContext(sparkContext);
 
       if (!success) {
         setJobStatus(JobStatus.FAILED);
         statusMessage(""Unable to continue - creating the ARFF header failed!"");
         logMessage(""[Randomly shuffle data] Unable to continue - creating the ARFF header failed!"");
         return false;
       }
 
       Dataset d = m_arffHeaderJob.getDataset(TRAINING_DATA);
 
       headerWithSummary = d.getHeaderWithSummary();
       inputData = d.getDataset();
       logMessage(""Fetching RDD<Instance> dataset from ARFF job: ""
         + inputData.partitions().size() + "" partitions."");
     }
 
     /*
      * int minSlices = 1; if
      * (!DistributedJobConfig.isEmpty(m_sjConfig.getMinInputSlices())) { try {
      * minSlices = Integer
      * .parseInt(environmentSubstitute(m_sjConfig.getMinInputSlices())); } catch
      * (NumberFormatException e) { } }
      */
 
     /*
      * if (!m_cleanOutputDir) { // check for existing chunk files... String
      * pathPlusChunk = outputPath + ""/part-00000"";
      * logMessage(""[Randomly shuffle data] Checking output directory: "" +
      * outputPath); if (SparkJob.checkFileExists(pathPlusChunk)) {
      * logMessage(""[Randomly shuffle data] Output directory is populated "" +
      * ""with randomly shuffled chunk files already - "" + ""no need to execute."");
      * 
      * loadShuffledDataFiles(outputPath, sparkContext,
      * CSVToARFFHeaderReduceTask.stripSummaryAtts(headerWithSummary),
      * minSlices); return true; } }
      */
 
     /*
      * // TODO revisit at some stage... Current assumption: if you // have
      * output from this job as serialized instances then you // are happy with
      * the shuffling and will not want to re-shuffle if
      * (m_sjConfig.getSerializedInput()) { throw new DistributedWekaException(
      * ""Randomly shuffling serialized Instance "" +
      * ""input is not supported yet.""); }
      */
 
     // clean the output directory
     SparkJob.deleteDirectory(outputPath);
 
     String inputFile = environmentSubstitute(m_sjConfig.getInputFile());
 
     int seed = 1;
     if (!DistributedJobConfig.isEmpty(getRandomSeed())) {
       seed = Integer.parseInt(environmentSubstitute(getRandomSeed()));
     }
     final Instances headerNoSummary =
       CSVToARFFHeaderReduceTask.stripSummaryAtts(headerWithSummary);
 
     try {
       WekaClassifierSparkJob.setClassIndex(
         environmentSubstitute(m_classAttribute), headerNoSummary,
         !m_dontDefaultToLastAttIfClassNotSpecified);
 
     } catch (Exception e) {
       logMessage(e);
       throw new DistributedWekaException(e);
     }
 
     // find summary attribute for class (if set, otherwise just use the first
     // numeric on nominal attribute). We're using this simply to find out
     // the total number of instances in the dataset
     String className = null;
     if (headerNoSummary.classIndex() >= 0) {
       className = headerNoSummary.classAttribute().name();
     } else {
       for (int i = 0; i < headerNoSummary.numAttributes(); i++) {
         if (headerNoSummary.attribute(i).isNumeric()
           || headerNoSummary.attribute(i).isNominal()) {
           className = headerNoSummary.attribute(i).name();
           break;
         }
       }
     }
     Attribute summaryClassAtt =
       headerWithSummary
         .attribute(CSVToARFFHeaderMapTask.ARFF_SUMMARY_ATTRIBUTE_PREFIX
           + className);
     if (summaryClassAtt == null) {
       throw new DistributedWekaException(
         ""Was unable to find the summary attribute for "" + ""the class: ""
           + className);
     }
 
     int totalNumInstances = 0;
     int numFoldSlices = 10;
     // summary attribute for getting the total number of instances
     Attribute summaryAttOrig = null;
     for (int i = 0; i < headerNoSummary.numAttributes(); i++) {
       if (headerNoSummary.attribute(i).isNumeric()
         || headerNoSummary.attribute(i).isNominal()) {
         summaryAttOrig = headerNoSummary.attribute(i);
         break;
       }
     }
     String summaryName = summaryAttOrig.name();
     Attribute summaryAtt =
       headerWithSummary
         .attribute(
           CSVToARFFHeaderMapTask.ARFF_SUMMARY_ATTRIBUTE_PREFIX + summaryName);
     if (summaryAtt == null) {
       logMessage(""[RandomizedDataSparkJob] Was unable to find the summary ""
         + ""attribute for attribute: "" + summaryName);
       throw new DistributedWekaException(""Was unable to find the summary ""
         + ""attribute for attribute: "" + summaryName);
     }
 
-    if (summaryAtt.isNominal()) {
+    if (summaryAttOrig.isNominal()) {
       NominalStats stats = NominalStats.attributeToStats(summaryAtt);
       for (String label : stats.getLabels()) {
         totalNumInstances += stats.getCount(label);
       }
     } else {
       NumericStats stats = NumericStats.attributeToStats(summaryAtt);
       totalNumInstances =
         (int) stats.getStats()[ArffSummaryNumericMetric.COUNT.ordinal()];
     }
 
     if (DistributedJobConfig.isEmpty(getNumRandomlyShuffledSplits())
       && DistributedJobConfig.isEmpty(getNumInstancesPerShuffledSplit())) {
       logMessage(""[RandomizedDataSparkJob] Must specify either the number of ""
         + ""splits or the number of instances per split"");
       throw new DistributedWekaException(""Must specify either the number of ""
         + ""splits or the number of instances per split"");
     }
 
     if (!DistributedJobConfig.isEmpty(getNumRandomlyShuffledSplits())) {
       numFoldSlices =
         Integer.parseInt(environmentSubstitute(getNumRandomlyShuffledSplits()));
     } else {
       int numInsts = 0;
       try {
         numInsts =
           Integer
             .parseInt(environmentSubstitute(getNumInstancesPerShuffledSplit()));
       } catch (NumberFormatException ex) {
         throw new DistributedWekaException(ex);
       }
 
       if (numInsts <= 0) {
         throw new DistributedWekaException(
           ""Number of instances per split must "" + ""be > 0"");
       }
 
       if (numInsts > totalNumInstances) {
         throw new DistributedWekaException(""Can't have more instances per split ""
           + ""than there are instances in the dataset!"");
       }
       double nc = (double) totalNumInstances / numInsts;
       nc = Math.ceil(nc);
       numFoldSlices = (int) nc;
     }
     logMessage(""[Randomly shuffle] creating "" + numFoldSlices + "" splits."");
 
     if (headerNoSummary.attribute(className).isNominal()) {
       NominalStats stats = NominalStats.attributeToStats(summaryClassAtt);
       for (String label : stats.getLabels()) {
         totalNumInstances += stats.getCount(label);
       }
     } else {
       NumericStats stats = NumericStats.attributeToStats(summaryClassAtt);
       totalNumInstances =
         (int) stats.getStats()[ArffSummaryNumericMetric.COUNT.ordinal()];
     }
 
     logMessage(""[Randomly shuffle data] Num slices = "" + numFoldSlices);
 
     final Random random = new Random(seed);
     for (int i = 0; i < 20; i++) {
       random.nextInt();
     }
 
     performRandomShuffle(inputData, outputPath, numFoldSlices, random,
       headerWithSummary, headerNoSummary.classIndex());
 
     setJobStatus(JobStatus.FINISHED);
 
     return true;
   }
\ No newline at end of file
","Fixed a bug in the calculation of the total number of instances in the dataset

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@11588 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,4830.json,9202bc66506c46f20388951597366af165de4928,"@@ -1,76 +1,77 @@
   public void processIncoming(Data data) throws WekaException {
 
     if (isStopRequested()) {
       getStepManager().interrupted();
       return;
     }
 
     getStepManager().processing();
 
     Instances predictedInsts = data.getPrimaryPayload();
     int maxSetNum =
       (Integer) data.getPayloadElement(StepManager.CON_AUX_DATA_MAX_SET_NUM);
     int setNum =
       (Integer) data.getPayloadElement(StepManager.CON_AUX_DATA_SET_NUM);
 
     if (maxSetNum > 1 && getPoolSets()) {
       if (m_isReset) {
         m_pooledData = new Instances(predictedInsts);
       } else {
         m_pooledData.addAll(predictedInsts);
       }
     }
 
     m_isReset = false;
 
     if (getPoolSets() && setNum < maxSetNum) {
+      getStepManager().finished();
       return;
     }
 
     if (getPoolSets() && maxSetNum > 1) {
       predictedInsts = m_pooledData;
     }
 
     if (predictedInsts.classIndex() < 0) {
       throw new WekaException(""No class set in the predicted data!"");
     }
 
     int numAttributes = predictedInsts.numAttributes();
     int numClasses = predictedInsts.classAttribute().numValues();
 
     // we always produce a curve for the first label. The user can
     // always choose a label by using a ClassValuePicker step
     Attribute classAtt = predictedInsts.classAttribute();
     Attribute predictedLabelProbAtt =
       predictedInsts.attribute(numAttributes - numClasses);
 
     ArrayList<Prediction> preds = new ArrayList<>();
     for (int i = 0; i < predictedInsts.numInstances(); i++) {
       Instance current = predictedInsts.instance(i);
       double[] dist = new double[numClasses];
       dist[0] = current.value(predictedLabelProbAtt.index());
       double actual = current.classValue();
 
       preds.add(new NominalPrediction(actual, dist, current.weight()));
     }
 
     try {
       Instances curveInsts =
         CalibrationCurveUtils
           .getCalibrationCurveAsInstances(preds, classAtt, 0);
       curveInsts.setRelationName(""__"" + curveInsts.relationName());
 
       Instance zero = curveInsts.remove(curveInsts.numInstances() - 2);
       zero.setWeight(-1);
       curveInsts.add(0, zero);
       curveInsts.lastInstance().setWeight(-1);
       Data output = new Data(StepManager.CON_DATASET, curveInsts);
       output.setPayloadElement(StepManager.CON_AUX_DATA_SET_NUM, 1);
       output.setPayloadElement(StepManager.CON_AUX_DATA_MAX_SET_NUM, 1);
       getStepManager().outputData(output);
     } catch (Exception ex) {
       throw new WekaException(ex);
     }
 
     getStepManager().finished();
   }
\ No newline at end of file
","Small bug fix in reporting finished state for step

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@14772 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,36414.json,81a1e225e8da398eb2d17f911d2de0b246ac22aa,"@@ -1,3 +1,3 @@
     void setUpdateIncrementalClassifier(boolean update) {
-    m_updateIncrementalClassifier = true;
+    m_updateIncrementalClassifier = update;
   }
\ No newline at end of file
","Fixed a bug in the set method for updating an incremental classifier

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@13045 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,15017.json,a9246f58e2844ebadfa2c2b12f3f4d15755f5006,"@@ -1,58 +1,59 @@
   protected Instances process(Instances instances) throws Exception {
     // initializing necessary?
     if (!m_Initialized) {
       // do we have a file to initialize with?
       if ((getInitFile() != null) && getInitFile().isFile()) {
 	DataSource source = new DataSource(getInitFile().getAbsolutePath());
 	Instances data = source.getDataSet();
 	m_InitFileClassIndex.setUpper(data.numAttributes() - 1);
 	data.setClassIndex(m_InitFileClassIndex.getIndex());
 	initFilter(data);
       }
       else {
 	initFilter(instances);
       }
     }
 
     // apply filters
     if (m_Missing != null)
       instances = Filter.useFilter(instances, m_Missing); 
     if (m_NominalToBinary != null)
       instances = Filter.useFilter(instances, m_NominalToBinary); 
     if (m_ActualFilter != null)
       instances = Filter.useFilter(instances, m_ActualFilter);
 
     // backup class attribute and remove it
     double[] classes = instances.attributeToDoubleArray(instances.classIndex());
     int classIndex = instances.classIndex();
+    Attribute classAttribute = (Attribute)instances.classAttribute().copy();
     instances.setClassIndex(-1);
     instances.deleteAttributeAt(classIndex);
 
     // generate new header
     FastVector atts = new FastVector();
     for (int j = 0; j < m_NumTrainInstances; j++)
       atts.addElement(new Attribute(""Kernel "" + j));
-    atts.addElement(new Attribute(""Class""));
+    atts.addElement(classAttribute);
     Instances result = new Instances(""Kernel"", atts, 0);
     result.setClassIndex(result.numAttributes() - 1);
 
     // compute matrix
     for (int i = 0; i < instances.numInstances(); i++) {
       double[] k = new double[m_NumTrainInstances + 1];
       
       for (int j = 0; j < m_NumTrainInstances; j++) {
 	double v = m_ActualKernel.eval(-1, j, instances.instance(i));
 	k[j] = v;
       }
       k[k.length - 1] = classes[i];
 
       // create new instance
       Instance in = new DenseInstance(1.0, k);
       result.add(in);    
     }
 
     if (!isFirstBatchDone())
       setOutputFormat(result);
     
     return result;
   }
\ No newline at end of file
","Fixed bug in KernelFilter: now works with nominal class attributes as well.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@9561 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,36274.json,8072e35dd2cf69509b7d8d77a0a509d3ff3f5202,"@@ -1,82 +1,86 @@
   protected static void addStepJSONtoFlowArray(JSONNode stepArray,
     StepManagerImpl stepManager) throws WekaException {
 
     JSONNode step = stepArray.addObjectArrayElement();
     step.addPrimitive(""class"", stepManager.getManagedStep().getClass()
       .getCanonicalName());
     // step.addPrimitive(STEP_NAME, stepManager.getManagedStep().getName());
     JSONNode properties = step.addObject(PROPERTIES);
     try {
       Step theStep = stepManager.getManagedStep();
       BeanInfo bi = Introspector.getBeanInfo(theStep.getClass());
       PropertyDescriptor[] stepProps = bi.getPropertyDescriptors();
 
       for (PropertyDescriptor p : stepProps) {
         if (p.isHidden() || p.isExpert()) {
           continue;
         }
 
         String name = p.getDisplayName();
         Method getter = p.getReadMethod();
         Method setter = p.getWriteMethod();
         if (getter == null || setter == null) {
           continue;
         }
         boolean skip = false;
         for (Annotation a : getter.getAnnotations()) {
           if (a instanceof NotPersistable) {
             skip = true;
             break;
           }
         }
         if (skip) {
           continue;
         }
 
         Object[] args = {};
         Object propValue = getter.invoke(theStep, args);
         if (propValue == null) {
           properties.addNull(name);
         } else if (propValue instanceof Boolean) {
           properties.addPrimitive(name, (Boolean) propValue);
         } else if (propValue instanceof Integer || propValue instanceof Long) {
           properties.addPrimitive(name,
             new Integer(((Number) propValue).intValue()));
         } else if (propValue instanceof Double) {
           properties.addPrimitive(name, (Double) propValue);
         } else if (propValue instanceof Number) {
           properties.addPrimitive(name,
             new Double(((Number) propValue).doubleValue()));
         } else if (propValue instanceof weka.core.converters.Loader) {
           addLoader(name, (weka.core.converters.Loader) propValue, properties);
         } else if (propValue instanceof weka.core.converters.Saver) {
           addSaver(name, (weka.core.converters.Saver) propValue, properties);
         } else if (propValue instanceof OptionHandler) {
           addOptionHandler(name, (OptionHandler) propValue, properties);
         } else if (propValue instanceof Enum) {
           addEnum(name, (Enum) propValue, properties);
+        } else if (propValue instanceof File) {
+          String fString = propValue.toString();
+          fString = fString.replace('\\', '/');
+          properties.addPrimitive(name, fString);
         } else {
           properties.addPrimitive(name, propValue.toString());
         }
       }
     } catch (Exception ex) {
       throw new WekaException(ex);
     }
 
     JSONNode connections = step.addObject(CONNECTIONS);
     for (Map.Entry<String, List<StepManager>> e : stepManager.m_connectedByTypeOutgoing
       .entrySet()) {
       String connName = e.getKey();
       JSONNode connTypeArray = connections.addArray(connName);
       for (StepManager c : e.getValue()) {
         connTypeArray.addArrayElement(c.getName());
       }
     }
 
     if (stepManager.getStepVisual() != null) {
       String coords =
         """" + stepManager.getStepVisual().getX() + "",""
           + stepManager.getStepVisual().getY();
       step.addPrimitive(COORDINATES, coords);
     }
   }
\ No newline at end of file
","Fixed a bug that affected the parsing of step properties involving files containing Windows separator charactors

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@12964 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,26684.json,f36aad315fb901cb71922f7ae08459999978c9d9,"@@ -1,65 +1,83 @@
   public Instances getCurve(FastVector predictions, int classIndex) {
 
     if ((predictions.size() == 0) ||
         (((NominalPrediction)predictions.elementAt(0))
          .distribution().length <= classIndex)) {
       return null;
     }
 
     double totPos = 0, totNeg = 0;
     double [] probs = getProbabilities(predictions, classIndex);
 
     // Get distribution of positive/negatives
     for (int i = 0; i < probs.length; i++) {
       NominalPrediction pred = (NominalPrediction)predictions.elementAt(i);
       if (pred.actual() == Prediction.MISSING_VALUE) {
         System.err.println(getClass().getName() 
                            + "" Skipping prediction with missing class value"");
         continue;
       }
       if (pred.weight() < 0) {
         System.err.println(getClass().getName() 
                            + "" Skipping prediction with negative weight"");
         continue;
       }
       if (pred.actual() == classIndex) {
         totPos += pred.weight();
       } else {
         totNeg += pred.weight();
       }
     }
 
     Instances insts = makeHeader();
     int [] sorted = Utils.sort(probs);
     TwoClassStats tc = new TwoClassStats(totPos, totNeg, 0, 0);
+    double threshold = 0;
+    double cumulativePos = 0;
+    double cumulativeNeg = 0;
     for (int i = 0; i < sorted.length; i++) {
+
+      if ((i == 0) || (probs[sorted[i]] > threshold)) {
+	tc.setTruePositive(tc.getTruePositive() - cumulativePos);
+	tc.setFalseNegative(tc.getFalseNegative() + cumulativePos);
+	tc.setFalsePositive(tc.getFalsePositive() - cumulativeNeg);
+	tc.setTrueNegative(tc.getTrueNegative() + cumulativeNeg);
+	threshold = probs[sorted[i]];
+	insts.add(makeInstance(tc, threshold));
+	cumulativePos = 0;
+	cumulativeNeg = 0;
+	if (i == sorted.length - 1) {
+	  break;
+	}
+      }
+
       NominalPrediction pred = (NominalPrediction)predictions.elementAt(sorted[i]);
+
       if (pred.actual() == Prediction.MISSING_VALUE) {
-        System.err.println(getClass().getName()
-                           + "" Skipping prediction with missing class value"");
-        continue;
+	System.err.println(getClass().getName()
+			   + "" Skipping prediction with missing class value"");
+	continue;
       }
       if (pred.weight() < 0) {
-        System.err.println(getClass().getName() 
-                           + "" Skipping prediction with negative weight"");
-        continue;
+	System.err.println(getClass().getName() 
+			   + "" Skipping prediction with negative weight"");
+	continue;
       }
       if (pred.actual() == classIndex) {
-        tc.setTruePositive(tc.getTruePositive() - pred.weight());
-        tc.setFalseNegative(tc.getFalseNegative() + pred.weight());
+	cumulativePos += pred.weight();
       } else {
-        tc.setFalsePositive(tc.getFalsePositive() - pred.weight());
-        tc.setTrueNegative(tc.getTrueNegative() + pred.weight());
+	cumulativeNeg += pred.weight();
       }
+
       /*
       System.out.println(tc + "" "" + probs[sorted[i]] 
                          + "" "" + (pred.actual() == classIndex));
       */
-      if ((i != (sorted.length - 1)) &&
+      /*if ((i != (sorted.length - 1)) &&
           ((i == 0) ||  
           (probs[sorted[i]] != probs[sorted[i - 1]]))) {
         insts.add(makeInstance(tc, probs[sorted[i]]));
-      }
+	}*/
     }
     return insts;
   }
\ No newline at end of file
","Fixed bug in ThresholdCurve, which resulted in one instance being on the wrong side of the threshold.


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@2134 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,27269.json,8e4d3f359b3b7e7182d587aaab8f838daae5c8fa,"@@ -1,11 +1,14 @@
   public double eval(int id1, int id2, Instance inst1) 
     throws Exception {
 	
-    double div = Math.sqrt(super.eval(id1, id1, inst1) * 
-			   super.eval(id2, id2, m_data.instance(id2)));
-    if(div != 0){
+
+    double div = Math.sqrt(super.eval(id1, id1, inst1) * ((m_keys != null)
+                           ? super.eval(id2, id2, m_data.instance(id2))
+                           : super.eval(-1, -1, m_data.instance(id2))));
+
+    if(div != 0){      
       return super.eval(id1, id2, inst1) / div;
     } else {
       return 0;
     }
-  }
\ No newline at end of file
+  }    
\ No newline at end of file
","Fixed a bug in NormalizedPolyKernel that resulted in an attempted access to the cache for test instances


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@2490 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,30125.json,4f854d24790f7ba7429f74355b69542147801667,"@@ -1,105 +1,104 @@
   public String toSummaryString() {
 
     StringBuffer result = new StringBuffer();
     result.append(""Relation Name:  "").append(relationName()).append('\n');
     result.append(""Num Instances:  "").append(numInstances()).append('\n');
     result.append(""Num Attributes: "").append(numAttributes()).append('\n');
     result.append('\n');
 
     result.append(Utils.padLeft("""", 5)).append(Utils.padRight(""Name"", 25));
     result.append(Utils.padLeft(""Type"", 5)).append(Utils.padLeft(""Nom"", 5));
     result.append(Utils.padLeft(""Int"", 5)).append(Utils.padLeft(""Real"", 5));
     result.append(Utils.padLeft(""Missing"", 12));
     result.append(Utils.padLeft(""Unique"", 12));
     result.append(Utils.padLeft(""Dist"", 6)).append('\n');
     Instances temp = new Instances(this);
     int total = temp.numInstances();
     for (int i = 0; i < numAttributes(); i++) {
       Attribute a = attribute(i);
       temp.sort(i);
       int intCount = 0, realCount = 0, missingCount = 0;
       int distinctCount = 0, uniqueCount = 0, currentCount = 0;
       double prev = Instance.missingValue();
       for (int j = 0; j < temp.numInstances(); j++) {
 	Instance current = temp.instance(j);
 	if (current.isMissing(i)) {
 	  missingCount = temp.numInstances() - j;
 	  break;
 	}
 	if (Utils.eq(current.value(i), prev)) {
 	  currentCount++;
 	} else {
 	  distinctCount++;
 	  if (currentCount == 1) {
 	    uniqueCount++;
 	  }
 	  if (currentCount > 0) {
 	    if (Utils.eq(prev, (double)((int)prev))) {
 	      intCount += currentCount;
 	    } else {
 	      realCount += currentCount;
 	    }
 	  }
 	  currentCount = 1;
 	  prev = current.value(i);
 	}
       }
       if (currentCount == 1) {
 	uniqueCount++;
       }
       if (currentCount > 0) {
 	if (Utils.eq(prev, (double)((int)prev))) {
 	  intCount += currentCount;
 	} else {
 	  realCount += currentCount;
 	}
       }
-      
       result.append(Utils.padLeft("""" + (i + 1), 4)).append(' ');
       result.append(Utils.padRight(a.name(), 25)).append(' ');
-      int percent;
+      long percent;
       switch (a.type()) {
       case Attribute.NOMINAL:
 	result.append(Utils.padLeft(""Nom"", 4)).append(' ');
-	percent = 100 * intCount / total;
+	percent = Math.round(100.0 * intCount / total);
 	result.append(Utils.padLeft("""" + percent, 3)).append(""% "");
 	result.append(Utils.padLeft("""" + 0, 3)).append(""% "");
-	percent = 100 * realCount / total;
+	percent = Math.round(100.0 * realCount / total);
 	result.append(Utils.padLeft("""" + percent, 3)).append(""% "");
 	break;
       case Attribute.NUMERIC:
 	result.append(Utils.padLeft(""Num"", 4)).append(' ');
 	result.append(Utils.padLeft("""" + 0, 3)).append(""% "");
-	percent = 100 * intCount / total;
+	percent = Math.round(100.0 * intCount / total);
 	result.append(Utils.padLeft("""" + percent, 3)).append(""% "");
-	percent = 100 * realCount / total;
+	percent = Math.round(100.0 * realCount / total);
 	result.append(Utils.padLeft("""" + percent, 3)).append(""% "");
 	break;
       case Attribute.STRING:
 	result.append(Utils.padLeft(""Str"", 4)).append(' ');
-	percent = 100 * intCount / total;
+	percent = Math.round(100.0 * intCount / total);
 	result.append(Utils.padLeft("""" + percent, 3)).append(""% "");
 	result.append(Utils.padLeft("""" + 0, 3)).append(""% "");
-	percent = 100 * realCount / total;
+	percent = Math.round(100.0 * realCount / total);
 	result.append(Utils.padLeft("""" + percent, 3)).append(""% "");
 	break;
       default:
 	result.append(Utils.padLeft(""???"", 4)).append(' ');
 	result.append(Utils.padLeft("""" + 0, 3)).append(""% "");
-	percent = 100 * intCount / total;
+	percent = Math.round(100.0 * intCount / total);
 	result.append(Utils.padLeft("""" + percent, 3)).append(""% "");
-	percent = 100 * realCount / total;
+	percent = Math.round(100.0 * realCount / total);
 	result.append(Utils.padLeft("""" + percent, 3)).append(""% "");
 	break;
       }
       result.append(Utils.padLeft("""" + missingCount, 5)).append("" /"");
-      percent = 100 * missingCount / total;
+      percent = Math.round(100.0 * missingCount / total);
       result.append(Utils.padLeft("""" + percent, 3)).append(""% "");
       result.append(Utils.padLeft("""" + uniqueCount, 5)).append("" /"");
-      percent = 100 * uniqueCount / total;
+      percent = Math.round(100.0 * uniqueCount / total);
       result.append(Utils.padLeft("""" + percent, 3)).append(""% "");
       result.append(Utils.padLeft("""" + distinctCount, 5)).append(' ');
       result.append('\n');
     }
     return result.toString();
   }
\ No newline at end of file
","- Fixed small rounding problem in summary method.


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@105 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,24450.json,d1fccde7b3f541c040561dbcfd7c68890d26bfad,"@@ -1,37 +1,37 @@
   public double logDensity(double[] valuePassed) {
     double[] value = valuePassed.clone();
     double logProb = 0;
     // calculate mean subtractions
     double[] subtractedMean = new double[value.length];
     for (int i = 0; i < value.length; i++) {
       subtractedMean[i] = value[i] - mean[i];
     }
-
+    value = subtractedMean.clone();
     double[][] L = this.chol.getL().getArray();
     int n = this.chol.getL().getRowDimension();
     // Solve L*Y = B;
     for (int k = 0; k < this.chol.getL().getRowDimension(); k++) {
       for (int i = 0; i < k; i++) {
         value[k] -= value[i] * L[k][i];
       }
 
       value[k] /= L[k][k];
     }
 
     // Solve L'*X = Y;
     for (int k = n - 1; k >= 0; k--) {
       for (int i = k + 1; i < n; i++) {
         value[k] -= value[i] * L[i][k];
       }
       value[k] /= L[k][k];
     }
 
     // compute dot product
     double innerProduct = 0;
     // do a fast dot product
     for (int i = 0; i < value.length; i++) {
       innerProduct += value[i] * subtractedMean[i];
     }
     logProb = lnconstant - innerProduct * 0.5;
     return logProb;
   }
\ No newline at end of file
","Bug fixes from Uday

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@10459 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,15350.json,21d3ace55220b46f80de8bfd5ac1a94760fe142b,"@@ -1,39 +1,38 @@
   protected Instances process(Instances instances) throws Exception {
 
     Instances result = getOutputFormat();
 
     for (Instance inst : instances) {
       if (instances.numAttributes() < result.numAttributes()) { // Do we actually need to add an attribute?
         double[] newVals = new double[result.numAttributes()];
         for (int i = 0; i < inst.numValues(); i++) {
           newVals[inst.index(i)] = inst.valueSparse(i);
         }
         String value = """";
         for (int i = 0; i < inst.numAttributes(); i++) {
           if (instances.attribute(i).isNominal() && m_Attributes.isInRange(i) && i != instances.classIndex()) {
             if (Utils.isMissingValue(newVals[i])) {
               value = null;
               break;
             } else {
               value += (value.length() > 0) ? ""_x_"" + instances.attribute(i).value((int) newVals[i]) :
                       instances.attribute(i).value((int) newVals[i]);
             }
           }
         }
         if (value == null) {
           newVals[newVals.length - 1] = Double.NaN;
         } else {
           newVals[newVals.length - 1] = result.attribute(result.numAttributes() - 1).indexOfValue(value);;
         }
-        if (inst instanceof DenseInstance) {
-          result.add(new DenseInstance(inst.weight(), newVals));
-        } else {
-          result.add(new SparseInstance(inst.weight(), newVals));
-        }
+        Instance newInst = inst.copy(newVals);
+        copyValues(newInst, false, inst.dataset(), result);
+        result.add(newInst);
       } else {
+        copyValues(inst, false, inst.dataset(), result);
         result.add(inst);
       }
     }
 
     return result;
   }
\ No newline at end of file
","Bug fix: CartesianProduct should now work correctly with string and relational attributes.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@15075 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,32640.json,f8fa07eb4f3b6e38a4952f907df8574bab292919,"@@ -1,3 +1,3 @@
   public static synchronized void loadPackages(boolean verbose) {
-    loadPackages(verbose, true, true);
+    loadPackages(verbose, false, true);
   }
\ No newline at end of file
","Standard loadPackages() call was not invoking full class discovery due to a bug introduced with the latest changes - fixed.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@10392 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,32072.json,e68cbb019cd730299b6a056ba88d78a04e771a90,"@@ -1,18 +1,17 @@
   protected void initialize() {
-    String part;
+    String part = """";
     URLClassLoader sysLoader;
     URL[] urls;
 
     m_Cache = new Hashtable<String, HashSet<String>>();
 
     sysLoader = (URLClassLoader) getClass().getClassLoader();
     urls = sysLoader.getURLs();
     for (URL url : urls) {
+      part = url.toString();
       if (VERBOSE) {
         System.out.println(""Classpath-part: "" + part);
       }
-
-      part = url.toString();
       initFromClasspathPart(part);
     }
   }
\ No newline at end of file
","Fixed a compilation problem that occurs when VERBOSE is set to true.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@11202 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,21163.json,65f17814a1d6158b5dc0b85d70c32f30efca4908,"@@ -1,18 +1,26 @@
   public EventSetDescriptor [] getEventSetDescriptors() {
     try {
       EventSetDescriptor [] esds =  
       { new EventSetDescriptor(PredictionAppender.class, 
-			       ""dataSet"",
-			       DataSourceListener.class,
-			       ""acceptDataSet""),
-	new EventSetDescriptor(DataSource.class, 
-			       ""instance"",
-			       InstanceListener.class,
-			       ""acceptInstance"")
-         };
+	  ""dataSet"",
+	  DataSourceListener.class,
+      ""acceptDataSet""),
+      new EventSetDescriptor(PredictionAppender.class, 
+	  ""instance"",
+	  InstanceListener.class,
+      ""acceptInstance""),
+      new EventSetDescriptor(PredictionAppender.class, 
+	  ""trainingSet"",
+	  TrainingSetListener.class,
+      ""acceptTrainingSet""),
+      new EventSetDescriptor(PredictionAppender.class, 
+	  ""testSet"",
+	  TestSetListener.class,
+      ""acceptTestSet"")
+      };
       return esds;
     } catch (Exception ex) {
       ex.printStackTrace();
     }
     return null;
   }
\ No newline at end of file
","Fixed a small bug and added event sets for training at test set events.


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@3814 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,32626.json,1d67da514cfac522915affd97cf003f12258f2f5,"@@ -1,46 +1,47 @@
   protected static void establishMirror() {
     if (m_offline) {
       return;
     }
 
     try {
       String mirrorListURL =
-        ""http://www.cs.waikato.ac.nz/ml/weka/packageMetaDataMirror.txt"";
+        ""https://www.cs.waikato.ac.nz/ml/weka/packageMetaDataMirror.txt"";
 
       URLConnection conn = null;
       URL connURL = new URL(mirrorListURL);
 
       if (PACKAGE_MANAGER.setProxyAuthentication(connURL)) {
         conn = connURL.openConnection(PACKAGE_MANAGER.getProxy());
       } else {
         conn = connURL.openConnection();
       }
 
       conn.setConnectTimeout(10000); // timeout after 10 seconds
       conn.setReadTimeout(10000);
 
       BufferedReader bi =
         new BufferedReader(new InputStreamReader(conn.getInputStream()));
 
       REP_MIRROR = bi.readLine();
 
       bi.close();
       if (REP_MIRROR != null && REP_MIRROR.length() > 0) {
         // use the mirror if it is different from the primary repo
         // and the user hasn't specified an explicit repo via the
         // property
         if (!REP_MIRROR.equals(PRIMARY_REPOSITORY) && !USER_SET_REPO) {
 
           log(weka.core.logging.Logger.Level.INFO,
             ""[WekaPackageManager] Package manager using repository mirror: ""
               + REP_MIRROR);
 
           REP_URL = new URL(REP_MIRROR);
         }
       }
     } catch (Exception ex) {
+      ex.printStackTrace();
       log(weka.core.logging.Logger.Level.WARNING,
         ""[WekaPackageManager] The repository meta data mirror file seems ""
           + ""to be unavailable ("" + ex.getMessage() + "")"");
     }
   }
\ No newline at end of file
","Package mirror settings now accessed via https instead of http. Fixes an error that gets printed to the log

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@14973 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,22555.json,6b82052500cf75da83431ce041e21658720d1816,"@@ -1,21 +1,21 @@
   public void layoutEditor() {
     m_stepToBlockBox.setEditable(true);
 
     StepManager sm = getStepToEdit().getStepManager();
     List<StepManagerImpl> flowSteps =
       getMainPerspective().getCurrentLayout().getFlow().getSteps();
     for (StepManagerImpl smi : flowSteps) {
       m_stepToBlockBox.addItem(smi.getName());
     }
 
     JPanel p = new JPanel(new BorderLayout());
-    p.setBorder(BorderFactory.createTitledBorder(""Choose class attribute""));
+    p.setBorder(BorderFactory.createTitledBorder(""Choose step to wait for""));
     p.add(m_stepToBlockBox, BorderLayout.NORTH);
 
     add(p, BorderLayout.CENTER);
 
     String userSelected = ((Block) getStepToEdit()).getStepToWaitFor();
     if (userSelected != null) {
       m_stepToBlockBox.setSelectedItem(userSelected);
     }
   }
\ No newline at end of file
","Fixed a bug in a label

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@12606 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,10201.json,2b9d972bd34de6f7911f39d55f81ab6194452ebe,"@@ -1,14 +1,16 @@
   public Instance getNextInstance(Instances structure) throws IOException {
     if (getRetrieval() == BATCH) {
       throw new IOException(""Cannot mix getting instances in both incremental and batch modes"");
     }
     m_structure = structure;
     setRetrieval(INCREMENTAL);
 
     //Have we read all the data?
     if ((m_currentTimeSlot == 0 && m_dataSet.TDIM == 0) || (m_currentTimeSlot < m_dataSet.TDIM)) {
-      return new SparseInstance(1.0, make1Darray(m_currentTimeSlot++));
+      Instance inst = new SparseInstance(1.0, make1Darray(m_currentTimeSlot++));
+      inst.setDataset(m_structure);
+      return inst;
      } else {
       return null;
     }
   }
\ No newline at end of file
","Fixed bug in incremental loading mode: instance was not assigned to a dataset.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@12106 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,23962.json,f48889f6b6237d7493f1e78fd7c3c417b636f27f,"@@ -1,20 +1,24 @@
   protected String doubleToString(double d, int prec) {
     String result;
     int currentPrec;
     int i;
 
     result = Utils.doubleToString(d, prec);
 
+    if (prec <= 0 || Double.isInfinite(d) || Double.isNaN(d)) {
+      return result;
+    }
+
     // decimal point?
     if (result.indexOf(""."") == -1) {
       result += ""."";
     }
 
     // precision so far?
     currentPrec = result.length() - result.indexOf(""."") - 1;
     for (i = currentPrec; i < prec; i++) {
       result += ""0"";
     }
 
     return result;
   }
\ No newline at end of file
","Fixed bug in output of experiment results occurring when number was NaN (or infinite). In that case, no decimal point and 0s should be added. Also, decimal point is no longer printed if user requests 0 decimal places (e.g., if the user requests precision 0).

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@13955 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,17296.json,9e4a9dc3de5bc88ccad6654a7df72b7c8807bb97,"@@ -1,76 +1,86 @@
   private void determineBounds() {
      double value,min,max;
     
     if (m_plotInstances != null && 
 	m_plotInstances.numAttributes() > 0 &&
 	m_plotInstances.numInstances() > 0) {
       // x bounds
       min=Double.POSITIVE_INFINITY;
       max=Double.NEGATIVE_INFINITY;
       if (m_plotInstances.attribute(m_xIndex).isNominal()) {
 	m_minX = 0;
 	m_maxX = m_plotInstances.attribute(m_xIndex).numValues()-1;
       } else {
 	for (int i=0;i<m_plotInstances.numInstances();i++) {
 	  if (!m_plotInstances.instance(i).isMissing(m_xIndex)) {
 	    value = m_plotInstances.instance(i).value(m_xIndex);
 	    if (value < min) {
 	      min = value;
 	    }
 	    if (value > max) {
 	      max = value;
 	    }
 	  }
 	}
 	
+	// handle case where all values are missing
+	if (min == Double.POSITIVE_INFINITY) min = max = 0.0;
+	
 	m_minX = min; m_maxX = max;
 	if (min == max) {
 	  m_maxX += 0.05;
 	  m_minX -= 0.05;
 	}
       }
 
       // y bounds
       min=Double.POSITIVE_INFINITY;
       max=Double.NEGATIVE_INFINITY;
       if (m_plotInstances.attribute(m_yIndex).isNominal()) {
 	m_minY = 0;
 	m_maxY = m_plotInstances.attribute(m_yIndex).numValues()-1;
       } else {
 	for (int i=0;i<m_plotInstances.numInstances();i++) {
 	  if (!m_plotInstances.instance(i).isMissing(m_yIndex)) {
 	    value = m_plotInstances.instance(i).value(m_yIndex);
 	    if (value < min) {
 	      min = value;
 	    }
 	    if (value > max) {
 	      max = value;
 	    }
 	  }
 	}
 	
+	// handle case where all values are missing
+	if (min == Double.POSITIVE_INFINITY) min = max = 0.0;
+
 	m_minY = min; m_maxY = max;
 	if (min == max) {
 	  m_maxY += 0.05;
 	  m_minY -= 0.05;
 	}
       }
       
       // colour bounds
       min=Double.POSITIVE_INFINITY;
       max=Double.NEGATIVE_INFINITY;
 
       for (int i=0;i<m_plotInstances.numInstances();i++) {
 	if (!m_plotInstances.instance(i).isMissing(m_cIndex)) {
 	  value = m_plotInstances.instance(i).value(m_cIndex);
 	  if (value < min) {
 	    min = value;
 	  }
 	  if (value > max) {
 	    max = value;
 	  }
 	}
       }
+
+      // handle case where all values are missing
+      if (min == Double.POSITIVE_INFINITY) min = max = 0.0;
+
       m_minC = min; m_maxC = max;
     }
   }
\ No newline at end of file
","Fixed bug caused when all numeric values are missing.


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@1220 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,20037.json,af57a617ece4a265b0e23698d4b5ab07ebd17dc5,"@@ -1,12 +1,13 @@
   public boolean eventGeneratable(String eventName) {
     if (m_listenee == null) {
       return false;
     }
 
     if (m_listenee instanceof EventConstraints) {
-      if (!((EventConstraints)m_listenee).eventGeneratable(""classifier"")) {
+      if (!((EventConstraints)m_listenee).
+	  eventGeneratable(""batchClassifier"")) {
 	return false;
       }
     }
     return true;
   }
\ No newline at end of file
","Fixed eventGeneratable bug


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@1631 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,17545.json,9d199c8ab7badc5fe3d5f2680f4caf570d1806f2,"@@ -1,132 +1,133 @@
   private void paintData(Graphics gx) {
 
     for (int j=0;j<m_plots.size();j++) {
       PlotData2D temp_plot = (PlotData2D)(m_plots.elementAt(j));
 
       for (int i=0;i<temp_plot.m_plotInstances.numInstances();i++) {
 	if (temp_plot.m_plotInstances.instance(i).isMissing(m_xIndex) ||
 	    temp_plot.m_plotInstances.instance(i).isMissing(m_yIndex)) {
 	} else {
 	  double x = (temp_plot.m_pointLookup[i][0] + 
 		      temp_plot.m_pointLookup[i][2]);
 	  double y = (temp_plot.m_pointLookup[i][1] + 
 		      temp_plot.m_pointLookup[i][3]);
 
 	  double prevx = 0;
 	  double prevy = 0;
 	  if (i > 0) {
 	    prevx = (temp_plot.m_pointLookup[i - 1][0] + 
 			temp_plot.m_pointLookup[i - 1][2]);
 	    prevy = (temp_plot.m_pointLookup[i - 1][1] + 
 			temp_plot.m_pointLookup[i - 1][3]);
 	  }
 
 	  int x_range = (int)x - m_XaxisStart;
 	  int y_range = (int)y - m_YaxisStart;
 
 	  if (x_range >= 0 && y_range >= 0) {
 	    if (m_drawnPoints[x_range][y_range] == i 
 		|| m_drawnPoints[x_range][y_range] == 0
 		|| temp_plot.m_displayAllPoints == true) {
 	      m_drawnPoints[x_range][y_range] = i;
 	      if (temp_plot.m_plotInstances.attribute(m_cIndex).isNominal()) {
 		if (temp_plot.m_plotInstances.attribute(m_cIndex).numValues() >
 		    m_colorList.size() && 
 		    !temp_plot.m_useCustomColour) {
 		  extendColourMap(temp_plot.m_plotInstances.
 				  attribute(m_cIndex).numValues());
 		}
 
 		Color ci;
 		if (temp_plot.m_plotInstances.instance(i).
 		    isMissing(m_cIndex)) {
 		  ci = Color.gray;
 		} else {
 		  int ind = (int)temp_plot.m_plotInstances.instance(i).
 		    value(m_cIndex);
 		  ci = (Color)m_colorList.elementAt(ind);
 		}
 
 		if (!temp_plot.m_useCustomColour) {
 		  gx.setColor(ci);	    
 		} else {
 		  gx.setColor(temp_plot.m_customColour);
 		}
 
 		if (temp_plot.m_plotInstances.instance(i).
 		    isMissing(m_cIndex)) {
 		  if (temp_plot.m_connectPoints[i] == true) {
 		    drawDataPoint(x,y,prevx,prevy,temp_plot.m_shapeSize[i],
 				  MISSING_SHAPE,gx);
 		  } else {
 		    drawDataPoint(x,y,temp_plot.m_shapeSize[i],
 				  MISSING_SHAPE,gx);
 		  }
 		} else {
 		  if (temp_plot.m_shapeType[i] == CONST_AUTOMATIC_SHAPE) {
 		    if (temp_plot.m_connectPoints[i] == true) {
 		      drawDataPoint(x,y,prevx,prevy,
 				    temp_plot.m_shapeSize[i],j,gx);
 		    } else {
 		      drawDataPoint(x,y,temp_plot.m_shapeSize[i],j,gx);
 		    }
 		  } else {
 		    if (temp_plot.m_connectPoints[i] == true) {
-
+		       drawDataPoint(x,y,prevx,prevy,temp_plot.m_shapeSize[i],
+				     temp_plot.m_shapeType[i],gx);
 		    } else {
-		      drawDataPoint(x,y,prevx,prevy,temp_plot.m_shapeSize[i],
+		      drawDataPoint(x,y,temp_plot.m_shapeSize[i],
 				    temp_plot.m_shapeType[i],gx);
 		    }
 		  }
 		}
 	      } else {
 		double r;
 		Color ci = null;
 		if (!temp_plot.m_plotInstances.instance(i).
 		    isMissing(m_cIndex)) {
 		  r = (temp_plot.m_plotInstances.instance(i).
 		       value(m_cIndex) - m_minC) / (m_maxC - m_minC);
 		  r = (r * 240) + 15;
 		  ci = new Color((int)r,150,(int)(255-r));
 		} else {
 		  ci = Color.gray;
 		}
 		if (!temp_plot.m_useCustomColour) {
 		  gx.setColor(ci);
 		} else {
 		  gx.setColor(temp_plot.m_customColour);
 		}
 		if (temp_plot.m_plotInstances.instance(i).
 		    isMissing(m_cIndex)) {
 		  if (temp_plot.m_connectPoints[i] == true) {
 		    drawDataPoint(x,y,prevx,prevy,temp_plot.m_shapeSize[i],
 				  MISSING_SHAPE,gx);
 		  } else {
 		    drawDataPoint(x,y,temp_plot.m_shapeSize[i],
 				  MISSING_SHAPE,gx);
 		  }
 		} else {
 		  if (temp_plot.m_shapeType[i] == CONST_AUTOMATIC_SHAPE) {
 		    if (temp_plot.m_connectPoints[i] == true) {
 		      drawDataPoint(x,y,prevx,prevy,
 				    temp_plot.m_shapeSize[i],j,gx);
 		    } else {
 		      drawDataPoint(x,y,temp_plot.m_shapeSize[i],j,gx);
 		    }
 		  } else {
 		    if (temp_plot.m_connectPoints[i] == true) {
 		      drawDataPoint(x,y,prevx,prevy,temp_plot.m_shapeSize[i],
 				    temp_plot.m_shapeType[i],gx);
 		    } else {
 		      drawDataPoint(x,y,temp_plot.m_shapeSize[i],
 				    temp_plot.m_shapeType[i],gx);
 		    }
 		  }
 		}
 	      }
 	    }
 	  }
 	}
       }
     }
   }
\ No newline at end of file
","Fixed bug that caused some lines to be drawn when visualizing
classifier errors.


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@977 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,30087.json,4eeaa9f5f013cff1e7007f66a4529ac662b22751,"@@ -1,46 +1,46 @@
   public void replaceAttributeAt(/* @non_null@ */Attribute att, int position) {
 
     if ((position < 0) || (position > m_Attributes.size())) {
       throw new IllegalArgumentException(""Index out of range"");
     }
 
     // Does the new attribute have a different name?
     if (!att.name().equals(m_Attributes.get(position).name())) {
 
       // Need to check if attribute name already exists
       Attribute candidate = attribute(att.name());
       if ((candidate != null) && (position != candidate.index())) {
         throw new IllegalArgumentException(""Attribute name '"" + att.name()
           + ""' already in use at position #"" + 
           attribute(att.name()).index());
       }
     }
     att = (Attribute) att.copy();
     att.setIndex(position);
 
     ArrayList<Attribute> newList = new ArrayList<Attribute>(m_Attributes.size());
     HashMap<String, Integer> newMap = new HashMap<String, Integer>((int) ((m_Attributes.size() + 1) / 0.75));
     for (int i = 0 ; i < position; i++) {
       Attribute oldAtt = m_Attributes.get(i);
       newList.add(oldAtt);
       newMap.put(oldAtt.name(), i);
     }
     newList.add(att);
     newMap.put(att.name(), position);
     for (int i = position + 1; i < m_Attributes.size(); i++) {
       Attribute newAtt = (Attribute) m_Attributes.get(i);
       newList.add(newAtt);
       newMap.put(newAtt.name(), i);
     }
     m_Attributes = newList;
     m_NamesToAttributeIndices = newMap;
 
     for (int i = 0; i < numInstances(); i++) {
       instance(i).setDataset(null);
       instance(i).setMissing(position);
       instance(i).setDataset(this);
     }
-    if (m_ClassIndex >= position) {
+    if (m_ClassIndex > position) {
       m_ClassIndex++;
     }
   }
\ No newline at end of file
","Fixed bug in replaceAttributeAt(): class index was incremented when class attribute was replaced.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@12100 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,30087.json,e4ae148238732024ecdbbd5e7b3ec87d4457ebb0,"@@ -1,46 +1,46 @@
   public void replaceAttributeAt(/* @non_null@ */Attribute att, int position) {
 
     if ((position < 0) || (position > m_Attributes.size())) {
       throw new IllegalArgumentException(""Index out of range"");
     }
 
     // Does the new attribute have a different name?
     if (!att.name().equals(m_Attributes.get(position).name())) {
 
       // Need to check if attribute name already exists
       Attribute candidate = attribute(att.name());
       if ((candidate != null) && (position != candidate.index())) {
         throw new IllegalArgumentException(""Attribute name '"" + att.name()
           + ""' already in use at position #"" + 
           attribute(att.name()).index());
       }
     }
     att = (Attribute) att.copy();
     att.setIndex(position);
 
     ArrayList<Attribute> newList = new ArrayList<Attribute>(m_Attributes.size());
     HashMap<String, Integer> newMap = new HashMap<String, Integer>((int) ((m_Attributes.size() + 1) / 0.75));
     for (int i = 0 ; i < position; i++) {
       Attribute oldAtt = m_Attributes.get(i);
       newList.add(oldAtt);
       newMap.put(oldAtt.name(), i);
     }
     newList.add(att);
     newMap.put(att.name(), position);
-    for (int i = position; i < m_Attributes.size(); i++) {
+    for (int i = position + 1; i < m_Attributes.size(); i++) {
       Attribute newAtt = (Attribute) m_Attributes.get(i);
       newList.add(newAtt);
       newMap.put(newAtt.name(), i);
     }
     m_Attributes = newList;
     m_NamesToAttributeIndices = newMap;
 
     for (int i = 0; i < numInstances(); i++) {
       instance(i).setDataset(null);
       instance(i).setMissing(position);
       instance(i).setDataset(this);
     }
     if (m_ClassIndex >= position) {
       m_ClassIndex++;
     }
   }
\ No newline at end of file
","Fixed bug in replaceAttributeAt() in Instances that I introduced in the modifications I made today.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@11339 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,29873.json,c5e5a38b7cb456c56a091a2581ec85b5e9c97afa,"@@ -1,16 +1,16 @@
   public double convictionForRule(AprioriItemSet premise,
 				   AprioriItemSet consequence,
 				   int premiseCount,
 				   int consequenceCount) {
     double num = 
-      (double)premiseCount * (double)(m_totalTransactions - consequenceCount) *
+      (double)premiseCount * (double)(m_totalTransactions - consequenceCount) /
        (double)m_totalTransactions;
     double denom = 
       ((premiseCount - consequence.m_counter)+1);
     
     if (num < 0 || denom < 0) {
       System.err.println(""*** ""+num+"" ""+denom);
       System.err.println(""premis count: ""+premiseCount+"" consequence count ""+consequenceCount+"" total trans ""+m_totalTransactions);
     }
     return num / denom;
   }
\ No newline at end of file
","Fixed bug in the computation of the conviction measure


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@2297 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,25075.json,51f46d90e1a9e13dbc38b52a664024090bef89d4,"@@ -1,68 +1,98 @@
   protected void adjustCanopies(double[] densities) {
     if (m_numClustersRequested < 0) {
       assignCanopiesToCanopyCenters();
 
       m_trainingData = new Instances(m_canopies, 0);
       return;
     }
 
     // more canopies than requested?
     if (m_canopies.numInstances() > m_numClustersRequested) {
       int[] sortedIndexes = Utils.stableSort(densities);
 
       Instances finalCanopies = new Instances(m_canopies, 0);
       int count = 0;
       for (int i = sortedIndexes.length - 1; count < m_numClustersRequested; i--) {
         finalCanopies.add(m_canopies.instance(sortedIndexes[i]));
         count++;
       }
 
       m_canopies = finalCanopies;
+      List<double[][]> tempCanopyCenters = new ArrayList<double[][]>();
+      List<double[]> tempT2Dists = new ArrayList<double[]>();
+      List<double[]> tempMissings = new ArrayList<double[]>();
+
+      // make sure that the center sums, densities and missing counts are
+      // aligned with the new canopy list
+      count = 0;
+      for (int i = sortedIndexes.length - 1; count < finalCanopies
+        .numInstances(); i--) {
+        tempCanopyCenters.add(m_canopyCenters.get(sortedIndexes[i]));
+        tempT2Dists.add(m_canopyT2Density.get(sortedIndexes[i]));
+        tempMissings.add(m_canopyNumMissingForNumerics.get(sortedIndexes[i]));
+        count++;
+      }
+      m_canopyCenters = tempCanopyCenters;
+      m_canopyT2Density = tempT2Dists;
+      m_canopyNumMissingForNumerics = tempMissings;
+
     } else if (m_canopies.numInstances() < m_numClustersRequested
       && m_trainingData != null && m_trainingData.numInstances() > 0) {
 
       // make up the difference with randomly selected instances (if possible)
       Random r = new Random(getSeed());
       for (int i = 0; i < 10; i++) {
         r.nextInt();
       }
       HashMap<DecisionTableHashKey, Integer> initC = new HashMap<DecisionTableHashKey, Integer>();
       DecisionTableHashKey hk = null;
 
       // put the existing canopies in the lookup
       for (int i = 0; i < m_canopies.numInstances(); i++) {
         try {
           hk = new DecisionTableHashKey(m_canopies.instance(i),
             m_canopies.numAttributes(), true);
 
           initC.put(hk, null);
         } catch (Exception e) {
           e.printStackTrace();
         }
       }
 
       for (int j = m_trainingData.numInstances() - 1; j >= 0; j--) {
         int instIndex = r.nextInt(j + 1);
         try {
           hk = new DecisionTableHashKey(m_trainingData.instance(instIndex),
             m_trainingData.numAttributes(), true);
         } catch (Exception e) {
           e.printStackTrace();
         }
         if (!initC.containsKey(hk)) {
-          m_canopies.add(m_trainingData.instance(instIndex));
+          Instance newInstance = m_trainingData.instance(instIndex);
+          m_canopies.add(newInstance);
+
+          double[] density = new double[1];
+          density[0] = 1.0;
+          m_canopyT2Density.add(density);
+
+          double[][] center = new double[newInstance.numAttributes()][0];
+          double[] numMissingNumerics = new double[newInstance.numAttributes()];
+          updateCanopyCenter(newInstance, center, numMissingNumerics);
+          m_canopyCenters.add(center);
+          m_canopyNumMissingForNumerics.add(numMissingNumerics);
+
           initC.put(hk, null);
         }
         m_trainingData.swap(j, instIndex);
 
         if (m_canopies.numInstances() == m_numClustersRequested) {
           break;
         }
       }
     }
 
     assignCanopiesToCanopyCenters();
 
     // save memory
     m_trainingData = new Instances(m_canopies, 0);
   }
\ No newline at end of file
","Fixed a bug that affected aggregation of Canopy clusterers - canopy center sums were not getting adjusted after the final number of canopies was determined.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@10597 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,37063.json,2a4806e3c2bd860a4e7b0496b5b05ff72dfdf46b,"@@ -1,84 +1,85 @@
   public void start() throws WekaException {
     if (getStepManager().numOutgoingConnections() > 0) {
       weka.datagenerators.DataGenerator generator = getDataGenerator();
       if (getStepManager()
         .numOutgoingConnectionsOfType(StepManager.CON_DATASET) > 0) {
         getStepManager().processing();
         StringWriter output = new StringWriter();
         try {
           generator.setOutput(new PrintWriter(output));
           getStepManager().statusMessage(""Generating..."");
           getStepManager().logBasic(""Generating data"");
           weka.datagenerators.DataGenerator.makeData(generator,
             generator.getOptions());
           Instances instances =
             new Instances(new StringReader(output.toString()));
 
           if (!isStopRequested()) {
             Data outputData = new Data(StepManager.CON_DATASET, instances);
             getStepManager().outputData(outputData);
           }
         } catch (Exception ex) {
           throw new WekaException(ex);
         }
         if (isStopRequested()) {
           getStepManager().interrupted();
         } else {
           getStepManager().finished();
         }
       } else {
         // streaming case
         try {
           if (!generator.getSingleModeFlag()) {
             throw new WekaException(""Generator does not support ""
               + ""incremental generation, so cannot be used with ""
               + ""outgoing 'instance' connections"");
           }
         } catch (Exception ex) {
           throw new WekaException(ex);
         }
         String stm =
           getName() + ""$"" + hashCode() + 99 + ""| overall flow throughput -|"";
         m_flowThroughput =
           new StreamThroughput(stm, ""Starting flow..."",
             ((StepManagerImpl) getStepManager()).getLog());
 
         try {
           getStepManager().logBasic(""Generating..."");
           generator.setDatasetFormat(generator.defineDataFormat());
 
           for (int i = 0; i < generator.getNumExamplesAct(); i++) {
+            m_flowThroughput.updateStart();
             getStepManager().throughputUpdateStart();
             if (isStopRequested()) {
               getStepManager().interrupted();
               return;
             }
 
             // over all examples to be produced
             Instance inst = generator.generateExample();
             m_incrementalData.setPayloadElement(StepManager.CON_INSTANCE, inst);
             getStepManager().throughputUpdateEnd();
 
             getStepManager().outputData(m_incrementalData);
             m_flowThroughput.updateEnd(((StepManagerImpl) getStepManager())
               .getLog());
           }
 
           if (isStopRequested()) {
             ((StepManagerImpl) getStepManager()).getLog().statusMessage(
               stm + ""remove"");
             getStepManager().interrupted();
             return;
           }
           m_flowThroughput.finished(((StepManagerImpl) getStepManager())
             .getLog());
 
           // signal end of input
           m_incrementalData.clearPayload();
           getStepManager().throughputFinished(m_incrementalData);
         } catch (Exception ex) {
           throw new WekaException(ex);
         }
       }
     }
   }
\ No newline at end of file
","Fixed a bug in the overall throughput status

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@13209 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,33600.json,4fbfba6d434318852d50cf855de7282fd21ceae3,"@@ -1,62 +1,63 @@
   public boolean isCompatibleBaseSystem() throws Exception {
 
     String baseSystemName = m_packageManager.getBaseSystemName();
     String systemVersion = m_packageManager.getBaseSystemVersion().toString();
     // System.err.println(""Base system version "" + systemVersion);
 
-    String dependencies = getPackageMetaDataElement(""Depends"").toString();
+    String dependencies = getPackageMetaDataElement(""Depends"") == null
+      ? null : getPackageMetaDataElement(""Depends"").toString();
     if (dependencies == null) {
       return true;
     }
-
+    
     boolean ok = true;
     StringTokenizer tok = new StringTokenizer(dependencies, "","");
     while (tok.hasMoreTokens()) {
       String nextT = tok.nextToken().trim();
       String[] split = splitNameVersion(nextT);
       if (split[0].startsWith(baseSystemName.toLowerCase())) {
         // check the system version
         if (split[1] != null) {
           if (split.length == 3) {
             VersionPackageConstraint.VersionComparison constraint =
               VersionPackageConstraint.getVersionComparison(split[1]);
             if (!VersionPackageConstraint.checkConstraint(systemVersion,
               constraint, split[2])) {
               ok = false;
               break;
             }
           } else {
             // construct a ""dummy"" package for the base system
             Map<String, String> baseMap = new HashMap<String, String>();
             baseMap.put(""PackageName"", ""weka"");
 
             baseMap.put(""Version"", systemVersion);
             Package basePackage =
               new DefaultPackage(null, m_packageManager, baseMap);
 
             VersionRangePackageConstraint versionRConstraint =
               new VersionRangePackageConstraint(basePackage);
             VersionPackageConstraint.VersionComparison comp1 =
               VersionPackageConstraint.getVersionComparison(split[1]);
             VersionPackageConstraint.VersionComparison comp2 =
               VersionPackageConstraint.getVersionComparison(split[3]);
 
             versionRConstraint.setRangeConstraint(split[2], comp1, split[4],
               comp2);
 
             if (!versionRConstraint.checkConstraint(basePackage)) {
               ok = false;
               break;
             }
           }
           /*
            * int comparisonResult =
            * VersionPackageConstraint.compare(systemVersion, split[2]); ok =
            * versionOK(split[1], comparisonResult); if (!ok) { break; }
            */
         }
       }
     }
 
     return ok;
   }
\ No newline at end of file
","Fixed a bug in DefaultPackage that would result in npe when checking dependencies for a malformed Description.props (that did not list at least a base Weka dependency).

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@15152 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,17605.json,d6ac3ed81063bb608413aa9d346e6e8e8b868874,"@@ -1,220 +1,221 @@
 	  public void mouseClicked(MouseEvent e) {
 	    
 	    if ((m_sIndex == 2 || m_sIndex == 3) && 
 		(m_createShape || 
 		 (e.getModifiers() & e.BUTTON1_MASK) == e.BUTTON1_MASK)) {
 	      if (m_createShape) {
 		//then it has been started already.
 
 		Graphics g = m_plot2D.getGraphics();
 		g.setColor(Color.black);
 		g.setXORMode(Color.white);
-		if ((e.getModifiers() & e.BUTTON1_MASK) == e.BUTTON1_MASK) {
+		if ((e.getModifiers() & e.BUTTON1_MASK) == e.BUTTON1_MASK &&
+                    !e.isAltDown()) {
 		  m_shapePoints.addElement(new 
 		    Double(m_plot2D.convertToAttribX(e.getX())));
 		  
 		  m_shapePoints.addElement(new 
 		    Double(m_plot2D.convertToAttribY(e.getY())));
 		  
 		  m_newMousePos.width = e.getX();
 		  m_newMousePos.height = e.getY();
 		  g.drawLine((int)Math.ceil
 			     (m_plot2D.convertToPanelX
 			      (((Double)m_shapePoints.
 				elementAt(m_shapePoints.size() - 2)).
 			       doubleValue())),
 			     
 			     (int)Math.ceil
 			     (m_plot2D.convertToPanelY
 			      (((Double)m_shapePoints.
 				elementAt(m_shapePoints.size() - 1)).
 			       doubleValue())),
 			     m_newMousePos.width, m_newMousePos.height);
 		  
 		}
 		else if (m_sIndex == 3) {
 		  //then extend the lines to infinity 
 		  //(100000 or so should be enough).
 		  //the area is selected by where the user right clicks 
 		  //the mouse button
 		  
 		  m_createShape = false;
 		  if (m_shapePoints.size() >= 5) {
 		    double cx = Math.ceil
 		      (m_plot2D.convertToPanelX
 		       (((Double)m_shapePoints.elementAt
 			 (m_shapePoints.size() - 4)).doubleValue()));
 		    
 		    double cx2 = Math.ceil
 		      (m_plot2D.convertToPanelX
 		       (((Double)m_shapePoints.elementAt
 			 (m_shapePoints.size() - 2)).doubleValue())) - 
 		      cx;
 		    
 		    cx2 *= 50000;
 		    
 		    double cy = Math.ceil
 		      (m_plot2D.
 		       convertToPanelY(((Double)m_shapePoints.
 					elementAt(m_shapePoints.size() - 3)).
 				       doubleValue()));
 		    double cy2 = Math.ceil
 		      (m_plot2D.convertToPanelY(((Double)m_shapePoints.
 					  elementAt(m_shapePoints.size() - 1)).
 					  doubleValue())) - cy;
 		    cy2 *= 50000;
 			    
 		    
 		    double cxa = Math.ceil(m_plot2D.convertToPanelX
 					   (((Double)m_shapePoints.
 					     elementAt(3)).
 					    doubleValue()));
 		    double cxa2 = Math.ceil(m_plot2D.convertToPanelX
 					    (((Double)m_shapePoints.
 					      elementAt(1)).
 					     doubleValue())) - cxa;
 		    cxa2 *= 50000;
 		    
 		    
 		    double cya = Math.ceil
 		      (m_plot2D.convertToPanelY
 		       (((Double)m_shapePoints.elementAt(4)).
 			doubleValue()));
 		    double cya2 = Math.ceil
 		      (m_plot2D.convertToPanelY
 		       (((Double)m_shapePoints.elementAt(2)).
 			doubleValue())) - cya;
 		    
 		    cya2 *= 50000;
 		    
 		    m_shapePoints.setElementAt
 		      (new Double(m_plot2D.convertToAttribX(cxa2 + cxa)), 1);
 		    
 		    m_shapePoints.setElementAt
 		      (new Double(m_plot2D.convertToAttribY(cy2 + cy)), 
 		       m_shapePoints.size() - 1);
 		    
 		    m_shapePoints.setElementAt
 		      (new Double(m_plot2D.convertToAttribX(cx2 + cx)), 
 		       m_shapePoints.size() - 2);
 		    
 		    m_shapePoints.setElementAt
 		      (new Double(m_plot2D.convertToAttribY(cya2 + cya)), 2);
 		    
 		    
 		    //determine how infinity line should be built
 		    
 		    cy = Double.POSITIVE_INFINITY;
 		    cy2 = Double.NEGATIVE_INFINITY;
 		    if (((Double)m_shapePoints.elementAt(1)).
 			doubleValue() > 
 			((Double)m_shapePoints.elementAt(3)).
 			doubleValue()) {
 		      if (((Double)m_shapePoints.elementAt(2)).
 			  doubleValue() == 
 			  ((Double)m_shapePoints.elementAt(4)).
 			  doubleValue()) {
 			cy = ((Double)m_shapePoints.elementAt(2)).
 			  doubleValue();
 		      }
 		    }
 		    if (((Double)m_shapePoints.elementAt
 			 (m_shapePoints.size() - 2)).doubleValue() > 
 			((Double)m_shapePoints.elementAt
 			 (m_shapePoints.size() - 4)).doubleValue()) {
 		      if (((Double)m_shapePoints.elementAt
 			   (m_shapePoints.size() - 3)).
 			  doubleValue() == 
 			  ((Double)m_shapePoints.elementAt
 			   (m_shapePoints.size() - 1)).doubleValue()) {
 			cy2 = ((Double)m_shapePoints.lastElement()).
 			  doubleValue();
 		      }
 		    }
 		    m_shapePoints.addElement(new Double(cy));
 		    m_shapePoints.addElement(new Double(cy2));
 		    
 		    if (!inPolyline(m_shapePoints, m_plot2D.convertToAttribX
 				    (e.getX()), 
 				    m_plot2D.convertToAttribY(e.getY()))) {
 		      Double tmp = (Double)m_shapePoints.
 			elementAt(m_shapePoints.size() - 2);
 		      m_shapePoints.setElementAt
 			(m_shapePoints.lastElement(), 
 			 m_shapePoints.size() - 2);
 		      m_shapePoints.setElementAt
 			(tmp, m_shapePoints.size() - 1);
 		    }
 		    
 		    if (m_shapes == null) {
 		      m_shapes = new FastVector(4);
 		    }
 		    m_shapes.addElement(m_shapePoints);
 
 		    m_submit.setText(""Submit"");
 		    m_submit.setActionCommand(""Submit"");
 		    
 		    m_submit.setEnabled(true);
 		  }
 		  
 		  m_shapePoints = null;
 		  PlotPanel.this.repaint();
 		  
 		}
 		else {
 		  //then close the shape
 		  m_createShape = false;
 		  if (m_shapePoints.size() >= 7) {
 		    m_shapePoints.addElement(m_shapePoints.elementAt(1));
 		    m_shapePoints.addElement(m_shapePoints.elementAt(2));
 		    if (m_shapes == null) {
 		      m_shapes = new FastVector(4);
 		    }
 		    m_shapes.addElement(m_shapePoints);
 			   
 		    m_submit.setText(""Submit"");
 		    m_submit.setActionCommand(""Submit"");
 		    
 		    m_submit.setEnabled(true);
 		  }
 		  m_shapePoints = null;
 		  PlotPanel.this.repaint();
 		}
 		g.dispose();
 		//repaint();
 	      }
 	      else if ((e.getModifiers() & e.BUTTON1_MASK) == e.BUTTON1_MASK) {
 		//then this is the first point
 		m_createShape = true;
 		m_shapePoints = new FastVector(17);
 		m_shapePoints.addElement(new Double(m_sIndex));
 		m_shapePoints.addElement(new 
 		  Double(m_plot2D.convertToAttribX(e.getX()))); //the new point
 		m_shapePoints.addElement(new 
 		  Double(m_plot2D.convertToAttribY(e.getY())));
 		m_newMousePos.width = e.getX();      //the temp mouse point
 		m_newMousePos.height = e.getY();
 
 		Graphics g = m_plot2D.getGraphics();
 		g.setColor(Color.black);
 		g.setXORMode(Color.white);
 		g.drawLine((int)Math.ceil
 			   (m_plot2D.convertToPanelX(((Double)m_shapePoints.
 					     elementAt(1)).doubleValue())),
 			   (int)Math.ceil
 			   (m_plot2D.convertToPanelY(((Double)m_shapePoints.
 					     elementAt(2)).doubleValue())),
 			   m_newMousePos.width, m_newMousePos.height);
 		g.dispose();
 	      }
 	    }
 	    else {
 	      if ((e.getModifiers() & InputEvent.BUTTON1_MASK) == 
 		  InputEvent.BUTTON1_MASK) {
 		
 		m_plot2D.searchPoints(e.getX(),e.getY(), false);
 	      } else {
 		m_plot2D.searchPoints(e.getX(), e.getY(), true);
 	      }
 	    }
 	  }
\ No newline at end of file
","Fixed bug that prevented polyline and polygon selection options from working with single button mice. The Alt key can now be held down to simulate button 2


git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@2621 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,20397.json,f2a4c20a55fa0e3b48af5bb5a2cb98a33f245eab,"@@ -1,24 +1,24 @@
   private void setupRendererOptsTipText(JLabel optsLab) {
     String renderer = m_rendererCombo.getSelectedItem().toString();
     if (renderer.equalsIgnoreCase(""weka chart renderer"")) {
       // built-in renderer
       WekaOffscreenChartRenderer rcr = new WekaOffscreenChartRenderer();
       String tipText = rcr.optionsTipTextHTML();
       tipText = tipText.replace(""<html>"", ""<html>Comma separated list of options:<br>"");
       optsLab.setToolTipText(tipText);
     } else {
       try {
-        Object rendererO = PluginManager.getPluginInstance(""weka.gui.beans.OffscreenChartRender"",
+        Object rendererO = PluginManager.getPluginInstance(""weka.gui.beans.OffscreenChartRenderer"",
             renderer);
 
         if (rendererO != null) {
           String tipText = ((OffscreenChartRenderer)rendererO).optionsTipTextHTML();
           if (tipText != null && tipText.length() > 0) {
             optsLab.setToolTipText(tipText);
           }
         }
       } catch (Exception ex) {
 
       }
     }
   }
\ No newline at end of file
","Fixed a bug in the routine that sets the tool tip for additional options in plugin renderers.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@7691 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,23551.json,0f79454f25618e64781b12a24a482ef8a0441bca,"@@ -1,44 +1,44 @@
   public Instance generateExample() throws Exception {
     Instance result;
     Random rand;
     double x;
     double y;
     double[] atts;
     Instance inst;
 
-    result = null;
     rand = getRandom();
 
     if (m_DatasetFormat == null) {
       throw new Exception(""Dataset format not defined."");
     }
 
     // random x
     x = rand.nextDouble();
     // fit into range
     x = x * (getMaxRange() - getMinRange()) + getMinRange();
 
     // generate y
     atts = new double[1];
     atts[0] = x;
     inst = new DenseInstance(1.0, atts);
+    inst.setDataset(m_RawData);
     m_Filter.input(inst);
     m_Filter.batchFinished();
     inst = m_Filter.output();
 
     // noise
     y = inst.value(1) + getAmplitude() * m_NoiseRandom.nextGaussian()
       * getNoiseRate() * getNoiseVariance();
 
     // generate attributes
     atts = new double[m_DatasetFormat.numAttributes()];
 
     atts[0] = x;
     atts[1] = y;
     result = new DenseInstance(1.0, atts);
 
     // dataset reference
     result.setDataset(m_DatasetFormat);
 
     return result;
   }
\ No newline at end of file
","Fixed problem that caused assertion to fail when executing unit test.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@11504 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,21037.json,05cc4c3b0752474605f5ea11f2c85e4a9c3d6043,"@@ -1,16 +1,37 @@
   public boolean eventGeneratable(String eventName) {
 
-    if (!m_listeneeTypes.contains(eventName)) {
-      return false;
+    if (eventName.equals(""instance"")) {
+
+      if (!m_listeneeTypes.contains(eventName)) {
+        return false;
+      }
+
+      for (Object listenee : m_listenees.values()) {
+        if (listenee instanceof EventConstraints
+          && !((EventConstraints) listenee).eventGeneratable(eventName)) {
+          return false;
+        }
+      }
     }
 
-    for (Object listenee : m_listenees.values()) {
-      if (listenee instanceof EventConstraints) {
-        if (!((EventConstraints) listenee).eventGeneratable(eventName)) {
-          return false;
+    if (eventName.equals(""dataSet"") || eventName.equals(""trainingSet"")
+      || eventName.equals(""testSet"")) {
+
+      if (!m_listeneeTypes.contains(""dataSet"")
+        && !m_listeneeTypes.contains(""trainingSet"")
+        && !m_listeneeTypes.contains(""testSet"")) {
+        return false;
+      }
+      for (Object listenee : m_listenees.values()) {
+        if (listenee instanceof EventConstraints) {
+          if (!((EventConstraints) listenee).eventGeneratable(""dataSet"")
+            && !((EventConstraints) listenee).eventGeneratable(""trainingSet"")
+            && !((EventConstraints) listenee).eventGeneratable(""testSet"")) {
+            return false;
+          }
         }
       }
     }
 
     return true;
   }
\ No newline at end of file
","Fixed a bug in the specification of event types produced by Appender and in the routine that determines whether a particular event type can be generated at a given point in time.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@10149 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
weka,23139.json,50e14ddcea9246c4b6c83142b493163b1e9b862c,"@@ -1,27 +1,42 @@
   protected void updateCapabilitiesFilter(Capabilities filter) {
     Instances 		tempInst;
     Capabilities 	filterClass;
 
     if (filter == null) {
       m_AttributeEvaluatorEditor.setCapabilitiesFilter(new Capabilities(null));
       m_AttributeSearchEditor.setCapabilitiesFilter(new Capabilities(null));
       return;
     }
     
     if (!ExplorerDefaults.getInitGenericObjectEditorFilter())
       tempInst = new Instances(m_Instances, 0);
     else
       tempInst = new Instances(m_Instances);
     tempInst.setClassIndex(m_ClassCombo.getSelectedIndex());
 
     try {
       filterClass = Capabilities.forInstances(tempInst);
     }
     catch (Exception e) {
       filterClass = new Capabilities(null);
     }
     
     // set new filter
     m_AttributeEvaluatorEditor.setCapabilitiesFilter(filterClass);
     m_AttributeSearchEditor.setCapabilitiesFilter(filterClass);
+    
+    m_StartBut.setEnabled(true);
+    // check capabilities...
+    Capabilities currentFilter = m_AttributeEvaluatorEditor.getCapabilitiesFilter();
+    ASEvaluation evaluator = (ASEvaluation) m_AttributeEvaluatorEditor.getValue();
+    Capabilities currentSchemeCapabilities =  null;
+    if (evaluator != null && currentFilter != null && 
+        (evaluator instanceof CapabilitiesHandler)) {
+      currentSchemeCapabilities = ((CapabilitiesHandler)evaluator).getCapabilities();
+      
+      if (!currentSchemeCapabilities.supportsMaybe(currentFilter) &&
+          !currentSchemeCapabilities.supports(currentFilter)) {
+        m_StartBut.setEnabled(false);
+      }
+    }
   }
\ No newline at end of file
","Fixed a bug where the enabled/disabled state of the start button was not being updated when a new data set was set on this panel.

git-svn-id: https://svn.cms.waikato.ac.nz/svn/weka/trunk@5385 e0a1b77d-ad91-4216-81b1-defd5f83fa92
",Buggy
xerces2-j,5527.json,2c3c54c0011dbb81897f1f1484b2a1da2d9bce5a,"@@ -1,3 +1,3 @@
     protected boolean versionSupported(String version) {
-        return version.equals(""1.1"");
+        return (version.equals(""1.1"") || version.equals(""1.0""));
     } // versionSupported(String):  boolean
\ No newline at end of file
","fix for bug 18789; thanks to Neil Delima for the patch


git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@319325 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,1404.json,4e11453e19d58d4481d2367028b0cb86c0deafeb,"@@ -1,62 +1,66 @@
 	protected void checkUnboundNamespacePrefixedNode (Node node) throws IOException{
 
 		if (fNamespaces) {
 
    			if (DEBUG) {
 			    System.out.println(""==>serializeNode(""+node.getNodeName()+"") [Entity Reference - Namespaces on]"");
 				System.out.println(""==>Declared Prefix Count: "" + fNSBinder.getDeclaredPrefixCount());
 				System.out.println(""==>Node Name: "" + node.getNodeName());
 				System.out.println(""==>First Child Node Name: "" + node.getFirstChild().getNodeName());
 				System.out.println(""==>First Child Node Prefix: "" + node.getFirstChild().getPrefix());
 				System.out.println(""==>First Child Node NamespaceURI: "" + node.getFirstChild().getNamespaceURI());			
 			}
 
 		
 			Node child, next;
 	        for (child = node.getFirstChild(); child != null; child = next) {
 	            next = child.getNextSibling();
 			    if (DEBUG) {
 			        System.out.println(""==>serializeNode(""+child.getNodeName()+"") [Child Node]"");
 			        System.out.println(""==>serializeNode(""+child.getPrefix()+"") [Child Node Prefix]"");
 	            }    
 	
 		 	    //If a NamespaceURI is not declared for the current
 		 	    //node's prefix, raise a fatal error.
 		 	    String prefix = child.getPrefix();
+                prefix = (prefix == null || 
+                        prefix.length() == 0) ? XMLSymbols.EMPTY_STRING : fSymbolTable.addSymbol(prefix);
 		 	    if (fNSBinder.getURI(prefix) == null && prefix != null) {
 					fatalError(""The replacement text of the entity node '"" 
 								+ node.getNodeName()  
 								+ ""' contains an element node '"" 
 								+ child.getNodeName() 
 								+ ""' with an undeclared prefix '"" 
 								+ prefix + ""'."");
 		 	    }	
 
 				if (child.getNodeType() == Node.ELEMENT_NODE) {
 					
 					NamedNodeMap attrs = child.getAttributes();
 					
 					for (int i = 0; i< attrs.getLength(); i++ ) {
 						
 				 	    String attrPrefix = attrs.item(i).getPrefix();
+                        attrPrefix = (attrPrefix == null || 
+                                attrPrefix.length() == 0) ? XMLSymbols.EMPTY_STRING : fSymbolTable.addSymbol(attrPrefix);
 				 	    if (fNSBinder.getURI(attrPrefix) == null && attrPrefix != null) {
 							fatalError(""The replacement text of the entity node '"" 
 										+ node.getNodeName()  
 										+ ""' contains an element node '"" 
 										+ child.getNodeName() 
 										+ ""' with an attribute '"" 
 										+ attrs.item(i).getNodeName() 										
 										+ ""' an undeclared prefix '"" 
 										+ attrPrefix + ""'."");
 				 	    }	
 						
 					}	
 
 				}
 					
 				if (child.hasChildNodes()) {
 					checkUnboundNamespacePrefixedNode(child);
 				}	
 	        }
 		}    
 	}	
\ No newline at end of file
","Fixing JIRA Bug #1043:
http://issues.apache.org/jira/browse/XERCESJ-1043

Looking up a namespace URI from a NamespaceContext requires that we pass in the interned
String from the SymbolTable as the prefix. We were failing to do that when checking for unbound
prefixes. Should be fixed now.


git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@320220 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,8183.json,a01d7a8db8b4fb1ff2a2f8c62736b56bb2d84d63,"@@ -1,12 +1,14 @@
-    public boolean equals(XMLGrammarDescription desc) {
+    public boolean equals(Object descObj) {
+        if(!(descObj instanceof XMLGrammarDescription)) return false;
+        XMLGrammarDescription desc = (XMLGrammarDescription)descObj;
         if (!getGrammarType().equals(desc.getGrammarType())) {
             return false;
         }
         if (fTargetNamespace != null && fTargetNamespace.equals(((XSDDescription)desc).getTargetNamespace())) {
             return true;
         }
         else if (fTargetNamespace == null && ((XSDDescription)desc).getTargetNamespace() == null) {
             return true;
         }
         return false;
     }
\ No newline at end of file
","fix a couple of bugs with schema preparsing:  make sure the error reporter knows about schemas; and make sure XSDDescription .equals method actually works in contexts such as Hashtables (the parameter should be an Object, not an XMLGrammarDescription).


git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@318470 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,8285.json,f33e487490b168dd0b29e7df099a1832fb79ee79,"@@ -1,84 +1,85 @@
     private int scanMixed(QName element) throws Exception {
 
         int valueIndex = -1;  // -1 is special value for #PCDATA
         int prevNodeIndex = -1;
         boolean starRequired = false;
         int[] valueSeen = new int[32];
         int valueCount = 0;
         boolean dupAttrType = false;
         int nodeIndex = -1;
 
         while (true) {
             if (fValidationEnabled) {
                 for (int i=0; i<valueCount;i++) {
                     if ( valueSeen[i] == valueIndex) {
                         dupAttrType = true;
                         break;
                     }
                 }
             }
             if (dupAttrType && fValidationEnabled) {
                 reportRecoverableXMLError(XMLMessages.MSG_DUPLICATE_TYPE_IN_MIXED_CONTENT,
                                           XMLMessages.VC_NO_DUPLICATE_TYPES,
                                           valueIndex);
                 dupAttrType = false;
 
             }
             else {
                 try {
                     valueSeen[valueCount] = valueIndex;
                 }
                 catch (ArrayIndexOutOfBoundsException ae) {
                     int[] newArray = new int[valueSeen.length*2];
                     System.arraycopy(valueSeen,0,newArray,0,valueSeen.length);
+                    valueSeen = newArray;
                     valueSeen[valueCount] = valueIndex;
                 }
                 valueCount++;
 
                 nodeIndex = fDTDGrammar.addUniqueLeafNode(valueIndex);
             }
 
             checkForPEReference(false);
             if (!fEntityReader.lookingAtChar('|', true)) {
                 if (!fEntityReader.lookingAtChar(')', true)) {
                     reportFatalXMLError(XMLMessages.MSG_CLOSE_PAREN_REQUIRED_IN_MIXED,
                                         XMLMessages.P51_CLOSE_PAREN_REQUIRED,
                                         element.rawname);
                     return -1;
                 }
                 decreaseParenDepth();
                 if (nodeIndex == -1) {
                     nodeIndex = prevNodeIndex;
                 } else if (prevNodeIndex != -1) {
                     nodeIndex = fDTDGrammar.addContentSpecNode(XMLContentSpec.CONTENTSPECNODE_CHOICE, prevNodeIndex, nodeIndex);
                 }
                 if (fEntityReader.lookingAtChar('*', true)) {
                     nodeIndex = fDTDGrammar.addContentSpecNode(XMLContentSpec.CONTENTSPECNODE_ZERO_OR_MORE, nodeIndex);
                 } else if (starRequired) {
                     reportFatalXMLError(XMLMessages.MSG_MIXED_CONTENT_UNTERMINATED,
                                         XMLMessages.P51_UNTERMINATED,
                                         fStringPool.toString(element.rawname),
                                         fDTDGrammar.getContentSpecNodeAsString(nodeIndex));
                     return -1;
                 }
                 return nodeIndex;
             }
             if (nodeIndex != -1) {
                 if (prevNodeIndex != -1) {
                     nodeIndex = fDTDGrammar.addContentSpecNode(XMLContentSpec.CONTENTSPECNODE_CHOICE, prevNodeIndex, nodeIndex);
                 }
                 prevNodeIndex = nodeIndex;
             }
             starRequired = true;
             checkForPEReference(false);
             checkForElementTypeWithPEReference(fEntityReader, ')', fElementRefQName);
             valueIndex = fElementRefQName.rawname;
             if (valueIndex == -1) {
                 reportFatalXMLError(XMLMessages.MSG_ELEMENT_TYPE_REQUIRED_IN_MIXED_CONTENT,
                                     XMLMessages.P51_ELEMENT_TYPE_REQUIRED,
                                     element.rawname);
                 return -1;
             }
         }
 
     } // scanMixed(QName):int
\ No newline at end of file
","Bug - fix is to assign the array reference


git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@315690 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,5598.json,c08116e59d73beba99136a5c0d0b920e74a6c891,"@@ -1,33 +1,33 @@
     synchronized RangeToken getCaseInsensitiveToken() {
         if (this.icaseCache != null)
             return this.icaseCache;
             
         RangeToken uppers = this.type == Token.RANGE ? Token.createRange() : Token.createNRange();
         for (int i = 0;  i < this.ranges.length;  i += 2) {
             for (int ch = this.ranges[i];  ch <= this.ranges[i+1];  ch ++) {
                 if (ch > 0xffff)
                     uppers.addRange(ch, ch);
                 else {
                     char uch = Character.toUpperCase((char)ch);
                     uppers.addRange(uch, uch);
                 }
             }
         }
         RangeToken lowers = this.type == Token.RANGE ? Token.createRange() : Token.createNRange();
         for (int i = 0;  i < uppers.ranges.length;  i += 2) {
             for (int ch = uppers.ranges[i];  ch <= uppers.ranges[i+1];  ch ++) {
                 if (ch > 0xffff)
                     lowers.addRange(ch, ch);
                 else {
-                    char uch = Character.toUpperCase((char)ch);
+                    char uch = Character.toLowerCase((char)ch);
                     lowers.addRange(uch, uch);
                 }
             }
         }
         lowers.mergeRanges(uppers);
         lowers.mergeRanges(this);
         lowers.compactRanges();
 
         this.icaseCache = lowers;
         return lowers;
     }
\ No newline at end of file
","Fix a problem with range tokens where lower case characters where not added (in a case insensitive mode)

git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@827769 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,2798.json,c12fd694626841e15a23993537a61d1ef75260c4,"@@ -1,3 +1,6 @@
     public TypeInfo getSchemaTypeInfo(){
-      return this;
+        if(needsSyncData()) {
+            synchronizeData();
+        }
+        return this;
     }
\ No newline at end of file
","A TypeInfo.getTypeName(...) bug fix.


git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@320508 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,4988.json,860cb3b9c2ad281211d6d52beb871b2439720fa5,"@@ -1,3 +1,6 @@
     public static Element getParent(Element elem) {
-        return (Element)elem.getParentNode();
+        Node parent = elem.getParentNode();
+        if (parent instanceof Element)
+            return (Element)parent;
+        return null;
     } // getParent(Element):Element
\ No newline at end of file
","Fixed some small bugs. Now we can have a sequence of two elements.


git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@317613 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,4757.json,c7c7140fbc0baf115a90871a337515ebc33c7265,"@@ -1,45 +1,45 @@
     public XMLInputSource resolveEntity(XMLResourceIdentifier resourceIdentifier)
             throws XNIException, IOException {
         
         if (fEntityResolver != null) {
             
             String pubId = resourceIdentifier.getPublicId();
-            String sysId = resourceIdentifier.getExpandedSystemId();
+            String sysId = resourceIdentifier.getLiteralSystemId();
             String baseURI = resourceIdentifier.getBaseSystemId();
             String name = null;
             if (resourceIdentifier instanceof XMLDTDDescription) {
                 name = ""[dtd]"";
             }
             else if (resourceIdentifier instanceof XMLEntityDescription) {
                 name = ((XMLEntityDescription) resourceIdentifier).getEntityName();
             }
             
             // When both pubId and sysId are null, the user's entity resolver
             // can do nothing about it. We'd better not bother calling it.
             // This happens when the resourceIdentifier is a GrammarDescription,
             // which describes a schema grammar of some namespace, but without
             // any schema location hint. -Sg
             if (pubId == null && sysId == null) {
                 return null;
             }
             
             // Resolve using EntityResolver2
             try {
                 InputSource inputSource = 
                     fEntityResolver.resolveEntity(name, pubId, baseURI, sysId);
                 return (inputSource != null) ? createXMLInputSource(inputSource, baseURI) : null;
             }
             // error resolving entity
             catch (SAXException e) {
                 Exception ex = e.getException();
                 if (ex == null) {
                     ex = e;
                 }
                 throw new XNIException(ex);
             }   
         }
         
         // unable to resolve entity
         return null;
         
     } // resolveEntity(XMLResourceIdentifier):XMLInputSource
\ No newline at end of file
","Fixing a bug. The systemId passed to EntityResolver2.resolveEntity may be an absolute or relative URI.
That is it should be the literal system identifier, not the expanded one which resolved from the base URI.


git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@320213 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,1574.json,474a683ae11a84aaa7da8861708189c9d0c5d551,"@@ -1,11 +1,14 @@
     public boolean isNonEscapingElement( String tagName )
     {
         int i;
 
-        if ( _nonEscapingElements == null )
-            return false;
+        if ( _nonEscapingElements == null ) {
+            // non escaping was not set
+            // by default output value for elements as unescaped
+            return true;
+        }
         for ( i = 0 ; i < _nonEscapingElements.length ; ++i )
             if ( _nonEscapingElements[ i ].equals( tagName ) )
                 return true;
         return false;
     }
\ No newline at end of file
","Bug fix: http://nagoya.apache.org/bugzilla/show_bug.cgi?id=2389


git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@318097 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,5596.json,1543bbc70bee5fdf7d5abd54532f9b21e7617de5,"@@ -1,86 +1,86 @@
     protected void intersectRanges(Token token) {
         RangeToken tok = (RangeToken)token;
         if (tok.ranges == null || this.ranges == null)
             return;
         this.icaseCache = null;
         this.sortRanges();
         this.compactRanges();
         tok.sortRanges();
         tok.compactRanges();
 
         int[] result = new int[this.ranges.length+tok.ranges.length];
         int wp = 0, src1 = 0, src2 = 0;
         while (src1 < this.ranges.length && src2 < tok.ranges.length) {
             int src1begin = this.ranges[src1];
             int src1end = this.ranges[src1+1];
             int src2begin = tok.ranges[src2];
             int src2end = tok.ranges[src2+1];
             if (src1end < src2begin) {          // Not overlapped
                                                 // src1: o-----o
                                                 // src2:         o-----o
                                                 // res:  empty
                                                 // Reuse src2
                 src1 += 2;
             } else if (src1end >= src2begin
                        && src1begin <= src2end) { // Overlapped
                                                 // src1:    o--------o
                                                 // src2:  o----o
                                                 // src2:      o----o
                                                 // src2:          o----o
                                                 // src2:  o------------o
-                if (src2begin <= src2begin && src1end <= src2end) {
+                if (src2begin <= src1begin && src1end <= src2end) {
                                                 // src1:    o--------o
                                                 // src2:  o------------o
                                                 // res:     o--------o
                                                 // Reuse src2
                     result[wp++] = src1begin;
                     result[wp++] = src1end;
                     src1 += 2;
                 } else if (src2begin <= src1begin) {
                                                 // src1:    o--------o
                                                 // src2:  o----o
                                                 // res:     o--o
                                                 // Reuse the rest of src1
                     result[wp++] = src1begin;
                     result[wp++] = src2end;
                     this.ranges[src1] = src2end+1;
                     src2 += 2;
                 } else if (src1end <= src2end) {
                                                 // src1:    o--------o
                                                 // src2:          o----o
                                                 // res:           o--o
                                                 // Reuse src2
                     result[wp++] = src2begin;
                     result[wp++] = src1end;
                     src1 += 2;
                 } else {
                                                 // src1:    o--------o
                                                 // src2:      o----o
                                                 // res:       o----o
                                                 // Reuse the rest of src1
                     result[wp++] = src2begin;
                     result[wp++] = src2end;
                     this.ranges[src1] = src2end+1;
                 }
             } else if (src2end < src1begin) {
                                                 // Not overlapped
                                                 // src1:          o-----o
                                                 // src2: o----o
                 src2 += 2;
             } else {
                 throw new RuntimeException(""Token#intersectRanges(): Internal Error: [""
                                            +this.ranges[src1]
                                            +"",""+this.ranges[src1+1]
                                            +""] & [""+tok.ranges[src2]
                                            +"",""+tok.ranges[src2+1]
                                            +""]"");
             }
         }
         while (src1 < this.ranges.length) {
             result[wp++] = this.ranges[src1++];
             result[wp++] = this.ranges[src1++];
         }
         this.ranges = new int[wp];
         System.arraycopy(result, 0, this.ranges, 0, wp);
                                                 // this.ranges is sorted and compacted.
     }
\ No newline at end of file
","Fixing JIRA Bug #1224:
http://issues.apache.org/jira/browse/XERCESJ-1224

Correcting a typo in intersectRanges(). Thanks to Dave Brosius 
for catching this error and suggesting how to correct it.


git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@504431 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,3365.json,163dc12c725a4e9bc243970c82016cb18998c25c,"@@ -1,34 +1,37 @@
     public TimeZone getTimeZone(int defaultZoneoffset) {
         TimeZone result = null;
         int zoneoffset = getTimezone();
 
         if (zoneoffset == DatatypeConstants.FIELD_UNDEFINED) {
             zoneoffset = defaultZoneoffset;
         }
         if (zoneoffset == DatatypeConstants.FIELD_UNDEFINED) {
             result = TimeZone.getDefault();
         } else {
             // zoneoffset is in minutes. Convert to custom timezone id format.
             char sign = zoneoffset < 0 ? '-' : '+';
             if (sign == '-') {
                 zoneoffset = -zoneoffset;
             }
             int hour = zoneoffset / 60;
             int minutes = zoneoffset - (hour * 60);
 
             // Javadoc for java.util.TimeZone documents max length
             // for customTimezoneId is 8 when optional ':' is not used.
             // Format is 
             // ""GMT"" ('-'|''+') (digit digit?) (digit digit)?
             //                   hour          minutes
             StringBuffer customTimezoneId = new StringBuffer(8);
             customTimezoneId.append(""GMT"");
             customTimezoneId.append(sign);
             customTimezoneId.append(hour);
             if (minutes != 0) {
+                if (minutes < 10) {
+                    customTimezoneId.append('0');
+                }
                 customTimezoneId.append(minutes);
             }
             result = TimeZone.getTimeZone(customTimezoneId.toString());
         }
         return result;
     }
\ No newline at end of file
","Fixing JIRA Bug #1243:
http://issues.apache.org/jira/browse/XERCESJ-1243

When we're building the TimeZone string if minutes < 10 we need to prepend a zero
to conform to the format expected by TimeZone.getTimeZone().


git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@524223 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,4419.json,0414900df065f25d451157d2c0f4d9ed5079d3a8,"@@ -1,13 +1,18 @@
     public void startParameterEntity (String name,
     XMLResourceIdentifier identifier,
     String encoding,
     Augmentations augs) throws XNIException {
         if (DEBUG_EVENTS) {
             System.out.println (""==>startParameterEntity: ""+name);
             if (DEBUG_BASEURI) {
                 System.out.println (""   expandedSystemId: ""+identifier.getExpandedSystemId ());
                 System.out.println (""   baseURI:""+ identifier.getBaseSystemId ());
             }
         }
+        if (augs != null && fInternalSubset != null && 
+            !fInDTDExternalSubset && 
+            Boolean.TRUE.equals(augs.getItem(Constants.ENTITY_SKIPPED))) {
+            fInternalSubset.append(name).append("";\n"");
+        }
         fBaseURIStack.push (identifier.getExpandedSystemId ());
     }
\ No newline at end of file
","Fixing JIRA Bug #1114:
http://issues.apache.org/jira/browse/XERCESJ-1114

If a parameter entity is skipped the parameter entity reference 
should be written into the internal subset string.

git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@441668 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,2331.json,c8ed9f7617b7aef095f3e03f97aefda48972f356,"@@ -1,178 +1,197 @@
     public short compareTreePosition(Node other) {
         // Questions of clarification for this method - to be answered by the
         // DOM WG.   Current assumptions listed - LM
         // 
         // 1. How do ENTITY nodes compare?  
         //    Current assumption: TREE_POSITION_DISCONNECTED, as ENTITY nodes 
         //    aren't really 'in the tree'
         //
         // 2. How do NOTATION nodes compare?
         //    Current assumption: TREE_POSITION_DISCONNECTED, as NOTATION nodes
         //    aren't really 'in the tree'
         //
         // 3. Are TREE_POSITION_ANCESTOR and TREE_POSITION_DESCENDANT     
         //    only relevant for nodes that are ""part of the document tree""?   
         //     <outer>
         //         <inner  myattr=""true""/>
         //     </outer>
         //    Is the element node ""outer"" considered an ancestor of ""myattr""?
         //    Current assumption: No.                                     
         //
         // 4. How do children of ATTRIBUTE nodes compare (with eachother, or  
         //    with children of other attribute nodes with the same element)    
         //    Current assumption: Children of ATTRIBUTE nodes are treated as if 
         //    they they are the attribute node itself, unless the 2 nodes 
         //    are both children of the same attribute. 
         //
         // 5. How does an ENTITY_REFERENCE node compare with it's children? 
         //    Given the DOM, it should precede its children as an ancestor. 
         //    Given ""document order"",  does it represent the same position?     
         //    Current assumption: An ENTITY_REFERENCE node is an ancestor of its
         //    children.
         //
         // 6. How do children of a DocumentFragment compare?   
         //    Current assumption: If both nodes are part of the same document 
         //    fragment, there are compared as if they were part of a document. 
 
         
         // If the nodes are the same...
         if (this==other) 
           return (TREE_POSITION_SAME_NODE | TREE_POSITION_EQUIVALENT);
         
         // If either node is of type ENTITY or NOTATION, compare as disconnected
         short thisType = this.getNodeType();
         short otherType = other.getNodeType();
 
         // If either node is of type ENTITY or NOTATION, compare as disconnected
         if (thisType == Node.ENTITY_NODE || 
             thisType == Node.NOTATION_NODE ||
             otherType == Node.ENTITY_NODE ||
             otherType == Node.NOTATION_NODE ) {
           return TREE_POSITION_DISCONNECTED; 
         }
 
         // Find the ancestor of each node, and the distance each node is from 
         // its ancestor.
         // During this traversal, look for ancestor/descendent relationships 
         // between the 2 nodes in question. 
         // We do this now, so that we get this info correct for attribute nodes 
         // and their children. 
 
         Node node; 
         Node thisAncestor = this;
         Node otherAncestor = other;
         int thisDepth=0;
         int otherDepth=0;
         for (node=this; node != null; node = node.getParentNode()) {
             thisDepth +=1;
             if (node == other) 
               // The other node is an ancestor of this one.
               return (TREE_POSITION_ANCESTOR | TREE_POSITION_PRECEDING);
             thisAncestor = node;
         }
 
         for (node=other; node!=null; node=node.getParentNode()) {
             otherDepth +=1;
             if (node == this) 
               // The other node is a descendent of the reference node.
               return (TREE_POSITION_DESCENDANT | TREE_POSITION_FOLLOWING);
             otherAncestor = node;
         }
         
        
         Node thisNode = this;
         Node otherNode = other;
 
         int thisAncestorType = thisAncestor.getNodeType();
         int otherAncestorType = otherAncestor.getNodeType();
 
         // if the ancestor is an attribute, get owning element. 
         // we are now interested in the owner to determine position.
 
         if (thisAncestorType == Node.ATTRIBUTE_NODE)  {
            thisNode = ((AttrImpl)thisAncestor).getOwnerElement();
         }
         if (otherAncestorType == Node.ATTRIBUTE_NODE) {
            otherNode = ((AttrImpl)otherAncestor).getOwnerElement();
         }
 
         // Before proceeding, we should check if both ancestor nodes turned
         // out to be attributes for the same element
         if (thisAncestorType == Node.ATTRIBUTE_NODE &&  
             otherAncestorType == Node.ATTRIBUTE_NODE &&  
             thisNode==otherNode)              
             return TREE_POSITION_EQUIVALENT;
 
         // Now, find the ancestor of the owning element, if the original
         // ancestor was an attribute
  
         // Note:  the following 2 loops are quite close to the ones above.
         // May want to common them up.  LM.
         if (thisAncestorType == Node.ATTRIBUTE_NODE) {
             thisDepth=0;
             for (node=thisNode; node != null; node=node.getParentNode()) {
                 thisDepth +=1;
                 if (node == otherNode) 
                   // The other node is an ancestor of the owning element
+                  {
                   return TREE_POSITION_PRECEDING;
+                  }
                 thisAncestor = node;
             }
         }
 
         // Now, find the ancestor of the owning element, if the original
         // ancestor was an attribute
         if (otherAncestorType == Node.ATTRIBUTE_NODE) {
             otherDepth=0;
             for (node=otherNode; node != null; node=node.getParentNode()) {
                 otherDepth +=1;
                 if (node == thisNode) 
                   // The other node is a descendent of the reference 
                   // node's element
                   return TREE_POSITION_FOLLOWING;
                 otherAncestor = node;
             }
         }
 
         // thisAncestor and otherAncestor must be the same at this point,  
         // otherwise, we are not in the same tree or document fragment
         if (thisAncestor != otherAncestor) 
           return TREE_POSITION_DISCONNECTED; 
 
-        // Determine which node is of the greatest depth.  
+      
+        // Go up the parent chain of the deeper node, until we find a node 
+        // with the same depth as the shallower node
+
         if (thisDepth > otherDepth) {
           for (int i=0; i<thisDepth - otherDepth; i++)
             thisNode = thisNode.getParentNode();
+          // Check if the node we have reached is in fact ""otherNode"". This can
+          // happen in the case of attributes.  In this case, otherNode 
+          // ""precedes"" this.
+          if (thisNode == otherNode) 
+            return TREE_POSITION_PRECEDING;
         }
+ 
         else {
           for (int i=0; i<otherDepth - thisDepth; i++)
             otherNode = otherNode.getParentNode();
+          // Check if the node we have reached is in fact ""thisNode"".  This can
+          // happen in the case of attributes.  In this case, otherNode 
+          // ""follows"" this.
+          if (otherNode == thisNode) 
+            return TREE_POSITION_FOLLOWING;
         }
-          
+             
         // We now have nodes at the same depth in the tree.  Find a common 
         // ancestor.                                   
         Node thisNodeP, otherNodeP;
         for (thisNodeP=thisNode.getParentNode(),
                   otherNodeP=otherNode.getParentNode();
              thisNodeP!=otherNodeP;) {
              thisNode = thisNodeP;
              otherNode = otherNodeP;
              thisNodeP = thisNodeP.getParentNode();
              otherNodeP = otherNodeP.getParentNode();
         }
 
+        // At this point, thisNode and otherNode are direct children of 
+        // the common ancestor.  
         // See whether thisNode or otherNode is the leftmost
+
         for (Node current=thisNodeP.getFirstChild(); 
                   current!=null;
                   current=current.getNextSibling()) {
                if (current==otherNode) {
                  return TREE_POSITION_PRECEDING;
                }
                else if (current==thisNode) {
                  return TREE_POSITION_FOLLOWING;
                }
         }
         // REVISIT:  shouldn't get here.   Should probably throw an 
         // exception
         return 0;
 
     }
\ No newline at end of file
","Fix for bug 13054


git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@318777 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,4598.json,1ab22779af45496ed09d0d35aa50271c6e881b33,"@@ -1,3 +1,4 @@
     public void setLocale(Locale locale) throws XNIException {
+    	super.setLocale(locale);
         fErrorReporter.setLocale(locale);
     } // setLocale(Locale)
\ No newline at end of file
","fix for bug id 5927. Thanks to 'Taki' for the solution.


git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@318115 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,1891.json,61370c8cd1f67817077ae8b356b0f69747471746,"@@ -1,72 +1,74 @@
     protected boolean matchChildSequence(QName element, int event)
             throws XNIException {
     	
         // need to resize fCurrentChildSequence
         if (fCurrentChildDepth >= fCurrentChildSequence.length) {
             int tmpCurrentChildSequence[] = new int[fCurrentChildSequence.length];
             System.arraycopy(fCurrentChildSequence, 0, tmpCurrentChildSequence,
                     0, fCurrentChildSequence.length);
 
             // Increase the size by a factor of 2 (?)
             fCurrentChildSequence = new int[fCurrentChildDepth * 2];
             System.arraycopy(tmpCurrentChildSequence, 0, fCurrentChildSequence,
                     0, tmpCurrentChildSequence.length);
         }
 
         //     
         if (fIsResolveElement) {
             // start
             if (event == XPointerPart.EVENT_ELEMENT_START) {
                 fCurrentChildSequence[fCurrentChildDepth] = fCurrentChildPosition;
                 fCurrentChildDepth++;
 
                 // reset the current child position 
                 fCurrentChildPosition = 1;
 
                 //if (!fSchemeNameFound) {
                 if ((fCurrentChildDepth <= fFoundDepth) || (fFoundDepth == 0)) {
                     if (checkMatch()) {
                         fIsElementFound = true;
                         fFoundDepth = fCurrentChildDepth;
                     } else {
                         fIsElementFound = false;
                         fFoundDepth = 0;
                     }
                 }
 
             } else if (event == XPointerPart.EVENT_ELEMENT_END) {
                 if (fCurrentChildDepth == fFoundDepth) {
                     fIsElementFound = true;
                 } else if (((fCurrentChildDepth < fFoundDepth) && (fFoundDepth != 0))
                         || ((fCurrentChildDepth > fFoundDepth) // or empty element found
                         && (fFoundDepth == 0))) {
                     fIsElementFound = false;
                 }
 
                 // reset array position of last child
                 fCurrentChildSequence[fCurrentChildDepth] = 0;
 
                 fCurrentChildDepth--;
                 fCurrentChildPosition = fCurrentChildSequence[fCurrentChildDepth] + 1;
                 
             } else if (event == XPointerPart.EVENT_ELEMENT_EMPTY) {
 
                 fCurrentChildSequence[fCurrentChildDepth] = fCurrentChildPosition;
                 fCurrentChildPosition++;
 
                 // Donot check for empty elements if the empty element is 
                 // a child of a found parent element 
-                //if (!fIsElementFound) {
-                    if (checkMatch()) {
-                        fIsElementFound = true;
+                if (checkMatch()) {
+                    if (!fIsElementFound) {
                         fWasOnlyEmptyElementFound = true;
                     } else {
-                        fIsElementFound = false;
+                        fWasOnlyEmptyElementFound = false;
                     }
-                //} 
-                
+                    fIsElementFound = true;
+                } else {
+                    fIsElementFound = false;
+                    fWasOnlyEmptyElementFound = false;
+                }  
             }
         }
 
         return fIsElementFound;
     }
\ No newline at end of file
","Fixing JIRA Bug #1134: http://issues.apache.org/jira/browse/XERCESJ-1134

git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@415823 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,7694.json,60697c3db7e640a090be94027b7b5e35be8de0e4,"@@ -1,19 +1,21 @@
     public synchronized XSObjectList getAnnotations() {
         if(fAnnotations != null) 
             return fAnnotations;
 
         // do this in two passes to avoid inaccurate array size
         int totalAnnotations = 0;
         for (int i = 0; i < fGrammarCount; i++) {
             totalAnnotations += fGrammarList[i].fNumAnnotations;
         }
         XSAnnotationImpl [] annotations = new XSAnnotationImpl [totalAnnotations];
         int currPos = 0;
         for (int i = 0; i < fGrammarCount; i++) {
             SchemaGrammar currGrammar = fGrammarList[i];
-            System.arraycopy(currGrammar.fAnnotations, 0, annotations, currPos, currGrammar.fNumAnnotations);
-            currPos += currGrammar.fNumAnnotations;
+            if (currGrammar.fNumAnnotations > 0) {
+                System.arraycopy(currGrammar.fAnnotations, 0, annotations, currPos, currGrammar.fNumAnnotations);
+                currPos += currGrammar.fNumAnnotations;
+            }
         }
         fAnnotations = new XSObjectListImpl(annotations, annotations.length);
         return fAnnotations;
     }
\ No newline at end of file
","Fixing Jira Bug #968:
http://nagoya.apache.org/jira/browse/XERCESJ-968

If no annotations exist for a SchemaGrammar the array
of annotations is never created. For such schema docs
we were passing null to System.arrayCopy which caused
a NullPointerException to be thrown. This is now fixed.


git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@319923 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,2219.json,5a14bab0762a851069a18eebd7f278b943f88c00,"@@ -1,20 +1,20 @@
     public Object getTypeInfo(int nodeIndex) {
         if (nodeIndex == -1) {
             return null;
         }
 
         int chunk = nodeIndex >> CHUNK_SHIFT;
         int index = nodeIndex & CHUNK_MASK;
         
         
-        Object value = fNodeValue[chunk][index];
+        Object value = fNodeValue[chunk] != null ? fNodeValue[chunk][index] : null;
         if (value != null) {
             fNodeValue[chunk][index] = null;
             RefCount c = (RefCount) fNodeValue[chunk][CHUNK_SIZE];
             c.fCount--;
             if (c.fCount == 0) {
                 fNodeValue[chunk] = null;
             }
         }
         return value;
     }
\ No newline at end of file
","Fix a bug introduced in the new getTypeInfo method (DOM L3)


git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@318962 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,4324.json,53ec54f2822c25f6815aa81b3b2eb8f46dd3caf5,"@@ -1,91 +1,91 @@
     protected void configurePipeline() {
         if (fCurrentDVFactory != fDatatypeValidatorFactory) {
             fCurrentDVFactory = fDatatypeValidatorFactory;
             // use XML 1.0 datatype library
             setProperty(DATATYPE_VALIDATOR_FACTORY, fCurrentDVFactory);
         }
 
         // setup DTD pipeline
         if (fCurrentDTDScanner != fDTDScanner) {
-			fCurrentDTDScanner = fDTDScanner;
+            fCurrentDTDScanner = fDTDScanner;
             setProperty(DTD_SCANNER, fCurrentDTDScanner);
             setProperty(DTD_PROCESSOR, fDTDProcessor);
-            fDTDScanner.setDTDHandler(fDTDProcessor);
-            fDTDProcessor.setDTDSource(fDTDScanner);
-            fDTDProcessor.setDTDHandler(fDTDHandler);
-            if (fDTDHandler != null) {
-                 fDTDHandler.setDTDSource(fDTDProcessor);
-            }
+        }
+        fDTDScanner.setDTDHandler(fDTDProcessor);
+        fDTDProcessor.setDTDSource(fDTDScanner);
+        fDTDProcessor.setDTDHandler(fDTDHandler);
+        if (fDTDHandler != null) {
+            fDTDHandler.setDTDSource(fDTDProcessor);
+        }
 
-            fDTDScanner.setDTDContentModelHandler(fDTDProcessor);
-            fDTDProcessor.setDTDContentModelSource(fDTDScanner);
-            fDTDProcessor.setDTDContentModelHandler(fDTDContentModelHandler);
-            if (fDTDContentModelHandler != null) {
-                fDTDContentModelHandler.setDTDContentModelSource(fDTDProcessor);
-            }            
+        fDTDScanner.setDTDContentModelHandler(fDTDProcessor);
+        fDTDProcessor.setDTDContentModelSource(fDTDScanner);
+        fDTDProcessor.setDTDContentModelHandler(fDTDContentModelHandler);
+        if (fDTDContentModelHandler != null) {
+            fDTDContentModelHandler.setDTDContentModelSource(fDTDProcessor);
         }
 
         // setup document pipeline
         if (fFeatures.get(NAMESPACES) == Boolean.TRUE) {
             if (fCurrentScanner != fNamespaceScanner) {
                 fCurrentScanner = fNamespaceScanner;
                 setProperty(DOCUMENT_SCANNER, fNamespaceScanner);
                 setProperty(DTD_VALIDATOR, fDTDValidator);
             }
             fNamespaceScanner.setDTDValidator(fDTDValidator);
             fNamespaceScanner.setDocumentHandler(fDTDValidator);
             fDTDValidator.setDocumentSource(fNamespaceScanner);
             fDTDValidator.setDocumentHandler(fDocumentHandler);
             if (fDocumentHandler != null) {
                 fDocumentHandler.setDocumentSource(fDTDValidator);
             }
             fLastComponent = fDTDValidator;
         } else {
             // create components
             if (fNonNSScanner == null) {
                 fNonNSScanner = new XMLDocumentScannerImpl();
                 fNonNSDTDValidator = new XMLDTDValidator();
                 // add components
                 addComponent((XMLComponent) fNonNSScanner);
                 addComponent((XMLComponent) fNonNSDTDValidator);
             }
             if (fCurrentScanner != fNonNSScanner) {
                 fCurrentScanner = fNonNSScanner;
                 setProperty(DOCUMENT_SCANNER, fNonNSScanner);
                 setProperty(DTD_VALIDATOR, fNonNSDTDValidator);
             }
 
             fNonNSScanner.setDocumentHandler(fNonNSDTDValidator);
             fNonNSDTDValidator.setDocumentSource(fNonNSScanner);
             fNonNSDTDValidator.setDocumentHandler(fDocumentHandler);
             if (fDocumentHandler != null) {
                 fDocumentHandler.setDocumentSource(fNonNSDTDValidator);
             }
             fLastComponent = fNonNSDTDValidator;
         }
 
         // add XML Schema validator if needed
         if (fFeatures.get(XMLSCHEMA_VALIDATION) == Boolean.TRUE) {
             // If schema validator was not in the pipeline insert it.
             if (fSchemaValidator == null) {
                 fSchemaValidator = new XMLSchemaValidator();
                 // add schema component
                 setProperty(SCHEMA_VALIDATOR, fSchemaValidator);
                 addCommonComponent(fSchemaValidator);
-				fSchemaValidator.reset(this);
+                fSchemaValidator.reset(this);
                 // add schema message formatter
                 if (fErrorReporter.getMessageFormatter(XSMessageFormatter.SCHEMA_DOMAIN) == null) {
                     XSMessageFormatter xmft = new XSMessageFormatter();
                     fErrorReporter.putMessageFormatter(XSMessageFormatter.SCHEMA_DOMAIN, xmft);
                 }
 
             }
             fLastComponent.setDocumentHandler(fSchemaValidator);
             fSchemaValidator.setDocumentSource(fLastComponent);
             fSchemaValidator.setDocumentHandler(fDocumentHandler);
             if (fDocumentHandler != null) {
                 fDocumentHandler.setDocumentSource(fSchemaValidator);
             }
             fLastComponent = fSchemaValidator;
         }
     } // configurePipeline()
\ No newline at end of file
","Fixing a bug in XML10 configurePipeline: we should always setup DTD pipeline (was only
setup if scanner has not been changed)


git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@319532 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,4808.json,70b3c80f83b7fcd277b5905ccde6e49f5e6274bb,"@@ -1,4 +1,4 @@
     public String getType(String qname) {
         int index = getIndex(qname);
-        return index != -1 ? fAttributes[index].type : null;
+        return index != -1 ? getType(index): null;
     } // getType(String):String
\ No newline at end of file
","fixing bug 15584.  Thanks to Michael Glavassevich for pointing out this bug in a SAX context; it was equally an XNI bug, however.


git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@319115 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,2281.json,f905e13bf111fee815eabfc522f4dfc0949fb422,"@@ -1,3 +1,3 @@
     public void setType(XSTypeDefinition type) {
-        type = type;
-    }
\ No newline at end of file
+        this.type = type;
+    }    
\ No newline at end of file
","Bug fix: http://nagoya.apache.org/bugzilla/show_bug.cgi?id=17064
Patch submitter: Michael Glavassevich


git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@319093 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,3095.json,955ef6b2ca713901bd702935c131a09390af1389,"@@ -1,9 +1,8 @@
     int indexOf(Node child, Node parent) {
-        Node node;
-        int i = 0;
         if (child.getParentNode() != parent) return -1;
-        for(node = child; node!= null; node=node.getPreviousSibling()) {
+        int i = 0;
+        for(Node node = parent.getFirstChild(); node!= child; node=node.getNextSibling()) {
             i++;
         }
         return i;
     }
\ No newline at end of file
","applied patch from Lynn Monson:
fixed a bug in indexOf which was off by 1


git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@316616 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,3693.json,b23b90432763872d07b931251896abce3e1e90e6,"@@ -1,39 +1,39 @@
         public InputSource resolveEntity(String name, String publicId, 
                 String baseURI, String systemId) throws SAXException, IOException {
             if (fEntityResolver != null) {
                 LSInput lsInput = fEntityResolver.resolveResource(XML_TYPE, null, publicId, systemId, baseURI);
                 if (lsInput != null) {
                     final String pubId = lsInput.getPublicId();
                     final String sysId = lsInput.getSystemId();
                     final String baseSystemId = lsInput.getBaseURI();
                     final Reader charStream = lsInput.getCharacterStream();
                     final InputStream byteStream = lsInput.getByteStream();
                     final String data = lsInput.getStringData();
                     final String encoding = lsInput.getEncoding();
 
                     /**
                      * An LSParser looks at inputs specified in LSInput in
                      * the following order: characterStream, byteStream,
                      * stringData, systemId, publicId. For consistency
                      * with the DOM Level 3 Load and Save Recommendation
                      * use the same lookup order here.
                      */
                     InputSource inputSource = new InputSource();
                     inputSource.setPublicId(pubId);
-                    inputSource.setSystemId((baseSystemId != null) ? resolveSystemId(systemId, baseSystemId) : systemId);
+                    inputSource.setSystemId((baseSystemId != null) ? resolveSystemId(sysId, baseSystemId) : sysId);
                     
                     if (charStream != null) {
                         inputSource.setCharacterStream(charStream);
                     }
                     else if (byteStream != null) {
                         inputSource.setByteStream(byteStream);
                     }
                     else if (data != null && data.length() != 0) {
                         inputSource.setCharacterStream(new StringReader(data));
                     }
                     inputSource.setEncoding(encoding);
                     return inputSource;
                 }
             }
             return null;
         }
\ No newline at end of file
","Fixing a minor bug. The InputSource returned from the resolution forwarder should 
contain the system identifier returned from the application's LSResourceResolver 
not the one which was passed to the resolveEntity() method.

git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@374971 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,1803.json,6c7a16c3202d0e50e4cd05449e9a5a9963f80e1b,"@@ -1,6 +1,7 @@
     public int hashCode() {
         if (uri != null) {
-            return uri.hashCode() + localpart.hashCode();
+            return uri.hashCode() + 
+                ((localpart != null) ? localpart.hashCode() : 0);
         }
-        return rawname.hashCode();
+        return (rawname != null) ? rawname.hashCode() : 0;
     } // hashCode():int
\ No newline at end of file
","Fixing Jira Bug #997:
http://nagoya.apache.org/jira/browse/XERCESJ-997

Fixing an NPE which may occur in the hashCode method
when either the localpart or rawname fields are null. This
seems to only be a problem for external users of this class.


git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@320004 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,3399.json,0df32768beedf6778651639c24d234d5b70f3b6e,"@@ -1,30 +1,33 @@
     private static void organizeParts(
         String whole,
         String[] parts,
         int[] partsIndex,
         int len,
         String tokens)
         throws IllegalArgumentException {
 
         int idx = tokens.length();
         for (int i = len - 1; i >= 0; i--) {
+            if (parts[i] == null) {
+                throw new IllegalArgumentException(whole);
+            }
             int nidx =
                 tokens.lastIndexOf(
                     parts[i].charAt(parts[i].length() - 1),
                     idx - 1);
             if (nidx == -1) {
                 throw new IllegalArgumentException(whole);
                 // ,partsIndex[i]+parts[i].length()-1);
             }
 
             for (int j = nidx + 1; j < idx; j++) {
                 parts[j] = null;
             }
             idx = nidx;
             parts[idx] = parts[i];
             partsIndex[idx] = partsIndex[i];
         }
         for (idx--; idx >= 0; idx--) {
             parts[idx] = null;
         }
     }
\ No newline at end of file
","Fixing JIRA Bug #1416: http://issues.apache.org/jira/browse/XERCESJ-1416. An NPE could occur when the value of the duration is invalid. Check for this condition and throw the correct exception.

git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@906803 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,3918.json,3260ba200fec37c5d074e5bb96ebd856e494ebe9,"@@ -1,14 +1,22 @@
     public void setFeature(String name, boolean value)
         throws ParserConfigurationException, SAXNotRecognizedException, 
 		SAXNotSupportedException
     {
         // XXX This is ugly.  We have to collect the features and then
         // later create an XMLReader to verify the features.
         if (features == null) {
             features = new Hashtable();
         }
         features.put(name, new Boolean(value));
 
         // Test the feature by possibly throwing SAX exceptions
-        newSAXParserImpl();
+        try {
+            newSAXParserImpl();
+        } catch (SAXNotSupportedException e) {
+            features.remove(name);
+            throw e;
+        } catch (SAXNotRecognizedException e) {
+            features.remove(name);
+            throw e;
+        }
     }
\ No newline at end of file
","Fix setFeature() bug provided by Kohsuke Kawaguchi


git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@317014 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,5468.json,7b91d52436909c5274ee9d683e37e15b4d73c03b,"@@ -1,111 +1,116 @@
     public void print(Node node) {
 
         // is there anything to do?
         if ( node == null ) {
             return;
         }
 
         int type = node.getNodeType();
         switch ( type ) {
         // print document
         case Node.DOCUMENT_NODE: {
                 if ( !canonical ) {
                     String  Encoding = this.getWriterEncoding();
                     if ( Encoding.equalsIgnoreCase( ""DEFAULT"" ) )
                         Encoding = ""UTF-8"";
                     else if ( Encoding.equalsIgnoreCase( ""Unicode"" ) )
                         Encoding = ""UTF-16"";
                     else
                         Encoding = MIME2Java.reverse( Encoding );
 
                     out.println(""<?xml version=\""1.0\"" encoding=\""""+
                                 Encoding + ""\""?>"");
                 }
-                print(((Document)node).getDocumentElement());
+                //print(((Document)node).getDocumentElement());
+                
+                NodeList children = node.getChildNodes(); 
+                for ( int iChild = 0; iChild < children.getLength(); iChild++ ) { 
+                    print(children.item(iChild)); 
+                } 
                 out.flush();
                 break;
             }
 
             // print element with attributes
         case Node.ELEMENT_NODE: {
                 out.print('<');
                 out.print(node.getNodeName());
                 Attr attrs[] = sortAttributes(node.getAttributes());
                 for ( int i = 0; i < attrs.length; i++ ) {
                     Attr attr = attrs[i];
                     out.print(' ');
                     out.print(attr.getNodeName());
                     out.print(""=\"""");
                     out.print(normalize(attr.getNodeValue()));
                     out.print('""');
                 }
                 out.print('>');
                 NodeList children = node.getChildNodes();
                 if ( children != null ) {
                     int len = children.getLength();
                     for ( int i = 0; i < len; i++ ) {
                         print(children.item(i));
                     }
                 }
                 break;
             }
 
             // handle entity reference nodes
         case Node.ENTITY_REFERENCE_NODE: {
                 if ( canonical ) {
                     NodeList children = node.getChildNodes();
                     if ( children != null ) {
                         int len = children.getLength();
                         for ( int i = 0; i < len; i++ ) {
                             print(children.item(i));
                         }
                     }
                 } else {
                     out.print('&');
                     out.print(node.getNodeName());
                     out.print(';');
                 }
                 break;
             }
 
             // print cdata sections
         case Node.CDATA_SECTION_NODE: {
                 if ( canonical ) {
                     out.print(normalize(node.getNodeValue()));
                 } else {
                     out.print(""<![CDATA["");
                     out.print(node.getNodeValue());
                     out.print(""]]>"");
                 }
                 break;
             }
 
             // print text
         case Node.TEXT_NODE: {
                 out.print(normalize(node.getNodeValue()));
                 break;
             }
 
             // print processing instruction
         case Node.PROCESSING_INSTRUCTION_NODE: {
                 out.print(""<?"");
                 out.print(node.getNodeName());
                 String data = node.getNodeValue();
                 if ( data != null && data.length() > 0 ) {
                     out.print(' ');
                     out.print(data);
                 }
-                out.print(""?>"");
+                out.println(""?>"");
                 break;
             }
         }
 
         if ( type == Node.ELEMENT_NODE ) {
             out.print(""</"");
             out.print(node.getNodeName());
             out.print('>');
         }
 
         out.flush();
 
     } // print(Node)
\ No newline at end of file
","Fix submitted by Ed Stub. Fixes problem reported by Stephane.RAULT@r2isa... where we
are no reporting PI's


PR:
Obtained from:
Submitted by:
Reviewed by:


git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@316112 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,684.json,d1fd0668a071ddcf44c6bdf1b50030bab12d18ee,"@@ -1,25 +1,26 @@
     public synchronized void deleteRow( int index )
     {
         Node    child;
         
         child = getFirstChild();
         while ( child != null )
         {
             if ( child instanceof HTMLTableRowElement )
             {
                 if ( index == 0 )
                 {
                     removeChild ( child );
                     return;
                 }
+                --index;
             }
             else
             if ( child instanceof HTMLTableSectionElementImpl )
             {
                 index = ( (HTMLTableSectionElementImpl) child ).deleteRowX( index );
                 if ( index < 0 )
                     return;
             }
             child = child.getNextSibling();
         }
     }
\ No newline at end of file
","Fixing bug in HTML DOM (http://nagoya.apache.org/bugzilla/show_bug.cgi?id=18744). Deletion of rows other than row 0 were failing siliently.

Thanks to Brett Sutton for the fix.


git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@319291 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,5580.json,af847434ae5a2c3408cae3c4b738622800c93e4f,"@@ -1,43 +1,43 @@
     private static void buildCaseInsensitiveMap() {
         caseInsensitiveMap = new int[INITIAL_CHUNK_COUNT][][];
         for (int i=0; i<INITIAL_CHUNK_COUNT; i++) {
             caseInsensitiveMap[i] = new int[CHUNK_SIZE][];
         }
         
         int lc, uc;
         for (int i=0; i<0x10000; i++) {
-            lc = Character.toLowerCase(i);
-            uc = Character.toUpperCase(i);
+            lc = Character.toLowerCase((char) i);
+            uc = Character.toUpperCase((char) i);
 
             // lower/upper case value is not the same as code point
             if (lc != uc || lc != i) {
                 int[] map = new int[2];
                 int index = 0;
 
                 if (lc != i) {
                     map[index++] = lc;
                     map[index++] = LOWER_CASE_MATCH;
                     int[] lcMap = getMapping(lc);
                     if (lcMap != null) {
                         map = updateMap(i, map, lc, lcMap, LOWER_CASE_MATCH);
                     }
                 }
                 
                 if (uc != i) {
                     if (index == map.length) {
                         map = expandMap(map, 2);
                     }
                     map[index++] = uc;
                     map[index++] = UPPER_CASE_MATCH;
                     int[] ucMap = getMapping(uc);
                     if (ucMap != null) {
                         map = updateMap(i, map, uc, ucMap, UPPER_CASE_MATCH);
                     }
                 }
                 
                 set(i, map);
             }
         }
 
         mapBuilt = Boolean.TRUE;
     }
\ No newline at end of file
","Fixing compilation errors on Java SE 1.4 and below. Character.toLowerCase(int) and Character.toUpperCase(int) didn't exist until Java SE 5.

git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@834593 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,7513.json,13892ec89f2b5203650caf1d7b5355df433dacfd,"@@ -1,74 +1,74 @@
         private void mergeSchemaGrammars(SchemaGrammar cachedGrammar, SchemaGrammar newGrammar) {
 
             /** Add new top-level element declarations. **/
             XSNamedMap map = newGrammar.getComponents(XSConstants.ELEMENT_DECLARATION);
             int length = map.getLength();
             for (int i = 0; i < length; ++i) {
                 XSElementDecl decl = (XSElementDecl) map.item(i);
-                if (cachedGrammar.getElementDeclaration(decl.getName()) == null) {
+                if (cachedGrammar.getGlobalElementDecl(decl.getName()) == null) {
                     cachedGrammar.addGlobalElementDecl(decl);
                 }
             }
             
             /** Add new top-level attribute declarations. **/
             map = newGrammar.getComponents(XSConstants.ATTRIBUTE_DECLARATION);
             length = map.getLength();
             for (int i = 0; i < length; ++i) {
                 XSAttributeDecl decl = (XSAttributeDecl) map.item(i);
-                if (cachedGrammar.getAttributeDeclaration(decl.getName()) == null) {
+                if (cachedGrammar.getGlobalAttributeDecl(decl.getName()) == null) {
                     cachedGrammar.addGlobalAttributeDecl(decl);
                 }
             }
             
             /** Add new top-level type definitions. **/
             map = newGrammar.getComponents(XSConstants.TYPE_DEFINITION);
             length = map.getLength();
             for (int i = 0; i < length; ++i) {
                 XSTypeDefinition decl = (XSTypeDefinition) map.item(i);
                 if (cachedGrammar.getGlobalTypeDecl(decl.getName()) == null) {
                     cachedGrammar.addGlobalTypeDecl(decl);
                 }
             }
             
             /** Add new top-level attribute group definitions. **/
             map = newGrammar.getComponents(XSConstants.ATTRIBUTE_GROUP);
             length = map.getLength();
             for (int i = 0; i < length; ++i) {
                 XSAttributeGroupDecl decl = (XSAttributeGroupDecl) map.item(i);
-                if (cachedGrammar.getAttributeDeclaration(decl.getName()) == null) {
+                if (cachedGrammar.getGlobalAttributeGroupDecl(decl.getName()) == null) {
                     cachedGrammar.addGlobalAttributeGroupDecl(decl);
                 }
             }
             
             /** Add new top-level model group definitions. **/
             map = newGrammar.getComponents(XSConstants.MODEL_GROUP);
             length = map.getLength();
             for (int i = 0; i < length; ++i) {
                 XSGroupDecl decl = (XSGroupDecl) map.item(i);
                 if (cachedGrammar.getGlobalGroupDecl(decl.getName()) == null) {
                     cachedGrammar.addGlobalGroupDecl(decl);
                 }
             }
             
             /** Add new top-level notation declarations. **/
             map = newGrammar.getComponents(XSConstants.NOTATION_DECLARATION);
             length = map.getLength();
             for (int i = 0; i < length; ++i) {
                 XSNotationDecl decl = (XSNotationDecl) map.item(i);
                 if (cachedGrammar.getGlobalNotationDecl(decl.getName()) == null) {
                     cachedGrammar.addGlobalNotationDecl(decl);
                 }
             }
             
             /** 
              * Add all annotations. Since these components are not named it's
              * possible we'll add duplicate components. There isn't much we can
              * do. It's no worse than XMLSchemaLoader when used as an XSLoader.
              */
             XSObjectList annotations = newGrammar.getAnnotations();
             length = annotations.getLength();
             for (int i = 0; i < length; ++i) {
                 cachedGrammar.addAnnotation((XSAnnotationImpl) annotations.item(i));
             }
             
         }
\ No newline at end of file
","Fixing a few minor bugs.


git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@320162 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,2176.json,b16dd097ce2ebce1533edaab4e6743b08da63bfe,"@@ -1,26 +1,26 @@
     public int createDeferredDocumentType(String rootElementName,
                                           String publicId, String systemId) {
 
         // create node
         int nodeIndex = createNode(Node.DOCUMENT_TYPE_NODE);
         int chunk     = nodeIndex >> CHUNK_SHIFT;
         int index     = nodeIndex & CHUNK_MASK;
 
         // added for DOM2: createDoctype factory method includes
         // name, publicID, systemID
 
         // create extra data node
         int extraDataIndex = createNode((short)0); // node type unimportant
         int echunk = extraDataIndex >> CHUNK_SHIFT;
         int eindex = extraDataIndex & CHUNK_MASK;
 
         // save name, public id, system id
         setChunkValue(fNodeName, rootElementName, chunk, index);
-        setChunkValue(fNodeValue, publicId, chunk, eindex);
-        setChunkValue(fNodeURI, systemId, chunk, eindex);
+        setChunkValue(fNodeValue, publicId, chunk, index);
+        setChunkValue(fNodeURI, systemId, chunk, index);
         setChunkIndex(fNodeExtra, extraDataIndex, chunk, index);
 
         // return node index
         return nodeIndex;
 
     } // createDeferredDocumentType(String,String,String):int
\ No newline at end of file
","Fixed bug that caused namespace information to be lost
in the deferred DOM.


git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@317632 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,5971.json,b3530fffbb47d1dc2dab5e538c013f388b4e142f,"@@ -1,26 +1,31 @@
         protected void resolveExternalSubsetAndRead()
             throws IOException, XNIException {
             
             fDTDDescription.setValues(null, null, fEntityManager.getCurrentResourceIdentifier().getExpandedSystemId(), null);
             fDTDDescription.setRootName(fElementQName.rawname);
             XMLInputSource src = fExternalSubsetResolver.getExternalSubset(fDTDDescription);
             
             if (src != null) {
                 fDoctypeName = fElementQName.rawname;
                 fDoctypePublicId = src.getPublicId();
                 fDoctypeSystemId = src.getSystemId();
                 // call document handler
                 if (fDocumentHandler != null) {
                     // This inserts a doctypeDecl event into the stream though no 
                     // DOCTYPE existed in the instance document.
                     fDocumentHandler.doctypeDecl(fDoctypeName, fDoctypePublicId, fDoctypeSystemId, null);
                 }
                 try {
-                    fDTDScanner.setInputSource(src);
-                    while (fDTDScanner.scanDTDExternalSubset(true));
+                    if (fValidationManager == null || !fValidationManager.isCachedDTD()) {
+                        fDTDScanner.setInputSource(src);
+                        while (fDTDScanner.scanDTDExternalSubset(true));
+                    }
+                    else {
+                        fDTDScanner.setInputSource(null);
+                    }
                 }
                 finally {
                     fEntityManager.setEntityHandler(XMLDocumentScannerImpl.this);
                 }
             }
         } // resolveExternalSubsetAndRead()
\ No newline at end of file
","Fixing a bug reported by Ritu Raj Tiwari on xerces-j-dev. When resolving
an external subset if there's already a DTD in the grammar pool do not
read the input source.


git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@320234 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,2755.json,2b2593eef2e2d2c5352fbc9b4e356053a93e34ab,"@@ -1,6 +1,12 @@
     Node matchNodeOrParent(Node node) {
+        // Additions and removals in the underlying data structure may occur
+        // before any iterations, and in this case the reference_node is null.
+        if (fCurrentNode == null) return null;
+        
+        // check if the removed node is an _ancestor_ of the 
+        // reference node
         for (Node n = fCurrentNode; n != fRoot; n = n.getParentNode()) {
             if (node == n) return n;
         }
         return null;
     }
\ No newline at end of file
","Bug fix: http://nagoya.apache.org/bugzilla/show_bug.cgi?id=13062


git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@318813 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,2755.json,7f856ddb5537fc5e98c71ff23700a48bac7f652d,"@@ -1,6 +1,6 @@
     Node matchNodeOrParent(Node node) {
-        for (Node n = node; n != fRoot; n = n.getParentNode()) {
+        for (Node n = fCurrentNode; n != fRoot; n = n.getParentNode()) {
             if (node == n) return n;
         }
         return null;
     }
\ No newline at end of file
","Applying patch suggested by Joe Kesselman. This fixes the following bug:
http://nagoya.apache.org/bugzilla/show_bug.cgi?id=6888


git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@318267 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,4545.json,3893a210786fea6e8236c54214287515c5333708,"@@ -1,8 +1,9 @@
     public void setFeature(String featureId, boolean state)
         throws XMLConfigurationException {
         if (featureId.equals(XINCLUDE_FEATURE)) {
             fXIncludeEnabled = state;
+            fConfigUpdated = true;
             return;
         }
         super.setFeature(featureId,state);
     }
\ No newline at end of file
","Fixing a bug. It was possible that the XIncludeHandler could be used without being properly reset.


git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@320336 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,376.json,9768ff6cd6cd57357deb3c4be70cb29bb476e3d2,"@@ -1,15 +1,16 @@
     public String getJavaEncoding() {
         String javaEncoding = null;
         String mimeEncoding = getMimeEncoding();
 
         if (mimeEncoding != null) {
             if (mimeEncoding.equals( ""DEFAULT"" ))
                 javaEncoding =  ""UTF8"";
             else if (mimeEncoding.equalsIgnoreCase( ""UTF-16"" ))
                 javaEncoding = ""Unicode"";
             else
                 javaEncoding = EncodingMap.getIANA2JavaMapping( mimeEncoding );    
-        } else   // Should never return null
+        } 
+        if(javaEncoding == null)   // Should never return null
             javaEncoding = ""UTF8"";
         return(javaEncoding);
     }
\ No newline at end of file
","fix for bug #6008


git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@318133 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,5806.json,f6fbb6219a5d2f0cfd71f23812b4571049b5613b,"@@ -1,93 +1,97 @@
     Token parseFactor() throws ParseException {        
         int ch = this.read();
         Token tok;
         switch (ch) {
           case T_CARET:         return this.processCaret();
           case T_DOLLAR:        return this.processDollar();
           case T_LOOKAHEAD:     return this.processLookahead();
           case T_NEGATIVELOOKAHEAD: return this.processNegativelookahead();
           case T_LOOKBEHIND:    return this.processLookbehind();
           case T_NEGATIVELOOKBEHIND: return this.processNegativelookbehind();
 
           case T_COMMENT:
             this.next();
             return Token.createEmpty();
 
           case T_BACKSOLIDUS:
             switch (this.chardata) {
               case 'A': return this.processBacksolidus_A();
               case 'Z': return this.processBacksolidus_Z();
               case 'z': return this.processBacksolidus_z();
               case 'b': return this.processBacksolidus_b();
               case 'B': return this.processBacksolidus_B();
               case '<': return this.processBacksolidus_lt();
               case '>': return this.processBacksolidus_gt();
             }
                                                 // through down
         }
         tok = this.parseAtom();
         ch = this.read();
         switch (ch) {
           case T_STAR:  return this.processStar(tok);
           case T_PLUS:  return this.processPlus(tok);
           case T_QUESTION: return this.processQuestion(tok);
           case T_CHAR:
             if (this.chardata == '{' && this.offset < this.regexlen) {
 
                 int off = this.offset;          // this.offset -> next of '{'
                 int min = 0, max = -1;
 
                 if ((ch = this.regex.charAt(off++)) >= '0' && ch <= '9') {
 
                     min = ch -'0';
                     while (off < this.regexlen
                            && (ch = this.regex.charAt(off++)) >= '0' && ch <= '9') {
                         min = min*10 +ch-'0';
+                        if (min < 0)
+                            throw ex(""parser.quantifier.5"", this.offset);
                     }
                 }
                 else {
                     throw ex(""parser.quantifier.1"", this.offset);
                 }
 
                 max = min;
                 if (ch == ',') {
 
                    if (off >= this.regexlen) {
                        throw ex(""parser.quantifier.3"", this.offset);
                    }
                    else if ((ch = this.regex.charAt(off++)) >= '0' && ch <= '9') {                       
 
                         max = ch -'0';       // {min,max}
                         while (off < this.regexlen
                                && (ch = this.regex.charAt(off++)) >= '0'
                                && ch <= '9') {
                             max = max*10 +ch-'0';
+                            if (max < 0)
+                                throw ex(""parser.quantifier.5"", this.offset);
                         }
 
                         if (min > max)
                             throw ex(""parser.quantifier.4"", this.offset);
                    }
                    else { // assume {min,}
                         max = -1;           
                     }
                 }
 
                if (ch != '}')
                    throw ex(""parser.quantifier.2"", this.offset);
 
                if (this.checkQuestion(off)) {  // off -> next of '}'
                     tok = Token.createNGClosure(tok);
                     this.offset = off+1;
                 } else {
                     tok = Token.createClosure(tok);
                     this.offset = off;
                 }
 
                 tok.setMin(min);
                 tok.setMax(max);
                 //System.err.println(""CLOSURE: ""+min+"", ""+max);
                 this.next();
             }
         }
         return tok;
     }
\ No newline at end of file
","Fixing bugs 17415: Regexes with large min/max not handled correctly.
Many thanks to Khaled Noaman for the patch.


git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@319162 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,5806.json,218c54d8d80c22fd4d9f45f8013e14eb23838699,"@@ -1,89 +1,93 @@
     Token parseFactor() throws ParseException {        
         int ch = this.read();
         Token tok;
         switch (ch) {
           case T_CARET:         return this.processCaret();
           case T_DOLLAR:        return this.processDollar();
           case T_LOOKAHEAD:     return this.processLookahead();
           case T_NEGATIVELOOKAHEAD: return this.processNegativelookahead();
           case T_LOOKBEHIND:    return this.processLookbehind();
           case T_NEGATIVELOOKBEHIND: return this.processNegativelookbehind();
 
           case T_COMMENT:
             this.next();
             return Token.createEmpty();
 
           case T_BACKSOLIDUS:
             switch (this.chardata) {
               case 'A': return this.processBacksolidus_A();
               case 'Z': return this.processBacksolidus_Z();
               case 'z': return this.processBacksolidus_z();
               case 'b': return this.processBacksolidus_b();
               case 'B': return this.processBacksolidus_B();
               case '<': return this.processBacksolidus_lt();
               case '>': return this.processBacksolidus_gt();
             }
                                                 // through down
         }
         tok = this.parseAtom();
         ch = this.read();
         switch (ch) {
           case T_STAR:  return this.processStar(tok);
           case T_PLUS:  return this.processPlus(tok);
           case T_QUESTION: return this.processQuestion(tok);
           case T_CHAR:
-            if (this.chardata == '{') {
-                                                // this.offset -> next of '{'
-                int off = this.offset;
+            if (this.chardata == '{' && this.offset < this.regexlen) {
+
+                int off = this.offset;          // this.offset -> next of '{'
                 int min = 0, max = -1;
-                if (off >= this.regexlen)  break;
-                ch = this.regex.charAt(off++);
-                if (ch != ',' && (ch < '0' || ch > '9'))  break;
-                if (ch != ',') {                // 0-9
-                    min = ch-'0';
+
+                if ((ch = this.regex.charAt(off++)) >= '0' && ch <= '9') {
+
+                    min = ch -'0';
                     while (off < this.regexlen
                            && (ch = this.regex.charAt(off++)) >= '0' && ch <= '9') {
                         min = min*10 +ch-'0';
-                        ch = -1;
                     }
-                    if (ch < 0)  break;
                 }
-                //if (off >= this.regexlen)  break;
+                else {
+                    throw ex(""parser.quantifier.1"", this.offset);
+                }
+
                 max = min;
                 if (ch == ',') {
-                    if (off >= this.regexlen
-                        || ((ch = this.regex.charAt(off++)) < '0' || ch > '9')
-                        && ch != '}')
-                        break;
-                    if (ch == '}') {
-                        max = -1;           // {min,}
-                    } else {
-                        max = ch-'0';       // {min,max}
+
+                   if (off >= this.regexlen) {
+                       throw ex(""parser.quantifier.3"", this.offset);
+                   }
+                   else if ((ch = this.regex.charAt(off++)) >= '0' && ch <= '9') {                       
+
+                        max = ch -'0';       // {min,max}
                         while (off < this.regexlen
                                && (ch = this.regex.charAt(off++)) >= '0'
                                && ch <= '9') {
                             max = max*10 +ch-'0';
-                            ch = -1;
                         }
-                        if (ch < 0)  break;
-                        //if (min > max)
-                        //    throw new ParseException(""parseFactor(): min > max: ""+min+"", ""+max);
+
+                        if (min > max)
+                            throw ex(""parser.quantifier.4"", this.offset);
+                   }
+                   else { // assume {min,}
+                        max = -1;           
                     }
                 }
-                if (ch != '}')  break;
-                                                // off -> next of '}'
-                if (this.checkQuestion(off)) {
+
+               if (ch != '}')
+                   throw ex(""parser.quantifier.2"", this.offset);
+
+               if (this.checkQuestion(off)) {  // off -> next of '}'
                     tok = Token.createNGClosure(tok);
                     this.offset = off+1;
                 } else {
                     tok = Token.createClosure(tok);
                     this.offset = off;
                 }
+
                 tok.setMin(min);
                 tok.setMax(max);
                 //System.err.println(""CLOSURE: ""+min+"", ""+max);
                 this.next();
             }
         }
         return tok;
     }
\ No newline at end of file
","Fixing bugs 17417: Regex {min,max} with min > max not rejected.
Many thanks to Khaled Noaman for the patch.


git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@319159 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,7034.json,ba7898b39060234e9c88e9e06c0dd5fbed52a9fb,"@@ -1,12 +1,13 @@
     public void startDocument() throws SAXException {
         fNeedPushNSContext = true;
+        fNamespaceContext.reset();
         try {
             fSchemaDOMParser.startDocument(fSAXLocatorWrapper, null, fNamespaceContext, null);
         }
         catch (XMLParseException e) {
             convertToSAXParseException(e);
         }
         catch (XNIException e) {
             convertToSAXException(e);
         }
     }
\ No newline at end of file
","Fixing a bug. We weren't reseting the NamespaceContext which can cause all sorts
of problems including the loss of some namespace decls on XSAnnotation components.

git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@644489 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,3375.json,883dc18e1cd70be3f4dc6fcaf48ddcdfe4c2a99d,"@@ -1,19 +1,19 @@
         private int parseInt(int minDigits, int maxDigits)
             throws IllegalArgumentException {
             int vstart = vidx;
-            while (isDigit(peek()) && (vidx - vstart) <= maxDigits) {
+            while (isDigit(peek()) && (vidx - vstart) < maxDigits) {
                 vidx++;
             }
             if ((vidx - vstart) < minDigits) {
                 // we are expecting more digits
                 throw new IllegalArgumentException(value); //,vidx);
             }
 
             // NumberFormatException is IllegalArgumentException            
             //           try {
             return Integer.parseInt(value.substring(vstart, vidx));
             //            } catch( NumberFormatException e ) {
             //                // if the value is too long for int, NumberFormatException is thrown
             //                throw new IllegalArgumentException(value,vstart);
             //            }
         }
\ No newline at end of file
","Fixing a bug. parseInt() was allowing maxDigits + 1 which caused 
XMLGregorianCalendar to accept bogus dates like ""2007-008-003"".

git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@565088 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,6542.json,3574857d4a4ddaf8aabec99216c178a5a6089a19,"@@ -1,46 +1,46 @@
     private void setOrdered(){
 
-        // When {variety} is atomic, {value} is inherited from {value} of {base type definition}. For all primitive types {value} is as specified in the table in Fundamental Facets (C.1).
+        // When {variety} is atomic, {value} is inherited from {value} of {base type definition}. For all ""primitive"" types {value} is as specified in the table in Fundamental Facets (C.1).
         if(fVariety == VARIETY_ATOMIC){
             this.fOrdered = fBase.fOrdered;
         }
 
         // When {variety} is list, {value} is false.
         else if(fVariety == VARIETY_LIST){
             this.fOrdered = ORDERED_FALSE;
         }
 
         // When {variety} is union, the {value} is partial unless one of the following:
         // 1. If every member of {member type definitions} is derived from a common ancestor other than the simple ur-type, then {value} is the same as that ancestor's ordered facet.
         // 2. If every member of {member type definitions} has a {value} of false for the ordered facet, then {value} is false.
         else if(fVariety == VARIETY_UNION){
             int length = fMemberTypes.length;
             // REVISIT: is the length possible to be 0?
             if (length == 0) {
                 this.fOrdered = ORDERED_PARTIAL;
                 return;
             }
             // we need to process the first member type before entering the loop
             short ancestorId = getPrimitiveDV(fMemberTypes[0].fValidationDV);
             boolean commonAnc = ancestorId != DV_ANYSIMPLETYPE;
             boolean allFalse = fMemberTypes[0].fOrdered == ORDERED_FALSE;
             // for the other member types, check whether the value is false
             // and whether they have the same ancestor as the first one
             for (int i = 1; i < fMemberTypes.length && (commonAnc || allFalse); i++) {
                 if (commonAnc)
                     commonAnc = ancestorId == getPrimitiveDV(fMemberTypes[i].fValidationDV);
                 if (allFalse)
                     allFalse = fMemberTypes[i].fOrdered == ORDERED_FALSE;
             }
             if (commonAnc) {
                 // REVISIT: all member types should have the same ordered value
                 //          just use the first one. Can we assume this?
                 this.fOrdered = fMemberTypes[0].fOrdered;
             } else if (allFalse) {
                 this.fOrdered = ORDERED_FALSE;
             } else {
                 this.fOrdered = ORDERED_PARTIAL;
             }
         }
 
     }//setOrdered
\ No newline at end of file
","fixing bug 16714


git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@319088 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,7850.json,d6e418eec78c8b253b3f353be05259d353faa58a,"@@ -1,12 +1,12 @@
     private CMNode multiNodes(CMNode node, int num, boolean copyFirst) {
         if (num == 0) {
             return null;
         }
         if (num == 1) {
             return copyFirst ? copyNode(node) : node;
         }
         int num1 = num/2;
         return fNodeFactory.getCMBinOpNode(XSModelGroupImpl.MODELGROUP_SEQUENCE,
                                            multiNodes(node, num1, copyFirst),
-                                           multiNodes(node, num-num1, false));
+                                           multiNodes(node, num-num1, true));
     }
\ No newline at end of file
","Fixing a bug introduced by a previous commit when trying to balance the
syntax tree.


git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@319270 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,8612.json,841a543458d7b19286dbcc32207d8978ccf195f5,"@@ -1,19 +1,19 @@
     protected void init() {
         if(fValidation || fDynamicValidation) {
             super.init();
             // now overwrite some entries in parent:
 
             try {
                 fValID       = fDatatypeValidatorFactory.getBuiltInDV(""XML11ID"");
-                fValIDRef    = fDatatypeValidatorFactory.getBuiltInDV(""XML11IDREFS"");
+                fValIDRef    = fDatatypeValidatorFactory.getBuiltInDV(""XML11IDREF"");
                 fValIDRefs   = fDatatypeValidatorFactory.getBuiltInDV(""XML11IDREFS"");
-                fValNMTOKEN  = fDatatypeValidatorFactory.getBuiltInDV(""XML11NMTOKENSymbol"");
+                fValNMTOKEN  = fDatatypeValidatorFactory.getBuiltInDV(""XML11NMTOKEN"");
                 fValNMTOKENS = fDatatypeValidatorFactory.getBuiltInDV(""XML11NMTOKENS"");
 
             }
             catch (Exception e) {
                 // should never happen
                 e.printStackTrace(System.err);
             }
         }
     } // init()
\ No newline at end of file
","Fixing 2 bugs:
1) Bugzilla# 18429, NPE thrown validating NMTOKEN. Thanks to Neil Delima for the patch.
2) S production is unchanged in XML 1.1, so shouldn't override isSpace()


git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@319269 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,27.json,874363b725dcbddf23ed1f1d07d9a6fcd6e3ca4c,"@@ -1,46 +1,47 @@
     public void attributeDecl(String elementName, String attributeName,
                               String type, String[] enumeration,
                               String defaultType, XMLString defaultValue, 
+                              XMLString nonNormalizedDefaultValue,
                               Augmentations augs) throws XNIException {
 
         printIndent();
         fOut.print(""attributeDecl("");
         fOut.print(""elementName="");
         printQuotedString(elementName);
         fOut.print(',');
         fOut.print(""attributeName="");
         printQuotedString(attributeName);
         fOut.print(',');
         fOut.print(""type="");
         printQuotedString(type);
         fOut.print(',');
         fOut.print(""enumeration="");
         if (enumeration == null) {
             fOut.print(""null"");
         }
         else {
             fOut.print('{');
             for (int i = 0; i < enumeration.length; i++) {
                 printQuotedString(enumeration[i]);
                 if (i < enumeration.length - 1) {
                     fOut.print(',');
                 }
             }
             fOut.print('}');
         }
         fOut.print(',');
         fOut.print(""defaultType="");
         printQuotedString(defaultType);
         fOut.print(',');
         fOut.print(""defaultValue="");
         if (defaultValue == null) {
             fOut.print(""null"");
         }
         else {
             printQuotedString(defaultValue.ch, defaultValue.offset,
                               defaultValue.length);
         }
         fOut.println(')');
         fOut.flush();
 
     } // attributeDecl(String,String,String,String[],String,XMLString)
\ No newline at end of file
","corrected attributeDecl signature in samples.
Thanks to John Spitzer for pointing that out (bug#6447).


git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@318206 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,7660.json,c034fce51f8f78ab929b74f4a902deb10034459a,"@@ -1,5 +1,5 @@
     static final Field[] resize(Field[] oldArray, int newSize) {
         Field[] newArray = new Field[newSize];
-        System.arraycopy(oldArray, 0, newArray, 0, newSize);
+        System.arraycopy(oldArray, 0, newArray, 0, oldArray.length);
         return newArray;
     }
\ No newline at end of file
","Fixing bug 9022: arrayCopy should take oldArray.length, instead of newSize.


git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@318392 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,938.json,0dde63af37b11224e5bc46928596405440cd0107,"@@ -1,15 +1,8 @@
     public Node cloneNode( boolean deep )
     {
         HTMLDocumentImpl    clone;
-        NodeImpl            node;
 
         clone = new HTMLDocumentImpl();
-        if ( deep ) {
-            node = (NodeImpl) getFirstChild();
-            while ( node != null ) {
-                clone.appendChild( clone.importNode( node, true ) );
-                node = (NodeImpl) node.getNextSibling();
-            }
-        }
+        cloneNode(clone, deep);
         return clone;
     }
\ No newline at end of file
","Fixing JIRA Bug #1021:
http://issues.apache.org/jira/browse/XERCESJ-1021

DocumentType nodes cannot be imported. Instead of attempting to loop
over the children of the Document node we should delegate to the
cloneNode(CoreDocumentImpl,boolean) method on DocumentImpl which
knows how to do the right thing. This should also fix ID assignment
and possibly other things.

git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@418366 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,8262.json,ef4f12df6ceef58d0976e59c42d72c11836172c8,"@@ -1,4 +1,10 @@
     public void setInputSource(XMLInputSource inputSource) throws IOException {
+        if (inputSource == null) {
+            // no system id was available
+            fDTDHandler.startDTD(null, null);
+            fDTDHandler.endDTD(null);
+            return;
+        }
         fEntityManager.setEntityHandler(this);
         fEntityManager.startDTDEntity(inputSource);
     } // setInputSource(XMLInputSource)
\ No newline at end of file
","Fixing bug http://nagoya.apache.org/bugzilla/show_bug.cgi?id=11176


git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@318583 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,1373.json,51be532c652cf9a20ca7e950b34b2f00f7dafdd3,"@@ -1,4 +1,4 @@
     public void printText( StringBuffer text )
     {
-        _text.append( text );
+        _text.append( text.toString() );
     }
\ No newline at end of file
","fixing bug 15768.  According to the javadoc for StringBuffer and String, this is what the original code would have compiled to; this fix simply makes sure that, if compiled under JDK 1.4, Xerces will work with previous JDKs


git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@318938 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
xerces2-j,5333.json,5ba592aa9007de9e5392ebab7095bfd0cfa63824,"@@ -1,13 +1,13 @@
     protected boolean sameBaseURIAsIncludeParent() {
         String parentBaseURI = getIncludeParentBaseURI();
         String baseURI = fCurrentBaseURI.getExpandedSystemId();
         // REVISIT: should we use File#sameFile() ?
         //          I think the benefit of using it is that it resolves host names
         //          instead of just doing a string comparison.
         // TODO: [base URI] is still an open issue with the working group.
         //       They're deciding if xml:base should be added if the [base URI] is different in terms
         //       of resolving relative references, or if it should be added if they are different at all.
         //       Revisit this after a final decision has been made.
         //       The decision also affects whether we output the file name of the URI, or just the path.
-        return parentBaseURI.equals(baseURI);
+        return parentBaseURI != null && parentBaseURI.equals(baseURI);
     }
\ No newline at end of file
","Partial fix for Bug #24992. Fix NPE which would occur if an 
include parent has no base URI.


git-svn-id: https://svn.apache.org/repos/asf/xerces/java/trunk@319611 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
hibernate-orm,14257.json,8463057b85db928fe8d3aa0b4379bc5b0f255c71,"@@ -1,110 +1,123 @@
 	private void addSetter(ClassFile classfile, final Method[] setters) throws CannotCompileException {
 		ConstPool cp = classfile.getConstPool();
 		int target_type_index = cp.addClassInfo( this.targetBean.getName() );
 		String desc = GET_SETTER_DESC;
 		MethodInfo mi = new MethodInfo( cp, GENERATED_SETTER_NAME, desc );
 
 		Bytecode code = new Bytecode( cp, 4, 6 );
+		StackMapTable stackmap = null;
 		/* | this | bean | args | i | raw bean | exception | */
 		if ( setters.length > 0 ) {
 			int start, end; // required to exception table
 			// iconst_0 // i
 			code.addIconst( 0 );
 			// istore_3 // store i
 			code.addIstore( 3 );
 			// aload_1 // load the bean
 			code.addAload( 1 );
 			// checkcast // cast the bean into a raw bean
 			code.addCheckcast( this.targetBean.getName() );
 			// astore 4 // store the raw bean
 			code.addAstore( 4 );
 			/* current stack len = 0 */
 			// start region to handling exception (BulkAccessorException)
 			start = code.currentPc();
 			int lastIndex = 0;
 			for ( int i = 0; i < setters.length; ++i ) {
 				if ( setters[i] != null ) {
 					int diff = i - lastIndex;
 					if ( diff > 0 ) {
 						// iinc 3, 1
 						code.addOpcode( Opcode.IINC );
 						code.add( 3 );
 						code.add( diff );
 						lastIndex = i;
 					}
 				}
 				/* current stack len = 0 */
 				// aload 4 // load the raw bean
 				code.addAload( 4 );
 				// aload_2 // load the args
 				code.addAload( 2 );
 				// iconst_i
 				code.addIconst( i );
 				// aaload
 				code.addOpcode( Opcode.AALOAD );
 				// checkcast
 				Class[] setterParamTypes = setters[i].getParameterTypes();
 				Class setterParamType = setterParamTypes[0];
 				if ( setterParamType.isPrimitive() ) {
 					// checkcast (case of primitive type)
 					// invokevirtual (case of primitive type)
 					this.addUnwrapper( classfile, code, setterParamType );
 				}
 				else {
 					// checkcast (case of reference type)
 					code.addCheckcast( setterParamType.getName() );
 				}
 				/* current stack len = 2 */
 				String rawSetterMethod_desc = RuntimeSupport.makeDescriptor( setters[i] );
 				if ( !this.targetBean.isInterface() ) {
 					// invokevirtual
 					code.addInvokevirtual( target_type_index, setters[i].getName(), rawSetterMethod_desc );
 				}
 				else {
 					// invokeinterface
 					Class[] params = setters[i].getParameterTypes();
 					int size;
 					if ( params[0].equals( Double.TYPE ) || params[0].equals( Long.TYPE ) ) {
 						size = 3;
 					}
 					else {
 						size = 2;
 					}
 
 					code.addInvokeinterface( target_type_index, setters[i].getName(), rawSetterMethod_desc, size );
 				}
 			}
 
 			// end region to handling exception (BulkAccessorException)
 			end = code.currentPc();
 			// return
 			code.addOpcode( Opcode.RETURN );
 			/* current stack len = 0 */
 			// register in exception table
 			int throwableType_index = cp.addClassInfo( THROWABLE_CLASS_NAME );
-			code.addExceptionHandler( start, end, code.currentPc(), throwableType_index );
+			int handler_pc = code.currentPc();
+			code.addExceptionHandler( start, end, handler_pc, throwableType_index );
 			// astore 5 // store exception
 			code.addAstore( 5 );
 			// new // BulkAccessorException
 			code.addNew( BULKEXCEPTION_CLASS_NAME );
 			// dup
 			code.addOpcode( Opcode.DUP );
 			// aload 5 // load exception
 			code.addAload( 5 );
 			// iload_3 // i
 			code.addIload( 3 );
 			// invokespecial // BulkAccessorException.<init>
 			String cons_desc = ""(Ljava/lang/Throwable;I)V"";
 			code.addInvokespecial( BULKEXCEPTION_CLASS_NAME, MethodInfo.nameInit, cons_desc );
 			// athrow
 			code.addOpcode( Opcode.ATHROW );
+			StackMapTable.Writer writer = new StackMapTable.Writer(32);
+			int[] localTags = { StackMapTable.OBJECT, StackMapTable.OBJECT, StackMapTable.OBJECT, StackMapTable.INTEGER };
+			int[] localData = { cp.getThisClassInfo(), cp.addClassInfo(""java/lang/Object""),
+                        	cp.addClassInfo(""[Ljava/lang/Object;""), 0};
+			int[] stackTags = { StackMapTable.OBJECT };
+			int[] stackData = { throwableType_index };
+			writer.fullFrame(handler_pc, localTags, localData, stackTags, stackData);
+			stackmap = writer.toStackMapTable(cp);
 		}
 		else {
 			// return
 			code.addOpcode( Opcode.RETURN );
 		}
-
-		mi.setCodeAttribute( code.toCodeAttribute() );
+		CodeAttribute ca = code.toCodeAttribute();
+		if (stackmap != null) {
+			ca.setAttribute(stackmap);
+		}
+		mi.setCodeAttribute( ca );
 		mi.setAccessFlags( AccessFlag.PUBLIC );
 		classfile.addMethod( mi );
 	}
\ No newline at end of file
","HHH-7850 BulkAccessorFactory Java 7 verify error resolved by JASSIST-163 BulkAccessorFactory.java.diff2 patch from Shigeru Chiba.
",Buggy
hibernate-orm,15873.json,8fb35947ff6525a8286295f2959cd5a71502b2f9,"@@ -1,3 +1,3 @@
 	public String getQuerySequencesString() {
-		return ""select table_name from information_schema.TABLES where table_type='SEQUENCE'"";
+		return ""select table_name from information_schema.TABLES where table_schema = database() and table_type = 'SEQUENCE'"";
 	}
\ No newline at end of file
","HHH-13373 fix the bug that 'different sequence names in differnt dbs' breaks SequenceInformationExtractorMariaDBDatabaseImpl
",Buggy
hibernate-orm,15816.json,fc6312a73b99c8edf2af32122165cc8b31b79aa7,"@@ -1,3 +1,8 @@
 	public String getQuerySequencesString() {
-		return null ;
+		if ( supportsSequences() ) {
+			return ""select SEQUENCENAME from SYS.SYSSEQUENCES"";
+		}
+		else {
+			throw new MappingException( ""Derby does not support sequence prior to release 10.6.1.0"" );
+		}
 	}
\ No newline at end of file
","HHH-10110 - Fix DerbyDialect#getQuerySequencesString() causing error during schema update
",Buggy
hibernate-orm,22027.json,b33c6d435780a96d6f911fbf8a9d796f10c7af0d,"@@ -1,15 +1,17 @@
-	public void onLoad(final LoadEvent event,
-					   final LoadEventListener.LoadType loadType) throws HibernateException {
+	public void onLoad(
+			final LoadEvent event,
+			final LoadEventListener.LoadType loadType) throws HibernateException {
 
 		final EntityPersister persister = getPersister( event );
 
 		if ( persister == null ) {
 			throw new HibernateException( ""Unable to locate persister: "" + event.getEntityClassName() );
 		}
 
 		final Class idClass = persister.getIdentifierType().getReturnedClass();
-		if ( idClass != null && !idClass.isInstance( event.getEntityId() ) )
+		if ( idClass != null && !idClass.isInstance( event.getEntityId() ) ) {
 			checkIdClass( persister, event, loadType, idClass );
+		}
 
 		doOnLoad( persister, event, loadType );
 	}
\ No newline at end of file
","HHH-10366 - Fix checkstyle error
",Buggy
hibernate-orm,15530.json,220365600cd7692ede1977d366966a5828dc749c,"@@ -1,7 +1,14 @@
 	public String getProcessedSql() {
-		boolean useLimitOffset = supportsLimit() && supportsLimitOffset()
-				&& LimitHelper.hasFirstRow( selection ) && LimitHelper.hasMaxRows( selection );
-		return dialect.getLimitString(
-				sql, useLimitOffset ? LimitHelper.getFirstRow( selection ) : 0, getMaxOrLimit()
-		);
+		if (LimitHelper.useLimit(this, selection)) {
+			// useLimitOffset: whether ""offset"" is set or not;
+			// if set, use ""LIMIT offset, row_count"" syntax;
+			// if not, use ""LIMIT row_count""
+			boolean useLimitOffset = LimitHelper.hasFirstRow(selection);
+
+			return new StringBuilder(sql.length() + 20).append(sql)
+							.append(useLimitOffset ? "" limit ?, ?"" : "" limit ?"").toString();
+		}
+		else {
+			return sql; // or return unaltered SQL
+		}
 	}
\ No newline at end of file
","HHH-7716 Fixed a bug in CUBRIDLimitHandler. Now correctly processes
LIMIT
clause
in SQL.
",Buggy
hibernate-orm,26062.json,6a14aeeba79d3536a893f63154c0b697db3f3711,"@@ -1,13 +1,15 @@
 	private void processExpression(ReadWriteExpression annotation) {
 		String nonNullLogicalColumnName = logicalColumnName != null ? logicalColumnName : """"; //use the default for annotations 
-		if ( annotation != null && annotation.forColumn().equals( nonNullLogicalColumnName ) ) {
+		if ( annotation != null &&
+				( StringHelper.isEmpty( annotation.forColumn() )
+						|| annotation.forColumn().equals( nonNullLogicalColumnName ) ) ) {
 			readExpression = annotation.read();
 			if ( StringHelper.isEmpty( readExpression ) ) {
 				readExpression = null;
 			}
 			writeExpression = annotation.write();
 			if ( StringHelper.isEmpty( writeExpression ) ) {
 				writeExpression = null;
 			}
 		}
 	}
\ No newline at end of file
","HHH-4510 Fix bug where explicit @Column would not match @ReadWriteExpresion with empty forColumn

git-svn-id: https://svn.jboss.org/repos/hibernate/core/trunk@20747 1b8cb986-b30d-0410-93ca-fae66ebed9b2
",Buggy
hibernate-orm,4331.json,f5e10c29ebf103df4de7ea7b528702f0d2d9fc2a,"@@ -1,9 +1,18 @@
 	public void destroy() {
 		if ( !active ) {
 			return;
 		}
 		active = false;
 		destroy( classLoaderServiceBinding );
 		destroy( strategySelectorBinding );
 		destroy( integratorServiceBinding );
+
+		if ( childRegistries != null ) {
+			for(ServiceRegistry serviceRegistry : childRegistries) {
+				if(serviceRegistry instanceof ServiceRegistryImplementor) {
+					ServiceRegistryImplementor serviceRegistryImplementor = (ServiceRegistryImplementor) serviceRegistry;
+					serviceRegistryImplementor.destroy();
+				}
+			}
+		}
 	}
\ No newline at end of file
","HHH-10907 - Fix connection leak problem in hibernate-core tests
",Buggy
hibernate-orm,3407.json,8b9f171a034f7604853d4c4bc1ffa78a8e2991fe,"@@ -1,54 +1,55 @@
 	private void cleanseUniqueKeyMap() {
 		// We need to account for a few conditions here...
 		// 	1) If there are multiple unique keys contained in the uniqueKeys Map, we need to deduplicate
 		// 		any sharing the same columns as other defined unique keys; this is needed for the annotation
 		// 		processor since it creates unique constraints automagically for the user
 		//	2) Remove any unique keys that share the same columns as the primary key; again, this is
 		//		needed for the annotation processor to handle @Id @OneToOne cases.  In such cases the
 		//		unique key is unnecessary because a primary key is already unique by definition.  We handle
 		//		this case specifically because some databases fail if you try to apply a unique key to
 		//		the primary key columns which causes schema export to fail in these cases.
 		if ( uniqueKeys.isEmpty() ) {
 			// nothing to do
 			return;
 		}
 		else if ( uniqueKeys.size() == 1 ) {
 			// we have to worry about condition 2 above, but not condition 1
 			final Map.Entry<String,UniqueKey> uniqueKeyEntry = uniqueKeys.entrySet().iterator().next();
 			if ( isSameAsPrimaryKeyColumns( uniqueKeyEntry.getValue() ) ) {
 				uniqueKeys.remove( uniqueKeyEntry.getKey() );
 			}
 		}
 		else {
 			// we have to check both conditions 1 and 2
 			final Iterator<Map.Entry<String,UniqueKey>> uniqueKeyEntries = uniqueKeys.entrySet().iterator();
 			while ( uniqueKeyEntries.hasNext() ) {
 				final Map.Entry<String,UniqueKey> uniqueKeyEntry = uniqueKeyEntries.next();
 				final UniqueKey uniqueKey = uniqueKeyEntry.getValue();
 				boolean removeIt = false;
 
 				// condition 1 : check against other unique keys
 				for ( UniqueKey otherUniqueKey : uniqueKeys.values() ) {
 					// make sure its not the same unique key
 					if ( uniqueKeyEntry.getValue() == otherUniqueKey ) {
 						continue;
 					}
 					if ( otherUniqueKey.getColumns().containsAll( uniqueKey.getColumns() )
 							&& uniqueKey.getColumns().containsAll( otherUniqueKey.getColumns() ) ) {
 						removeIt = true;
 						break;
 					}
 				}
 
 				// condition 2 : check against pk
 				if ( isSameAsPrimaryKeyColumns( uniqueKeyEntry.getValue() ) ) {
 					removeIt = true;
 				}
 
 				if ( removeIt ) {
-					uniqueKeys.remove( uniqueKeyEntry.getKey() );
+					//uniqueKeys.remove( uniqueKeyEntry.getKey() );
+					uniqueKeyEntries.remove();
 				}
 			}
 
 		}
 	}
\ No newline at end of file
","HHH-7446 bug-fix
",Buggy
hibernate-orm,29945.json,8e6fcce523698018a1e9952a8cf3a78485458ac7,"@@ -1,25 +1,25 @@
 	private void internalSetValue(T value) {
 		if ( procedureParameter.getMode() != ParameterMode.IN && procedureParameter.getMode() != ParameterMode.INOUT ) {
 			throw new IllegalStateException( ""Can only bind values for IN/INOUT parameters : "" + procedureParameter );
 		}
 
 		if ( procedureParameter.getParameterType() != null ) {
 			if ( value == null ) {
 				if ( !procedureParameter.isPassNullsEnabled() ) {
-					throw new IllegalArgumentException( ""The parameter with the ["" +
+					throw new IllegalArgumentException( ""The parameter "" +
 							( procedureParameter.getName() != null
-									? procedureParameter.getName() + ""] name""
-									: procedureParameter.getPosition() + ""] position"" )
+									? ""named ["" + procedureParameter.getName() + ""]""
+									: ""at position ["" + procedureParameter.getPosition() + ""]"" )
 							+ "" was null. You need to call ParameterRegistration#enablePassingNulls(true) in order to pass null parameters."" );
 				}
 			}
 			else if ( !procedureParameter.getParameterType().isInstance( value ) &&
 					!procedureParameter.getHibernateType().getReturnedClass().isInstance( value ) ) {
 				throw new IllegalArgumentException( ""Bind value ["" + value + ""] was not of specified type ["" + procedureParameter
 						.getParameterType() );
 			}
 		}
 
 		this.value = value;
 		this.isBound = true;
 	}
\ No newline at end of file
","HHH-12905 Improve the error message and update the tests accordingly

Also fix a loose end in the MySQL test: at least with MariaDB, using
a bit(1) as datatype for boolean does not work: it always return true
even if you set it to 0. Using either boolean or tinyint(1) solves
the issue.

As I'm not sure older versions of MySQL supports a real boolean type I
used a tinyint(1).
",Buggy
hibernate-orm,9074.json,50b788266339ac7f22f2f43dc011378e7b0b0aad,"@@ -1,33 +1,33 @@
 	private EnumValueMapper interpretParameters(Properties parameters) {
 		if ( parameters.containsKey( NAMED ) ) {
 			final boolean useNamed = ConfigurationHelper.getBoolean( NAMED, parameters );
 			if ( useNamed ) {
 				return new NamedEnumValueMapper();
 			}
 			else {
 				return new OrdinalEnumValueMapper();
 			}
 		}
 
 		if ( parameters.containsKey( TYPE ) ) {
 			final int type = Integer.decode( (String) parameters.get( TYPE ) );
 			if ( isNumericType( type ) ) {
 				return new OrdinalEnumValueMapper();
 			}
 			else if ( isCharacterType( type ) ) {
-				return new OrdinalEnumValueMapper();
+				return new NamedEnumValueMapper();
 			}
 			else {
 				throw new HibernateException(
 						String.format(
 								Locale.ENGLISH,
 								""Passed JDBC type code [%s] not recognized as numeric nor character"",
 								type
 						)
 				);
 			}
 		}
 
 		// the fallback
 		return new OrdinalEnumValueMapper();
 	}
\ No newline at end of file
","HHH-10766 Resolve mapping 'type' parameter error
",Buggy
presto,26733.json,d9c1e2084c70835d5feecf645ed8836064809fc2,"@@ -1,18 +1,18 @@
     private void startDiscovery()
     {
         discoveryService.scheduleWithFixedDelay(() -> {
             try {
                 // jitter to avoid overloading database and overloading the backup store
-                SECONDS.sleep(ThreadLocalRandom.current().nextLong(1, organizationDiscoveryIntervalMillis));
+                MILLISECONDS.sleep(ThreadLocalRandom.current().nextLong(1, organizationDiscoveryIntervalMillis));
 
                 log.info(""Running shard organizer..."");
                 submitJobs(discoverAndInitializeTablesToOrganize());
             }
             catch (InterruptedException e) {
                 Thread.currentThread().interrupt();
             }
             catch (Throwable t) {
                 log.error(t, ""Error running shard organizer"");
             }
         }, 0, organizationDiscoveryIntervalMillis, TimeUnit.MILLISECONDS);
     }
\ No newline at end of file
","fix organizationDiscoveryIntervalMillis bug
",Buggy
presto,16973.json,83ee1b402bab99302d7c271fcd5dc8a560c027dc,"@@ -1,14 +1,14 @@
     private void loadCatalog(File file)
             throws Exception
     {
         log.info(""-- Loading catalog %s --"", file);
         Map<String, String> properties = new HashMap<>(loadProperties(file));
 
         String connectorName = properties.remove(""connector.name"");
-        checkState(connectorName != null, ""Catalog configuration %s does not contain conector.name"", file.getAbsoluteFile());
+        checkState(connectorName != null, ""Catalog configuration %s does not contain connector.name"", file.getAbsoluteFile());
 
         String catalogName = Files.getNameWithoutExtension(file.getName());
 
         connectorManager.createConnection(catalogName, connectorName, ImmutableMap.copyOf(properties));
         log.info(""-- Added catalog %s using connector %s --"", catalogName, connectorName);
     }
\ No newline at end of file
","Fix typo in error message about connector.name
",Buggy
presto,14423.json,8c469bda0657f41c146796ea2ccaaea6dfa552e6,"@@ -1,4 +1,4 @@
     public static boolean isPrefixSubnetOf(@SqlType(StandardTypes.IPPREFIX) Slice first, @SqlType(StandardTypes.IPPREFIX) Slice second)
     {
-        return between(ipSubnetMin(second), ipSubnetMin(first), ipSubnetMax(first));
+        return between(ipSubnetMin(second), ipSubnetMin(first), ipSubnetMax(first)) && between(ipSubnetMax(second), ipSubnetMin(first), ipSubnetMax(first));
     }
\ No newline at end of file
","Fix bug in IS_SUBNET_OF function
",Buggy
presto,8688.json,97566626dd63db55ee08b48b3e366d6d9453badb,"@@ -1,39 +1,39 @@
     private SymbolStatsEstimate normalizeSymbolStats(Symbol symbol, SymbolStatsEstimate symbolStats, PlanNodeStatsEstimate stats, TypeProvider types)
     {
         if (symbolStats.isUnknown()) {
             return SymbolStatsEstimate.unknown();
         }
 
         double outputRowCount = stats.getOutputRowCount();
         double distinctValuesCount = symbolStats.getDistinctValuesCount();
         double nullsFraction = symbolStats.getNullsFraction();
 
         if (!isNaN(distinctValuesCount)) {
-            Type type = requireNonNull(types.get(symbol), () -> ""No stats for symbol "" + symbol);
+            Type type = requireNonNull(types.get(symbol), () -> ""type is missing for symbol "" + symbol);
             double maxDistinctValuesByLowHigh = maxDistinctValuesByLowHigh(symbolStats, type);
             if (distinctValuesCount > maxDistinctValuesByLowHigh) {
                 distinctValuesCount = maxDistinctValuesByLowHigh;
             }
 
             if (distinctValuesCount > outputRowCount) {
                 distinctValuesCount = outputRowCount;
             }
 
             double nonNullValues = outputRowCount * (1 - nullsFraction);
             if (distinctValuesCount > nonNullValues) {
                 double difference = distinctValuesCount - nonNullValues;
                 distinctValuesCount -= difference / 2;
                 nonNullValues += difference / 2;
                 nullsFraction = 1 - nonNullValues / outputRowCount;
             }
         }
 
         if (distinctValuesCount == 0.0) {
             return SymbolStatsEstimate.zero();
         }
 
         return SymbolStatsEstimate.buildFrom(symbolStats)
                 .setDistinctValuesCount(distinctValuesCount)
                 .setNullsFraction(nullsFraction)
                 .build();
     }
\ No newline at end of file
","Fix error message in StatsNormalizer
",Buggy
presto,26619.json,3325ab0064b5fd93af18c1d5e87170f5d66bae28,"@@ -1,10 +1,7 @@
     public void deleteRows(Block rowIds)
     {
-        if (rowsToDelete == null) {
-            rowsToDelete = new BitSet(Ints.checkedCast(recordReader.getFileRowCount()));
-        }
         for (int i = 0; i < rowIds.getPositionCount(); i++) {
             long rowId = BIGINT.getLong(rowIds, i);
             rowsToDelete.set(Ints.checkedCast(rowId));
         }
     }
\ No newline at end of file
","Fix bug in delete for Raptor

When no rows match for delete, rowsToDelete is not set causing a NPE.
Set it in the constructor because we already know the maximum size.
We might over allocate for cases where no rows are selected for
deletion, but this is a short lived bit vector so it should be low
impact.
",Buggy
presto,14862.json,9adc687000043241a0c0ecb1b56ef6b810c2a430,"@@ -1,23 +1,26 @@
     public static Block bigintDistinct(@SqlType(""array(bigint)"") Block array)
     {
         if (array.getPositionCount() == 0) {
             return array;
         }
 
         boolean containsNull = false;
         LongSet set = new LongOpenHashSet(array.getPositionCount());
         BlockBuilder distinctElementBlockBuilder = BIGINT.createBlockBuilder(new BlockBuilderStatus(), array.getPositionCount());
         for (int i = 0; i < array.getPositionCount(); i++) {
-            if (!containsNull && array.isNull(i)) {
-                containsNull = true;
-                distinctElementBlockBuilder.appendNull();
+            if (array.isNull(i)) {
+                if (!containsNull) {
+                    containsNull = true;
+                    distinctElementBlockBuilder.appendNull();
+                }
                 continue;
             }
+
             long value = BIGINT.getLong(array, i);
             if (set.add(value)) {
                 BIGINT.writeLong(distinctElementBlockBuilder, value);
             }
         }
 
         return distinctElementBlockBuilder.build();
     }
\ No newline at end of file
","Fix null-handling bug in ArrayDistinctFunction
",Buggy
presto,20594.json,2d9e768a03b5c9d804825c9a489383465f373801,"@@ -1,8 +1,10 @@
         public PlanWithProperties visitFilter(FilterNode node, PreferredProperties preferredProperties)
         {
-            if (node.getSource() instanceof TableScanNode) {
+            if (node.getSource() instanceof TableScanNode && metadata.isLegacyGetLayoutSupported(session, ((TableScanNode) node.getSource()).getTable())) {
+                // If isLegacyGetLayoutSupported, then we can continue with legacy predicate pushdown logic.
+                // Otherwise, we leave the filter as is in the plan as it will be pushed into the TableScan by filter pushdown logic in the connector.
                 return planTableScan((TableScanNode) node.getSource(), node.getPredicate());
             }
 
             return rebaseAndDeriveProperties(node, planChild(node, preferredProperties));
         }
\ No newline at end of file
","Fix bug AddExchanges dropping filter when pushdown is enabled
",Buggy
presto,30019.json,9e755c76e9d8e3a5e0a486002b3898be9d6d5d25,"@@ -1,14 +1,13 @@
     public void close()
     {
         closed = true;
-
         // use try with resources to close everything properly
-        try (ResultSet resultSet = this.resultSet;
+        try (Connection connection = this.connection;
                 Statement statement = this.statement;
-                Connection connection = this.connection) {
+                ResultSet resultSet = this.resultSet) {
             // do nothing
         }
         catch (SQLException e) {
             throw Throwables.propagate(e);
         }
     }
\ No newline at end of file
","Fix ""Connection already closed"" error in JdbcRecordCursor

The resultset, statement and connection were being closed in
the wrong order.
",Buggy
presto,32288.json,1eb20ea3faeb66b18c4c9300b4a6c8c3190ca6ce,"@@ -1,8 +1,9 @@
     public List<SchemaTableName> listTables(ConnectorSession session, String schemaNameOrNull)
     {
-        checkArgument(schemaNameOrNull == null || schemaNameOrNull.equals(SCHEMA_NAME),
-                ""Only '%s' schema is supported"", SCHEMA_NAME);
+        if (schemaNameOrNull != null && !schemaNameOrNull.equals(SCHEMA_NAME)) {
+            return ImmutableList.of();
+        }
         return tables.values().stream()
                 .map(BlackHoleTableHandle::toSchemaTableName)
                 .collect(toList());
     }
\ No newline at end of file
","Fix listing tables in blackhole connector

Listing tables in a non-existent schema should not be an error.
",Buggy
presto,32344.json,5bc9087c740ce60796c3b92131fe7c2a09bc04f7,"@@ -1,4 +1,10 @@
     public List<File> getFiles(SchemaTableName table)
     {
-        return cachedFiles.getUnchecked(table);
+        try {
+            return cachedFiles.getUnchecked(table);
+        }
+        catch (UncheckedExecutionException e) {
+            throwIfInstanceOf(e.getCause(), PrestoException.class);
+            throw e;
+        }
     }
\ No newline at end of file
","Fix error categorization in local file connector

Exceptions are wrapped by LoadingCache and must be unwrapped.
",Buggy
presto,28248.json,dce842fd5d590740f0f7ca26ec5c7eb192e64640,"@@ -1,11 +1,16 @@
         protected Node visitNegativeExpression(NegativeExpression node, Context<C> context)
         {
             if (!context.isDefaultRewrite()) {
                 Node result = nodeRewriter.rewriteNegativeExpression(node, context.get(), TreeRewriter.this);
                 if (result != null) {
                     return result;
                 }
             }
 
+            Expression child = rewrite(node.getValue(), context.get());
+            if (child != node.getValue()) {
+                return new NegativeExpression(child);
+            }
+
             return node;
         }
\ No newline at end of file
","Fix bug when rewriting NegativeExpression

It was discarding the rewritten subexpression of an arithmetic negation
",Buggy
presto,8271.json,d560b6e644e49cab94fa9076ec62406cd62afa68,"@@ -1,12 +1,16 @@
         public InputStream handle(Request request, com.facebook.airlift.http.client.Response response)
         {
             try {
+                if (response.getStatusCode() != HTTP_OK) {
+                    String result = new BufferedReader(new InputStreamReader(response.getInputStream())).lines().collect(Collectors.joining(""\n""));
+                    throw new PrestoException(DRUID_BROKER_RESULT_ERROR, result);
+                }
                 if (APPLICATION_JSON.equals(response.getHeader(CONTENT_TYPE))) {
                     return response.getInputStream();
                 }
                 throw new PrestoException(DRUID_BROKER_RESULT_ERROR, ""Response received was not of type "" + APPLICATION_JSON);
             }
             catch (IOException e) {
                 throw new PrestoException(DRUID_BROKER_RESULT_ERROR, ""Unable to read response from worker"", e);
             }
         }
\ No newline at end of file
","Fix unhandled HTTP response error for druid client
",Buggy
presto,22102.json,37377fdfa6f208809b77185abca3b1d0bdcb2f92,"@@ -1,72 +1,73 @@
     public static Map<List<RowExpression>, Boolean> getExpressionsPartitionedByCSE(Collection<? extends RowExpression> expressions)
     {
         if (expressions.isEmpty()) {
             return ImmutableMap.of();
         }
 
         CommonSubExpressionCollector expressionCollector = new CommonSubExpressionCollector();
         expressions.forEach(expression -> expression.accept(expressionCollector, null));
         Set<RowExpression> cse = expressionCollector.cseByLevel.values().stream().flatMap(Set::stream).collect(toImmutableSet());
 
         if (cse.isEmpty()) {
             return expressions.stream().collect(toImmutableMap(ImmutableList::of, m -> false));
         }
 
         ImmutableMap.Builder<List<RowExpression>, Boolean> expressionsPartitionedByCse = ImmutableMap.builder();
         SubExpressionChecker subExpressionChecker = new SubExpressionChecker(cse);
         Map<Boolean, List<RowExpression>> expressionsWithCseFlag = expressions.stream().collect(Collectors.partitioningBy(expression -> expression.accept(subExpressionChecker, null)));
         expressionsWithCseFlag.get(false).forEach(expression -> expressionsPartitionedByCse.put(ImmutableList.of(expression), false));
 
         List<RowExpression> expressionsWithCse = expressionsWithCseFlag.get(true);
         if (expressionsWithCse.size() == 1) {
             RowExpression expression = expressionsWithCse.get(0);
             expressionsPartitionedByCse.put(ImmutableList.of(expression), true);
             return expressionsPartitionedByCse.build();
         }
 
         List<Set<RowExpression>> cseDependency = expressionsWithCse.stream()
                 .map(expression -> subExpressions(expression).stream()
                         .filter(cse::contains)
                         .collect(toImmutableSet()))
                 .collect(toImmutableList());
 
         boolean[] merged = new boolean[expressionsWithCse.size()];
 
         int i = 0;
         while (i < merged.length) {
             while (i < merged.length && merged[i]) {
                 i++;
             }
             if (i >= merged.length) {
                 break;
             }
             merged[i] = true;
             ImmutableList.Builder<RowExpression> newList = ImmutableList.builder();
             newList.add(expressionsWithCse.get(i));
             Set<RowExpression> dependencies = new HashSet<>();
             Set<RowExpression> first = cseDependency.get(i);
             dependencies.addAll(first);
             int j = i + 1;
             while (j < merged.length) {
                 while (j < merged.length && merged[j]) {
                     j++;
                 }
                 if (j >= merged.length) {
                     break;
                 }
                 Set<RowExpression> second = cseDependency.get(j);
                 if (!Sets.intersection(dependencies, second).isEmpty()) {
                     RowExpression expression = expressionsWithCse.get(j);
                     newList.add(expression);
                     dependencies.addAll(second);
                     merged[j] = true;
+                    j = i + 1;
                 }
                 else {
                     j++;
                 }
             }
             expressionsPartitionedByCse.put(newList.build(), true);
         }
 
         return expressionsPartitionedByCse.build();
     }
\ No newline at end of file
","Fixing a bug in common sub expression partitioning

The previous implementation could group expressions differently with different order or exprsesions.
",Buggy
presto,10913.json,e6f650722f4041eade54638d355de2b9f7a9e280,"@@ -1,4 +1,4 @@
     public boolean isFinalQueryInfo()
     {
-        return state.isDone() && getAllStages(outputStage).stream().allMatch(StageInfo::isFinalStageInfo);
+        return state.equals(QueryState.FAILED) || state.isDone() && getAllStages(outputStage).stream().allMatch(StageInfo::isFinalStageInfo);
     }
\ No newline at end of file
","fix the client hang problem after query failed
",Buggy
presto,7159.json,130527265fd8aebee395ed2412f4058d0e269f51,"@@ -1,84 +1,83 @@
         public PlanNode visitProject(ProjectNode project, Void context)
         {
             if (!(project.getSource() instanceof TableScanNode)) {
                 return visitPlan(project, context);
             }
 
             TableScanNode tableScan = (TableScanNode) project.getSource();
             if (!isParquetDereferenceEnabled(session, tableScan.getTable())) {
                 return visitPlan(project, context);
             }
 
             Map<RowExpression, Subfield> dereferenceToNestedColumnMap = extractDereferences(
                     session,
                     rowExpressionService.getExpressionOptimizer(),
                     new HashSet<>(project.getAssignments().getExpressions()));
             if (dereferenceToNestedColumnMap.isEmpty()) {
                 return visitPlan(project, context);
             }
 
-            Map<String, HiveColumnHandle> regularHiveColumnHandles = tableScan.getAssignments().values().stream()
-                    .map(columnHandle -> (HiveColumnHandle) columnHandle)
-                    .collect(toMap(HiveColumnHandle::getName, identity()));
+            Map<String, HiveColumnHandle> regularHiveColumnHandles = tableScan.getAssignments().entrySet().stream()
+                    .collect(toMap(e -> e.getKey().getName(), e -> (HiveColumnHandle) e.getValue()));
 
             List<VariableReferenceExpression> newOutputVariables = new ArrayList<>(tableScan.getOutputVariables());
             Map<VariableReferenceExpression, ColumnHandle> newAssignments = new HashMap<>(tableScan.getAssignments());
 
             Map<RowExpression, VariableReferenceExpression> dereferenceToVariableMap = new HashMap<>();
 
             for (Map.Entry<RowExpression, Subfield> dereference : dereferenceToNestedColumnMap.entrySet()) {
                 Subfield nestedColumn = dereference.getValue();
                 RowExpression dereferenceExpression = dereference.getKey();
 
                 // Find the nested column Hive Type
                 HiveColumnHandle regularColumnHandle = regularHiveColumnHandles.get(nestedColumn.getRootName());
                 if (regularColumnHandle == null) {
                     throw new IllegalArgumentException(""nested column ["" + nestedColumn + ""]'s base column "" + nestedColumn.getRootName() + "" is not present in table scan output"");
                 }
 
                 Optional<HiveType> nestedColumnHiveType = regularHiveColumnHandles.get(nestedColumn.getRootName())
                         .getHiveType()
                         .findChildType(
                                 nestedColumn.getPath().stream()
                                         .map(p -> ((Subfield.NestedField) p).getName())
                                         .collect(Collectors.toList()));
 
                 if (!nestedColumnHiveType.isPresent()) {
                     throw new IllegalArgumentException(""nested column ["" + nestedColumn + ""] type is not present in Hive column type"");
                 }
 
                 String pushdownColumnName = pushdownColumnNameForSubfield(nestedColumn);
                 // Create column handle for nested column
                 HiveColumnHandle nestedColumnHandle = new HiveColumnHandle(
                         pushdownColumnName,
                         nestedColumnHiveType.get(),
                         dereferenceExpression.getType().getTypeSignature(),
                         -1,
                         SYNTHESIZED,
                         Optional.of(""nested column pushdown""),
                         ImmutableList.of(nestedColumn),
                         Optional.empty());
 
                 VariableReferenceExpression newOutputVariable = variableAllocator.newVariable(pushdownColumnName, dereferenceExpression.getType());
                 newOutputVariables.add(newOutputVariable);
                 newAssignments.put(newOutputVariable, nestedColumnHandle);
 
                 dereferenceToVariableMap.put(dereferenceExpression, newOutputVariable);
             }
 
             TableScanNode newTableScan = new TableScanNode(
                     idAllocator.getNextId(),
                     tableScan.getTable(),
                     newOutputVariables,
                     newAssignments,
                     tableScan.getCurrentConstraint(),
                     tableScan.getEnforcedConstraint());
 
             Assignments.Builder newProjectAssignmentBuilder = Assignments.builder();
             for (Map.Entry<VariableReferenceExpression, RowExpression> entry : project.getAssignments().entrySet()) {
                 RowExpression newExpression = rewriteWith(new DereferenceExpressionRewriter(dereferenceToVariableMap), entry.getValue());
                 newProjectAssignmentBuilder.put(entry.getKey(), newExpression);
             }
 
             return new ProjectNode(idAllocator.getNextId(), newTableScan, newProjectAssignmentBuilder.build(), project.getLocality());
         }
\ No newline at end of file
","Fix base column name not present error when dereference pushdown enabled
",Buggy
presto,22204.json,b88a9a91b24500d3c46df8cd613783effdc9d70c,"@@ -1,34 +1,34 @@
     private static Map<LambdaDefinitionExpression, CompiledLambda> generateMethodsForLambda(
             ClassDefinition containerClassDefinition,
             CallSiteBinder callSiteBinder,
             CachedInstanceBinder cachedInstanceBinder,
             List<RowExpression> expressions,
             Metadata metadata,
             SqlFunctionProperties sqlFunctionProperties,
             String methodNamePrefix,
             Set<LambdaDefinitionExpression> existingCompiledLambdas)
     {
         Set<LambdaDefinitionExpression> lambdaExpressions = expressions.stream()
                 .map(LambdaExpressionExtractor::extractLambdaExpressions)
                 .flatMap(List::stream)
                 .filter(lambda -> !existingCompiledLambdas.contains(lambda))
                 .collect(toImmutableSet());
         ImmutableMap.Builder<LambdaDefinitionExpression, CompiledLambda> compiledLambdaMap = ImmutableMap.builder();
 
-        int counter = 0;
+        int counter = existingCompiledLambdas.size();
         for (LambdaDefinitionExpression lambdaExpression : lambdaExpressions) {
             CompiledLambda compiledLambda = LambdaBytecodeGenerator.preGenerateLambdaExpression(
                     lambdaExpression,
                     methodNamePrefix + ""lambda_"" + counter,
                     containerClassDefinition,
                     compiledLambdaMap.build(),
                     callSiteBinder,
                     cachedInstanceBinder,
                     metadata,
                     sqlFunctionProperties);
             compiledLambdaMap.put(lambdaExpression, compiledLambda);
             counter++;
         }
 
         return compiledLambdaMap.build();
     }
\ No newline at end of file
","Fix compiler error in LambdaBytecodeGenerator

When there are lambda expressions from different SQL functions, and they are
compiled into the same class due to CSE, we need to make sure the generated
function names are always unique.
",Buggy
presto,1269.json,4cb4d192f1cc8e0da404521946d7566738d45c00,"@@ -1,6 +1,6 @@
         private void prepareDropPartition(SchemaTableName schemaTableName, List<String> partitionValues)
         {
             metastoreDeleteOperations.add(new IrreversibleMetastoreOperation(
-                    format(""drop partition %s.%s %s"", schemaTableName, schemaTableName.getTableName(), partitionValues),
+                    format(""drop partition %s.%s %s"", schemaTableName.getSchemaName(), schemaTableName.getTableName(), partitionValues),
                     () -> delegate.dropPartition(schemaTableName.getSchemaName(), schemaTableName.getTableName(), partitionValues, true)));
         }
\ No newline at end of file
","Fix SemiTransactionalHiveMetastore error message
",Buggy
presto,17974.json,0498c0df5aff14c9f7f88db1fe2e43ed3470aa5b,"@@ -1,12 +1,16 @@
     private static Optional<TaskInfo> findFailedTask(StageInfo stageInfo)
     {
+        if (stageInfo == null) {
+            return Optional.empty();
+        }
+
         for (StageInfo subStage : stageInfo.getSubStages()) {
             Optional<TaskInfo> task = findFailedTask(subStage);
             if (task.isPresent()) {
                 return task;
             }
         }
         return stageInfo.getTasks().stream()
                 .filter(taskInfo -> taskInfo.getState() == TaskState.FAILED)
                 .findFirst();
     }
\ No newline at end of file
","Fix NPE when query fails during parsing/planning

Commit 135626b793b42841c77f6b8c8b7fe80fac8ffc46 introduced a bug
where queries that fail during parsing/analysis/planning
throw an NPE when the completion event is processed.

This is due to an incorrect assumption that QueryInfos always
have an output stage, which is not true for queries that fail
before execution starts.
",Buggy
presto,22343.json,913c3f81cdc1a8dbc3201382b38d5e429f43fa7f,"@@ -1,36 +1,37 @@
     public BytecodeNode generateExpression(Signature signature, BytecodeGeneratorContext context, Type rowType, List<RowExpression> arguments)
     {
         BytecodeBlock block = new BytecodeBlock().setDescription(""Constructor for "" + rowType.toString());
         CallSiteBinder binder = context.getCallSiteBinder();
         Scope scope = context.getScope();
         List<Type> types = rowType.getTypeParameters();
 
         block.comment(""BlockBuilder blockBuilder = new InterleavedBlockBuilder(types, new BlockBuilderStatus(), 1);"");
         Variable blockBuilder = scope.createTempVariable(BlockBuilder.class);
         Binding typesBinding = binder.bind(types, List.class);
         block.append(blockBuilder.set(
                 newInstance(InterleavedBlockBuilder.class, loadConstant(typesBinding), newInstance(BlockBuilderStatus.class), constantInt(1))));
 
         for (int i = 0; i < arguments.size(); ++i) {
             Type fieldType = types.get(i);
             Class<?> javaType = fieldType.getJavaType();
             if (javaType == void.class) {
                 block.comment(i + ""-th field type of row is undefined"");
                 block.append(blockBuilder.invoke(""appendNull"", BlockBuilder.class).pop());
             }
             else {
                 Variable field = scope.createTempVariable(javaType);
-                block.comment(""Generate + "" + i + ""-th field of row"");
+                block.comment(""Clean wasNull and Generate + "" + i + ""-th field of row"");
+                block.append(context.wasNull().set(constantFalse()));
                 block.append(context.generate(arguments.get(i)));
                 block.putVariable(field);
                 block.append(new IfStatement()
                         .condition(context.wasNull())
                         .ifTrue(blockBuilder.invoke(""appendNull"", BlockBuilder.class).pop())
                         .ifFalse(constantType(binder, fieldType).writeValue(blockBuilder, field).pop()));
             }
         }
         block.comment(""put (Block) blockBuilder.build(); wasNull = false;"");
         block.append(blockBuilder.invoke(""build"", Block.class));
         block.append(context.wasNull().set(constantFalse()));
         return block;
     }
\ No newline at end of file
","Fix bug when constructing ROW with null values

Not all generators set wasNull, causing following values
(generated from one generator that also doesn't set wasNull) to be null.
",Buggy
presto,1944.json,d439d475c1eb6674ff8a9fb75ee08565217bc39c,"@@ -1,8 +1,8 @@
     public boolean isSingleValue()
     {
         return !low.isLowerUnbounded() &&
                 !high.isUpperUnbounded() &&
                 low.getBound() == Marker.Bound.EXACTLY &&
                 high.getBound() == Marker.Bound.EXACTLY &&
-                low.getValue() == high.getValue();
+                low.getValue().equals(high.getValue());
     }
\ No newline at end of file
","Fix Range bug in SPI
",Buggy
presto,17855.json,18088bed1462b2cf8f46ab44293b3791136588d3,"@@ -1,8 +1,7 @@
     public String toString()
     {
         return Objects.toStringHelper(this)
                 .add(""tableHandle"", tableHandle)
-                .add(""filters"", filters)
                 .add(""addresses"", addresses)
                 .toString();
     }
\ No newline at end of file
","System connector predicate pushdown bug fix
",Buggy
presto,3309.json,c798add760c213bafe85a1f7934e54b5fe0b8728,"@@ -1,4 +1,4 @@
     public int getPositionCount()
     {
-        return blocks[0].getPositionCount();
+        return positionCount;
     }
\ No newline at end of file
","Fix bug in count aggregation from inline view

This query now works:

SELECT COUNT(*) FROM (SELECT ... ) x
",Buggy
presto,12870.json,f20d677b8203f10728649c8f4b038f68a08dd909,"@@ -1,4 +1,4 @@
     private static List<ParameterMetadata> createInputParameterMetadata(Type value, Type key)
     {
-        return ImmutableList.of(new ParameterMetadata(STATE), new ParameterMetadata(NULLABLE_BLOCK_INPUT_CHANNEL, value), new ParameterMetadata(NULLABLE_BLOCK_INPUT_CHANNEL, key), new ParameterMetadata(BLOCK_INDEX));
+        return ImmutableList.of(new ParameterMetadata(STATE), new ParameterMetadata(NULLABLE_BLOCK_INPUT_CHANNEL, value), new ParameterMetadata(BLOCK_INPUT_CHANNEL, key), new ParameterMetadata(BLOCK_INDEX));
     }
\ No newline at end of file
","Fix null-handling bug in min_by/max_by

Null keys were previously incorrectly handled. They were effectively treated
as default value of the type for comparison in the input function.
",Buggy
presto,16287.json,c5b89795521472323d392daa860240d64d3876f0,"@@ -1,35 +1,59 @@
     static DecodedBlockNode decodeBlock(BlockFlattener flattener, Closer blockLeaseCloser, Block block)
     {
         BlockLease lease = flattener.flatten(block);
         blockLeaseCloser.register(lease::close);
         Block decodedBlock = lease.get();
 
+        long estimatedSizeInBytes = decodedBlock.getLogicalSizeInBytes();
+
         if (decodedBlock instanceof ArrayBlock) {
             ColumnarArray columnarArray = ColumnarArray.toColumnarArray(decodedBlock);
-            return new DecodedBlockNode(columnarArray, ImmutableList.of(decodeBlock(flattener, blockLeaseCloser, columnarArray.getElementsBlock())));
+            Block childBlock = columnarArray.getElementsBlock();
+            return new DecodedBlockNode(
+                    columnarArray,
+                    ImmutableList.of(decodeBlock(flattener, blockLeaseCloser, childBlock)),
+                    columnarArray.getRetainedSizeInBytes(),
+                    estimatedSizeInBytes);
         }
 
         if (decodedBlock instanceof MapBlock) {
             ColumnarMap columnarMap = ColumnarMap.toColumnarMap(decodedBlock);
-            return new DecodedBlockNode(columnarMap, ImmutableList.of(decodeBlock(flattener, blockLeaseCloser, columnarMap.getKeysBlock()), decodeBlock(flattener, blockLeaseCloser, columnarMap.getValuesBlock())));
+            Block keyBlock = columnarMap.getKeysBlock();
+            Block valueBlock = columnarMap.getValuesBlock();
+            return new DecodedBlockNode(
+                    columnarMap,
+                    ImmutableList.of(decodeBlock(flattener, blockLeaseCloser, keyBlock), decodeBlock(flattener, blockLeaseCloser, valueBlock)),
+                    columnarMap.getRetainedSizeInBytes(),
+                    estimatedSizeInBytes);
         }
 
         if (decodedBlock instanceof RowBlock) {
             ColumnarRow columnarRow = ColumnarRow.toColumnarRow(decodedBlock);
             ImmutableList.Builder<DecodedBlockNode> children = ImmutableList.builder();
             for (int i = 0; i < columnarRow.getFieldCount(); i++) {
-                children.add(decodeBlock(flattener, blockLeaseCloser, columnarRow.getField(i)));
+                Block childBlock = columnarRow.getField(i);
+                children.add(decodeBlock(flattener, blockLeaseCloser, childBlock));
             }
-            return new DecodedBlockNode(columnarRow, children.build());
+            return new DecodedBlockNode(columnarRow, children.build(), columnarRow.getRetainedSizeInBytes(), estimatedSizeInBytes);
         }
 
         if (decodedBlock instanceof DictionaryBlock) {
-            return new DecodedBlockNode(decodedBlock, ImmutableList.of(decodeBlock(flattener, blockLeaseCloser, ((DictionaryBlock) decodedBlock).getDictionary())));
+            Block dictionary = ((DictionaryBlock) decodedBlock).getDictionary();
+            return new DecodedBlockNode(
+                    decodedBlock,
+                    ImmutableList.of(decodeBlock(flattener, blockLeaseCloser, dictionary)),
+                    decodedBlock.getRetainedSizeInBytes(),
+                    estimatedSizeInBytes);
         }
 
         if (decodedBlock instanceof RunLengthEncodedBlock) {
-            return new DecodedBlockNode(decodedBlock, ImmutableList.of(decodeBlock(flattener, blockLeaseCloser, ((RunLengthEncodedBlock) decodedBlock).getValue())));
+            Block childBlock = ((RunLengthEncodedBlock) decodedBlock).getValue();
+            return new DecodedBlockNode(
+                    decodedBlock,
+                    ImmutableList.of(decodeBlock(flattener, blockLeaseCloser, childBlock)),
+                    decodedBlock.getRetainedSizeInBytes(),
+                    estimatedSizeInBytes);
         }
 
-        return new DecodedBlockNode(decodedBlock, ImmutableList.of());
+        return new DecodedBlockNode(decodedBlock, ImmutableList.of(), block.getRetainedSizeInBytes(), estimatedSizeInBytes);
     }
\ No newline at end of file
","Fix estimatedSerializedSizeInBytes for RLE and Dictionary Blocks

When a block passed to OptimizedPartitionedOutputOperator is a RLE or
Dictionary block, we used to estimated the serialized size using
getLogicalSize() which returns the size of the block after inflation.
However the child block of the RLE or Dictionary Block was using plain
sizeInBytes without considering it is going to be expanded. This
commit fixes this problem by adding a scale factor to estimate how many
times the child blocks are going to be expanded.
",Buggy
presto,21104.json,58e78de1c0cde073cc472bb7b2d4cf52155e15e3,"@@ -1,4 +1,8 @@
         public StreamProperties visitTopN(TopNNode node, List<StreamProperties> inputProperties)
         {
+            // Partial TopN doesn't guarantee that stream is ordered
+            if (node.getStep().equals(TopNNode.Step.PARTIAL)) {
+                return Iterables.getOnlyElement(inputProperties);
+            }
             return StreamProperties.ordered();
         }
\ No newline at end of file
","Fix stream properties for partial TopN

This is a bug fix, that seems to could never occur.
",Buggy
presto,18169.json,86913bdc9e40dd112bda300f21ae0f95e1330515,"@@ -1,4 +1,4 @@
         public Type getType(int field)
         {
-            return delegate.getType(field);
+            return delegate.getType(toDelegateField(field));
         }
\ No newline at end of file
","Fix MappedRecordCursor bug
",Buggy
presto,26959.json,90e7efd07b37da0ff012bb99798ed37b4173661b,"@@ -1,85 +1,83 @@
     private String toPredicate(int columnIndex, Domain domain)
     {
         String columnName = columnsNames.get(columnIndex);
         Type type = types.get(columnIndex);
 
         if (domain.getRanges().isNone() && domain.isNullAllowed()) {
             return columnName + "" IS NULL"";
         }
 
         if (domain.getRanges().isAll() && !domain.isNullAllowed()) {
             return columnName + "" IS NOT NULL"";
         }
 
         // Add disjuncts for ranges
         List<String> disjuncts = new ArrayList<>();
         List<Comparable<?>> singleValues = new ArrayList<>();
         for (Range range : domain.getRanges()) {
             checkState(!range.isAll()); // Already checked
-            Comparable<?> lowValue = range.getLow().getValue();
             if (range.isSingleValue()) {
-                singleValues.add(lowValue);
+                singleValues.add(range.getLow().getValue());
             }
             else {
                 List<String> rangeConjuncts = new ArrayList<>();
                 if (!range.getLow().isLowerUnbounded()) {
-                    Object bindValue = getBindValue(columnIndex, lowValue);
+                    Object bindValue = getBindValue(columnIndex, range.getLow().getValue());
                     switch (range.getLow().getBound()) {
                         case ABOVE:
                             rangeConjuncts.add(toBindPredicate(columnName, "">""));
                             bindValues.add(ValueBuffer.create(columnIndex, type, bindValue));
                             break;
                         case EXACTLY:
                             rangeConjuncts.add(toBindPredicate(columnName, "">=""));
                             bindValues.add(ValueBuffer.create(columnIndex, type, bindValue));
                             break;
                         case BELOW:
                             throw new IllegalStateException(""Low Marker should never use BELOW bound: "" + range);
                         default:
                             throw new AssertionError(""Unhandled bound: "" + range.getLow().getBound());
                     }
                 }
                 if (!range.getHigh().isUpperUnbounded()) {
-                    Comparable<?> highValue = range.getHigh().getValue();
-                    Object bindValue = getBindValue(columnIndex, highValue);
+                    Object bindValue = getBindValue(columnIndex, range.getHigh().getValue());
                     switch (range.getHigh().getBound()) {
                         case ABOVE:
                             throw new IllegalStateException(""High Marker should never use ABOVE bound: "" + range);
                         case EXACTLY:
                             rangeConjuncts.add(toBindPredicate(columnName, ""<=""));
                             bindValues.add(ValueBuffer.create(columnIndex, type, bindValue));
                             break;
                         case BELOW:
                             rangeConjuncts.add(toBindPredicate(columnName, ""<""));
                             bindValues.add(ValueBuffer.create(columnIndex, type, bindValue));
                             break;
                         default:
                             throw new AssertionError(""Unhandled bound: "" + range.getHigh().getBound());
                     }
                 }
                 // If rangeConjuncts is null, then the range was ALL, which should already have been checked for
                 checkState(!rangeConjuncts.isEmpty());
                 disjuncts.add(""("" + Joiner.on("" AND "").join(rangeConjuncts) + "")"");
             }
         }
 
         // Add back all of the possible single values either as an equality or an IN predicate
         if (singleValues.size() == 1) {
             disjuncts.add(toBindPredicate(columnName, ""=""));
             bindValues.add(ValueBuffer.create(columnIndex, type, getBindValue(columnIndex, getOnlyElement(singleValues))));
         }
         else if (singleValues.size() > 1) {
             disjuncts.add(columnName + "" IN ("" + Joiner.on("","").join(limit(cycle(""?""), singleValues.size())) + "")"");
             for (Comparable<?> singleValue : singleValues) {
                 bindValues.add(ValueBuffer.create(columnIndex, type, getBindValue(columnIndex, singleValue)));
             }
         }
 
         // Add nullability disjuncts
         checkState(!disjuncts.isEmpty());
         if (domain.isNullAllowed()) {
             disjuncts.add(columnName + "" IS NULL"");
         }
 
         return ""("" + Joiner.on("" OR "").join(disjuncts) + "")"";
     }
\ No newline at end of file
","Fix bug for domain with lower unbounded range
",Buggy
presto,1063.json,097536e42a4f29b25497ec5c782ef60cabdf71ef,"@@ -1,26 +1,31 @@
     public <V> Callable<V> wrap(Callable<V> callable)
     {
         return () -> {
             try (TimeStat.BlockTimer ignored = time.time()) {
                 return callable.call();
             }
             catch (Exception e) {
                 if (e instanceof MetaException) {
                     metastoreExceptions.update(1);
                     // Need to throw here instead of falling through due to JDK-8059299
                     totalFailures.update(1);
                     throw e;
                 }
 
                 if (e instanceof TException) {
+                    if (e instanceof TBase) {
+                        // This exception is an API response and not a server error
+                        throw e;
+                    }
+
                     thriftExceptions.update(1);
                     // Need to throw here instead of falling through due to JDK-8059299
                     totalFailures.update(1);
                     throw e;
                 }
 
                 totalFailures.update(1);
                 throw e;
             }
         };
     }
\ No newline at end of file
","Fix Hive metastore client API stats

The stats were counting API response exceptions as server errors.
",Buggy
presto,2919.json,54dd54cb681af311e9b6fb6910ae004dfa71988b,"@@ -1,8 +1,8 @@
     public SingleArrayBlockWriter beginBlockEntry()
     {
         if (currentEntryOpened) {
-            throw new IllegalStateException(""Expected current entry to be closed but was closed"");
+            throw new IllegalStateException(""Expected current entry to be closed but was opened"");
         }
         currentEntryOpened = true;
         return new SingleArrayBlockWriter(values, values.getPositionCount());
     }
\ No newline at end of file
","Minor exception message fix for ArrayBlockBuilder

When attempting to begin an entry on an already opened block writer,
the error message does not accurately reflect the current state.
",Buggy
presto,37880.json,954e4714ac1aac177bbf00d5641088cc7eb15289,"@@ -1,8 +1,8 @@
     public int getPartition(Object key)
     {
         int partition = requireNonNull((Integer) key, ""key is null"");
         if (!(partition >= 0 && partition < numPartitions)) {
-            throw new IllegalArgumentException(""invalid partition: %s"" + partition);
+            throw new IllegalArgumentException(format(""Unexpected partition: %s. Total number of partitions: %s."", partition, numPartitions));
         }
         return partition;
     }
\ No newline at end of file
","Fix error message in IntegerIdentityPartitioner
",Buggy
presto,5480.json,3d776ab3a9b34d155caa2097ed5e0a82c3f9ca39,"@@ -1,6 +1,7 @@
     private static Class<? extends InputFormat<?, ?>> getInputFormatClass(JobConf conf, String inputFormatName)
             throws ClassNotFoundException
     {
         Class<?> clazz = conf.getClassByName(inputFormatName);
-        return (Class<? extends InputFormat<?, ?>>) clazz.asSubclass(InputFormat.class);
+        // TODO: remove redundant cast to Object after IDEA-118533 is fixed
+        return (Class<? extends InputFormat<?, ?>>) (Object) clazz.asSubclass(InputFormat.class);
     }
\ No newline at end of file
","Fix bogus error message in IDEA 13
",Buggy
presto,14661.json,a5a04929e51756cac167c14cf73399a0df74f4c5,"@@ -1,4 +1,5 @@
     public static long valueAtQuantileBigint(@SqlType(""qdigest(bigint)"") Slice input, @SqlType(StandardTypes.DOUBLE) double quantile)
     {
+        checkCondition(quantile >= 0 && quantile <= 1, INVALID_FUNCTION_ARGUMENT, ""Quantile should be within bounds [0, 1], was: "" + quantile);
         return new QuantileDigest(input).getQuantile(quantile);
     }
\ No newline at end of file
","Fix invalid quantile to be a user error
",Buggy
presto,2512.json,ff82d4c25dcaeb742f1eb3470a04e89a8d2ede7b,"@@ -1,5 +1,5 @@
     public Block getRegion(int positionOffset, int length)
     {
         checkValidRegion(positionCount, positionOffset, length);
-        return new DictionaryBlock(idsOffset + positionOffset, length, dictionary, ids, false, randomDictionaryId());
+        return new DictionaryBlock(idsOffset + positionOffset, length, getDictionary(), ids, false, getDictionarySourceId());
     }
\ No newline at end of file
","Fix bug in DictionaryBlock getRegion
",Buggy
presto,22974.json,eb4e582942793631a8de8cf6e6e1c06ce3053d75,"@@ -1,8 +1,8 @@
     public void setConfigurationManager(String name, Map<String, String> properties)
     {
         SessionPropertyConfigurationManagerFactory factory = factories.get(name);
-        checkState(factory != null, ""Session property configuration manager %s is not registered"");
+        checkState(factory != null, ""Session property configuration manager '%s' is not registered"", name);
 
         SessionPropertyConfigurationManager manager = factory.create(properties, configurationManagerContext);
         checkState(delegate.compareAndSet(null, manager), ""sessionPropertyConfigurationManager is already set"");
     }
\ No newline at end of file
","Fix error message in SessionPropertyDefaults
",Buggy
presto,22974.json,59d297913ff6641b852bd236161f237a3f9e3af7,"@@ -1,8 +1,8 @@
     public void setConfigurationManager(String name, Map<String, String> properties)
     {
         SessionPropertyConfigurationManagerFactory factory = sessionPropertyConfigurationManagerFactories.get(name);
-        checkState(factory != null, ""Session property configuration manager %s is not registered"");
+        checkState(factory != null, ""Session property configuration manager '%s' is not registered"", name);
 
         SessionPropertyConfigurationManager manager = factory.create(properties, configurationManagerContext);
         checkState(sessionPropertyConfigurationManager.compareAndSet(null, manager), ""sessionPropertyConfigurationManager is already set"");
     }
\ No newline at end of file
","Fix error message in QuerySessionSupplier
",Buggy
presto,31633.json,318f9bf12b4402074f5f8caf0845a121c026f0df,"@@ -1,8 +1,8 @@
     public Object getObjectValue(ConnectorSession session, Block block, int position)
     {
         if (block.isNull(position)) {
             return null;
         }
 
-        return BingTile.decode(block.getLong(0, 0));
+        return BingTile.decode(block.getLong(position, 0));
     }
\ No newline at end of file
","Fix getObjectValue in BingTileType

This change fixes a bug in decoding arrays of bing tiles.
",Buggy
netty,5669.json,b39ffed042844adecaf0a4fc4e9a2f53edaa111d,"@@ -1,15 +1,15 @@
         private void record(int actualReadBytes) {
-            if (actualReadBytes <= SIZE_TABLE[max(0, index - INDEX_DECREMENT - 1)]) {
+            if (actualReadBytes <= SIZE_TABLE[max(0, index - INDEX_DECREMENT)]) {
                 if (decreaseNow) {
                     index = max(index - INDEX_DECREMENT, minIndex);
                     nextReceiveBufferSize = SIZE_TABLE[index];
                     decreaseNow = false;
                 } else {
                     decreaseNow = true;
                 }
             } else if (actualReadBytes >= nextReceiveBufferSize) {
                 index = min(index + INDEX_INCREMENT, maxIndex);
                 nextReceiveBufferSize = SIZE_TABLE[index];
                 decreaseNow = false;
             }
         }
\ No newline at end of file
","Fix incorrect calculation of next buffer size in AdaptiveRecvByteBufAllocator (#9555)

Motivation:

Due a bug we did not always correctly calculate the next buffer size in AdaptiveRecvByteBufAllocator.

Modification:

Fix calculation and add unit test

Result:

Correct calculation is always used. 
",Buggy
netty,10635.json,799350c369e68462b61c6aef97db2a33ea937434,"@@ -1,63 +1,67 @@
     public void updateDependencyTree(int childStreamId, int parentStreamId, short weight, boolean exclusive) {
         if (weight < MIN_WEIGHT || weight > MAX_WEIGHT) {
             throw new IllegalArgumentException(String.format(
                     ""Invalid weight: %d. Must be between %d and %d (inclusive)."", weight, MIN_WEIGHT, MAX_WEIGHT));
         }
         if (childStreamId == parentStreamId) {
             throw new IllegalArgumentException(""A stream cannot depend on itself"");
         }
 
         State state = state(childStreamId);
         if (state == null) {
             // If there is no State object that means there is no Http2Stream object and we would have to keep the
             // State object in the stateOnlyMap and stateOnlyRemovalQueue. However if maxStateOnlySize is 0 this means
             // stateOnlyMap and stateOnlyRemovalQueue are empty collections and cannot be modified so we drop the State.
             if (maxStateOnlySize == 0) {
                 return;
             }
             state = new State(childStreamId);
             stateOnlyRemovalQueue.add(state);
             stateOnlyMap.put(childStreamId, state);
         }
 
         State newParent = state(parentStreamId);
         if (newParent == null) {
             // If there is no State object that means there is no Http2Stream object and we would have to keep the
             // State object in the stateOnlyMap and stateOnlyRemovalQueue. However if maxStateOnlySize is 0 this means
             // stateOnlyMap and stateOnlyRemovalQueue are empty collections and cannot be modified so we drop the State.
             if (maxStateOnlySize == 0) {
                 return;
             }
             newParent = new State(parentStreamId);
             stateOnlyRemovalQueue.add(newParent);
             stateOnlyMap.put(parentStreamId, newParent);
+            // Only the stream which was just added will change parents. So we only need an array of size 1.
+            List<ParentChangedEvent> events = new ArrayList<ParentChangedEvent>(1);
+            connectionState.takeChild(newParent, false, events);
+            notifyParentChanged(events);
         }
 
         // if activeCountForTree == 0 then it will not be in its parent's pseudoTimeQueue and thus should not be counted
         // toward parent.totalQueuedWeights.
         if (state.activeCountForTree != 0 && state.parent != null) {
             state.parent.totalQueuedWeights += weight - state.weight;
         }
         state.weight = weight;
 
         if (newParent != state.parent || (exclusive && newParent.children.size() != 1)) {
             final List<ParentChangedEvent> events;
             if (newParent.isDescendantOf(state)) {
                 events = new ArrayList<ParentChangedEvent>(2 + (exclusive ? newParent.children.size() : 0));
                 state.parent.takeChild(newParent, false, events);
             } else {
                 events = new ArrayList<ParentChangedEvent>(1 + (exclusive ? newParent.children.size() : 0));
             }
             newParent.takeChild(state, exclusive, events);
             notifyParentChanged(events);
         }
 
         // The location in the dependency tree impacts the priority in the stateOnlyRemovalQueue map. If we created new
         // State objects we must check if we exceeded the limit after we insert into the dependency tree to ensure the
         // stateOnlyRemovalQueue has been updated.
         while (stateOnlyRemovalQueue.size() > maxStateOnlySize) {
             State stateToRemove = stateOnlyRemovalQueue.poll();
             stateToRemove.parent.removeChild(stateToRemove);
             stateOnlyMap.remove(stateToRemove.streamId);
         }
     }
\ No newline at end of file
","Fix HTTP/2 dependency tree corruption

Motivation:

Chrome was randomly getting stuck loading the tiles examples.
Investigation showed that the Netty flow controller thought it had
nothing to send for the connection even though some streams has queued
data and window available.

Modifications:

Fixed an accounting error where an implicitly created parent was not
being added to the dependency tree, thus it and all of its children were
orphaned from the connection's tree and would never have data written.

Result:

Fixes #6621
",Buggy
netty,536.json,6fc7c589f023b069ac5f4df8a6766f0b501487fb,"@@ -1,10 +1,11 @@
         DatagramPacket newDatagramPacket(ByteBuf buffer, InetSocketAddress localAddress) throws UnknownHostException {
             final InetAddress address;
-            if (scopeId != 0) {
-                address = Inet6Address.getByAddress(null, addr, scopeId);
+            if (addrLen == ipv4Bytes.length) {
+                System.arraycopy(addr, 0, ipv4Bytes, 0, addrLen);
+                address = InetAddress.getByAddress(ipv4Bytes);
             } else {
-                address = InetAddress.getByAddress(addr);
+                address = Inet6Address.getByAddress(null, addr, scopeId);
             }
             return new DatagramPacket(buffer.writerIndex(count),
                     localAddress, new InetSocketAddress(address, port));
         }
\ No newline at end of file
","Correctly handle ipv6 mapped ipv4 addresses when using recvmmsg (#9541)


Motivation:

394a1b3485000c211595aff7495c4f863972af29 introduced the possibility to use recvmmsg(...) but did not correctly handle ipv6 mapped ip4 addresses to make it consistent with other transports.

Modifications:

- Correctly handle ipv6 mapped ipv4 addresses by only copy over the relevant bytes
- Small improvement on how to detect ipv6 mapped ipv4 addresses by using memcmp and not byte by byte compare
- Adjust test to cover this bug

Result:

Correctly handle ipv6 mapped ipv4 addresses
",Buggy
netty,15758.json,f0a3f849f7d0e028eb97e672a3cbf52648b98617,"@@ -1,26 +1,27 @@
     public ByteBuf writeZero(int length) {
         if (length == 0) {
             return this;
         }
 
+        ensureWritable(length);
         checkIndex(writerIndex, length);
 
         int nLong = length >>> 3;
         int nBytes = length & 7;
         for (int i = nLong; i > 0; i --) {
             writeLong(0);
         }
         if (nBytes == 4) {
             writeInt(0);
         } else if (nBytes < 4) {
             for (int i = nBytes; i > 0; i --) {
                 writeByte((byte) 0);
             }
         } else {
             writeInt(0);
             for (int i = nBytes - 4; i > 0; i --) {
                 writeByte((byte) 0);
             }
         }
         return this;
     }
\ No newline at end of file
","Fix a bug in AbstractByteBuf.writeZero() where the capacity is not auto-expanded
",Buggy
netty,14984.json,dcc39e5b21eda7bdd9563ed86253a693923f6432,"@@ -1,13 +1,13 @@
     protected String format(ChannelHandlerContext ctx, String eventName, Object firstArg, Object secondArg) {
         if (secondArg == null) {
             return formatSimple(ctx, eventName, firstArg);
         }
 
         String chStr = ctx.channel().toString();
         String arg1Str = String.valueOf(firstArg);
         String arg2Str = secondArg.toString();
         StringBuilder buf = new StringBuilder(
-                chStr.length() + 1 + eventName + 2 + arg1Str.length() + 2 + arg2Str.length());
+                chStr.length() + 1 + eventName.length() + 2 + arg1Str.length() + 2 + arg2Str.length());
         buf.append(chStr).append(' ').append(eventName).append("": "").append(arg1Str).append("", "").append(arg2Str);
         return buf.toString();
     }
\ No newline at end of file
","Fixes a LoggingHandler#format method with two arguments

Motivation:
Bug in capacity calculation: occurs auto convert to string instead of sum up.

Modifications:
Use `eventName.length()` in sum.

Result:
Less trash in logs.
",Buggy
netty,2881.json,338e1a991c5d15695bd654a7b8d2bd4008e868ae,"@@ -1,51 +1,51 @@
         public void run() {
             if (!state.compareAndSet(SUBMITTED, RUNNING)) {
                 return;
             }
             for (;;) {
                 int i = 0;
                 try {
                     for (; i < maxTaskExecutePerRun; i++) {
                         Runnable task = tasks.poll();
                         if (task == null) {
                             break;
                         }
                         safeExecute(task);
                     }
                 } finally {
                     if (i == maxTaskExecutePerRun) {
                         try {
                             state.set(SUBMITTED);
                             executor.execute(this);
                             return; // done
                         } catch (Throwable ignore) {
                             // Reset the state back to running as we will keep on executing tasks.
                             state.set(RUNNING);
                             // if an error happened we should just ignore it and let the loop run again as there is not
                             // much else we can do. Most likely this was triggered by a full task queue. In this case
                             // we just will run more tasks and try again later.
                         }
                     } else {
                         state.set(NONE);
                         // After setting the state to NONE, look at the tasks queue one more time.
                         // If it is empty, then we can return from this method.
                         // Otherwise, it means the producer thread has called execute(Runnable)
                         // and enqueued a task in between the tasks.poll() above and the state.set(NONE) here.
                         // There are two possible scenarios when this happen
                         //
                         // 1. The producer thread sees state == NONE, hence the compareAndSet(NONE, SUBMITTED)
                         //    is successfully setting the state to SUBMITTED. This mean the producer
                         //    will call / has called executor.execute(this). In this case, we can just return.
                         // 2. The producer thread don't see the state change, hence the compareAndSet(NONE, SUBMITTED)
                         //    returns false. In this case, the producer thread won't call executor.execute.
                         //    In this case, we need to change the state to RUNNING and keeps running.
                         //
                         // The above cases can be distinguished by performing a
                         // compareAndSet(NONE, RUNNING). If it returns ""false"", it is case 1; otherwise it is case 2.
-                        if (tasks.peek() == null || !state.compareAndSet(NONE, RUNNING)) {
+                        if (tasks.isEmpty() || !state.compareAndSet(NONE, RUNNING)) {
                             return; // done
                         }
                     }
                 }
             }
         }
\ No newline at end of file
","Fix a bug introduced by 79706357c73ded02615d0445db7503b646ff9547 which can cause thread to spin in an infinite loop. (#9579)

Motivation:
peek() is implemented in a similar way to poll() for the mpsc queue, thus it is more like a consumer call.
It is possible that we could have multiple thread call peek() and possibly one thread calls poll() at at the same time.
This lead to multiple consumer scenario, which violates the multiple producer single consumer condition and could lead to spin in an infinite loop in peek()

Modification:
Use isEmpty() instead of peek() to check if task queue is empty

Result:
Dont violate the mpsc semantics.
",Buggy
netty,2881.json,79706357c73ded02615d0445db7503b646ff9547,"@@ -1,34 +1,51 @@
         public void run() {
             if (!state.compareAndSet(SUBMITTED, RUNNING)) {
                 return;
             }
             for (;;) {
                 int i = 0;
                 try {
                     for (; i < maxTaskExecutePerRun; i++) {
                         Runnable task = tasks.poll();
                         if (task == null) {
                             break;
                         }
                         safeExecute(task);
                     }
                 } finally {
                     if (i == maxTaskExecutePerRun) {
                         try {
                             state.set(SUBMITTED);
                             executor.execute(this);
                             return; // done
                         } catch (Throwable ignore) {
                             // Reset the state back to running as we will keep on executing tasks.
                             state.set(RUNNING);
                             // if an error happened we should just ignore it and let the loop run again as there is not
                             // much else we can do. Most likely this was triggered by a full task queue. In this case
                             // we just will run more tasks and try again later.
                         }
                     } else {
                         state.set(NONE);
-                        return; // done
+                        // After setting the state to NONE, look at the tasks queue one more time.
+                        // If it is empty, then we can return from this method.
+                        // Otherwise, it means the producer thread has called execute(Runnable)
+                        // and enqueued a task in between the tasks.poll() above and the state.set(NONE) here.
+                        // There are two possible scenarios when this happen
+                        //
+                        // 1. The producer thread sees state == NONE, hence the compareAndSet(NONE, SUBMITTED)
+                        //    is successfully setting the state to SUBMITTED. This mean the producer
+                        //    will call / has called executor.execute(this). In this case, we can just return.
+                        // 2. The producer thread don't see the state change, hence the compareAndSet(NONE, SUBMITTED)
+                        //    returns false. In this case, the producer thread won't call executor.execute.
+                        //    In this case, we need to change the state to RUNNING and keeps running.
+                        //
+                        // The above cases can be distinguished by performing a
+                        // compareAndSet(NONE, RUNNING). If it returns ""false"", it is case 1; otherwise it is case 2.
+                        if (tasks.peek() == null || !state.compareAndSet(NONE, RUNNING)) {
+                            return; // done
+                        }
                     }
                 }
             }
         }
\ No newline at end of file
","Fix race condition in the NonStickyEventExecutorGroup (#8232)

Motivation:

There was a race condition between the task submitter and task executor threads such that the last Runnable submitted may not get executed. 

Modifications:

The bug was fixed by checking the task queue and state in the task executor thread after it saw the task queue was empty.

Result:

Fixes #8230",Buggy
netty,17549.json,20894bc99e28191cc3926ae95a23f5c7d3969a33,"@@ -1,4 +1,3 @@
     public ByteBuffer internalNioBuffer(int index, int length) {
-        // Do not mess with the internal buffer's byte order.
-        return buf.nioBuffer(index, length).order(order);
+        return buf.internalNioBuffer(index, length).duplicate().order(order);
     }
\ No newline at end of file
","Fix a bug in internalNioBuffer() implementations of derived buffers

- A user can create multiple duplicates of a buffer and access their internal NIO buffers. (e.g. write multiple duplicates to multiple channels assigned to different event loop.)  Because the derived buffers' internalNioBuffer() simply delegates the call to the original buffer, all derived buffers and the original buffer's internalNioBuffer() will return the same buffer, which will lead to a race condition.
- Fixes #1739
",Buggy
netty,2272.json,cd3254df88b60476dc04b39915d3d70c200eb6f4,"@@ -1,6 +1,7 @@
         private static void reachabilityFence0(Object ref) {
             if (ref != null) {
-                // Empty synchronized is ok: https://stackoverflow.com/a/31933260/1151521
-                synchronized (ref) { }
+                synchronized (ref) {
+                    // Empty synchronized is ok: https://stackoverflow.com/a/31933260/1151521
+                }
             }
         }
\ No newline at end of file
","Update to new checkstyle plugin (#8777) (#8780)

Motivation:

We need to update to a new checkstyle plugin to allow the usage of lambdas.

Modifications:

- Update to new plugin version.
- Fix checkstyle problems.

Result:

Be able to use checkstyle plugin which supports new Java syntax.",Buggy
netty,1691.json,32746c53c1089550f79bd2d6eeba4d65dab1f2d3,"@@ -1,24 +1,24 @@
-    static byte padWithZeros(byte b, int lowOrderBitsToPreserve) {
+    private static byte padWithZeros(byte b, int lowOrderBitsToPreserve) {
         switch (lowOrderBitsToPreserve) {
         case 0:
             return 0;
         case 1:
-            return (byte) (0x01 & b);
+            return (byte) (0x80 & b);
         case 2:
-            return (byte) (0x03 & b);
+            return (byte) (0xC0 & b);
         case 3:
-            return (byte) (0x07 & b);
+            return (byte) (0xE0 & b);
         case 4:
-            return (byte) (0x0F & b);
+            return (byte) (0xF0 & b);
         case 5:
-            return (byte) (0x1F & b);
+            return (byte) (0xF8 & b);
         case 6:
-            return (byte) (0x3F & b);
+            return (byte) (0xFC & b);
         case 7:
-            return (byte) (0x7F & b);
+            return (byte) (0xFE & b);
         case 8:
             return b;
         default:
             throw new IllegalArgumentException(""lowOrderBitsToPreserve: "" + lowOrderBitsToPreserve);
         }
     }
\ No newline at end of file
","EDNS Client Subnet is not encoded correctly when source prefix length is not a multiple of 8.

Motivation:
When the ECS source prefix length is not a mutiple of 8, the last byte the address inside the
ECS OPT record is not padded properly.

Modifications:
DefaultDnsRecordEncoder.padWithZeros(...) was modified to add padding from the least
significant bits.

Result:
ECS encoding bug fixed.
",Buggy
netty,13070.json,a29532df43c9db08db5dbc83f30bb7bd2e55a596,"@@ -1,12 +1,12 @@
     private static Method updateByteBuffer(Checksum checksum) {
         if (PlatformDependent.javaVersion() >= 8) {
             try {
                 Method method = checksum.getClass().getDeclaredMethod(""update"", ByteBuffer.class);
-                method.invoke(method, ByteBuffer.allocate(1));
+                method.invoke(checksum, ByteBuffer.allocate(1));
                 return method;
             } catch (Throwable ignore) {
                 return null;
             }
         }
         return null;
     }
\ No newline at end of file
","Fix ByteBufChecksum optimisation for CRC32 and Adler32 (#9242)

Motivation:

Because of a simple bug in ByteBufChecksum#updateByteBuffer(Checksum),
ReflectiveByteBufChecksum is never used for CRC32 and Adler32, resulting
in direct ByteBuffers being checksummed byte by byte, which is
undesriable.

Modification:

Fix ByteBufChecksum#updateByteBuffer(Checksum) method to pass the
correct argument to Method#invoke(Checksum, ByteBuffer).

Result:

ReflectiveByteBufChecksum will now be used for Adler32 and CRC32 on
Java8+ and direct ByteBuffers will no longer be checksummed on slow
byte-by-byte basis.",Buggy
netty,239.json,1cc104e1c02f5ee54979d8dfcba5aa4fb20d3503,"@@ -1,3 +1,3 @@
-    public static SctpServerChannel open() {
+    public static SctpServerChannel open() throws IOException {
         return null;
     }
\ No newline at end of file
","Fix a compilation error
",Buggy
netty,1341.json,a4c96483d1e83981a1e0860d3a6f71fbe21d500c,"@@ -1,18 +1,20 @@
     private static boolean anyInterfaceSupportsIpV6() {
         try {
             Enumeration<NetworkInterface> interfaces = NetworkInterface.getNetworkInterfaces();
             while (interfaces.hasMoreElements()) {
                 NetworkInterface iface = interfaces.nextElement();
                 Enumeration<InetAddress> addresses = iface.getInetAddresses();
                 while (addresses.hasMoreElements()) {
-                    if (addresses.nextElement() instanceof Inet6Address) {
+                    InetAddress inetAddress = addresses.nextElement();
+                    if (inetAddress instanceof Inet6Address && !inetAddress.isAnyLocalAddress() &&
+                        !inetAddress.isLoopbackAddress() && !inetAddress.isLinkLocalAddress()) {
                         return true;
                     }
                 }
             }
         } catch (SocketException e) {
             logger.debug(""Unable to detect if any interface supports IPv6, assuming IPv4-only"", e);
             // ignore
         }
         return false;
     }
\ No newline at end of file
","Fix a bug where making IPv6 DnsQuestion when it's not supported (#10170)

Motivation:
Related https://github.com/line/armeria/issues/2463
Here is an example that an NIC has only link local address for IPv6.
```
$ ipaddr
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host
       valid_lft forever preferred_lft forever
3: eth0@if18692: <BROADCAST,MULTICAST,UP,LOWER_UP,M-DOWN> mtu 1460 qdisc noqueue
    link/ether 1a:5e:xx:xx:xx:xx brd ff:ff:ff:ff:ff:ff
    inet 10.xxx.xxx.xxx/24 scope global eth0
       valid_lft forever preferred_lft forever
    inet6 fe80::xxxx:xxxx:xxxx:xxxx/64 scope link
       valid_lft forever preferred_lft forever
```
If the NICs have only local or link local addresses, We should not send IPv6 DNS queris.

Modification:
- Ignore link-local IPv6 addresses which may exist even on a machine without IPv6 network.

Result:
- `DnsNameResolver` does not send DNS queries for AAAA when IPv6 is not available.",Buggy
netty,17654.json,c0bbde48b78163a394ae3fd63f98b6b6c56acb25,"@@ -1,3 +1,3 @@
     public ByteBuffer nioBuffer(int index, int length) {
-        return (ByteBuffer) buffer.duplicate().position(index).position(index + length);
+        return (ByteBuffer) buffer.duplicate().position(index).limit(index + length);
     }
\ No newline at end of file
","[#1852] Fix bug in UnpooledDirectByteBuf.nioBuffer(...) implementation
",Buggy
netty,12409.json,6983f704c0882dd322bc1cf0c7c1c635e4b05ea5,"@@ -1,3 +1,5 @@
     public ByteBuf readBytes(ByteBuf dst) {
-        throw new UnreplayableOperationException();
+        checkReadableBytes(dst.writableBytes());
+        buffer.readBytes(dst);
+        return this;
     }
\ No newline at end of file
","Fix unreplayble error
",Buggy
netty,9557.json,97d07253e2933dbca0d08cd19072503506bda863,"@@ -1,12 +1,12 @@
     public static SpdySessionStatus valueOf(int code) {
         switch (code) {
         case 0:
             return OK;
         case 1:
             return PROTOCOL_ERROR;
-        case 11:
+        case 2:
             return INTERNAL_ERROR;
         }
 
         return new SpdySessionStatus(code, ""UNKNOWN ("" + code + ')');
     }
\ No newline at end of file
","SPDY: fixed session status (internal error misdocumented)
",Buggy
argouml,1941.json,045f33e22637950982cc1193584f80301860683e,"@@ -1,7 +1,7 @@
     public void notationTextChanged(NotationTextEvent event) {
         this.setText(event.getText());
         this.setUnderline(event.isUnderlined());
-        this.setUnderline(event.isBold());
-        this.setItalic(event.isBold());
+        this.setBold(event.isBold());
+        this.setItalic(event.isItalic());
         this.damage();
     }
\ No newline at end of file
","Fix some cut and paste errors

git-svn-id: http://argouml.tigris.org/svn/argouml/trunk@19262 a161b567-7d1e-0410-9ef9-912c70fedb3f
",Buggy
argouml,1718.json,126f591fd6961fb320d035184050b65257130479,"@@ -1,6 +1,8 @@
     public boolean doesAccept(Object objectToAccept) {
         if (Model.getFacade().isAClassifier(objectToAccept)) {
             return true;
+        } else if (Model.getFacade().isAComment(objectToAccept)) {
+        	return true;
         }
         return false;
     }
\ No newline at end of file
","Fixed a bug where comments could not be added in Seq2 diagrams.

git-svn-id: http://argouml.tigris.org/svn/argouml/trunk@15998 a161b567-7d1e-0410-9ef9-912c70fedb3f
",Buggy
docx4j,8366.json,9f08fd2eac1d042d1fe3b2e70b2918f551ea677e,"@@ -1,50 +1,50 @@
     public static Document CxnSpToSVG(CxnSp cxnSp) {
     	
     	// Geometrical transforms
     	CTTransform2D xfrm = cxnSp.getSpPr().getXfrm();
     	Box b = new Box(xfrm.getOff().getX(), xfrm.getOff().getY(),
-    			xfrm.getExt().getCx(), xfrm.getExt().getCx() );
+    			xfrm.getExt().getCx(), xfrm.getExt().getCy() );
     	
     	if (xfrm.getRot()!=0) {
     		b.rotate(xfrm.getRot());
     	}
     	if (xfrm.isFlipH() ) {
     		b.flipH();
     	}
     	if (xfrm.isFlipV() ) {
     		b.flipV();
     	}
     	
     	// Convert from EMU to pixels
     	b.toPixels();
 
     	// Wrap in a div positioning it on the page
     	Document document = createDocument();
 		Element xhtmlDiv = document.createElement(""div"");
 		// Firefox needs the following; Chrome doesn't
 		xhtmlDiv.setAttribute(""style"", 
 				""position: absolute; width:100%; height:100%; left:0px; top:0px;"");		
 		Node n = document.appendChild(xhtmlDiv);
     	
     	// Convert the object itself to SVG
 		Svg svg = oFactory.createSvg();
     	Line line = oFactory.createLine();
     	svg.getSVGDescriptionClassOrSVGAnimationClassOrSVGStructureClass().add(line);
     	
     	line.setX1(b.getOffset().getXAsString() );
     	line.setY1(b.getOffset().getYAsString() );
     	
     	Point otherEnd = b.getOtherCorner();
     	
     	line.setX2( otherEnd.getXAsString() );
     	line.setY2( otherEnd.getYAsString() );
 
     	line.setStyle(""stroke:rgb(99,99,99)"");
     	// You can't see the line in Midori, unless you specify the color.
     	// width eg stroke-width:2 is optional
     	
     	Document d2 = XmlUtils.marshaltoW3CDomDocument(svg, jcSVG);   
     	XmlUtils.treeCopy(d2, n);
     	return document;
     	
     }
\ No newline at end of file
","Fix typo bug.
",Buggy
docx4j,5289.json,e0638645ae07b75593d031844af2c84f5b7a4960,"@@ -1,50 +1,50 @@
 	public OpcPackage get() throws Docx4JException {
 		
 		long startTime = System.currentTimeMillis();				
 
 		// 1. Get [Content_Types].xml
 		ContentTypeManager ctm = new ContentTypeManager();
 		try {
 			InputStream is = partStore.loadPart(""[Content_Types].xml"");		
 			ctm.parseContentTypesFile(is);
 		} catch (Docx4JException e) {
 			throw new Docx4JException(""Couldn't get [Content_Types].xml from ZipFile"", e);
 		} catch (NullPointerException e) {
 			throw new Docx4JException(""Couldn't get [Content_Types].xml from ZipFile"", e);
 		}
 		
 		// .. now find the name of the main part
 		String partName = ""_rels/.rels"";
 		RelationshipsPart rp = getRelationshipsPartFromZip(null, partName);
 		if (rp==null) {
 			throw new Docx4JException(""_rels/.rels appears to be missing from this package!"");
 		}
 		
 		String mainPartName = PackageRelsUtil.getNameOfMainPart(rp);
 		String pkgContentType = ctm.getContentType(new PartName(""/"" + mainPartName));
 
 		// 2. Create a new Package; this'll return the appropriate subclass
 		OpcPackage p = ctm.createPackage(pkgContentType);
 		log.info(""Instantiated package of type "" + p.getClass().getName() );
 		p.setPartStore(partStore);
 
 		p.setRelationships(rp);
 		rp.setSourceP(p); //
 		
 		// 5. Now recursively 
 //		(i) create new Parts for each thing listed
 //		in the relationships
 //		(ii) add the new Part to the package
 //		(iii) cross the PartName off unusedZipEntries
 		addPartsFromRelationships(p, rp, ctm );
 
 		// 6.
 		registerCustomXmlDataStorageParts(p);
 		
-		partStore.finishLoad();
+		partStore.finishSave();
 		
 		long endTime = System.currentTimeMillis();
 		log.info(""package read;  elapsed time: "" + Math.round((endTime-startTime)) + "" ms"" );
 		 
 		 return p;
 	}
\ No newline at end of file
","Fix compilation errors in some classes
",Buggy
docx4j,5988.json,e43c7ce6875ed0292eea114d1f12f5b9bed3e549,"@@ -1,30 +1,31 @@
 	public static Part newPartForContentType(String contentType, String partName)
 	throws InvalidFormatException, PartUnrecognisedException {
 		
-		if (contentType.equals(ContentTypes.PRESENTATIONML_MAIN)) {
+		if (contentType.equals(ContentTypes.PRESENTATIONML_MAIN)
+				|| contentType.equals(ContentTypes.PRESENTATIONML_TEMPLATE) ) {
 			return new MainPresentationPart(new PartName(partName));
 		} else if (contentType.equals(ContentTypes.PRESENTATIONML_SLIDE)) {
 			return new SlidePart(new PartName(partName));
 		} else if (contentType.equals(ContentTypes.PRESENTATIONML_SLIDE_MASTER)) {
 			return new SlideMasterPart(new PartName(partName));
 		} else if (contentType.equals(ContentTypes.PRESENTATIONML_SLIDE_LAYOUT)) {
 			return new SlideLayoutPart(new PartName(partName));
 		} else if (contentType.equals(ContentTypes.PRESENTATIONML_TABLE_STYLES)) {
 			return new TableStylesPart(new PartName(partName));
 		} else if (contentType.equals(ContentTypes.PRESENTATIONML_PRES_PROPS)) {
 			return new PresentationPropertiesPart(new PartName(partName));
 		} else if (contentType.equals(ContentTypes.PRESENTATIONML_VIEW_PROPS)) {
 			return new ViewPropertiesPart(new PartName(partName));
 		} else if (contentType.equals(ContentTypes.PRESENTATIONML_TAGS)) {
 			return new TagsPart(new PartName(partName));
 		} else if (contentType.equals(ContentTypes.PRESENTATIONML_HANDOUT_MASTER)) {
 			return new HandoutMasterPart(new PartName(partName));
 		} else if (contentType.equals(ContentTypes.PRESENTATIONML_NOTES_MASTER)) {
 			return new NotesMasterPart(new PartName(partName));
 		} else if (contentType.equals(ContentTypes.PRESENTATIONML_NOTES_SLIDE)) {
 			return new NotesSlidePart(new PartName(partName));
 		} else {
 			throw new PartUnrecognisedException(""No subclass found for "" 
 					+ partName + "" (content type '"" + contentType + ""')"");					
 		}
 	}	
\ No newline at end of file
","Arnaud Kleinpeter's patch of 10 April, fixing error when trying to open a .potx file (powerpoint
template).
",Buggy
docx4j,6677.json,e7a3747180c1121e45343a31225052ae7dc68b01,"@@ -1,7 +1,6 @@
 	public Node toNode(AbstractWmlConversionContext context, Model model, TransformState state, Document doc) throws TransformerException {
 	HyperlinkModel hyperlinkModel = (HyperlinkModel)model;
 	Node ret = null;
 		ret = toNode(context, hyperlinkModel, doc);
-		XmlUtils.treeCopy(hyperlinkModel.getContent().getChildNodes(), ret);
 		return ret;
 	}
\ No newline at end of file
","Fixed several problems converting docx to pdf

Fixes:
- removed treeCopy from AbstractHyperlinkWriter.java to prevent double
links creation;
- added creation of TblPr to prevent NPE and moving of P created for
<caption> tag in nestedTableHierarchyFix() method in XHTMLimporter.java.
So if one generates docx from html and then pdf from this docx
everything will work.
",Buggy
docx4j,5744.json,ec6c723c0edc1ad95aa484b4da21adf68c9e5f49,"@@ -1,27 +1,27 @@
 	public void registerInContentTypeManager() {
 		
 		ContentTypeManager ctm = this.getPackage().getContentTypeManager(); 
 		if (type.equals(AltChunkType.Xhtml) ) {
 			ctm.addDefaultContentType(""xhtml"", ""application/xhtml+xml"");
 		} else if (type.equals(AltChunkType.Mht) ) {
-			ctm.addDefaultContentType(""mht"", ""multipart/related"");
+			ctm.addDefaultContentType(""mht"", ""message/rfc822"");
 		} else if (type.equals(AltChunkType.Xml) ) {
 			ctm.addDefaultContentType(""xml"", ""application/xml"");
 		} else if (type.equals(AltChunkType.TextPlain) ) {
 			ctm.addDefaultContentType(""txt"", ""text/plain"");
 		} else if (type.equals(AltChunkType.WordprocessingML) ) { //Docx
 			// In case we're being added to a docm/dotx/dotm
 			ctm.addDefaultContentType(""docx"", ContentTypes.WORDPROCESSINGML_DOCUMENT);
 		} else if (type.equals(AltChunkType.OfficeWordMacroEnabled) ) {
 			ctm.addDefaultContentType(""docm"", ContentTypes.WORDPROCESSINGML_DOCUMENT_MACROENABLED);
 		} else if (type.equals(AltChunkType.OfficeWordTemplate) ) {
 			ctm.addDefaultContentType(""dotx"", ContentTypes.WORDPROCESSINGML_TEMPLATE);
 		} else if (type.equals(AltChunkType.OfficeWordMacroEnabledTemplate) ) {
 			ctm.addDefaultContentType(""dotm"", ContentTypes.WORDPROCESSINGML_TEMPLATE_MACROENABLED);
 		} else if (type.equals(AltChunkType.Rtf) ) {
 			ctm.addDefaultContentType(""rtf"", ""text/rtf"");
 		} else if (type.equals(AltChunkType.Html) ) {
 			ctm.addDefaultContentType(""html"", ""text/html"");
 		}
 		
 	}
\ No newline at end of file
","Bug fix: Change content type for mht to ""message/rfc822"" (Zoltan Luspai)
",Buggy
docx4j,6106.json,e89bdbce6981005eb9b5b3c2c5893d0f1561ac1f,"@@ -1,20 +1,25 @@
 	public static String getNameOfMainPart(RelationshipsPart packageRels) throws Docx4JException  {
 		
 		// find rel of type officeDocument
 		for (Relationship rel : packageRels.getRelationships().getRelationship() ) {
 			
 			if (rel.getType().equals(
 					""http://schemas.openxmlformats.org/officeDocument/2006/relationships/officeDocument"") ) {
 				return rel.getTarget();
 			} 
 			else if (rel.getType().equals(
 					""http://schemas.microsoft.com/office/2006/relationships/graphicFrameDoc"") ) {
 				// v:shape/@o:gfxdata
 				return rel.getTarget();
 			} 
+			else if (rel.getType().equals(
+					""http://schemas.openxmlformats.org/officeDocument/2006/relationships/diagramLayout"") ) {
+				// Glox
+				return rel.getTarget();
+			} 
 //			else {
 //				System.out.println(rel.getType());
 //			}
 		}
 		throw new Docx4JException(""No relationship of type officeDocument"");
 	}
\ No newline at end of file
","Bug fix: make ParseGlox sample work.
",Buggy
docx4j,5455.json,8d2fa40ea092e0c98a6e8648a80184c0dfe88ed7,"@@ -1,62 +1,68 @@
 	public void removePart(PartName partName) {
 		
 		log.info(""trying to removePart "" + partName.getName() );
 		
 		if (partName == null)
 			throw new IllegalArgumentException(""partName was null"");
 		
 		Part part = getPackage().getParts().get(partName);
 		
 		if (part!=null) {
 
 			// Remove the relationship for which it is a target from here
 			// Throw an error if this can't be found!
 			Relationship relToBeRemoved = null;
 //			for (Relationship rel : relationshipsByID.values() ) {
 			for (Relationship rel : relationships.getRelationship() ) {
+				
+				if (rel.getTargetMode() !=null
+						&& rel.getTargetMode().equals(""External"") ) {
+					// This method can't be used to remove external resources
+					continue;
+				}
 								
 				URI resolvedTargetURI = null;
 
 				try {
 					resolvedTargetURI = org.docx4j.openpackaging.URIHelper
 							.resolvePartUri(sourceP.partName.getURI(), new URI(
 									rel.getTarget()));
 				} catch (URISyntaxException e) {
 					log.error(""Cannot convert "" + rel.getTarget()
 							+ "" in a valid relationship URI-> ignored"", e);
 				}		
 
 				log.debug(""Comparing "" + resolvedTargetURI + "" == "" + partName.getName());
 				
 				if (partName.getName().equals(resolvedTargetURI.toString()) ) { // was rel.getTargetURI()
 					
 					log.info(""True - will delete relationship with target "" + rel.getTarget());
 					relToBeRemoved = rel; // Avoid java.util.ConcurrentModificationException
 					break;
 				}
 				
 			}
 			if (relToBeRemoved==null) {
 				// The Part may be in the package somewhere, but its not
 				// a target of this relationships part!
 				throw new IllegalArgumentException(partName + "" is not a target of "" + this.partName );
 			} else {
 				removeRelationship(relToBeRemoved);				
 			}
 						
 			// Remove parts it references
 			if (part.getRelationshipsPart()!=null) {
 				part.getRelationshipsPart().removeParts();
 				
 				// part.setRelationships(null);  // Unnecessary
 			}			
 
 			// Remove from Content Type Manager
 				// TODO			
 			
 			// Delete the specified part from the package.
 			getPackage().getParts().remove(partName);						
 		}
 
 //		this.isDirty = true;
 	}
\ No newline at end of file
","Bug fix in removePart - ignore external resources.
",Buggy
docx4j,3230.json,71277942a6f5c967ca96c8454953e8c6697dffbb,"@@ -1,9 +1,14 @@
 	public void setXslFO(Element foElement) {
 		
 		if (((Color)this.getObject()).getVal()!=null ) {
-			foElement.setAttribute(FO_NAME, ""#"" + ((Color)this.getObject()).getVal());
+			if (((Color)this.getObject()).getVal().equals(""auto"")) {
+				// set it to black
+				foElement.setAttribute(FO_NAME, ""black"");				
+			} else {
+				foElement.setAttribute(FO_NAME, ""#"" + ((Color)this.getObject()).getVal());
+			}
 		} else {
 			//
 		}
 
 	}
\ No newline at end of file
","bug fix: XSL FO doesn't like font color #auto
",Buggy
docx4j,18108.json,b7d10c89810f8fb9ba39216b7630f82f493bfdee,"@@ -1,126 +1,125 @@
 	public static void main(String[] args) throws Docx4JException {
 		
 		// Input file
 		String inputfilepath = System.getProperty(""user.dir"") + ""/sample-docs/pptx/pptx-chart.pptx"";
 		
 		// The names of the parts which will be edited
 		// Alter these to match what is in your input pptx
 		// .. the chart
 		String chartPartName = ""/ppt/charts/chart1.xml"";
 		// .. the xlsx
 		String xlsPartName = ""/ppt/embeddings/Microsoft_Excel_Sheet1.xlsx"";
-//		String xlsPartName = ""/ppt/embeddings/Microsoft_Office_Excel_Worksheet1.xlsx"";
 		
 		// Output file
 		String outputfilepath = System.getProperty(""user.dir"") 
 				+ ""/OUT_EditEmbeddedCharts-"" 
 				+ System.currentTimeMillis() + "".pptx"";
 		
 		// Values to change
 		Random rand = new Random();
 
 		String firstValue  = String.valueOf(rand.nextInt(99));
 		String secondValue = String.valueOf(rand.nextInt(99));
 		
 		// Open the PPT template file
 		PresentationMLPackage ppt = (PresentationMLPackage) OpcPackage
 			.load(new java.io.File(inputfilepath));
 
 		/*
 		 * Get the Chart object and update the values. Afterwards, we'll update 
 		 * the associated spreadsheet so that the data is synchronized.
 		 */
 		Chart chart = (Chart) ppt.getParts().get(new PartName(chartPartName));
 		
 		List<Object> objects = chart.getJaxbElement().getChart().getPlotArea()
 				.getAreaChartOrArea3DChartOrLineChart();
 		
 		for (Object object : objects) {
 			
 			if (object instanceof CTBarChart) {
 
 				List<CTBarSer> ctBarSers = ((CTBarChart) object).getSer();
 				
 				for (CTBarSer ctBarSer : ctBarSers)
 				{
 					List<CTNumVal> ctNumVals = ctBarSer.getVal().getNumRef().getNumCache().getPt();
 					for (CTNumVal ctNumVal : ctNumVals)
 					{
 						System.out.println(""ctNumVal Val BEFORE: "" + ctNumVal.getV());
 						if (ctNumVal.getIdx() == 0) {
 							ctNumVal.setV(firstValue);
 						}
 						else if (ctNumVal.getIdx() == 1) {
 							ctNumVal.setV(secondValue);	
 						}
 						System.out.println(""ctNumVal Val AFTER: "" + ctNumVal.getV());
 					}
 				}
 			}
 		}
 				
 		/*
 		 * Get the spreadsheet and find the cell values that need to be updated
 		 */
 		
 		EmbeddedPackagePart epp  = (EmbeddedPackagePart) ppt
 			.getParts().get(new PartName(xlsPartName));
 		
 		if (epp==null) {
 			throw new Docx4JException(""Could find EmbeddedPackagePart: "" + xlsPartName);
 		}
 		
 		InputStream is = BufferUtil.newInputStream(epp.getBuffer());
 		
 		SpreadsheetMLPackage spreadSheet = (SpreadsheetMLPackage) SpreadsheetMLPackage.load(is);
 
 		Map<PartName,Part> partsMap = spreadSheet.getParts().getParts();		 
 		Iterator<Entry<PartName, Part>> it = partsMap.entrySet().iterator();
 
 		while(it.hasNext()) {
 			Map.Entry<PartName, Part> pairs = it.next();
 			
 			if (partsMap.get(pairs.getKey()) instanceof WorksheetPart) {
 				
 				WorksheetPart wsp = (WorksheetPart) partsMap.get(pairs.getKey()) ;
 				
 				List<Row> rows = wsp.getJaxbElement().getSheetData().getRow();
 
 				for (Row row : rows) {
 					List<Cell> cells = row.getC();
 					for (Cell cell : cells)
 					{
 						if (cell.getR().equals(""B2"") && cell.getV() != null) {
 							System.out.println(""B2 CELL VAL: "" + cell.getV());
 							// change the B2 cell value
+							cell.setT(STCellType.STR);
 							cell.setV(firstValue);
 						}
 						else if (cell.getR().equals(""B3"") && cell.getV() != null) {
 							System.out.println(""B3 CELL VAL: "" + cell.getV());
 							// Change the B3 cell value
-							cell.setV(secondValue); 
+							cell.setT(STCellType.STR);
+							cell.setV(secondValue);
 						}
 					}					
 				}
 			}
 		}
 
 		/*
 		 * Convert the Spreadsheet to a binary format, set it on the 
 		 * EmbeddedPackagePart, add it back onto the deck and save to a file.
 		 *  
 		 */		
 		ByteArrayOutputStream baos = new ByteArrayOutputStream();
 		
 		SaveToZipFile saver = new SaveToZipFile(spreadSheet);
 
 		saver.save(baos);
 		epp.setBinaryData(baos.toByteArray());
 
-		ppt.addTargetPart(epp);
-
 		// Write the new file to disk
 		ppt.save(new java.io.File(outputfilepath));
 
 		System.out.println(""\n\n done .. saved "" + outputfilepath);
 	}
\ No newline at end of file
",EditEmbeddedCharts - bug fixes,Buggy
docx4j,5328.json,2b240431a940e8529960d06423db48c7122090ec,"@@ -1,67 +1,70 @@
 	public void addPartsFromRelationships(ZipOutputStream out,  RelationshipsPart rp )
 	 throws Docx4JException {
 		
 //		for (Iterator it = rp.iterator(); it.hasNext(); ) {
 //			Relationship r = (Relationship)it.next();
 //			log.info(""For Relationship Id="" + r.getId() + "" Source is "" + r.getSource().getPartName() + "", Target is "" + r.getTargetURI() );
 		for ( Relationship r : rp.getRelationships().getRelationship() ) {
 			
 			log.debug(""For Relationship Id="" + r.getId() 
 					+ "" Source is "" + rp.getSourceP().getPartName() 
 					+ "", Target is "" + r.getTarget() );
 			
-//			if (!r.getTargetMode().equals(TargetMode.INTERNAL) ) {
+			if (r.getType().equals(Namespaces.HYPERLINK)) {				
+				continue;  // whether internal or external								
+			}
+			
 			if (r.getTargetMode() != null
 					&& r.getTargetMode().equals(""External"") ) {
 				
 				// ie its EXTERNAL
 				// As at 1 May 2008, we don't have a Part for these;
 				// there is just the relationship.
 
 				log.warn(""Encountered external resource "" + r.getTarget() 
 						   + "" of type "" + r.getType() );
 				
 				// So
 				continue;				
 			}
 			
 			try {
 				//String resolvedPartUri = URIHelper.resolvePartUri(r.getSourceURI(), r.getTargetURI() ).toString();
 
 				String resolvedPartUri = URIHelper.resolvePartUri(rp.getSourceURI(), new URI(r.getTarget() ) ).toString();		
 				
 				// Now drop leading ""/'
 				resolvedPartUri = resolvedPartUri.substring(1);				
 				
 				// Now normalise it .. ie abc/def/../ghi
 				// becomes abc/ghi
 				// Maybe this isn't necessary with a zip file,
 				// - ZipFile class may be smart enough to do it.
 				// But it is certainly necessary in the JCR case.
 //				target = (new java.net.URI(target)).normalize().toString();
 //				log.info(""Normalised, it is "" + target );				
 				
 //				Document contents = getDocumentFromZippedPart( zf,  target);
 				
 				if (!false) {
 					log.debug(""Getting part /"" + resolvedPartUri );
 					
 					Part part = p.getParts().get(new PartName(""/"" + resolvedPartUri));
 					
 					if (part==null) {
 						log.error(""Part "" + resolvedPartUri + "" not found!"");
 					} else {
 						log.debug(part.getClass().getName() );
 					}
 					
 					savePart(out, part);
 					
 				}
 					
 			} catch (Exception e) {
 				throw new Docx4JException(""Failed to add parts from relationships"", e);				
 			}
 		}
 		
 		
 	}
\ No newline at end of file
","Bug fix: save file containing internal hyperlink rel
",Buggy
docx4j,6285.json,712217fb5f02ee12b18281bf0abe099e8e2cfe55,"@@ -1,32 +1,29 @@
 	private RelationshipsPart getRelationshipsPartFromXmlPackage(Base p, String partName) 
 			throws Docx4JException {
 		
-		RelationshipsPart thePart = null;
+		RelationshipsPart rp = null;
 		
 		try {
 			
 			org.docx4j.xmlPackage.Part part = parts.get(partName);
 			
 			if (part == null) {
 				return null;
 			}
 			
 			org.w3c.dom.Element el = part.getXmlData().getAny();
 			
-			RelationshipsPart rp = new RelationshipsPart(new PartName(partName) );
+			rp = new RelationshipsPart(new PartName(partName) );
 			// PartName already starts with a '/', so no need to add it
 			rp.setSourceP(p);
-			rp.unmarshal(el);
 			
-//			// Convert it to a Dom4J element
-//			thePart = new RelationshipsPart( p, new PartName( partName), convertW3CtoDom4J(el) );
-//				// PartName already starts with a '/', so no need to add it
-			
+			rp.setRelationships( (Relationships)rp.unmarshal(el) );
+						
 		} catch (Exception e) {
 			e.printStackTrace();
 			throw new Docx4JException(""Error getting document from XmlPackage:"" + partName, e);
 			
 		} 
 		
-		return thePart;
+		return rp;
 	}
\ No newline at end of file
","bug fix in getRelationshipsPartFromXmlPackage
",Buggy
mockito,494.json,881c1d9cace557e64641d9b104c59b2b0c86ee4c,"@@ -1,8 +1,7 @@
     public static IMockitoConfiguration getConfig() {
         if (!initialized) {
-            //TODO check email of mockito group
             throw new IllegalStateException(""Something went wrong. GlobalConfiguration should be initialised by now.\n"" +
                 ""Please report issue at http://mockito.org or write an email to mockito@googlegroups.com"");
         }
         return globalConfiguration;
     }
\ No newline at end of file
","removed TODOs,
fixed the minor problem of breaking the invocation string when no args given

--HG--
extra : convert_revision : svn%3Aaa2aecf3-ea3e-0410-9d70-716747e7c967/trunk%401161
",Buggy
mongo-java-driver,3587.json,e53bde1953e3e4d12809ce6c27c69a1eb8a4b8dd,"@@ -1,3 +1,4 @@
     public Binary readBinaryData(final String name) {
-        return readBinaryData(name);
+        verifyName(name);
+        return readBinaryData();
     }
\ No newline at end of file
","fixed infinite recursion error: test forthcoming
",Buggy
mongo-java-driver,2935.json,6fa5b4b1073a1df6d2a70d2fef360622bae6fbea,"@@ -1,14 +1,15 @@
     public void apply(final ClassModelBuilder<?> classModelBuilder) {
         for (PropertyModelBuilder<?> propertyModelBuilder : classModelBuilder.getPropertyModelBuilders()) {
             if (!(propertyModelBuilder.getPropertyAccessor() instanceof PropertyAccessorImpl)) {
                 throw new CodecConfigurationException(format(""The SET_PRIVATE_FIELDS_CONVENTION is not compatible with ""
                         + ""propertyModelBuilder instance that have custom implementations of org.bson.codecs.pojo.PropertyAccessor: %s"",
                         propertyModelBuilder.getPropertyAccessor().getClass().getName()));
             }
             PropertyAccessorImpl<?> defaultAccessor = (PropertyAccessorImpl<?>) propertyModelBuilder.getPropertyAccessor();
             PropertyMetadata<?> propertyMetaData = defaultAccessor.getPropertyMetadata();
-            if (!propertyMetaData.isDeserializable() && isPrivate(propertyMetaData.getField().getModifiers())) {
+            if (!propertyMetaData.isDeserializable() && propertyMetaData.getField() != null
+                    && isPrivate(propertyMetaData.getField().getModifiers())) {
                 setPropertyAccessor(propertyModelBuilder);
             }
         }
     }
\ No newline at end of file
","Fix NPE error with ConventionSetPrivateField

JAVA-2951
",Buggy
mongo-java-driver,3321.json,9d17beae8f95df45c855e8284e96a6ddbdca07b7,"@@ -1,26 +1,28 @@
     public static UUID decodeBinaryToUuid(final byte[] data, final byte type, final UuidRepresentation uuidRepresentation) {
         if (data.length != 16) {
             throw new BsonSerializationException(String.format(""Expected length to be 16, not %d."", data.length));
         }
 
         if (type == BsonBinarySubType.UUID_LEGACY.getValue()) {
             switch(uuidRepresentation) {
                 case C_SHARP_LEGACY:
                     reverseByteArray(data, 0, 4);
                     reverseByteArray(data, 4, 2);
                     reverseByteArray(data, 6, 2);
                     break;
                 case JAVA_LEGACY:
                     reverseByteArray(data, 0, 8);
                     reverseByteArray(data, 8, 8);
                     break;
                 case PYTHON_LEGACY:
-                case STANDARD:
                     break;
+                case STANDARD:
+                    throw new BSONException(""Can not decode a subtype 3 (UUID legacy) BSON binary when the decoder is configured to use "" +
+                            ""the standard UUID representation"");
                 default:
                     throw new BSONException(""Unexpected UUID representation"");
             }
         }
 
         return new UUID(readLongFromArrayBigEndian(data, 0), readLongFromArrayBigEndian(data, 8));
     }
\ No newline at end of file
","Fix UUID decoder bug

The UUID decoder now does NOT allow decoding of a subtype 3 (legacy UUID) BSON Binary value
when the UUID decoder's UUID representation is STANDARD.
",Buggy
mongo-java-driver,2112.json,381a79da3eab8c3d819826af40b0ae39dd08ae08,"@@ -1,3 +1,3 @@
-    public void pipe(BSONReader reader) {
+    public void pipe(final BSONReader reader) {
         pipeDocument(reader);
     }
\ No newline at end of file
","Fixed checkstyle errors
",Buggy
mongo-java-driver,685.json,0a759943e1d5a8b971798db82e8a89330545e558,"@@ -1,8 +1,3 @@
     public GridFSInputFile createFile(final File file) throws IOException {
-        FileInputStream fileInputStream = new FileInputStream(file);
-        try {
-            return createFile(fileInputStream, file.getName(), true);
-        } finally {
-            fileInputStream.close();
-        }
+        return createFile(new FileInputStream(file), file.getName(), true);
     }
\ No newline at end of file
","Fixed GridFS.createFile bug

The underlying call handles the closure of the stream correctly

JAVA-1813
",Buggy
junit5,2294.json,01eb2e4e3ba37aedc2c8f578fcc77a55ef305cd5,"@@ -1,3 +1,9 @@
 	private static String toString(Object obj) {
-		return (obj instanceof Class ? getCanonicalName((Class<?>) obj) : String.valueOf(obj));
+		if (obj instanceof Class) {
+			return getCanonicalName((Class<?>) obj);
+		}
+		if (obj instanceof Object[]) {
+			return Arrays.toString((Object[]) obj);
+		}
+		return StringUtils.nullSafeToString(obj);
 	}
\ No newline at end of file
","Fix bug in AssertionUtils.toString(Object)

Prior to this commit, AssertionUtils.toString(Object) printed an array via
the array's toString() method which resulted in non-user-friendly output.

This commit addresses this issue by printing arrays using Arrays.toString(),
which produces human readable output.

This is a prerequisite for #961.

Issue: #1030
",Buggy
Essentials,1046.json,880ec1b3d953f1aef72ac925fe524799e4df8898,"@@ -1,13 +1,13 @@
 	protected void run(Server server, CommandSender sender, String commandLabel, String[] args) throws Exception
 	{
 		charge(sender);
 		sender.sendMessage(Util.format(""gcmax"", (Runtime.getRuntime().maxMemory() / 1024 / 1024)));
 		sender.sendMessage(Util.format(""gcmin"", (Runtime.getRuntime().freeMemory() / 1024 / 1024)));
 		for (World w : server.getWorlds())
 		{
 			sender.sendMessage(
 					(w.getEnvironment() == World.Environment.NETHER ? ""Nether"" : ""World"") + "" \"""" + w.getName() + ""\"": ""
 					+ w.getLoadedChunks().length + Util.i18n(""gcchunks"")
-					+ w.getEntities().size() + Util.i18n(""entities""));
+					+ w.getEntities().size() + Util.i18n(""gcentities""));
 		}
 	}
\ No newline at end of file
","Fix translation error in gc

git-svn-id: https://svn.java.net/svn/essentials~svn/trunk@1465 e251c2fe-e539-e718-e476-b85c1f46cddb
",Buggy
Essentials,2593.json,4c78ab4f2a3eb4d598564069aa5a21e0380de29d,"@@ -1,28 +1,29 @@
 	private List<String> sort(List<String> permList) {
 		
 		List<String> result = new ArrayList<String>();
 		
 		for (String key : permList) {
 			String a = key.charAt(0) == '-'? key.substring(1):key;
 			Map<String, Boolean> allchildren = GroupManager.BukkitPermissions.getAllChildren(a, new HashSet<String>());
 			if (allchildren != null) {
 
 				ListIterator<String> itr = result.listIterator();
 				
 				while (itr.hasNext()){
 					String node = (String) itr.next();
 					String b = node.charAt(0) == '-'? node.substring(1):node;
 					
+					// Insert the parent node before the child
 					if (allchildren.containsKey(b)) {
-						itr.previous();
-						itr.add(key);
+						itr.set(key);
+						itr.add(node);
 						break;
 					}
 				}
 			}
 			if (!result.contains(key))
 				result.add(key);
 		}
 		
 		return result;
 	}
\ No newline at end of file
",fix for an iterator error if there is only one element in the array.,Buggy
Essentials,1458.json,4823712f47bfb7f64e22b8633b05e3f6801919c5,"@@ -1,13 +1,16 @@
 		public void onEntityDamageByEntity(final EntityDamageByEntityEvent event)
 		{
 			if (event.getCause() != DamageCause.ENTITY_ATTACK || event.getEntity().getType() != EntityType.PLAYER)
 			{
 				return;
 			}
 			final Entity damager = event.getDamager();
-			final User user = ess.getUser(damager);
-			if (user.isJailed())
+			if (damager.getType() == EntityType.PLAYER)
 			{
-				event.setCancelled(true);
+				final User user = ess.getUser(damager);
+				if (user != null && user.isJailed())
+				{
+					event.setCancelled(true);
+				}
 			}
 		}
\ No newline at end of file
","Fixing up NPE bug in jails (implemented in Dev2.9.163)
",Buggy
Essentials,832.json,67b5b4e06b5a5952d86afe241001c0f5ba589ed4,"@@ -1,4 +1,5 @@
 	private boolean isAuthor(BookMeta bmeta, String player)
 	{
-		return bmeta.getAuthor().equalsIgnoreCase(player);
+		String author = bmeta.getAuthor();
+		return author != null && author.equalsIgnoreCase(player);
 	}
\ No newline at end of file
","Fix minor /book bug (Null author)
",Buggy
wicket,4568.json,89c5acbf41b98ab890ed489bbe15a5702da4595c,"@@ -1,4 +1,4 @@
 	public IModel<T> getModel()
 	{
-		return null;
+		return model;
 	}
\ No newline at end of file
","fix small bug

git-svn-id: https://svn.apache.org/repos/asf/wicket/trunk@1159660 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
wicket,10114.json,f78f8eb142782d7931d91aec9a77037a8582f6cd,"@@ -1,5 +1,6 @@
 	public void renderHead(IHeaderResponse response)
 	{
 		super.renderHead(response);
-		response.render(CssHeaderItem.forReference(PageViewCSSResourceReference.get()));
+		response.render(
+			CssHeaderItem.forReference(new CssResourceReference(PageView.class, ""pageview.css"")));
 	}
\ No newline at end of file
","WICKET-6737: fixed compilation error after deleting class
",Buggy
wicket,7162.json,8c62ff32ea564e1efb3b9fc84b75fe783508732e,"@@ -1,39 +1,41 @@
 	public boolean equalTo(final MarkupStream that)
 	{
 		// While a has more markup elements
 		while (this.hasMore())
 		{
 			// Get an element from each
-			final MarkupElement thisElement = this.next();
-			final MarkupElement thatElement = that.next();
+			final MarkupElement thisElement = this.get();
+			final MarkupElement thatElement = that.get();
 			
 			// and if the elements are not equal
 			if (thisElement != null && thatElement != null)
 			{
 				if (!thisElement.equalTo(thatElement))
 				{
 					// fail the comparison
 					return false;
 				}
 			}
 			else
 			{
 				// If one element is null,
 				if (!(thisElement == null && thatElement == null))
 				{
 					// fail the comparison
 					return false;
 				}
 			}
+			this.next();
+			that.next();
 		}
 
 		// If we've run out of markup elements in b
 		if (!that.hasMore())
 		{
 			// then the two streams match perfectly
 			return true;
 		}
 
 		// Stream b had extra elements
 		return false;
 	}
\ No newline at end of file
","fixed error in DiffUtil (MarkupStream.equalsTo). It failed to compare markup streams with just one MarkupElement.

git-svn-id: https://svn.apache.org/repos/asf/incubator/wicket/trunk@552187 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
wicket,2888.json,e72ed7e22a7d002070ffe4a1d3e7daf514351c20,"@@ -1,14 +1,19 @@
 	public Serializable getCacheKey()
 	{
 		Class<?> scope = getScope();
 		String currentStyle = getCurrentStyle();
 		Locale currentLocale = getCurrentLocale();
 		
+		 IResourceStream packageResource = Application.get()
+			.getResourceSettings()
+			.getResourceStreamLocator()
+			.locate(scope, absolutePath, currentStyle, variation, currentLocale, null, false);
+		 
 		// if resource stream can not be found do not cache
-		if (exists(scope, absolutePath, currentLocale, currentStyle, variation))
+		if (packageResource != null)
 		{
 			return new CacheKey(scopeName, absolutePath, currentLocale, currentStyle, variation);
 		}
 
 		return null;
 	}
\ No newline at end of file
","WICKET-6061 improved getChacheKey to fix problems with absolute path of package resources
",Buggy
wicket,6423.json,835db0bf267a6c1b713f9801237c68cba043e9af,"@@ -1,5 +1,15 @@
 	public Border remove(final Component component)
 	{
-		getBodyContainer().remove(component);
+		if (component == body)
+		{
+			// when the user calls foo.add(getBodyContainer()) this method will be called with it to
+			// clear body container's old parent, in which case we do not want to redirect to body
+			// container but to border's old remove.
+			super.remove(body);
+		}
+		else
+		{
+			getBodyContainer().remove(component);
+		}
 		return this;
 	}
\ No newline at end of file
","fixes a bug where border's getbodycontainer is left as a child of border even if it was added to another container
",Buggy
wicket,9455.json,7480012fafc537e405b6c0a624c1b76f39d56f41,"@@ -1,29 +1,29 @@
 	public static Number getMinValue(Class<? extends Number> numberType)
 	{
 		Number result;
 		if (Integer.class == numberType || int.class == numberType)
 		{
 			result = Integer.MIN_VALUE;
 		}
 		else if (Long.class == numberType || long.class == numberType) {
 			result = Long.MIN_VALUE;
 		}
 		else if (Float.class == numberType || float.class == numberType) {
 			result = Float.MIN_VALUE;
 		}
 		else if (Double.class == numberType || double.class == numberType) {
 			result = Double.MIN_VALUE;
 		}
 		else if (Byte.class == numberType || byte.class == numberType) {
 			result = Byte.MIN_VALUE;
 		}
 		else if (Short.class == numberType || short.class == numberType) {
 			result = Short.MIN_VALUE;
 		}
 		else { // null of any other Number
-			LOG.debug(""'{}' has no maximum value. Falling back to Double.MIN_VALUE."", numberType);
+			LOG.debug(""'{}' has no minimum value. Falling back to Double.MIN_VALUE."", numberType);
 			result = Double.MIN_VALUE;
 		}
 
 		return result;
 	}
\ No newline at end of file
","Fix a copy/paste error
",Buggy
vraptor4,95.json,d57d1be4185c180ec3a99dab938a0cfaec66516c,"@@ -1,33 +1,33 @@
 	public <T> T forwardTo(final Class<T> type) {
 		return proxifier.proxify(type, new MethodInvocation<T>() {
 
 			@Override
 			public Object intercept(T proxy, Method method, Object[] args, SuperMethod superMethod) {
 				try {
 					logger.debug(""Executing {}"", method);
 					ControllerMethod old = methodInfo.getControllerMethod();
 					methodInfo.setControllerMethod(DefaultControllerMethod.instanceFor(type, method));
 					Object methodResult = method.invoke(container.instanceFor(type), args);
 					methodInfo.setControllerMethod(old);
 
 					Type returnType = method.getGenericReturnType();
 					if (!(returnType == void.class)) {
 						request.setAttribute(extractor.nameFor(returnType), methodResult);
 					}
-					if (response.isCommitted() || result.used()) {
+					if (response.isCommitted()) {
 						logger.debug(""Response already commited, not forwarding."");
 						return null;
 					}
 					String path = resolver.pathFor(DefaultControllerMethod.instanceFor(type, method));
 					logger.debug(""Forwarding to {}"", path);
 					request.getRequestDispatcher(path).forward(request, response);
 					return null;
 				} catch (InvocationTargetException e) {
 					propagateIfPossible(e.getCause());
 					throw new ProxyInvocationException(e);
 				} catch (Exception e) {
 					throw new ProxyInvocationException(e);
 				}
 			}
 		});
 	}
\ No newline at end of file
","Fixing problem with forward.
",Buggy
vraptor4,1079.json,cff51ec6e04f0bcb011c05510d72b8c4c22b1b66,"@@ -1,4 +1,13 @@
 	public <T extends View> T use(Class<T> view) {
+		if(view.isAssignableFrom(Results.json()) && validator.hasErrors()) {
+	        throw new IllegalStateException(
+	                ""There are validation errors and you forgot to specify where to go. Please add in your method ""
+	                        + ""something like:\n""
+	                        + ""validator.onErrorUse(page()).of(AnyController.class).anyMethod();\n""
+	                        + ""or any view that you like.\n""
+	                        + ""If you didn't add any validation error, it is possible that a conversion error had happened."");
+	    }
+		
 		responseCommitted = true;
 		return container.instanceFor(view);
 	}
\ No newline at end of file
","Fixing problem: validation ignored on redirects.
",Buggy
flink,4079.json,1863bb88e4f2388a2f91b8000bcb3ca1e44d352b,"@@ -1,9 +1,8 @@
 	static SupplierWithException<BufferPool, IOException> createBufferPoolFactory(
 			BufferPoolFactory bufferPoolFactory,
 			int networkBuffersPerChannel,
 			int floatingNetworkBuffersPerGate,
 			int size,
 			ResultPartitionType type) {
-		int maxNumberOfMemorySegments = type.isBounded() ? floatingNetworkBuffersPerGate : Integer.MAX_VALUE;
-		return () -> bufferPoolFactory.createBufferPool(0, maxNumberOfMemorySegments);
+		return () -> bufferPoolFactory.createBufferPool(0, floatingNetworkBuffersPerGate);
 	}
\ No newline at end of file
","[FLINK-14872][runtime] Temporary fix for potential deadlock problem when tasks read from blocking ResultPartitions. (#10472)

This commit implements a temporary fix for the potential deadlock problem reported in FLINK-14872. The problem itself is not solved completely, however the possibility of deadlock is largely reduced. We leave the proper fix of this problem to the future version.",Buggy
flink,18562.json,d8c74d20970e6cf379165ffafe8550a5b98d7c4d,"@@ -1,16 +1,19 @@
 		public boolean equals(final Object obj) {
+			if (obj == this) {
+				return true;
+			}
 
 			if (obj instanceof FSKey) {
 				final FSKey key = (FSKey) obj;
 
 				if (!this.scheme.equals(key.scheme)) {
 					return false;
 				}
 
 				if ((this.authority == null) || (key.authority == null)) {
 					return this.authority == null && key.authority == null;
 				}
 				return this.authority.equals(key.authority);
 			}
 			return false;
 		}
\ No newline at end of file
","[FLINK-1766]Fix the bug of equals function of FSKey

The equals function in org.apache.flink.core.fs.FileSystem.FSKey should first confirm whether obj == this, if obj is the same object.It should return true

Author: hongsibao <hongsibao@huawei.com>

Closes #511 from matadorhong/Bug_Flink_1776 and squashes the following commits:

1ad06d7 [hongsibao] Fix the code format problem
431fc4b [hongsibao] Fix the code format problem
ab0ae5e [hongsibao] [FLINK-1766]Fix the bug of equals function of FSKey
",Buggy
flink,2817.json,cbfb807d65b68b2b6157e1b1d42606123ea499ad,"@@ -1,8 +1,7 @@
 	public void stop() throws Exception {
 		LOG.info(""Stopping ZooKeeperLeaderRetrievalService."");
 
 		client.getConnectionStateListenable().removeListener(connectionStateListener);
 
 		cache.close();
-		client.close();
 	}
\ No newline at end of file
","[FLINK-5190] [runtime] fix ZooKeeperLeaderRetrievalService close the zk client when stopping bug
",Buggy
flink,43722.json,f0ed58c6a580db0966104b81491d08d25d1ff57e,"@@ -1,32 +1,33 @@
 		public void reduce(Iterable<T> records, Collector<T> out) {
 			final AggregationFunction<Object>[] aggFunctions = this.aggFunctions;
 			final int[] fieldPositions = this.fieldPositions;
 
 			// aggregators are initialized from before
 
 			T current = null;
 			final Iterator<T> values = records.iterator();
 			while (values.hasNext()) {
 				current = values.next();
 
 				for (int i = 0; i < fieldPositions.length; i++) {
 					Object val = current.productElement(fieldPositions[i]);
 					aggFunctions[i].aggregate(val);
 				}
 			}
 
 			Object[] fields = new Object[serializer.getArity()];
+			int length = serializer.getArity();
 			// First copy all tuple fields, then overwrite the aggregated ones
-			for (int i = 0; i < fieldPositions.length; i++) {
-				fields[0] = current.productElement(i);
+			for (int i = 0; i < length; i++) {
+				fields[i] = current.productElement(i);
 			}
 			for (int i = 0; i < fieldPositions.length; i++) {
 				Object aggVal = aggFunctions[i].getAggregate();
 				fields[fieldPositions[i]] = aggVal;
 				aggFunctions[i].initializeAggregate();
 			}
 
 			T result = serializer.createInstance(fields);
 
 			out.collect(result);
 		}
\ No newline at end of file
","Fix Bug in ScalaAggregate Operator and add ITCase
",Buggy
flink,25849.json,0081fb2ef2bd03d06a786dd8988865d2ff6168c2,"@@ -1,5 +1,5 @@
 		public void combine(Iterable<Tuple3<K1, K2, IN>> values, Collector<Tuple3<K1, K2, IN>> out) throws Exception {
 			iter.set(values.iterator());
 			coll.set(out);
-			this.wrappedFunction.combine(iter, coll);
+			((GroupCombineFunction)this.wrappedFunction).combine(iter, coll);
 		}
\ No newline at end of file
","[FLINK-2135] Fix faulty cast to GroupReduceFunction

This closes #769
",Buggy
flink,17423.json,6624562982c9d57bebba8cb4b574b8ed28640a0d,"@@ -1,15 +1,17 @@
 	public static DeweyNumber fromString(final String deweyNumberString) {
 		String[] splits = deweyNumberString.split(""\\."");
 
-		if (splits.length == 0) {
+		if (splits.length == 1) {
 			return new DeweyNumber(Integer.parseInt(deweyNumberString));
-		} else {
+		} else if (splits.length > 0) {
 			int[] deweyNumber = new int[splits.length];
 
 			for (int i = 0; i < splits.length; i++) {
 				deweyNumber[i] = Integer.parseInt(splits[i]);
 			}
 
 			return new DeweyNumber(deweyNumber);
+		} else {
+			throw new IllegalArgumentException(""Failed to parse "" + deweyNumberString + "" as a Dewey number"");
 		}
 	}
\ No newline at end of file
","[FLINK-13043] [Library / CEP] Fix the bug of parsing Dewey number from string

This closes #8936
",Buggy
flink,18090.json,624cb64a462765419bb0f81e2a50b3cec1c877f6,"@@ -1,25 +1,22 @@
 	public void copyNormalizedKey(MemorySegment target, int offset, int len) {
+		// note that the char is an unsigned data type in java and consequently needs
+		// no code that transforms the signed representation to an offsetted representation
+		// that is equivalent to unsigned, when compared byte by byte
 		if (len == 2) {
 			// default case, full normalized key
-			int highByte = ((value >>> 8) & 0xff);
-			highByte -= Byte.MIN_VALUE;
-			target.put(offset, (byte) highByte);
-			target.put(offset + 1, (byte) ((value) & 0xff));
+			target.put(offset,     (byte) ((value >>> 8) & 0xff));
+			target.put(offset + 1, (byte) ((value      ) & 0xff));
 		}
 		else if (len <= 0) {
 		}
 		else if (len == 1) {
-			int highByte = ((value >>> 8) & 0xff);
-			highByte -= Byte.MIN_VALUE;
-			target.put(offset, (byte) highByte);
+			target.put(offset,     (byte) ((value >>> 8) & 0xff));
 		}
 		else {
-			int highByte = ((value >>> 8) & 0xff);
-			highByte -= Byte.MIN_VALUE;
-			target.put(offset, (byte) highByte);
-			target.put(offset + 1, (byte) ((value) & 0xff));
+			target.put(offset,     (byte) ((value >>> 8) & 0xff));
+			target.put(offset + 1, (byte) ((value      ) & 0xff));
 			for (int i = 2; i < len; i++) {
 				target.put(offset + i, (byte) 0);
 			}
 		}
 	}
\ No newline at end of file
","Fixed erroneous normalized key generation in PactCharacter.
",Buggy
flink,18559.json,f04b32b02900181db82c6c518ffbd6430a0a369a,"@@ -1,40 +1,40 @@
 	private static HashMap<String, FileSystemFactory> loadFileSystems() {
 		final HashMap<String, FileSystemFactory> map = new HashMap<>();
 
 		// by default, we always have the local file system factory
 		map.put(""file"", new LocalFileSystemFactory());
 
 		LOG.debug(""Loading extension file systems via services"");
 
 		try {
 			ServiceLoader<FileSystemFactory> serviceLoader = ServiceLoader.load(FileSystemFactory.class);
 			Iterator<FileSystemFactory> iter = serviceLoader.iterator();
 
 			// we explicitly use an iterator here (rather than for-each) because that way
 			// we can catch errors in individual service instantiations
 
 			//noinspection WhileLoopReplaceableByForEach
 			while (iter.hasNext()) {
 				try {
 					FileSystemFactory factory = iter.next();
 					String scheme = factory.getScheme();
 					map.put(scheme, factory);
 					LOG.debug(""Added file system {}:{}"", scheme, factory.getClass().getName());
 				}
 				catch (Throwable t) {
 					// catching Throwable here to handle various forms of class loading
 					// and initialization errors
 					ExceptionUtils.rethrowIfFatalErrorOrOOM(t);
-					LOG.error(""Failed to load a file systems via services"", t);
+					LOG.error(""Failed to load a file system via services"", t);
 				}
 			}
 		}
 		catch (Throwable t) {
 			// catching Throwable here to handle various forms of class loading
 			// and initialization errors
 			ExceptionUtils.rethrowIfFatalErrorOrOOM(t);
 			LOG.error(""Failed to load additional file systems via services"", t);
 		}
 
 		return map;
 	}
\ No newline at end of file
","[hotfix] [core] Fix lots of checkstyle errors in core.fs
",Buggy
flink,11393.json,84b39dcb50167368d45882a88842760237fa3560,"@@ -1,19 +1,23 @@
 	public static String getUserRunning() {
 		try {
 			return UserGroupInformation.getCurrentUser().getShortUserName();
 		}
+		catch (LinkageError e) {
+			// hadoop classes are not in the classpath
+			LOG.debug(""Cannot determine user/group information using Hadoop utils. "" +
+					""Hadoop classes not loaded or compatible"", e);
+		}
 		catch (Throwable t) {
-			if (LOG.isDebugEnabled() && !(t instanceof ClassNotFoundException)) {
-				LOG.debug(""Cannot determine user/group information using Hadoop utils."", t);
-			}
+			// some other error occurred that we should log and make known
+			LOG.warn(""Error while accessing user/group information via Hadoop utils."", t);
 		}
 		
 		String user = System.getProperty(""user.name"");
 		if (user == null) {
 			user = UNKNOWN;
 			if (LOG.isDebugEnabled()) {
 				LOG.debug(""Cannot determine user/group information for the current user."");
 			}
 		}
 		return user;
 	}
\ No newline at end of file
","[hotfix] Fix error messages in EnvironmentInformation when accessing user information
",Buggy
flink,11393.json,e45534cf2275f6918294c81de5377146c243904c,"@@ -1,12 +1,19 @@
 	public static String getUserRunning() {
 		try {
 			return UserGroupInformation.getCurrentUser().getShortUserName();
-		} catch (Throwable t) {
-			if (LOG.isDebugEnabled()) {
-				LOG.debug(""Cannot determine user/group information for the current user."", t);
-			} else {
-				LOG.info(""Cannot determine user/group information for the current user."");
-			}
-			return UNKNOWN;
 		}
+		catch (Throwable t) {
+			if (LOG.isDebugEnabled() && !(t instanceof ClassNotFoundException)) {
+				LOG.debug(""Cannot determine user/group information using Hadoop utils."", t);
+			}
+		}
+		
+		String user = System.getProperty(""user.name"");
+		if (user == null) {
+			user = UNKNOWN;
+			if (LOG.isDebugEnabled()) {
+				LOG.debug(""Cannot determine user/group information for the current user."");
+			}
+		}
+		return user;
 	}
\ No newline at end of file
","Fix problems with missing files/dependencies with cdh-4 distribution.
",Buggy
flink,3887.json,4d693c4fbc5e6f3ff34ccb3cb3a1d9f35d6bbd76,"@@ -1,25 +1,27 @@
 	private void writeAndCloseBufferConsumer(BufferConsumer bufferConsumer) throws IOException {
 		try {
 			final Buffer buffer = bufferConsumer.build();
 			try {
 				if (canBeCompressed(buffer)) {
 					final Buffer compressedBuffer = parent.bufferCompressor.compressToIntermediateBuffer(buffer);
 					data.writeBuffer(compressedBuffer);
-					compressedBuffer.recycleBuffer();
+					if (compressedBuffer != buffer) {
+						compressedBuffer.recycleBuffer();
+					}
 				} else {
 					data.writeBuffer(buffer);
 				}
 
 				numBuffersAndEventsWritten++;
 				if (buffer.isBuffer()) {
 					numDataBuffersWritten++;
 				}
 			}
 			finally {
 				buffer.recycleBuffer();
 			}
 		}
 		finally {
 			bufferConsumer.close();
 		}
 	}
\ No newline at end of file
","[FLINK-15166][runtime] Fix the bug of wrongly recycling uncompressed buffer

For blocking shuffle data compression, the compressed intermediate buffer is recycled after it is written out. However when the data can not be compressed, the returned buffer is the original buffer which should not be recycled.

This commit fixes the bug of wrongly recycling uncompressed buffer by comparing the returned buffer with the original buffer.",Buggy
flink,18028.json,0f28095f9f79b49d45905e61709ff4fab6fedd54,"@@ -1,8 +1,8 @@
 	public Appendable append(CharSequence csq, int start, int end) {
 		final int otherLen = end - start;
 		grow(this.len + otherLen);
-		for (int pos = start; pos < len; pos++)
+		for (int pos = start; pos < end; pos++)
 			this.value[this.len + pos] = csq.charAt(pos);
 		this.len += otherLen;
 		return this;
 	}
\ No newline at end of file
","Fixed bug in PactString append.
",Buggy
flink,40862.json,6cf15c29b1bf3bb3ddcf69157079f9e5b185d9c8,"@@ -1,5 +1,4 @@
 	public SingleOutputStreamOperator<OUT, ?> reduce(ReduceFunction<OUT> reducer) {
 		return dataStream.addFunction(""groupReduce"", reducer, getTypeWrapper(reducer),
-				getTypeWrapper(reducer), new GroupReduceInvokable<OUT>(reducer, keyPosition))
-				.partitionBy(keyPosition);
+				getTypeWrapper(reducer), new GroupReduceInvokable<OUT>(reducer, keyPosition));
 	}
\ No newline at end of file
","[streaming] Minor bug and license header fixes
",Buggy
flink,18045.json,6e9b2848d5fabace5c6ef491c87c562eed9b5f43,"@@ -1,27 +1,26 @@
 	public void copy(DataInputView in, DataOutputView target) throws IOException {
 		int len = in.readUnsignedByte();
 		target.writeByte(len);
 
 		if (len >= HIGH_BIT) {
 			int shift = 7;
 			int curr;
 			len = len & 0x7f;
 			while ((curr = in.readUnsignedByte()) >= HIGH_BIT) {
 				len |= (curr & 0x7f) << shift;
 				shift += 7;
 				target.writeByte(curr);
 			}
 			len |= curr << shift;
+			target.writeByte(curr);
 		}
 
 		for (int i = 0; i < len; i++) {
 			int c = in.readUnsignedByte();
 			target.writeByte(c);
-			if (c >= HIGH_BIT) {
-				int curr;
-				while ((curr = in.readUnsignedByte()) >= HIGH_BIT) {
-					target.writeByte(curr);
-				}
+			while (c >= HIGH_BIT) {
+				c = in.readUnsignedByte();
+				target.writeByte(c);
 			}
 		}
 	}
\ No newline at end of file
","[FLINK-1336] [core] Fix bug in StringValue binary copy method
",Buggy
flink,26584.json,32440227eceb122008906878136156ffa839efa6,"@@ -1,3 +1,4 @@
 	public String toString() {
-		return ""Local Environment (DOP = "" + (getDegreeOfParallelism() == -1 ? ""default"" : getDegreeOfParallelism()) + "") : "" + getIdString();
+		return ""Local Environment (DOP = "" + (getDegreeOfParallelism() == -1 ? ""default"" : getDegreeOfParallelism())
+				+ ""Number task manager = "" + getNumTaskManager() + "") : "" + getIdString();
 	}
\ No newline at end of file
","Fixed free memory calculation bug in case where multiple task manager run on the same jvm.
",Buggy
flink,19363.json,7e10e2b7ba967332740e1058efa7310fe2834123,"@@ -1,22 +1,24 @@
 	public String toString()
 	{
 		if (this.indexes.size() == 0) {
 			return ""(none)"";
 		}
 		final StringBuffer buf = new StringBuffer();
 		for (int i = 0; i < indexes.size(); i++) {
 			if (buf.length() == 0) {
 				buf.append(""["");
 			}
 			else {
 				buf.append("","");
 			}
 			buf.append(this.indexes.get(i));
-			buf.append("":"");
-			buf.append(this.types.get(i).getName());
+			if (this.types.get(i) != null) {
+				buf.append("":"");
+				buf.append(this.types.get(i).getName());
+			}
 			buf.append("":"");
 			buf.append(this.orders.get(i).name());
 		}
 		buf.append(""]"");
 		return buf.toString();
 	}
\ No newline at end of file
","Fixed miscellaneous minor bugs in compiler.
",Buggy
flink,4441.json,81a7837a942668c23c795e5bd8a68c4d17009f85,"@@ -1,32 +1,35 @@
 	public void close() throws IOException {
 		// atomically set the close flag
 		synchronized (this.closeLock) {
 			if (this.closed) {
 				return;
 			}
 			this.closed = true;
 			
 			try {
 				// wait until as many buffers have been returned as were written
 				// only then is everything guaranteed to be consistent.
 				while (this.requestsNotReturned.get() > 0) {
 					try {
 						// we add a timeout here, because it is not guaranteed that the
 						// decrementing during buffer return and the check here are deadlock free.
 						// the deadlock situation is however unlikely and caught by the timeout
 						this.closeLock.wait(1000);
 						checkErroneous();
 					}
 					catch (InterruptedException iex) {
 						throw new IOException(""Closing of asynchronous file channel was interrupted."");
 					}
 				}
+
+				// Additional check because we might have skipped the while loop
+				checkErroneous();
 			}
 			finally {
 				// close the file
 				if (this.fileChannel.isOpen()) {
 					this.fileChannel.close();
 				}
 			}
 		}
 	}
\ No newline at end of file
","[FLINK-1545] [runtime][tests] Fixes AsynchronousFileIOChannelsTest.testExceptionForwardsToClose by introducing additional error check in AsynchronousFileIOChannel.close method

This closes #399
",Buggy
flink,25651.json,ce822bf7f5ec80df5d5a749b1439320af3fb8b18,"@@ -1,4 +1,7 @@
 	public <R> DeltaIteration<T, R> iterateDelta(DataSet<R> workset, int maxIterations, int... keyPositions) {
+		Preconditions.checkNotNull(workset);
+		Preconditions.checkNotNull(keyPositions);
+		
 		Keys.ExpressionKeys<T> keys = new Keys.ExpressionKeys<T>(keyPositions, getType(), false);
 		return new DeltaIteration<T, R>(getExecutionEnvironment(), getType(), this, workset, keys, maxIterations);
 	}
\ No newline at end of file
","[FLINK-1254] [compiler] Fix compiler bug for pipeline breaker placement

This closes #216
",Buggy
flink,18032.json,1bfeeaead158051cb5f78f403c4878fc89596cc8,"@@ -1,23 +1,21 @@
 	public void write(final DataOutput out) throws IOException {
 		final int maxBit = 0x1 << 7;
 
 		int len = this.value.length();
 
 		while (len >= maxBit) {
 			out.write(len | maxBit);
 			len >>= 7;
 		}
 		out.write(len);
 
 		for (int i = 0; i < this.value.length(); i++) {
 			int c = this.value.charAt(i);
 
-			if (c < maxBit)
-				out.write(c);
-			else
-				while (c >= maxBit) {
-					out.write(c | maxBit);
-					c >>= 7;
-				}
+			while (c >= maxBit) {
+				out.write(c | maxBit);
+				c >>= 7;
+			}
+			out.write(c);
 		}
 	}
\ No newline at end of file
","Fixed Serialization Bug in PactString
",Buggy
flink,22768.json,3854552ceefd2b2b9c0e2a9b6152a7fcb69153fe,"@@ -1,26 +1,32 @@
 	public static String unresolvedHostToNormalizedString(String host) {
 		// Return loopback interface address if host is null
 		// This represents the behavior of {@code InetAddress.getByName } and RFC 3330
 		if (host == null) {
 			host = InetAddress.getLoopbackAddress().getHostAddress();
 		} else {
 			host = host.trim().toLowerCase();
+			if (host.startsWith(""["") && host.endsWith(""]"")) {
+				String address = host.substring(1, host.length() - 1);
+				if (IPAddressUtil.isIPv6LiteralAddress(address)) {
+					host = address;
+				}
+			}
 		}
 
 		// normalize and valid address
 		if (IPAddressUtil.isIPv6LiteralAddress(host)) {
 			byte[] ipV6Address = IPAddressUtil.textToNumericFormatV6(host);
 			host = getIPv6UrlRepresentation(ipV6Address);
 		} else if (!IPAddressUtil.isIPv4LiteralAddress(host)) {
 			try {
 				// We don't allow these in hostnames
 				Preconditions.checkArgument(!host.startsWith("".""));
 				Preconditions.checkArgument(!host.endsWith("".""));
 				Preconditions.checkArgument(!host.contains("":""));
 			} catch (Exception e) {
 				throw new IllegalConfigurationException(""The configured hostname is not valid"", e);
 			}
 		}
 
 		return host;
 	}
\ No newline at end of file
","[FLINK-12840] [core] Fix network utils to work with ipv6 correctly

  - Fixes problems around akka configuration parsing with some IPv6 literals
  - Fixes an issue with address parsing and validation with some Ipv6 literals

This closes #8734
",Buggy
flink,28054.json,6e5954e8a03ad5d440447a57098976b0250f4f72,"@@ -1,43 +1,45 @@
 	private RexNode convertOver(List<Expression> children) {
 		List<Expression> args = children;
 		Expression agg = args.get(0);
 		SqlAggFunction aggFunc = agg.accept(new SqlAggFunctionVisitor(typeFactory));
 		RelDataType aggResultType = typeFactory.createFieldTypeFromLogicalType(
 				fromDataTypeToLogicalType(((ResolvedExpression) agg).getOutputDataType()));
 
 		// assemble exprs by agg children
 		List<RexNode> aggExprs = agg.getChildren().stream().map(expr -> expr.accept(this))
 				.collect(Collectors.toList());
 
 		// assemble order by key
 		Expression orderKeyExpr = args.get(1);
 		Set<SqlKind> kinds = new HashSet<>();
 		RexNode collationRexNode = createCollation(orderKeyExpr.accept(this), RelFieldCollation.Direction.ASCENDING,
 				null, kinds);
 		ImmutableList<RexFieldCollation> orderKey = ImmutableList
 				.of(new RexFieldCollation(collationRexNode, kinds));
 
 		// assemble partition by keys
 		List<RexNode> partitionKeys = args.subList(4, args.size()).stream().map(expr -> expr.accept(this))
 				.collect(Collectors.toList());
 		// assemble bounds
 		Expression preceding = args.get(2);
-		boolean isPhysical = ((ResolvedExpression) preceding).getOutputDataType().equals(DataTypes.BIGINT());
+		boolean isPhysical = LogicalTypeChecks.hasRoot(
+				fromDataTypeToLogicalType(((ResolvedExpression) preceding).getOutputDataType()),
+				LogicalTypeRoot.BIGINT);
 		Expression following = args.get(3);
 		RexWindowBound lowerBound = createBound(preceding, SqlKind.PRECEDING);
 		RexWindowBound upperBound = createBound(following, SqlKind.FOLLOWING);
 
 		// build RexOver
 		return relBuilder.getRexBuilder().makeOver(
 				aggResultType,
 				aggFunc,
 				aggExprs,
 				partitionKeys,
 				orderKey,
 				lowerBound,
 				upperBound,
 				isPhysical,
 				true,
 				false,
 				false);
 	}
\ No newline at end of file
","[FLINK-13107][table-planner-blink] Fix Bug to check whether OverCall is RowMode or RangeMode.
",Buggy
flink,22909.json,b01641bcc13631b0db82c54143670613babb7c0c,"@@ -1,79 +1,79 @@
 	public NumberSequenceIterator[] split(int numPartitions) {
 		if (numPartitions < 1) {
 			throw new IllegalArgumentException(""The number of partitions must be at least 1."");
 		}
 		
 		if (numPartitions == 1) {
 			return new NumberSequenceIterator[] { new NumberSequenceIterator(current, to) };
 		}
 		
 		// here, numPartitions >= 2 !!!
 		
 		long elementsPerSplit;
 		
-		if (to - current >= 0) {
-			elementsPerSplit = (to - current) / numPartitions;
+		if (to - current + 1 >= 0) {
+			elementsPerSplit = (to - current + 1) / numPartitions;
 		}
 		else {
 			// long overflow of the range.
 			// we compute based on half the distance, to prevent the overflow.
 			// in most cases it holds that: current < 0 and to > 0, except for: to == 0 and current == Long.MIN_VALUE
 			// the later needs a special case
 			final long halfDiff; // must be positive
 			
 			if (current == Long.MIN_VALUE) {
 				// this means to >= 0
 				halfDiff = (Long.MAX_VALUE/2+1) + to/2;
 			} else {
 				long posFrom = -current;
 				if (posFrom > to) {
 					halfDiff = to + ((posFrom - to) / 2);
 				} else {
 					halfDiff = posFrom + ((to - posFrom) / 2);
 				}
 			}
 			elementsPerSplit = halfDiff / numPartitions * 2;
 		}
 		
 		if (elementsPerSplit < Long.MAX_VALUE) {
 			// figure out how many get one in addition
-			long numWithExtra = -(elementsPerSplit * numPartitions) + to - current;
+			long numWithExtra = -(elementsPerSplit * numPartitions) + to - current + 1;
 			
 			// based on rounding errors, we may have lost one)
 			if (numWithExtra > numPartitions) {
 				elementsPerSplit++;
 				numWithExtra -= numPartitions;
 				
 				if (numWithExtra > numPartitions) {
 					throw new RuntimeException(""Bug in splitting logic. To much rounding loss."");
 				}
 			}
 			
 			NumberSequenceIterator[] iters = new NumberSequenceIterator[numPartitions];
 			long curr = current;
 			int i = 0;
 			for (; i < numWithExtra; i++) {
 				long next = curr + elementsPerSplit + 1;
-				iters[i] = new NumberSequenceIterator(curr, next);
+				iters[i] = new NumberSequenceIterator(curr, next-1);
 				curr = next;
 			}
 			for (; i < numPartitions; i++) {
 				long next = curr + elementsPerSplit;
-				iters[i] = new NumberSequenceIterator(curr, next);
+				iters[i] = new NumberSequenceIterator(curr, next-1, true);
 				curr = next;
 			}
 			
 			return iters;
 		}
 		else {
 			// this can only be the case when there are two partitions
 			if (numPartitions != 2) {
 				throw new RuntimeException(""Bug in splitting logic."");
 			}
 			
 			return new NumberSequenceIterator[] {
 				new NumberSequenceIterator(current, current + elementsPerSplit),
 				new NumberSequenceIterator(current + elementsPerSplit, to)
 			};
 		}
 	}
\ No newline at end of file
","Fixed bug in splitting logic of number sequence iterator.
",Buggy
flink,36898.json,6dcf74f022f4a127260b0e8d52b772fb28fa2249,"@@ -1,5 +1,10 @@
 	public void setCosts(Costs nodeCosts) {
-		// do not account for any cost, regardless of what the estimator
-		// calculates for our shipping strategies
-		super.setCosts(new Costs());
+		// the plan enumeration logic works as for regular two-input-operators, which is important
+		// because of the branch handling logic. it does pick redistributing network channels
+		// between the sink and the sink joiner, because sinks joiner has a different DOP than the sink.
+		// we discard any cost and simply use the sum of the costs from the two children.
+		
+		Costs totalCosts = getInput1().getSource().getCumulativeCosts().clone();
+		totalCosts.addCosts(getInput2().getSource().getCumulativeCosts());
+		super.setCosts(totalCosts);
 	}
\ No newline at end of file
","Fixed erroneous costs handling in sink joiner.
",Buggy
flink,9963.json,750325e74c1cd91006b251f18f3ed8acf90c2a91,"@@ -1,3 +1,8 @@
 		public void jobLeaderLostLeadership(final JobID jobId, final UUID oldJobLeaderId) {
-			ResourceManager.this.jobLeaderLostLeadership(jobId, oldJobLeaderId);
+			runAsync(new Runnable() {
+				@Override
+				public void run() {
+					ResourceManager.this.jobLeaderLostLeadership(jobId, oldJobLeaderId);
+				}
+			});
 		}
\ No newline at end of file
","[FLINK-5893] [RM] Fix the bug of race condition for removing previous JobManagerRegistration in ResourceManager

This closes #3399.
",Buggy
flink,14028.json,0f88c392b6ad6f91aed33e157bdc9df6f613f09d,"@@ -1,3 +1,3 @@
 	public TableSource<Row> projectFields(int[] fields) {
-		return new ParquetTableSource(path, parquetSchema, parquetConfig, recursiveEnumeration, fields, null);
+		return new ParquetTableSource(path, parquetSchema, parquetConfig, recursiveEnumeration, fields, predicate);
 	}
\ No newline at end of file
","[FLINK-15361][parquet] ParquetTableSource should pass predicate in projectFields

fix the problem, when after projectFields, ParquetTableSource will loose predicates.

this closes #10660.
",Buggy
flink,27787.json,37f67b7d394ccb3355ebc995af1c3fee04ce060f,"@@ -1,8 +1,8 @@
 	public Expression[] accumulateExpressions() {
 		Expression[] accExpressions = new Expression[1 + operands().length];
-		// sequence = if (lastValues equalTo orderKeys) sequence else sequence + 1
-		accExpressions[0] = ifThenElse(orderKeyEqualsExpression(), sequence, plus(sequence, literal(1L)));
+		// sequence = if (lastValues equalTo orderKeys and sequence != 0) sequence else sequence + 1
+		accExpressions[0] = ifThenElse(and(orderKeyEqualsExpression(), not(equalTo(sequence, literal(0L)))), sequence, plus(sequence, literal(1L)));
 		Expression[] operands = operands();
 		System.arraycopy(operands, 0, accExpressions, 1, operands.length);
 		return accExpressions;
 	}
\ No newline at end of file
","[FLINK-14053][table-planner-blink] Fix DenseRankAggFunction first row bug.

We should consider the possibility that first row's order by key is equal to the initial last value.

This closes #9966
",Buggy
flink,7316.json,c59f4836fecc4069b2cffeae8dd81e50ea5d5e73,"@@ -1,4 +1,4 @@
 	public String getDescription() {
-		return ""String value that specifies the termination mode. Supported values are: "" +
-			StringUtils.toQuotedListString(TerminationMode.values()) + '.';
+		return ""String value that specifies the termination mode. The only supported value is: \"""" +
+			TerminationMode.CANCEL.name().toLowerCase() + ""\""."";
 	}
\ No newline at end of file
","[FLINK-13136][docs] Fix documentation error about stopping job with restful api

This closes #9013.
",Buggy
flink,13283.json,2cb7bb96001f9780a27a880245382958448151c4,"@@ -1,3 +1,5 @@
 	public void setItemCount(long itemCount) throws IOException {
-		writeVarLongCount(out, itemCount);
+		if (itemCount > 0) {
+			writeVarLongCount(out, itemCount);
+		}
 	}
\ No newline at end of file
","Fix bug in avro serialization for empty collections.
Add additional test for avro.
",Buggy
flink,34466.json,a86bce5a176144e06d0120b804f3af986c325ebf,"@@ -1,18 +1,18 @@
 	private static int getMillis(String dateStr) {
 		int length = dateStr.length();
 		if (length == 19) {
 			// ""1999-12-31 12:34:56"", no milli second left
 			return 0;
 		} else if (length == 21) {
 			// ""1999-12-31 12:34:56.7"", return 7
 			return Integer.parseInt(dateStr.substring(20)) * 100;
 		} else if (length == 22) {
 			// ""1999-12-31 12:34:56.78"", return 78
 			return Integer.parseInt(dateStr.substring(20)) * 10;
 		} else if (length >= 23 && length <= 26) {
 			// ""1999-12-31 12:34:56.123"" ~ ""1999-12-31 12:34:56.123456""
-			return Integer.parseInt(dateStr.substring(20, 23)) * 10;
+			return Integer.parseInt(dateStr.substring(20, 23));
 		} else {
 			return 0;
 		}
 	}
\ No newline at end of file
","[FLINK-12553][table-runtime-blink] Fix bug that SqlDateTimeUtils#parseToTimeMillis doesn't parse millisecond correctly

This closes #8483
",Buggy
flink,22688.json,7b6b5a2e019866bf8fdd993775eab410e22f0f5d,"@@ -1,11 +1,14 @@
 	public static Object deserializeObject(byte[] bytes, ClassLoader cl) throws IOException, ClassNotFoundException {
 		ObjectInputStream oois = null;
+		final ClassLoader old = Thread.currentThread().getContextClassLoader();
 		try {
+			Thread.currentThread().setContextClassLoader(cl);
 			oois = new ClassLoaderObjectInputStream(new ByteArrayInputStream(bytes), cl);
 			return oois.readObject();
 		} finally {
+			Thread.currentThread().setContextClassLoader(old);
 			if (oois != null) {
 				oois.close();
 			}
 		}
 	}
\ No newline at end of file
","Fixes a bug where Thread.currentThread().getContextClassLoader() does not return the user code class loader within object deserialization.
",Buggy
flink,22189.json,e28b62e0e2973b01ad5b08ce319aaf0e7ce4c087,"@@ -1,11 +1,11 @@
 	public MethodVisitor visitMethod(int access, String name, String desc, String sig, String[] exceptions) {
-		return new MethodVisitor(Opcodes.ASM4) {
+		return new MethodVisitor(Opcodes.ASM5) {
 
 			@Override
 			public void visitFieldInsn(int op, String owner, String name, String desc) {
 				if (op == Opcodes.GETFIELD && name.equals(this0Name)) {
 					isThis0Accessed = true;
 				}
 			}
 		};
 	}
\ No newline at end of file
","[FLINK-3143] update Closure Cleaner's ASM references to ASM5

- This solves errors with reflectasm using Scala 2.11 and Java 8

This closes #1445.
",Buggy
flink,36539.json,73b5b3dd81e2a146592d9623f44ceff3d8c035fa,"@@ -1,6 +1,6 @@
 	public void setDegreeOfParallelism(int degreeOfParallelism) {
 		if (degreeOfParallelism < 1) {
-			throw new IllegalArgumentException();
+			throw new IllegalArgumentException(""Degree of parallelism of "" + degreeOfParallelism + "" is invalid."");
 		}
 		this.degreeOfParallelism = degreeOfParallelism;
 	}
\ No newline at end of file
","Fix error with invalid config values for degree of parallelism.
",Buggy
flink,1954.json,f28c28643df43633439b2c99c383e1ed01319ea3,"@@ -1,9 +1,9 @@
 	public <T extends Value> Class<? extends ConvergenceCriterion<T>> getConvergenceCriterion() {
 		@SuppressWarnings(""unchecked"")
-		Class<? extends ConvergenceCriterion<T>> clazz = (Class<? extends ConvergenceCriterion<T>>) 
+		Class<? extends ConvergenceCriterion<T>> clazz = (Class<? extends ConvergenceCriterion<T>>) (Class<?>) 
 							this.config.getClass(ITERATION_CONVERGENCE_CRITERION, null, ConvergenceCriterion.class);
 		if (clazz == null) {
 			throw new NullPointerException();
 		}
 		return clazz;
 	}
\ No newline at end of file
","Fixed compiler error in maven for TaskConfig.java
",Buggy
flink,2537.json,5e498dc9e763a5daa3867456f657e19cd08fbb66,"@@ -1,13 +1,11 @@
-		private void handleCompletedFuture(T value, Throwable throwable) {
+		private void handleCompletedFuture(int index, T value, Throwable throwable) {
 			if (throwable != null) {
 				completeExceptionally(throwable);
 			} else {
-				int index = nextIndex.getAndIncrement();
-
 				results[index] = value;
 
 				if (numCompleted.incrementAndGet() == numTotal) {
 					complete(Arrays.asList(results));
 				}
 			}
 		}
\ No newline at end of file
","[FLINK-12021] Deploy execution in topological sorted order

Due to changes how the slot futures are completed and due to the fact that the
ResultConjunctFuture does not maintain the order in which the futures were specified,
it could happen that executions were not deployed in topological order. This commit
fixes this problem by changing the ResultConjunctFuture so that it maintains the order
of the specified futures in its result collection.

This closes #8060.
",Buggy
eclipseJdt,3793.json,2f6e64cbbbc83dfd41e2988704a66b1a58193e8d,"@@ -1,3 +1,3 @@
 	public boolean isTypeAccess() {
-		return false;
+		return !this.haveReceiver;
 	}
\ No newline at end of file
","Fixed Bug 424226 - [1.8] Cannot use static method from an interface in
static method reference ",Buggy
eclipseJdt,651.json,969e112c287880aaa166b5c77a56bd62cba0db4b,"@@ -1,7 +1,11 @@
 private static IJavaProject getJavaProject(IPath path, IJavaModel model) {
-	IJavaProject project = model.getJavaProject(path.lastSegment());
+	String lastSeg = path.lastSegment();
+	if (lastSeg == null) {
+		lastSeg = path.toOSString();
+	}
+	IJavaProject project = model.getJavaProject(lastSeg);
 	if (project.exists()) {
 		return project;
 	}
 	return null;
 }
\ No newline at end of file
","Fix for Bug 464339 When finding references, Java Search fails with
NullPointerException",Buggy
eclipseJdt,20760.json,5666cb170a5113b959f09f9a106548eceb94f3e9,"@@ -1,17 +1,23 @@
 	private boolean isPrimaryType(String name, IType type, boolean partialMatch) {
 		/*
 		 * Please have a look at: NameLookup#NameLookup
 		 * The HashTable this.typesInWorkingCopies contains values which are HashTables themselves.
 		 * The values of these HashTables are either of IType or IType[].
 		 * These values are types belonging to a compilation unit. Please check:
 		 * CompilationUnit#getTypes().
 		 * Therefore the parents of these types would be compilation units.
 		 */
 		ICompilationUnit cu = (ICompilationUnit) type.getParent();
 		String cuName = cu.getElementName().substring(0, cu.getElementName().lastIndexOf('.'));
+		/*
+		 * Secondary types along with primary types have their parent as the compilation unit.
+		 * The names of the primary type would match with their compilation unit.
+		 */
+		if (!cuName.equals(type.getElementName()))
+			return false;
 		if (partialMatch) {
 			return cuName.regionMatches(0, name, 0, name.length());
 		} else {
 			return cuName.equals(name);
 		}
 	}
\ No newline at end of file
","Fixed Bug 431501 - NameLookup#findType API finds secondary types with
secondaryType and partial match set

Change-Id: Iad7904647729b2f282d039856b6ecee5325ebedb
Signed-off-by: Shankha Banerjee <shankhba@in.ibm.com>
",Buggy
eclipseJdt,1127.json,fe3ac1852503ee5f3d26919dd323775bfa197648,"@@ -1,14 +1,17 @@
 public PossibleMatch[] getPossibleMatches(IPackageFragmentRoot[] roots) {
 	PossibleMatch[] result = new PossibleMatch[this.elementCount];
 	int index = 0;
+	HashSet<IPath> processedHash = new HashSet<>();
 	for (int i = 0, length = roots.length; i < length; i++) {
-		ObjectVector possibleMatches = (ObjectVector) this.rootsToPossibleMatches.get(roots[i].getPath());
-		if (possibleMatches != null) {
+		IPath path = roots[i].getPath();
+		ObjectVector possibleMatches = (ObjectVector) this.rootsToPossibleMatches.get(path);
+		if (possibleMatches != null && !processedHash.contains(path)) {
 			possibleMatches.copyInto(result, index);
 			index += possibleMatches.size();
+			processedHash.add(path);
 		}
 	}
 	if (index < this.elementCount)
 		System.arraycopy(result, 0, result = new PossibleMatch[index], 0, index);
 	return result;
 }
\ No newline at end of file
","Fix for bug 478360 - [1.9][search] AIOOBE  while searching for java.base
methods",Buggy
eclipseJdt,3485.json,5df55b1d083f2bad66acc93a2ff019e72423c2c9,"@@ -1,12 +1,20 @@
 	public static IndexLocation createIndexLocation(URL url) {
 		URL localUrl;
 		try {
 			localUrl = FileLocator.resolve(url);
 		} catch (IOException e) {
 			return null;
 		}
 		if (localUrl.getProtocol().equals(""file"")) { //$NON-NLS-1$
-			return new FileIndexLocation(url, new File(localUrl.getPath()));
+			File localFile = null;
+			try {
+				URI localFileURI = new URI(localUrl.toExternalForm());
+				localFile = new File(localFileURI);
+			}
+			catch(Exception ex) {
+				localFile = new File(localUrl.getPath());
+			}
+			return new FileIndexLocation(url, localFile);
 		}
 		return new JarIndexLocation(url, localUrl);
 	}
\ No newline at end of file
","Fix for bug 397818 - An IndexLocation is not created properly if the
pre-build indexes are located in a directory with a space
",Buggy
eclipseJdt,3849.json,e14a67b89e92e257eae6e75fc0c7b3046b4c9f63,"@@ -1,5 +1,6 @@
 public Object reusableJSRTarget() {
-	if (this.constant != Constant.NotAConstant)
+	if (this.constant != Constant.NotAConstant && (this.implicitConversion & TypeIds.BOXING) == 0) {
 		return this.constant;
+	}
 	return null;
 }
\ No newline at end of file
",Fix for bug 394718 - VerifyError: Inconsistent stackmap frames,Buggy
eclipseJdt,2849.json,48e3ddc97a372ba17e3a8fb05bd8c143189dd168,"@@ -1,21 +1,21 @@
 	public static final char[] concat(char[] first, char[] second, char[] third, char[] fourth) {
 		if (first == null)
 			return concat(second, third, fourth);
 		if (second == null)
 			return concat(first, third, fourth);
 		if (third == null)
 			return concat(first, second, fourth);
 		if (fourth == null)
 			return concat(first, second, third);
 
 		int length1 = first.length;
 		int length2 = second.length;
 		int length3 = third.length;
 		int length4 = fourth.length;
 		char[] result = new char[length1 + length2 + length3 + length4];
 		System.arraycopy(first, 0, result, 0, length1);
 		System.arraycopy(second, 0, result, length1, length2);
 		System.arraycopy(third, 0, result, length1 + length2, length3);
-		System.arraycopy(third, 0, result, length1 + length2 + length3, length4);
+		System.arraycopy(fourth, 0, result, length1 + length2 + length3, length4);
 		return result;
 	}
\ No newline at end of file
","Bug 481796 - Fix ArrayIndexOutOfBoundsException

Change-Id: Ib1cded7b613262929f0c906a04bd69a523311141
Signed-off-by: Stefan Xenos <sxenos@gmail.com>
",Buggy
eclipseJdt,5117.json,8f577b9f934a073bf0b3684c3935f2cd08a1660a,"@@ -1,8 +1,8 @@
 	public StringBuffer printExpression(int indent, StringBuffer output) {
-		output.append(""NAryStringLiteral{""); //$NON-NLS-1$
+		output.append(""StringLiteralConcatenation{""); //$NON-NLS-1$
 		for (int i = 0, max = this.counter; i < max; i++) {
 			this.literals[i].printExpression(indent, output);
 			output.append(""+\n"");//$NON-NLS-1$
 		}
 		return output.append('}');
 	}
\ No newline at end of file
","HEAD - Fix bug in formatting string literal concatenation
",Buggy
eclipseJdt,20784.json,653036e82ad47971c36ae720862ebb4740be149f,"@@ -1,12 +1,13 @@
 char[][] fullExclusionPatternChars() {
 	try {
+		if (this.getKind() != IPackageFragmentRoot.K_SOURCE) return null;
 		ClasspathEntry entry = (ClasspathEntry)getRawClasspathEntry();
 		if (entry == null) {
 			return null;
 		} else {
 			return entry.fullExclusionPatternChars();
 		}
 	} catch (JavaModelException e) { 
 		return null;
 	}
 }		
\ No newline at end of file
","Fix for bug 28489
",Buggy
eclipseJdt,1595.json,0a908cd3dc3279066d94660987f6e5450b72486e,"@@ -1,54 +1,55 @@
 private MethodBinding getMethodBinding(MethodPattern methodPattern, TypeBinding declaringTypeBinding) {
 	MethodBinding result;
 	char[][] parameterTypes = methodPattern.parameterSimpleNames;
 	if (parameterTypes == null) return null;
 	int paramTypeslength = parameterTypes.length;
 	ReferenceBinding referenceBinding = (ReferenceBinding) declaringTypeBinding;
 	MethodBinding[] methods = referenceBinding.getMethods(methodPattern.selector);
 	int methodsLength = methods.length;
 	TypeVariableBinding[] refTypeVariables = referenceBinding.typeVariables();
 	int typeVarLength = refTypeVariables==null ? 0 : refTypeVariables.length;
 	List <MethodBinding> possibleMethods = new ArrayList<MethodBinding>(methodsLength);
 	for (int i=0; i<methodsLength; i++) {
 		TypeBinding[] methodParameters = methods[i].parameters;
 		int paramLength = methodParameters==null ? 0 : methodParameters.length;
 		TypeVariableBinding[] methodTypeVariables = methods[i].typeVariables;
 		int methTypeVarLength = methodTypeVariables==null ? 0 : methodTypeVariables.length;
 		boolean found = false;
 		if (methodParameters != null && paramLength == paramTypeslength) {
 			for (int p=0; p<paramLength; p++) {
-				if (CharOperation.equals(methodParameters[p].sourceName(), parameterTypes[p])) {
+				TypeBinding parameter = methodParameters[p];
+				if (matchParams(methodPattern, p, parameter)) {
 					// param erasure match
 					found = true;
 				} else {
 					// type variable
 					found = false;
 					if (refTypeVariables != null) {
 						for (int v=0; v<typeVarLength; v++) {
 							if (!CharOperation.equals(refTypeVariables[v].sourceName, parameterTypes[p])) {
 								found = false;
 								break;
 							}
 							found = true;
 						}
 					}
 					if (!found && methodTypeVariables != null) {
 						for (int v=0; v<methTypeVarLength; v++) {
 							if (!CharOperation.equals(methodTypeVariables[v].sourceName, parameterTypes[p])) {
 								found = false;
 								break;
 							}
 							found = true;
 						}
 					}
 					if (!found) break;
 				}
 			}
 		}
 		if (found) {
 			possibleMethods.add(methods[i]);
 		}
 	}
 	result =  getMostApplicableMethod(possibleMethods, methodPattern);
 	return result;
 }
\ No newline at end of file
",Fix for Bug 521240: Search ignores the qualifier of the parameter type,Buggy
eclipseJdt,1134.json,b7bd88d9bc859369d4d17c37d109bd3331837ba7,"@@ -1,7 +1,8 @@
 public int match(MessageSend msgSend, MatchingNodeSet nodeSet)  {
 	if ((msgSend.bits & ASTNode.InsideJavadoc) == 0) return IMPOSSIBLE_MATCH;
+	if (!this.pattern.findReferences) return IMPOSSIBLE_MATCH;
 	if (this.pattern.declaringSimpleName == null || CharOperation.equals(msgSend.selector, this.pattern.declaringSimpleName)) {
 		return nodeSet.addMatch(msgSend, this.pattern.mustResolve ? POSSIBLE_MATCH : ACCURATE_MATCH);
 	}
 	return IMPOSSIBLE_MATCH;
 }
\ No newline at end of file
","Fixed bug 381567: [search] Unexpected results from SearchEngine#search
Conflicts:
",Buggy
eclipseJdt,5656.json,905dec82e916c38704735fea38fad8cba693cc45,"@@ -1,3 +1,3 @@
 public TypeBinding clone(TypeBinding outerType) {
-	throw new IllegalStateException(); // shouldn't get here.
+	return this; // shouldn't get here.
 }
\ No newline at end of file
","Fixed Bug 427105 - [1.8][builder] Differences between incremental and
full builds in method contract verification in the presence of type
annotations",Buggy
eclipseJdt,1327.json,84f1aab618cdc74f8c6aecebdc0fb845b80d6368,"@@ -1,4 +1,6 @@
 protected void consumeMemberValuePair() {
 	super.consumeMemberValuePair();
-	this.patternLocator.match((MemberValuePair) this.astStack[this.astPtr], this.nodeSet);
+	if ((this.patternFineGrain & ~IJavaSearchConstants.METHOD_REFERENCE_EXPRESSION) != 0) {
+		this.patternLocator.match((MemberValuePair) this.astStack[this.astPtr], this.nodeSet);
+	}
 }
\ No newline at end of file
","Fix for Bug 435480 [1.8][search] search in method reference expressions
finds annotation element name",Buggy
eclipseJdt,165.json,fe024fd7797ce73b0a83969f685073606863b79e,"@@ -1,23 +1,23 @@
 	public PrimitiveTypeImpl getPrimitiveType(TypeKind kind)
 	{
 		switch (kind) {
 		case BOOLEAN:
 			return PrimitiveTypeImpl.BOOLEAN;
 		case BYTE:
 			return PrimitiveTypeImpl.BYTE;
 		case CHAR:
 			return PrimitiveTypeImpl.CHAR;
 		case DOUBLE:
 			return PrimitiveTypeImpl.DOUBLE;
 		case FLOAT:
 			return PrimitiveTypeImpl.FLOAT;
 		case INT:
 			return PrimitiveTypeImpl.INT;
 		case LONG:
 			return PrimitiveTypeImpl.LONG;
 		case SHORT:
 			return PrimitiveTypeImpl.SHORT;
 		default:
-			throw new IllegalStateException();
+			throw new IllegalArgumentException();
 		}
 	}
\ No newline at end of file
","Fixes Bug 427943 - The method
org.eclipse.jdt.internal.compiler.apt.model.Factory.getPrimitiveType
does not throw IllegalArgumentException

Change-Id: I652c422b80ef6192955ef508387f9fd0fac31a7e
Signed-off-by: Harry Terkelsen <het@google.com>",Buggy
eclipseJdt,1253.json,025c833d41053b8599d25c53d05e92e37975873f,"@@ -1,18 +1,29 @@
 protected int resolveLevelForType(char[] qualifiedPattern, TypeBinding type) {
 	if (qualifiedPattern == null) return ACCURATE_MATCH;
 	if (type == null || !type.isValidBinding()) return INACCURATE_MATCH;
 
 	// Type variable cannot be specified through pattern => this kind of binding cannot match it (see bug 79803)
 	if (type.isTypeVariable()) return IMPOSSIBLE_MATCH;
 
+	if (type instanceof IntersectionTypeBinding18) {
+		int result = IMPOSSIBLE_MATCH, prev = IMPOSSIBLE_MATCH;
+		IntersectionTypeBinding18 i18 = (IntersectionTypeBinding18) type;
+		for (ReferenceBinding ref : i18.intersectingTypes) {
+			result = resolveLevelForType(qualifiedPattern, ref);
+			if (result == ACCURATE_MATCH) return result; 
+			if (result == IMPOSSIBLE_MATCH) continue;
+			if (prev == IMPOSSIBLE_MATCH) prev = result;
+		}
+		return prev;
+	}
 	// NOTE: if case insensitive search then qualifiedPattern is assumed to be lowercase
 
 	char[] qualifiedPackageName = type.qualifiedPackageName();
 	char[] qualifiedSourceName = qualifiedSourceName(type);
 	char[] fullyQualifiedTypeName = qualifiedPackageName.length == 0
 		? qualifiedSourceName
 		: CharOperation.concat(qualifiedPackageName, qualifiedSourceName, '.');
 	return CharOperation.match(qualifiedPattern, fullyQualifiedTypeName, this.isCaseSensitive)
 		? ACCURATE_MATCH
 		: IMPOSSIBLE_MATCH;
 }
\ No newline at end of file
","Fix for Bug 485805 [1.8][search] Search engine throws
UnsupportedOperationException when searching for subclass implementors

Change-Id: I28b09ffc6e446e2967c4dbf077816ef2df83d2ab",Buggy
eclipseJdt,2496.json,7d2b09ebfd4cb99d1f345eedcae879729e8aff7e,"@@ -1,51 +1,53 @@
 	public MemoryAccessLog getReportFor(long address, int size) {
 		List<Tag> tags = new ArrayList<>();
 		tags.addAll(this.operationStack);
-		int pointerToStart = (this.insertionPosition + this.buffer0.length - this.currentEntries) % this.buffer0.length;
-		int currentPosition = (this.insertionPosition + this.buffer0.length - 1) % this.buffer0.length;
-		long currentWrite = this.timer;
 
 		List<MemoryOperation> operations = new ArrayList<>();
-		do {
-			long nextAddress = this.buffer0[currentPosition];
-			int nextArgument = this.buffer1[currentPosition];
-			byte nextOp = this.operation[currentPosition];
-
-			switch (nextOp) {
-				case POP_OPERATION: {
-					tags.add(getTagForId(nextArgument));
-					break;
-				}
-				case PUSH_OPERATION: {
-					tags.remove(tags.size() - 1);
-					break;
-				}
-				default: {
-					boolean isMatch = false;
-					if (address < nextAddress) {
-						long diff = nextAddress - address;
-						if (diff < size) {
-							isMatch = true;
-						}
-					} else {
-						long diff = address - nextAddress;
-						if (diff < nextArgument) {
-							isMatch = true;
-						}
+		if (this.buffer0 != null) {
+			int pointerToStart = (this.insertionPosition + this.buffer0.length - this.currentEntries) % this.buffer0.length;
+			int currentPosition = (this.insertionPosition + this.buffer0.length - 1) % this.buffer0.length;
+			long currentWrite = this.timer;
+			do {
+				long nextAddress = this.buffer0[currentPosition];
+				int nextArgument = this.buffer1[currentPosition];
+				byte nextOp = this.operation[currentPosition];
+	
+				switch (nextOp) {
+					case POP_OPERATION: {
+						tags.add(getTagForId(nextArgument));
+						break;
 					}
-
-					if (isMatch) {
-						List<Tag> stack = new ArrayList<>();
-						stack.addAll(tags);
-						MemoryOperation nextOperation = new MemoryOperation(nextOp, currentWrite, nextAddress,
-								nextArgument, stack);
-						operations.add(nextOperation);
+					case PUSH_OPERATION: {
+						tags.remove(tags.size() - 1);
+						break;
 					}
-
-					currentWrite--;
+					default: {
+						boolean isMatch = false;
+						if (address < nextAddress) {
+							long diff = nextAddress - address;
+							if (diff < size) {
+								isMatch = true;
+							}
+						} else {
+							long diff = address - nextAddress;
+							if (diff < nextArgument) {
+								isMatch = true;
+							}
+						}
+	
+						if (isMatch) {
+							List<Tag> stack = new ArrayList<>();
+							stack.addAll(tags);
+							MemoryOperation nextOperation = new MemoryOperation(nextOp, currentWrite, nextAddress,
+									nextArgument, stack);
+							operations.add(nextOperation);
+						}
+	
+						currentWrite--;
+					}
 				}
-			}
-			currentPosition = (currentPosition + this.buffer0.length - 1) % this.buffer0.length;
-		} while (currentPosition != pointerToStart);
+				currentPosition = (currentPosition + this.buffer0.length - 1) % this.buffer0.length;
+			} while (currentPosition != pointerToStart);
+		}
 		return new MemoryAccessLog(operations);
 	}
\ No newline at end of file
","Bug 514089 - Build a tool to help debug index corruption

Fix NPE when corruption is detected and the buffer size is 0.

Change-Id: I4163e9f294c96582b201bdf09593602ab1807d6e
",Buggy
eclipseJdt,15048.json,30961650a033c638f3a768401431bcd77f1a4058,"@@ -1,26 +1,29 @@
 	private void removeUnresolvedBindings(org.eclipse.jdt.internal.compiler.ast.TypeDeclaration type) {
 		final MemberTypeDeclaration[] memberTypes = type.memberTypes;
 		if (memberTypes != null) {
 			for (int i = 0, max = memberTypes.length; i < max; i++){
 				removeUnresolvedBindings(memberTypes[i]);
 			}
 		}
 		if (type.binding != null && (type.binding.modifiers & CompilerModifiers.AccUnresolved) != 0) {
 			type.binding = null;
-			final org.eclipse.jdt.internal.compiler.ast.FieldDeclaration[] fields = type.fields;
-			if (fields != null) {
-				for (int i = 0, max = fields.length; i < max; i++){
+		}
+		
+		final org.eclipse.jdt.internal.compiler.ast.FieldDeclaration[] fields = type.fields;
+		if (fields != null) {
+			for (int i = 0, max = fields.length; i < max; i++){
+				if (fields[i].binding != null && (fields[i].binding.modifiers & CompilerModifiers.AccUnresolved) != 0) {
 					fields[i].binding = null;
 				}
 			}
 		}
-
+	
 		final AbstractMethodDeclaration[] methods = type.methods;
 		if (methods != null) {
 			for (int i = 0, max = methods.length; i < max; i++){
 				if (methods[i].binding !=  null && (methods[i].binding.modifiers & CompilerModifiers.AccUnresolved) != 0) {
 					methods[i].binding = null;
 				}
 			}
 		}
 	}
\ No newline at end of file
","Fix for bug 40804
",Buggy
eclipseJdt,18985.json,4b7408bf1768e4fe08faa711e23ea5c6fe36d225,"@@ -1,6 +1,6 @@
 public String toString() {
-	return ""State for "" + this.javaProjectName
-		+ "" (#"" + this.buildNumber
+	return ""State for "" + this.javaProjectName //$NON-NLS-1$
+		+ "" (#"" + this.buildNumber //$NON-NLS-1$
 			+ "" @ "" + new Date(this.lastStructuralBuildTime) //$NON-NLS-1$
 				+ "")""; //$NON-NLS-1$
 }
\ No newline at end of file
","HEAD - Fix Clean-up pass 1 problems
",Buggy
eclipseJdt,4719.json,6fe04df602475d9f13e955fcfd38124da359e84a,"@@ -1,28 +1,34 @@
 public void computeConversion(Scope scope, TypeBinding runtimeTimeType, TypeBinding compileTimeType) {
 	if (runtimeTimeType == null || compileTimeType == null)
 		return;
-	if ((this.bits & Binding.FIELD) != 0 && this.binding != null && this.binding.isValidBinding()) {
-		// set the generic cast after the fact, once the type expectation is fully known (no need for strict cast)
-		FieldBinding field = (FieldBinding) this.binding;
-		FieldBinding originalBinding = field.original();
-		TypeBinding originalType = originalBinding.type;
-		// extra cast needed if field type is type variable
-		if (originalType.leafComponentType().isTypeVariable()) {
-	    	TypeBinding targetType = (!compileTimeType.isBaseType() && runtimeTimeType.isBaseType())
-	    		? compileTimeType  // unboxing: checkcast before conversion
-	    		: runtimeTimeType;
-	        this.genericCast = originalType.genericCast(scope.boxing(targetType));
-	        if (this.genericCast instanceof ReferenceBinding) {
+	if (this.binding != null && this.binding.isValidBinding()) {
+		TypeBinding originalType = null;
+		if ((this.bits & Binding.FIELD) != 0) {
+			// set the generic cast after the fact, once the type expectation is fully known (no need for strict cast)
+			FieldBinding field = (FieldBinding) this.binding;
+			FieldBinding originalBinding = field.original();
+			originalType = originalBinding.type;
+		} else if ((this.bits & Binding.LOCAL) != 0) {
+			LocalVariableBinding local = (LocalVariableBinding) this.binding;
+			originalType = local.type;
+		}
+		// extra cast needed if field/local type is type variable
+		if (originalType != null && originalType.leafComponentType().isTypeVariable()) {
+			TypeBinding targetType = (!compileTimeType.isBaseType() && runtimeTimeType.isBaseType())
+					? compileTimeType  // unboxing: checkcast before conversion
+							: runtimeTimeType;
+			this.genericCast = originalType.genericCast(scope.boxing(targetType));
+			if (this.genericCast instanceof ReferenceBinding) {
 				ReferenceBinding referenceCast = (ReferenceBinding) this.genericCast;
 				if (!referenceCast.canBeSeenBy(scope)) {
-		        	scope.problemReporter().invalidType(this,
-		        			new ProblemReferenceBinding(
-								CharOperation.splitOn('.', referenceCast.shortReadableName()),
-								referenceCast,
-								ProblemReasons.NotVisible));
+					scope.problemReporter().invalidType(this,
+							new ProblemReferenceBinding(
+									CharOperation.splitOn('.', referenceCast.shortReadableName()),
+									referenceCast,
+									ProblemReasons.NotVisible));
 				}
-	        }
+			}
 		}
 	}
 	super.computeConversion(scope, runtimeTimeType, compileTimeType);
 }
\ No newline at end of file
","Fixed Bug 416480 - Error in bytecode generated by ECJ compiler leads to
IncompatibleClassChangeError",Buggy
eclipseJdt,25728.json,ab7dabe7a80a22f7a1c8f6edce715e69ee26d4d5,"@@ -1,34 +1,36 @@
 	protected static boolean hasEmptyName(TypeReference reference, ASTNode assistNode) {
 		if (reference == null) return false;
 
-		if (reference.sourceStart <= assistNode.sourceStart && assistNode.sourceEnd <= reference.sourceEnd) return false;
+		// https://bugs.eclipse.org/bugs/show_bug.cgi?id=397070
+		if (reference != assistNode &&
+				reference.sourceStart <= assistNode.sourceStart && assistNode.sourceEnd <= reference.sourceEnd) return false;
 
 		if (reference instanceof CompletionOnSingleTypeReference ||
 				reference instanceof CompletionOnQualifiedTypeReference ||
 				reference instanceof CompletionOnParameterizedQualifiedTypeReference) {
 			char[][] typeName = reference.getTypeName();
 			if (typeName[typeName.length - 1].length == 0) return true;
 		}
 		if (reference instanceof ParameterizedSingleTypeReference) {
 			ParameterizedSingleTypeReference parameterizedReference = (ParameterizedSingleTypeReference) reference;
 			TypeReference[] typeArguments = parameterizedReference.typeArguments;
 			if (typeArguments != null) {
 				for (int i = 0; i < typeArguments.length; i++) {
 					if (hasEmptyName(typeArguments[i], assistNode)) return true;
 				}
 			}
 		} else if (reference instanceof ParameterizedQualifiedTypeReference) {
 			ParameterizedQualifiedTypeReference parameterizedReference = (ParameterizedQualifiedTypeReference) reference;
 			TypeReference[][] typeArguments = parameterizedReference.typeArguments;
 			if (typeArguments != null) {
 				for (int i = 0; i < typeArguments.length; i++) {
 					if (typeArguments[i] != null) {
 						for (int j = 0; j < typeArguments[i].length; j++) {
 							if (hasEmptyName(typeArguments[i][j], assistNode)) return true;
 						}
 					}
 				}
 			}
 		}
 		return false;
 	}
\ No newline at end of file
","Fix for bug 397070 - On completion in implements/extends clause,
supertype/interface-signature(s) can not be retrieved from enclosing
type",Buggy
eclipseJdt,20900.json,c79924988b83a4410dc68ac4bbc9ed2e5112cc61,"@@ -1,3 +1,3 @@
-	public static IClasspathContainer getUserLibrary(String name) {
-		return (IClasspathContainer) getLibraryMap().get(name);
+	public static UserLibrary getUserLibrary(String name) {
+		return (UserLibrary) getLibraryMap().get(name);
 	}
\ No newline at end of file
","Fix bug: invalid getUserLibrary return
",Buggy
eclipseJdt,14646.json,8bf6b68ac4b26f2f99e3e6e3e77b19496440917e,"@@ -1,12 +1,11 @@
 	public ITypeBinding getGenericTypeOfWildcardType() {
 		switch (this.binding.kind()) {
 			case Binding.WILDCARD_TYPE :
-			case Binding.INTERSECTION_TYPE :
 				WildcardBinding wildcardBinding = (WildcardBinding) this.binding;
 				if (wildcardBinding.genericType != null) {
 					return this.resolver.getTypeBinding(wildcardBinding.genericType);
 				}
 				break;
 		}
 		return null;
 	}
\ No newline at end of file
","HEAD - Fixed bug 341759: NPE in ITypeBinding#getName() for intersection type
",Buggy
eclipseJdt,19389.json,ae30fd6df4fe6e776883eda11e8cb81aefe2c34c,"@@ -1,29 +1,26 @@
 protected IBuffer openBuffer(IProgressMonitor pm, Object info) throws JavaModelException {
 
 	// create buffer
-	IBuffer buffer = this.owner.createBuffer(this);
-	if (buffer == null) return null;
+	IBuffer buffer = BufferManager.createBuffer(this);
 
 	// set the buffer source
-	if (buffer.getCharacters() == null) {
-		IBuffer classFileBuffer = this.classFile.getBuffer();
-		if (classFileBuffer != null) {
-			buffer.setContents(classFileBuffer.getCharacters());
-		} else {
-			// Disassemble
-			IClassFileReader reader = ToolFactory.createDefaultClassFileReader(this.classFile, IClassFileReader.ALL);
-			Disassembler disassembler = new Disassembler();
-			String contents = disassembler.disassemble(reader, Util.getLineSeparator("""", getJavaProject()), ClassFileBytesDisassembler.WORKING_COPY); //$NON-NLS-1$
-			buffer.setContents(contents);
-		}
+	IBuffer classFileBuffer = this.classFile.getBuffer();
+	if (classFileBuffer != null) {
+		buffer.setContents(classFileBuffer.getCharacters());
+	} else {
+		// Disassemble
+		IClassFileReader reader = ToolFactory.createDefaultClassFileReader(this.classFile, IClassFileReader.ALL);
+		Disassembler disassembler = new Disassembler();
+		String contents = disassembler.disassemble(reader, Util.getLineSeparator("""", getJavaProject()), ClassFileBytesDisassembler.WORKING_COPY); //$NON-NLS-1$
+		buffer.setContents(contents);
 	}
 
 	// add buffer to buffer cache
 	BufferManager bufManager = getBufferManager();
 	bufManager.addBuffer(buffer);
 
 	// listen to buffer changes
 	buffer.addBufferChangedListener(this);
 
 	return buffer;
 }
\ No newline at end of file
","HEAD - Fixed bug 337935: Test failures when run as an IDE (org.eclipse.sdk.ide)
",Buggy
eclipseJdt,25842.json,4c94b3d7ef7a5503607858476a6477496a59c95b,"@@ -1,5 +1,5 @@
-protected void consumeLambdaHeader() {
-	super.consumeLambdaHeader();
+protected void consumeNestedLambda() {
+	super.consumeNestedLambda();
 	LambdaExpression lexp = (LambdaExpression) this.astStack[this.astPtr];
 	pushOnElementStack(K_LAMBDA_EXPRESSION_DELIMITER, EXPRESSION_BODY, lexp);
 }
\ No newline at end of file
","Fixed Bug 430026 - [1.8] Lambda parameter has wrong parent if it
declares its type",Buggy
eclipseJdt,27032.json,b308074bc5b31f3a5857e47f87565296fbba4a15,"@@ -1,34 +1,39 @@
     public static EclipseDeclarationImpl createDeclaration(IBinding binding, BaseProcessorEnv env)
     {
         if(binding == null) return null;
        
         switch(binding.getKind())
         {
     	case IBinding.TYPE:
     		final ITypeBinding typeBinding = (ITypeBinding)binding;
         	if( typeBinding.isAnonymous() || typeBinding.isArray() || 
     			typeBinding.isWildcardType() || typeBinding.isPrimitive() )       
                 throw new IllegalStateException(""failed to create declaration from "" + binding); //$NON-NLS-1$
         	if( typeBinding.isTypeVariable() )
 	        	return new TypeParameterDeclarationImpl(typeBinding, env);
         	else
         		return createReferenceType(typeBinding, env);
         case IBinding.VARIABLE:
         	final IVariableBinding varBinding = (IVariableBinding)binding;            
             if(varBinding.isEnumConstant())
                 return new EnumConstantDeclarationImpl(varBinding, env);
             else
                 return new FieldDeclarationImpl(varBinding, env);
         case IBinding.METHOD:
             final IMethodBinding method = (IMethodBinding)binding;
             if( method.isConstructor() )
                 return new ConstructorDeclarationImpl(method, env);
             final ITypeBinding declaringType = method.getDeclaringClass();
             if( declaringType != null && declaringType.isAnnotation() )
                 return new AnnotationElementDeclarationImpl(method, env);
             else
-                return new MethodDeclarationImpl(method, env);             
+                return new MethodDeclarationImpl(method, env);
+        case IBinding.PACKAGE:
+            // https://bugs.eclipse.org/bugs/show_bug.cgi?id=352949
+            // Don't throw an exception, but just return null. 
+        	// apt also doesn't return a value
+        	return null;
         default:
             throw new IllegalStateException(""failed to create declaration from "" + binding); //$NON-NLS-1$
         }     
     }
\ No newline at end of file
","Fix for bug 352949: Impossible to process package-level annotations with
an AnnotationProcessor",Buggy
eclipseJdt,14260.json,ea916b0462fec6996e619f84c30f348e2877686a,"@@ -1,15 +1,23 @@
 	protected int retrieveEndOfRightParenthesisPosition(int start, int end) {
 		this.scanner.resetTo(start, end);
 		try {
 			int token;
+			int count = 0;
 			while ((token = this.scanner.getNextToken()) != TerminalTokens.TokenNameEOF) {
 				switch(token) {
 					case TerminalTokens.TokenNameRPAREN:
-						return this.scanner.currentPosition;
+						count--;
+						if (count <= 0) return this.scanner.currentPosition;
+						 break;
+					case TerminalTokens.TokenNameLPAREN:
+						count++;
+						//$FALL-THROUGH$
+					default:
+						break;
 				}
 			}
 		} catch(InvalidInputException e) {
 			// ignore
 		}
 		return -1;
 	}
\ No newline at end of file
","Fix for bug 399600 - ASTConverter#retrieveEndOfRightParenthesisPosition
fails for certain cases",Buggy
eclipseJdt,11577.json,3d11e595fd95f6b5ceb0fd10d1d7aa7d98828a7b,"@@ -1,56 +1,68 @@
 public void generateSyntheticEnclosingInstanceValues(BlockScope currentScope, ReferenceBinding targetType, Expression enclosingInstance, ASTNode invocationSite) {
 	// supplying enclosing instance for the anonymous type's superclass
 	ReferenceBinding checkedTargetType = targetType.isAnonymousType() ? (ReferenceBinding)targetType.superclass().erasure() : targetType;
 	boolean hasExtraEnclosingInstance = enclosingInstance != null;
 	if (hasExtraEnclosingInstance
 			&& (!checkedTargetType.isNestedType() || checkedTargetType.isStatic())) {
 		currentScope.problemReporter().unnecessaryEnclosingInstanceSpecification(enclosingInstance, checkedTargetType);
 		return;
 	}
 
 	// perform some emulation work in case there is some and we are inside a local type only
 	ReferenceBinding[] syntheticArgumentTypes;
 	if ((syntheticArgumentTypes = targetType.syntheticEnclosingInstanceTypes()) != null) {
 
 		ReferenceBinding targetEnclosingType = checkedTargetType.enclosingType();
 		long compliance = currentScope.compilerOptions().complianceLevel;
 
 		// deny access to enclosing instance argument for allocation and super constructor call (if 1.4)
 		// always consider it if complying to 1.5
 		boolean denyEnclosingArgInConstructorCall;
 		if (compliance <= ClassFileConstants.JDK1_3) {
 			denyEnclosingArgInConstructorCall = invocationSite instanceof AllocationExpression;
 		} else if (compliance == ClassFileConstants.JDK1_4){
 			denyEnclosingArgInConstructorCall = invocationSite instanceof AllocationExpression
 				|| invocationSite instanceof ExplicitConstructorCall && ((ExplicitConstructorCall)invocationSite).isSuperAccess();
-		} else {
+		} else if (compliance < ClassFileConstants.JDK1_7) {
 			//compliance >= JDK1_5
 			denyEnclosingArgInConstructorCall = (invocationSite instanceof AllocationExpression
 					|| invocationSite instanceof ExplicitConstructorCall && ((ExplicitConstructorCall)invocationSite).isSuperAccess())
 				&& !targetType.isLocalType();
+		} else {
+			//compliance >= JDK1_7
+			if (invocationSite instanceof AllocationExpression) {
+				denyEnclosingArgInConstructorCall = !targetType.isLocalType();
+			} else if (invocationSite instanceof ExplicitConstructorCall && 
+					((ExplicitConstructorCall)invocationSite).isSuperAccess()) {
+				MethodScope enclosingMethodScope = currentScope.enclosingMethodScope();
+				denyEnclosingArgInConstructorCall = !targetType.isLocalType() && enclosingMethodScope != null
+						&& enclosingMethodScope.isConstructorCall; 
+			} else {
+				denyEnclosingArgInConstructorCall = false;
+			}
 		}
 
 		boolean complyTo14 = compliance >= ClassFileConstants.JDK1_4;
 		for (int i = 0, max = syntheticArgumentTypes.length; i < max; i++) {
 			ReferenceBinding syntheticArgType = syntheticArgumentTypes[i];
 			if (hasExtraEnclosingInstance && TypeBinding.equalsEquals(syntheticArgType, targetEnclosingType)) {
 				hasExtraEnclosingInstance = false;
 				enclosingInstance.generateCode(currentScope, this, true);
 				if (complyTo14){
 					dup();
 					invokeObjectGetClass(); // will perform null check
 					pop();
 				}
 			} else {
 				Object[] emulationPath = currentScope.getEmulationPath(
 						syntheticArgType,
 						false /*not only exact match (that is, allow compatible)*/,
 						denyEnclosingArgInConstructorCall);
 				generateOuterAccess(emulationPath, invocationSite, syntheticArgType, currentScope);
 			}
 		}
 		if (hasExtraEnclosingInstance){
 			currentScope.problemReporter().unnecessaryEnclosingInstanceSpecification(enclosingInstance, checkedTargetType);
 		}
 	}
 }
\ No newline at end of file
","Fixed bug 373371 - [compiler] JDT Compiler reports an error whereas
javac compiles without problem

Change-Id: I1ca89bd73228aa19ee351e12ef64c474cbc58175
",Buggy
eclipseJdt,877.json,48d4662ccc94304b71283abf02dc80106ec8ea24,"@@ -1,21 +1,22 @@
 private void readIndexMap() {
 	try {
 		char[] indexMaps = org.eclipse.jdt.internal.compiler.util.Util.getFileCharContent(this.indexNamesMapFile, null);
 		char[][] names = CharOperation.splitOn('\n', indexMaps);
 		if (names.length >= 3) {
 			// First line is DiskIndex signature (see writeIndexMapFile())
 			String savedSignature = DiskIndex.SIGNATURE;
 			if (savedSignature.equals(new String(names[0]))) {
 				for (int i = 1, l = names.length-1 ; i < l ; i+=2) {
 					IndexLocation indexPath = IndexLocation.createIndexLocation(new URL(new String(names[i])));
+					if (indexPath == null) continue;
 					this.indexLocations.put(new Path(new String(names[i+1])), indexPath );
 					this.indexStates.put(indexPath, REUSE_STATE);
 				}
 			}		
 		}
 	} catch (IOException ignored) {
 		if (VERBOSE)
 			Util.verbose(""Failed to read saved index file names""); //$NON-NLS-1$
 	}
 	return;
 }
\ No newline at end of file
","Fix for Bug 420590
JavaIndexTests.testExistentIndexAfterRestart failed with error: NPE in
SimpleLookupTable.put
",Buggy
eclipseJdt,1436.json,0f1f2b20ab9c02179f9ab0cd2826219f39372374,"@@ -1,6 +1,8 @@
 public int match(ReferenceExpression node, MatchingNodeSet nodeSet) {
 	if (!this.pattern.findReferences) return IMPOSSIBLE_MATCH;
 	if (!matchesName(this.pattern.selector, node.selector)) return IMPOSSIBLE_MATCH;
+	if (node.selector != null &&  Arrays.equals(node.selector, org.eclipse.jdt.internal.compiler.codegen.ConstantPool.Init))
+		return IMPOSSIBLE_MATCH; // :: new
 	nodeSet.mustResolve = true;
 	return nodeSet.addMatch(node, this.pattern.mustResolve ? POSSIBLE_MATCH : ACCURATE_MATCH);
 }
\ No newline at end of file
","Fix for [Bug][458614][1.8][search] Constructor reference not found in
search",Buggy
eclipseJdt,23118.json,01fe9b211e794ff01834ebe0e40bd02cb1110d75,"@@ -1,30 +1,39 @@
 public static char[] getSignatureSimpleName(char[] typeSignature) {
 	if(typeSignature == null) return CharOperation.NO_CHAR;
 
 	char[] qualifiedType = Signature.toCharArray(typeSignature);
 
 	int dotCount = 0;
 	indexFound: for(int i = 0; i < typeSignature.length; i++) {
 		switch(typeSignature[i]) {
 			case C_DOT:
 				dotCount++;
 				break;
 			case C_GENERIC_START:
 				break indexFound;
 			case C_DOLLAR:
 				break indexFound;
 		}
 	}
 
 	if(dotCount > 0) {
+		int typeStart = 0;
 		for(int i = 0; i < qualifiedType.length; i++) {
-			if(qualifiedType[i] == '.') {
-				dotCount--;
+			switch (qualifiedType[i]) {
+				case '.':
+					dotCount--;
+					break;
+				case ' ':
+					typeStart = i+1;
+					break;
 			}
 			if(dotCount <= 0) {
-				return CharOperation.subarray(qualifiedType, i + 1, qualifiedType.length);
+				char[] simpleName = CharOperation.subarray(qualifiedType, i + 1, qualifiedType.length);
+				if (typeStart > 0 && typeStart < qualifiedType.length)
+					return CharOperation.concat(CharOperation.subarray(qualifiedType, 0, typeStart), simpleName);
+				return simpleName;
 			}
 		}
 	}
 	return qualifiedType;
 }
\ No newline at end of file
","Bug 463533 - Signature.getSignatureSimpleName() returns different
results for resolved and unresolved extends

Change-Id: Iaa8b4273dab596b84734326ad99f775bbe74a330
Signed-off-by: Stephan Herrmann <stephan.herrmann@berlin.de>",Buggy
eclipseJdt,26368.json,04a3935ecc2f9e24622bcfddda7aa95a0643fdd7,"@@ -1 +1,10 @@
-    public String toString(){ return _arrayBinding.toString(); }
\ No newline at end of file
+    public String toString(){ 
+    	final ITypeBinding elementType = _arrayBinding.getElementType();
+    	final StringBuilder buffer = new StringBuilder();
+    	String name = elementType.getQualifiedName();
+    	buffer.append(name);
+		for( int i=0, dim = _arrayBinding.getDimensions(); i<dim; i++ )
+			buffer.append(""[]""); //$NON-NLS-1$
+		
+		return buffer.toString();
+    }
\ No newline at end of file
","CR244832 | Annotation member that returns Class[] produces error in generated ControlBean

fixed ArrayType toString()

drt: apt.core
",Buggy
eclipseJdt,1082.json,41e3b1756b128250deb0f9b82843aa520278c691,"@@ -1,53 +1,53 @@
 void matchReportReference(Expression expr, int lastIndex, TypeBinding refBinding, MatchLocator locator) throws CoreException {
 
 	// Look if there's a need to special report for parameterized type
 	if (refBinding.isParameterizedType() || refBinding.isRawType()) {
 
 		// Try to refine accuracy
 		ParameterizedTypeBinding parameterizedBinding = (ParameterizedTypeBinding)refBinding;
 		updateMatch(parameterizedBinding, this.pattern.getTypeArguments(), this.pattern.hasTypeParameters(), 0, locator);
 		
 		// See whether it is necessary to report or not
 		if (match.getRule() == 0) return; // impossible match
 		boolean report = (this.isErasureMatch && match.isErasure()) || (this.isEquivalentMatch && match.isEquivalent()) || match.isExact();
 		if (!report) return;
 
 		// Make a special report for parameterized types if necessary
 		 if (refBinding.isParameterizedType() && this.pattern.hasTypeArguments())  {
 			TypeReference typeRef = null;
 			TypeReference[] typeArguments = null;
 			if (expr instanceof ParameterizedQualifiedTypeReference) {
 				typeRef = (ParameterizedQualifiedTypeReference) expr;
 				typeArguments = ((ParameterizedQualifiedTypeReference) expr).typeArguments[lastIndex];
 			}
 			else if (expr instanceof ParameterizedSingleTypeReference) {
 				typeRef = (ParameterizedSingleTypeReference) expr;
 				typeArguments = ((ParameterizedSingleTypeReference) expr).typeArguments;
 			}
 			if (typeRef != null) {
 				locator.reportAccurateParameterizedTypeReference(match, typeRef, lastIndex, typeArguments);
 				return;
 			}
 		}
 	} else if (this.pattern.hasTypeArguments()) { // binding has no type params, compatible erasure if pattern does
 		match.setRule(SearchPattern.R_ERASURE_MATCH);
 	}
 
 	// Report match
 	if (expr instanceof ArrayTypeReference) {
 		locator.reportAccurateTypeReference(match, expr, this.pattern.simpleName);
 		return;
 	}
 	if (refBinding.isLocalType()) {
-		// see bug https://bugs.eclipse.org/bugs/show_bug.cgi?id=84049
+		// see bug https://bugs.eclipse.org/bugs/show_bug.cgi?id=82673
 		LocalTypeBinding local = (LocalTypeBinding) refBinding;
 		IJavaElement focus = ((InternalSearchPattern)pattern).focus;
 		if (focus != null && local.enclosingMethod != null && focus.getParent().getElementType() == IJavaElement.METHOD) {
 			IMethod method = (IMethod) focus.getParent();
 			if (!CharOperation.equals(local.enclosingMethod.selector, method.getElementName().toCharArray())) {
 				return;
 			}
 		}
 	}
 	locator.report(match);
 }
\ No newline at end of file
","Fix bug reference
",Buggy
eclipseJdt,25078.json,71d81627399572ca242308eb9b1f8436f445d7df,"@@ -1,9 +1,9 @@
 	public TypeBinding resolveType(BlockScope scope) {
 		TypeBinding type = super.resolveType(scope);
-		if (type instanceof PolyTypeBinding)
+		if (type == null || type instanceof ProblemReferenceBinding || type instanceof PolyTypeBinding)
 			return type;
 		MethodBinding method = getMethodBinding();
 		if (method != null && method.isValidBinding() && !method.isSynthetic())
 			throw new SelectionNodeFound(this.actualMethodBinding);
 		throw new SelectionNodeFound();
 	}
\ No newline at end of file
","Fixed Bug 440731 - [1.8][code select] Hover, F3 doesn't work for method
reference in method invocation of overloaded method

Signed-off-by: shankha banerjee <shankhba@in.ibm.com>",Buggy
eclipseJdt,25078.json,a5e431ef5dd3e4ca66d16fb63b6f792ceeb0643b,"@@ -1,7 +1,9 @@
 	public TypeBinding resolveType(BlockScope scope) {
-		super.resolveType(scope);
+		TypeBinding type = super.resolveType(scope);
+		if (type instanceof PolyTypeBinding)
+			return type;
 		MethodBinding method = getMethodBinding();
 		if (method != null && method.isValidBinding() && !method.isSynthetic())
 			throw new SelectionNodeFound(this.actualMethodBinding);
 		throw new SelectionNodeFound();
 	}
\ No newline at end of file
","Fixed Bug 424110 - [1.8][hovering] Hover, F3 does not work for method
reference in method invocation",Buggy
eclipseJdt,3790.json,293a53a19363893dc72bcd9c4bf117c4e143553f,"@@ -1,3 +1,3 @@
 	public TypeBinding[] genericTypeArguments() {
-		return null;
+		return this.resolvedTypeArguments;
 	}
\ No newline at end of file
","Fixed Bug 420580 - [1.8][compiler] ReferenceExpression drops explicit
type arguments",Buggy
eclipseJdt,144.json,63326b7a3054b32190c64b8268487d927040f016,"@@ -1,4 +1,4 @@
 	public Element getEnclosingElement()
 	{
-		return null;
+		return getGenericElement();
 	}
\ No newline at end of file
","HEAD - Fixed bug 342470: javax.lang.model.element.Element.getEnclosingElement() doesn't return null for type parameter
",Buggy
eclipseJdt,11825.json,ee5e3843269e8af70318f7535175e87d19c752b4,"@@ -1,10 +1,11 @@
 	public int literalIndexForMethodHandle(MethodBinding binding) {
 		boolean isInterface = binding.declaringClass.isInterface();
 		int referenceKind =
 			isInterface ? binding.isStatic() ? MethodHandleRefKindInvokeStatic : binding.isPrivate() ? MethodHandleRefKindInvokeSpecial : MethodHandleRefKindInvokeInterface
 			: binding.isConstructor() ? MethodHandleRefKindNewInvokeSpecial
 			: binding.isStatic() ? MethodHandleRefKindInvokeStatic
+			: binding.isPrivate() ? MethodHandleRefKindInvokeSpecial
 			: MethodHandleRefKindInvokeVirtual;
 		
 		return literalIndexForMethodHandle(referenceKind, binding.declaringClass, binding.selector, binding.signature(), isInterface);
 	}
\ No newline at end of file
","Fixed Bug 439889 - [1.8][compiler] [lambda] Deserializing lambda fails
with IllegalArgumentException: ""Invalid lambda deserialization""",Buggy
eclipseJdt,11825.json,6a493caae74ed7f294c44634abfb786fa2111d3d,"@@ -1,10 +1,10 @@
 	public int literalIndexForMethodHandle(MethodBinding binding) {
 		boolean isInterface = binding.declaringClass.isInterface();
 		int referenceKind =
-			isInterface ? binding.isStatic() ? MethodHandleRefKindInvokeStatic : MethodHandleRefKindInvokeInterface
+			isInterface ? binding.isStatic() ? MethodHandleRefKindInvokeStatic : binding.isPrivate() ? MethodHandleRefKindInvokeSpecial : MethodHandleRefKindInvokeInterface
 			: binding.isConstructor() ? MethodHandleRefKindNewInvokeSpecial
 			: binding.isStatic() ? MethodHandleRefKindInvokeStatic
 			: MethodHandleRefKindInvokeVirtual;
 		
 		return literalIndexForMethodHandle(referenceKind, binding.declaringClass, binding.selector, binding.signature(), isInterface);
 	}
\ No newline at end of file
","Fixed Bug 421797 - [1.8][compiler] ClassFormatError with default 
methods & I.super.foo() syntax ",Buggy
eclipseJdt,11825.json,ffd96339198fcdfc38a0c44d4da9dfd0a59d21fc,"@@ -1,10 +1,10 @@
 	public int literalIndexForMethodHandle(MethodBinding binding) {
 		boolean isInterface = binding.declaringClass.isInterface();
 		int referenceKind =
-			isInterface ? MethodHandleRefKindInvokeInterface
+			isInterface ? binding.isStatic() ? MethodHandleRefKindInvokeStatic : MethodHandleRefKindInvokeInterface
 			: binding.isConstructor() ? MethodHandleRefKindNewInvokeSpecial
 			: binding.isStatic() ? MethodHandleRefKindInvokeStatic
 			: MethodHandleRefKindInvokeVirtual;
 		
 		return literalIndexForMethodHandle(referenceKind, binding.declaringClass, binding.selector, binding.signature(), isInterface);
 	}
\ No newline at end of file
","Fixed Bug 421712 - [1.8][compiler] java.lang.NoSuchMethodError with
lambda expression in interface default method.",Buggy
eclipseJdt,27787.json,6c76d390a016d2bc042688766f03adca637f8318,"@@ -1,4 +1,9 @@
 	public int run(InputStream in, OutputStream out, OutputStream err, String... arguments) {
-		boolean succeed = new Main(new PrintWriter(new OutputStreamWriter(out)), new PrintWriter(new OutputStreamWriter(err)), true/*systemExit*/, null/*options*/, null/*progress*/).compile(arguments);
+		boolean succeed = new Main(
+				new PrintWriter(new OutputStreamWriter(out != null ? out : System.out)),
+				new PrintWriter(new OutputStreamWriter(err != null ? err : System.err)),
+				true/* systemExit */,
+				null/* options */,
+				null/* progress */).compile(arguments);
 		return succeed ? 0 : -1;
 	}
\ No newline at end of file
","Fixed Bug 426434 - EclipseCompiler#run() crashes when null out/err
passed by client",Buggy
eclipseJdt,16316.json,f372eb4169324cad87b7cff6d25b5939cf1574c9,"@@ -1,4 +1,4 @@
 	public boolean isLocalTypeDeclaration() {
 		ASTNode parent = getParent();
-		return (parent instanceof Block);
+		return (parent instanceof TypeDeclarationStatement);
 	}
\ No newline at end of file
","Fix TypeDeclaration.isLocalTypeDeclaration (bug #10468)
",Buggy
eclipseJdt,5374.json,8739fac6b0362a32fbe52c714ff661e202a84e1e,"@@ -1,31 +1,31 @@
 public void resolve(BlockScope upperScope) {
 	// special scope for secret locals optimization.
 	this.scope = new BlockScope(upperScope);
 	TypeBinding type = this.expression.resolveType(this.scope);
-	if (type == null)
-		return;
-	switch (type.id) {
-		case T_boolean :
-		case T_char :
-		case T_float :
-		case T_double :
-		case T_byte :
-		case T_short :
-		case T_int :
-		case T_long :
-			this.scope.problemReporter().invalidTypeToSynchronize(this.expression, type);
-			break;
-		case T_void :
-			this.scope.problemReporter().illegalVoidExpression(this.expression);
-			break;
-		case T_null :
-			this.scope.problemReporter().invalidNullToSynchronize(this.expression);
-			break;
+	if (type != null) {
+		switch (type.id) {
+			case T_boolean :
+			case T_char :
+			case T_float :
+			case T_double :
+			case T_byte :
+			case T_short :
+			case T_int :
+			case T_long :
+				this.scope.problemReporter().invalidTypeToSynchronize(this.expression, type);
+				break;
+			case T_void :
+				this.scope.problemReporter().illegalVoidExpression(this.expression);
+				break;
+			case T_null :
+				this.scope.problemReporter().invalidNullToSynchronize(this.expression);
+				break;
+			}
+			//continue even on errors in order to have the TC done into the statements
+			this.synchroVariable = new LocalVariableBinding(SecretLocalDeclarationName, type, ClassFileConstants.AccDefault, false);
+			this.scope.addLocalVariable(this.synchroVariable);
+			this.synchroVariable.setConstant(Constant.NotAConstant); // not inlinable
+			this.expression.computeConversion(this.scope, type, type);
 	}
-	//continue even on errors in order to have the TC done into the statements
-	this.synchroVariable = new LocalVariableBinding(SecretLocalDeclarationName, type, ClassFileConstants.AccDefault, false);
-	this.scope.addLocalVariable(this.synchroVariable);
-	this.synchroVariable.setConstant(Constant.NotAConstant); // not inlinable
-	this.expression.computeConversion(this.scope, type, type);
 	this.block.resolveUsing(this.scope);
 }
\ No newline at end of file
","Bug 465048 - Bindings are null inside synchronized blocks

Resolve the block-part of a synchronized block, even if the synchronized
variable can't be resolved.

Change-Id: I3ed513fa21b10ae9c7fa39f1a94fe85fb98e5eb9
Signed-off-by: Carmi Grushko <carmi@google.com>
",Buggy
eclipseJdt,25918.json,8986600df161cd7584749fb6a28497a308fa862c,"@@ -1,5 +1,3 @@
 public boolean requireExtendedRecovery() {
-	if (this.assistNode instanceof TypeReference || this.assistNode instanceof CompletionOnKeyword2)
-		return false;
 	return lastIndexOfElement(K_LAMBDA_EXPRESSION_DELIMITER) >= 0;
 }
\ No newline at end of file
","Fixed Bug 427463 - [1.8][content assist] No completions available in
throw statement within lambda body ",Buggy
eclipseJdt,17024.json,c554caa948bbe051a5aeee635338c74832d8067f,"@@ -1,16 +1,15 @@
 	public static Token fromCurrent(Scanner scanner, int currentToken) {
 		int start = scanner.getCurrentTokenStartPosition();
 		int end = scanner.getCurrentTokenEndPosition();
 		if (currentToken == TokenNameCOMMENT_LINE) {
 			// don't include line separator
-			String source = scanner.getCurrentTokenString();
-			for (int i = source.length() - 1; i > 0; i--) {
-				char c = source.charAt(i);
+			while(end >= start) {
+				char c = scanner.source[end];
 				if (c != '\r' && c != '\n')
 					break;
 				end--;
 			}
 		}
 		Token token = new Token(start, end, currentToken);
 		return token;
 	}
\ No newline at end of file
","Fixed bug 471090: Java Code Formatter breaks code if single line
comments contains unicode escape

Change-Id: Id2c901c7853e4062182163ef714afc0e43833baf
Signed-off-by: Till Brychcy <register.eclipse@brychcy.de>
",Buggy
eclipseJdt,1305.json,63969f0e42bcdfc0a055ac0f3d2f47fa48cf3e29,"@@ -1,7 +1,9 @@
 protected void consumeCastExpressionLL1WithBounds() {
 	super.consumeCastExpressionLL1WithBounds();
 	if ((this.patternFineGrain & IJavaSearchConstants.CAST_TYPE_REFERENCE) != 0) {
 		CastExpression castExpression = (CastExpression) this.expressionStack[this.expressionPtr];
-		this.patternLocator.match(castExpression.type, this.nodeSet);
+		TypeReference[] typeReferences = ((IntersectionCastTypeReference) castExpression.type).typeReferences;
+		for (int i = 0, length = typeReferences.length; i < length; i++)
+			this.patternLocator.match(typeReferences[i], this.nodeSet);
 	}
 }
\ No newline at end of file
","Fixed Bug 427537 - [1.8][search] CCE with search match location set to
cast type and intersection casts",Buggy
eclipseJdt,17644.json,f7608e255b7a2e7cde81de854a6575f0fb055925,"@@ -1,20 +1,20 @@
 public char[] getMainTypeName() {
 	if (this.mainTypeName == null) {
 		int start = CharOperation.lastIndexOf('/', this.fileName) + 1;
 		if (start == 0 || start < CharOperation.lastIndexOf('\\', this.fileName))
 			start = CharOperation.lastIndexOf('\\', this.fileName) + 1;
-		int separator = CharOperation.indexOf('|', this.fileName) + 1;
+		int separator = CharOperation.lastIndexOf('|', this.fileName) + 1;
 		if (separator > start) // case of a .class file in a default package in a jar
 			start = separator;
 
 		int end = CharOperation.lastIndexOf('$', this.fileName);
 		if (end == -1 || !Util.isClassFileName(this.fileName)) {
 			end = CharOperation.lastIndexOf('.', this.fileName);
 			if (end == -1)
 				end = this.fileName.length;
 		}
 
 		this.mainTypeName = CharOperation.subarray(this.fileName, start, end);
 	}
 	return this.mainTypeName;
 }
\ No newline at end of file
","Fix for bug 515484 [1.9] [dom ast] ast not generated for
module-info.class  ",Buggy
eclipseJdt,19098.json,302894c7bc98fd880776f5e317788c7b3da88ebe,"@@ -1,23 +1,23 @@
 protected void recordParticipantResult(CompilationParticipantResult result) {
 	// any added/changed/deleted generated files have already been taken care
 	// just record the problems and dependencies - do not expect there to be many
 	// must be called after we're finished with the compilation unit results but before incremental loop adds affected files
 	CategorizedProblem[] problems = result.problems;
 	if (problems != null && problems.length > 0) {
 		// existing problems have already been removed so just add these as new problems
 		this.notifier.updateProblemCounts(problems);
 		try {
 			storeProblemsFor(result.sourceFile, problems);
 		} catch (CoreException e) {
 			// must continue with compile loop so just log the CoreException
 			Util.log(e, ""JavaBuilder logging CompilationParticipant's CoreException to help debugging""); //$NON-NLS-1$
 		}
 	}
 
 	String[] dependencies = result.dependencies;
 	if (dependencies != null) {
-		ReferenceCollection refs = (ReferenceCollection) this.newState.references.get(result.sourceFile.typeLocator());
+		ReferenceCollection refs = this.newState.references.get(result.sourceFile.typeLocator());
 		if (refs != null)
 			refs.addDependencies(dependencies);
 	}
 }
\ No newline at end of file
","Bug 563030 - builder.State: SimpleLookupTable performance does not
scale

- resolve new warning

Change-Id: I20cd500a7872eaa5cbda532f8f316d1a4168a3d9
",Buggy
eclipseJdt,25968.json,15950deb058261ec048eb3ddbd1c2ef13df604e6,"@@ -1,29 +1,30 @@
 private CodeSnippetToCuMapper getMapper() {
 	if (this.mapper == null) {
 		char[] varClassName = null;
 		VariablesInfo installedVars = this.context.installedVars;
 		if (installedVars != null) {
 			char[] superPackageName = installedVars.packageName;
 			if (superPackageName != null && superPackageName.length != 0) {
 				varClassName = CharOperation.concat(superPackageName, installedVars.className, '.');
 			} else {
 				varClassName = installedVars.className;
 			}
 
 		}
 		this.mapper = new CodeSnippetToCuMapper(
 			this.codeSnippet,
 			this.context.packageName,
 			this.context.imports,
 			getClassName(),
 			varClassName,
 			this.context.localVariableNames,
 			this.context.localVariableTypeNames,
 			this.context.localVariableModifiers,
 			this.context.declaringTypeName,
-			this.context.lineSeparator
+			this.context.lineSeparator,
+			CompilerOptions.versionToJdkLevel(this.options.get(JavaCore.COMPILER_COMPLIANCE))
 		);
 
 	}
 	return this.mapper;
 }
\ No newline at end of file
","HEAD - Fixed bug 345334: CodeSnippet's run method is missing @Override annotation
",Buggy
eclipseJdt,4105.json,35e2019a40c179f5dd02638e5bff541c41227721,"@@ -1,6 +1,9 @@
 	void recordResolution(LookupEnvironment env, TypeBinding typeFound) {
-		if (typeFound != null && typeFound.isValidBinding())
-			for (int i = 0; i < env.resolutionListeners.length; i++) {
-				env.resolutionListeners[i].recordResolution(this, typeFound);
+		if (typeFound != null && typeFound.isValidBinding()) {
+			synchronized (env.root) {
+				for (int i = 0; i < env.root.resolutionListeners.length; i++) {
+					env.root.resolutionListeners[i].recordResolution(this, typeFound);
+				}
 			}
+		}
 	}
\ No newline at end of file
","Fix for bug 519980 [9][search] search for a type does not return the
matches in provides 

Change-Id: I0059fa02a1040f10a8f4a949c07806018dee73b5",Buggy
eclipseJdt,11564.json,266fb0d2bc58e2f4f179d2c1279dee095ed53e45,"@@ -1,6 +1,6 @@
 public void generateSyntheticBodyForArrayConstructor(SyntheticMethodBinding methodBinding) {
 	initializeMaxLocals(methodBinding);
 	iload_0();
-	anewarray(((ArrayBinding) methodBinding.returnType).elementsType());
+	newArray(null, null, (ArrayBinding) methodBinding.returnType);
 	areturn();
 }
\ No newline at end of file
","Fixed Bug 424444 - [1.8] VerifyError when constructor reference used
with primitive array",Buggy
eclipseJdt,6346.json,409121a5eb3d3ef99ff5c31121bd10011631e82f,"@@ -1,61 +1,65 @@
 	private void checkAndSetModifiersForField(FieldBinding fieldBinding, FieldDeclaration fieldDecl) {
 		int modifiers = fieldBinding.modifiers;
 		final ReferenceBinding declaringClass = fieldBinding.declaringClass;
 		if ((modifiers & ExtraCompilerModifiers.AccAlternateModifierProblem) != 0)
 			problemReporter().duplicateModifierForField(declaringClass, fieldDecl);
 
 		if (declaringClass.isInterface()) {
 			final int IMPLICIT_MODIFIERS = ClassFileConstants.AccPublic | ClassFileConstants.AccStatic | ClassFileConstants.AccFinal;
 			// set the modifiers
 			modifiers |= IMPLICIT_MODIFIERS;
 
 			// and then check that they are the only ones
 			if ((modifiers & ExtraCompilerModifiers.AccJustFlag) != IMPLICIT_MODIFIERS) {
 				if ((declaringClass.modifiers  & ClassFileConstants.AccAnnotation) != 0)
 					problemReporter().illegalModifierForAnnotationField(fieldDecl);
 				else
 					problemReporter().illegalModifierForInterfaceField(fieldDecl);
 			}
 			fieldBinding.modifiers = modifiers;
 			return;
 		} else if (fieldDecl.getKind() == AbstractVariableDeclaration.ENUM_CONSTANT) {
 			// check that they are not modifiers in source
 			if ((modifiers & ExtraCompilerModifiers.AccJustFlag) != 0)
 				problemReporter().illegalModifierForEnumConstant(declaringClass, fieldDecl);
 
 			// set the modifiers
-			final int IMPLICIT_MODIFIERS = ClassFileConstants.AccPublic | ClassFileConstants.AccStatic | ClassFileConstants.AccFinal | ClassFileConstants.AccEnum;
+			// https://bugs.eclipse.org/bugs/show_bug.cgi?id=267670. Force all enumerators to be marked
+			// as used locally. We are unable to track the usage of these reliably as they could be used
+			// in non obvious ways via the synthesized methods values() and valueOf(String) or by using 
+			// Enum.valueOf(Class<T>, String).
+			final int IMPLICIT_MODIFIERS = ClassFileConstants.AccPublic | ClassFileConstants.AccStatic | ClassFileConstants.AccFinal | ClassFileConstants.AccEnum | ExtraCompilerModifiers.AccLocallyUsed;
 			fieldBinding.modifiers|= IMPLICIT_MODIFIERS;
 			return;
 		}
 
 		// after this point, tests on the 16 bits reserved.
 		int realModifiers = modifiers & ExtraCompilerModifiers.AccJustFlag;
 		final int UNEXPECTED_MODIFIERS = ~(ClassFileConstants.AccPublic | ClassFileConstants.AccPrivate | ClassFileConstants.AccProtected | ClassFileConstants.AccFinal | ClassFileConstants.AccStatic | ClassFileConstants.AccTransient | ClassFileConstants.AccVolatile);
 		if ((realModifiers & UNEXPECTED_MODIFIERS) != 0) {
 			problemReporter().illegalModifierForField(declaringClass, fieldDecl);
 			modifiers &= ~ExtraCompilerModifiers.AccJustFlag | ~UNEXPECTED_MODIFIERS;
 		}
 
 		int accessorBits = realModifiers & (ClassFileConstants.AccPublic | ClassFileConstants.AccProtected | ClassFileConstants.AccPrivate);
 		if ((accessorBits & (accessorBits - 1)) > 1) {
 			problemReporter().illegalVisibilityModifierCombinationForField(declaringClass, fieldDecl);
 
 			// need to keep the less restrictive so disable Protected/Private as necessary
 			if ((accessorBits & ClassFileConstants.AccPublic) != 0) {
 				if ((accessorBits & ClassFileConstants.AccProtected) != 0)
 					modifiers &= ~ClassFileConstants.AccProtected;
 				if ((accessorBits & ClassFileConstants.AccPrivate) != 0)
 					modifiers &= ~ClassFileConstants.AccPrivate;
 			} else if ((accessorBits & ClassFileConstants.AccProtected) != 0 && (accessorBits & ClassFileConstants.AccPrivate) != 0) {
 				modifiers &= ~ClassFileConstants.AccPrivate;
 			}
 		}
 
 		if ((realModifiers & (ClassFileConstants.AccFinal | ClassFileConstants.AccVolatile)) == (ClassFileConstants.AccFinal | ClassFileConstants.AccVolatile))
 			problemReporter().illegalModifierCombinationFinalVolatileForField(declaringClass, fieldDecl);
 
 		if (fieldDecl.initialization == null && (modifiers & ClassFileConstants.AccFinal) != 0)
 			modifiers |= ExtraCompilerModifiers.AccBlankFinal;
 		fieldBinding.modifiers = modifiers;
 	}
\ No newline at end of file
","Fix for bug #267670
",Buggy
eclipseJdt,4552.json,cc7009a12280dbb7a101bdbfbf1048948dc0093c,"@@ -1,66 +1,72 @@
 protected void verifyDuplicationAndOrder(int length, TypeBinding[] argumentTypes, boolean containsUnionTypes) {
 	// Verify that the catch clause are ordered in the right way:
 	// more specialized first.
 	if (containsUnionTypes) {
 		int totalCount = 0;
 		ReferenceBinding[][] allExceptionTypes = new ReferenceBinding[length][];
 		for (int i = 0; i < length; i++) {
+			if (argumentTypes[i] instanceof ArrayBinding)
+				continue;
 			ReferenceBinding currentExceptionType = (ReferenceBinding) argumentTypes[i];
 			TypeReference catchArgumentType = this.catchArguments[i].type;
 			if ((catchArgumentType.bits & ASTNode.IsUnionType) != 0) {
 				TypeReference[] typeReferences = ((UnionTypeReference) catchArgumentType).typeReferences;
 				int typeReferencesLength = typeReferences.length;
 				ReferenceBinding[] unionExceptionTypes = new ReferenceBinding[typeReferencesLength];
 				for (int j = 0; j < typeReferencesLength; j++) {
 					unionExceptionTypes[j] = (ReferenceBinding) typeReferences[j].resolvedType;
 				}
 				totalCount += typeReferencesLength;
 				allExceptionTypes[i] = unionExceptionTypes;
 			} else {
 				allExceptionTypes[i] = new ReferenceBinding[] { currentExceptionType };
 				totalCount++;
 			}
 		}
 		this.caughtExceptionTypes = new ReferenceBinding[totalCount];
 		this.caughtExceptionsCatchBlocks  = new int[totalCount];
 		for (int i = 0, l = 0; i < length; i++) {
 			ReferenceBinding[] currentExceptions = allExceptionTypes[i];
+			if (currentExceptions == null) continue;
 			loop: for (int j = 0, max = currentExceptions.length; j < max; j++) {
 				ReferenceBinding exception = currentExceptions[j];
 				this.caughtExceptionTypes[l] = exception;
 				this.caughtExceptionsCatchBlocks[l++] = i;
 				// now iterate over all previous exceptions
 				for (int k = 0; k < i; k++) {
 					ReferenceBinding[] exceptions = allExceptionTypes[k];
+					if (exceptions == null) continue;
 					for (int n = 0, max2 = exceptions.length; n < max2; n++) {
 						ReferenceBinding currentException = exceptions[n];
 						if (exception.isCompatibleWith(currentException)) {
 							TypeReference catchArgumentType = this.catchArguments[i].type;
 							if ((catchArgumentType.bits & ASTNode.IsUnionType) != 0) {
 								catchArgumentType = ((UnionTypeReference) catchArgumentType).typeReferences[j];
 							}
 							this.scope.problemReporter().wrongSequenceOfExceptionTypesError(
 								catchArgumentType,
 								exception,
 								currentException);
 							break loop;
 						}
 					}
 				}
 			}
 		}
 	} else {
 		this.caughtExceptionTypes = new ReferenceBinding[length];
 		for (int i = 0; i < length; i++) {
+			if (argumentTypes[i] instanceof ArrayBinding)
+				continue;
 			this.caughtExceptionTypes[i] = (ReferenceBinding) argumentTypes[i];
 			for (int j = 0; j < i; j++) {
 				if (this.caughtExceptionTypes[i].isCompatibleWith(argumentTypes[j])) {
 					this.scope.problemReporter().wrongSequenceOfExceptionTypesError(
 						this.catchArguments[i].type,
 						this.caughtExceptionTypes[i],
 						argumentTypes[j]);
 				}
 			}
 		}
 	}
 }
\ No newline at end of file
","Fixed bug 433879 - ArrayBinding cannot be cast to ReferenceBinding

Signed-off-by: Shankha Banerjee <shankhba@in.ibm.com>",Buggy
eclipseJdt,6311.json,c36a6a2b662267e56067d121b7f34ae48cbcb692,"@@ -1,16 +1,18 @@
 void checkInheritedMethods(MethodBinding inheritedMethod, MethodBinding otherInheritedMethod) {
 
 	// the 2 inherited methods clash because of a parameterized type overrides a raw type
 	//		interface I { void foo(A a); }
 	//		class Y { void foo(A<String> a) {} }
 	//		abstract class X extends Y implements I { }
 	//		class A<T> {}
 	// in this case the 2 inherited methods clash because of type variables
 	//		interface I { <T, S> void foo(T t); }
 	//		class Y { <T> void foo(T t) {} }
 	//		abstract class X extends Y implements I {}
 
-	if (inheritedMethod.declaringClass.isInterface() || inheritedMethod.isStatic()) return;
+	if (inheritedMethod.isStatic()) return;
+	if (this.environment.globalOptions.complianceLevel < ClassFileConstants.JDK1_7 && inheritedMethod.declaringClass.isInterface())
+		return;  // JDK7 checks for name clashes in interface inheritance, while JDK6 and below don't. See https://bugs.eclipse.org/bugs/show_bug.cgi?id=354229
 
 	detectInheritedNameClash(inheritedMethod.original(), otherInheritedMethod.original());
 }
\ No newline at end of file
","Fixed bug 354229: [compiler][1.7] Name clash error not being reported by
ecj.",Buggy
eclipseJdt,4397.json,7089fcfd703b096f125599a900905c00e15535fa,"@@ -1,30 +1,36 @@
 	public void getAllAnnotationContexts(int targetType, int typeParameterIndex, List allAnnotationContexts) {
 		AnnotationCollector collector = new AnnotationCollector(this, targetType, typeParameterIndex, allAnnotationContexts);
 		if (this.annotations != null) {
 			int annotationsLength = this.annotations.length;
 			for (int i = 0; i < annotationsLength; i++)
 				this.annotations[i].traverse(collector, (BlockScope) null);
 		}
 		switch(collector.targetType) {
 			case AnnotationTargetTypeConstants.CLASS_TYPE_PARAMETER :
 				collector.targetType = AnnotationTargetTypeConstants.CLASS_TYPE_PARAMETER_BOUND;
 				break;
 			case AnnotationTargetTypeConstants.METHOD_TYPE_PARAMETER :
 				collector.targetType = AnnotationTargetTypeConstants.METHOD_TYPE_PARAMETER_BOUND;
 		}
-		if (this.type != null && ((this.type.bits & ASTNode.HasTypeAnnotations) != 0)) {
-			collector.info2 = 0;
-			this.type.traverse(collector, (BlockScope) null);
+		int boundIndex = 0;
+		if (this.type != null) {
+			// boundIndex 0 is always a class
+			if (this.type.resolvedType.isInterface())
+				boundIndex = 1;
+			if ((this.type.bits & ASTNode.HasTypeAnnotations) != 0) {
+				collector.info2 = boundIndex;
+				this.type.traverse(collector, (BlockScope) null);
+			}
 		}
 		if (this.bounds != null) {
 			int boundsLength = this.bounds.length;
 			for (int i = 0; i < boundsLength; i++) {
 				TypeReference bound = this.bounds[i];
 				if ((bound.bits & ASTNode.HasTypeAnnotations) == 0) {
 					continue;
 				}
-				collector.info2 = i + 1;
+				collector.info2 = ++boundIndex;
 				bound.traverse(collector, (BlockScope) null);
 			}
 		}
 	}
\ No newline at end of file
","Fixed Bug 415543 - [1.8][compiler] Incorrect bound index in
RuntimeInvisibleTypeAnnotations attrribute

Signed-off-by: Andrew Clement <aclement@gopivotal.com>",Buggy
eclipseJdt,5447.json,3c8db8654fc8e2927c75863ec1232c9bc3800c9b,"@@ -1,31 +1,34 @@
 	public TypeBinding resolveType(BlockScope scope) {
 
 		if (this.compilerAnnotation != null)
 			return this.resolvedType;
 
 		this.constant = Constant.NotAConstant;
 
 		ReferenceBinding containerAnnotationType = (ReferenceBinding) this.resolvedType;
 		if (!containerAnnotationType.isValidBinding())
 			containerAnnotationType = (ReferenceBinding) containerAnnotationType.closestMatch();
 		Annotation repeatingAnnotation = this.containees[0];
 		ReferenceBinding repeatingAnnotationType = (ReferenceBinding) repeatingAnnotation.resolvedType;
+		if (!repeatingAnnotationType.isDeprecated() && isTypeUseDeprecated(containerAnnotationType, scope)) {
+			scope.problemReporter().deprecatedType(containerAnnotationType, repeatingAnnotation);
+		}
 		checkContainerAnnotationType(repeatingAnnotation, scope, containerAnnotationType, repeatingAnnotationType, true); // true => repeated *use* site error reporting requested.
 		this.resolvedType = containerAnnotationType = repeatingAnnotationType.containerAnnotationType();
 		if (!this.resolvedType.isValidBinding())
 			return this.resolvedType;
 		
 		// OK, the declaration site of the repeating annotation type as well as the use site where the annotations actually repeat pass muster. 
 		MethodBinding[] methods = containerAnnotationType.methods();
 		MemberValuePair pair = memberValuePairs()[0];
 		
 		for (int i = 0, length = methods.length; i < length; i++) {
 			MethodBinding method = methods[i];
 			if (CharOperation.equals(method.selector, TypeConstants.VALUE)) {
 				pair.binding = method;
 				pair.resolveTypeExpecting(scope, method.returnType);
 			}
 		}
 		this.compilerAnnotation = scope.environment().createAnnotation((ReferenceBinding) this.resolvedType, computeElementValuePairs());
 		return this.resolvedType;
 	}
\ No newline at end of file
","Follow up fixes for Bug 412153 - [1.8][compiler] Check validity of
annotations which may be repeatable",Buggy
eclipseJdt,3852.json,d15e79b3439bbaf42d22da90dbcfabf7ceac0248,"@@ -1,3 +1,3 @@
 public boolean isCompatibleWith(TypeBinding left, Scope scope) {
-	throw new UnsupportedOperationException(""Unexpected control flow, should not have reached Expression.isCompatibleWith""); //$NON-NLS-1$
+	return this.resolvedType != null && this.resolvedType.isCompatibleWith(left,  scope);
 }
\ No newline at end of file
","Fixed Bug 426315 - [1.8][compiler] UnsupportedOperationException with
conditional expression ",Buggy
eclipseJdt,22376.json,883d74a76cfedfa8b3e490bff988420af3184ead,"@@ -1,23 +1,24 @@
 	private void pushOnCommentsStack(int start, int end) {
 
 		for (int i=start; i<=end; i++) {
+			if (this.scanner.commentPtr < i) break;
 			// First see if comment hasn't been already stored
 			int scannerStart = this.scanner.commentStarts[i]<0 ? -this.scanner.commentStarts[i] : this.scanner.commentStarts[i];
 			int commentStart = this.commentPtr == -1 ? -1 : (this.commentStarts[this.commentPtr]<0 ? -this.commentStarts[this.commentPtr] : this.commentStarts[this.commentPtr]);
 			if (commentStart == -1 ||  scannerStart > commentStart) {
 				int stackLength = this.commentStarts.length;
 				if (++this.commentPtr >= stackLength) {
 					System.arraycopy(
 						this.commentStarts, 0,
 						this.commentStarts = new int[stackLength + CommentIncrement], 0,
 						stackLength);
 					System.arraycopy(
 						this.commentStops, 0,
 						this.commentStops = new int[stackLength + CommentIncrement], 0,
 						stackLength);
 				}
 				this.commentStarts[this.commentPtr] = this.scanner.commentStarts[i];
 				this.commentStops[this.commentPtr] = this.scanner.commentStops[i];
 			}
 		}
 	}
\ No newline at end of file
","Fix for Bug 526996: CompilationUnit.setCommentTable(...) throws
IllegalStateException",Buggy
eclipseJdt,27085.json,1793b84adc002b2d6c63dad898df1777f10b28a0,"@@ -1,89 +1,89 @@
 	public boolean containsAnnotations() throws IOException {
 		State state = NORMAL;
 		
 		// for escaping quotes -- need to ignore the next single character
 		// Since this applies to all states it's handled separately
 		boolean seenBackslash = false;
 		
 		int c = getNext();
 		while (c != -1) {
 			
 			if (seenBackslash) {
 				// Skip one character
 				seenBackslash = false;
 			}
 			else if (c == '\\') {
 				// Skip the next character
 				seenBackslash = true;
 			}
 			else {
 				// Handle the character based on state
 				switch (state) {
 				
-				case (NORMAL) :
+				case NORMAL :
 					if (c == '@')
 						return true;
 					if (c == '/') {
 						state = SEEN_SLASH;
 					}
 					else if (c == '\'') {
 						state = IN_SINGLE_QUOTE;
 					}
 					else if (c == '\""') {
 						state = IN_DOUBLE_QUOTE;
 					}
 					break;
 					
-				case (SEEN_SLASH) :
+				case SEEN_SLASH :
 					if (c == '*') {
 						state = IN_COMMENT;
 					}
 					else if (c == '/') {
 						state = IN_SINGLE_LINE_COMMENT;
 					}
 					else {
 						state = NORMAL;
 					}
 					break;
 				
-				case (IN_COMMENT) :
+				case IN_COMMENT :
 					if (c == '*') {
 						state = IN_COMMENT_SEEN_STAR;
 					}
 					break;
 				
-				case (IN_COMMENT_SEEN_STAR) :
+				case IN_COMMENT_SEEN_STAR :
 					if (c == '/') {
 						state = NORMAL;
 					}
 					else {
 						state = IN_COMMENT;
 					}
 					break;
 					
-				case (IN_SINGLE_LINE_COMMENT) :
+				case IN_SINGLE_LINE_COMMENT :
 					if (c == '\n' || c == '\r') {
 						state = NORMAL;
 					}
 					break;
 					
-				case (IN_SINGLE_QUOTE) :
+				case IN_SINGLE_QUOTE :
 					if (c == '\'') {
 						state = NORMAL;
 					}
 					break;
 					
-				case (IN_DOUBLE_QUOTE) :
+				case IN_DOUBLE_QUOTE :
 					if (c == '\""') {
 						state = NORMAL;
 					}
 					break;
 					
 				default :
 					throw new IllegalStateException(""Unhandled state: "" + state);  //$NON-NLS-1$
 				}
 			}
 			c = getNext();
 		}
 		return false;
 	}
\ No newline at end of file
","jgarms: fix syntax error in switch/case usage that is not caught by eclipse. This allows compiling by javac.
",Buggy
eclipseJdt,6097.json,9a8f94b0b98db0b5d6b8eb4d27d568dc18fc1309,"@@ -1,18 +1,20 @@
 public ReferenceBinding anonymousOriginalSuperType() {
 	if (!isPrototype())
 		return ((LocalTypeBinding) this.prototype).anonymousOriginalSuperType();
+	if (this.superclass == null && this.scope != null)
+		return this.scope.getJavaLangObject();
 	
 	if (this.superInterfaces != Binding.NO_SUPERINTERFACES) {
 		return this.superInterfaces[0];
 	}
 	if ((this.tagBits & TagBits.HierarchyHasProblems) == 0) {
 		return this.superclass;
 	}
 	if (this.scope != null) {
 		TypeReference typeReference = this.scope.referenceContext.allocation.type;
 		if (typeReference != null) {
 			return (ReferenceBinding) typeReference.resolvedType;
 		}
 	}
 	return this.superclass; // default answer
 }
\ No newline at end of file
","Fixed Bug 435348 - [1.8][compiler] NPE in JDT Core during AST creation

Signed-off-by: shankha banerjee <shankhba@in.ibm.com>",Buggy
eclipseJdt,20759.json,c71a2dd3276b1c054fbb64a586af2db8d142bd3f,"@@ -1,61 +1,66 @@
 	protected void seekTypesInSourcePackage(
 			String name,
 			IPackageFragment pkg,
 			int firstDot,
 			boolean partialMatch,
 			String topLevelTypeName,
 			int acceptFlags,
 			IJavaElementRequestor requestor) {
 
 		long start = -1;
 		if (VERBOSE)
 			start = System.currentTimeMillis();
 		try {
 			if (!partialMatch) {
 				try {
 					IJavaElement[] compilationUnits = pkg.getChildren();
 					for (int i = 0, length = compilationUnits.length; i < length; i++) {
 						if (requestor.isCanceled())
 							return;
 						IJavaElement cu = compilationUnits[i];
 						String cuName = cu.getElementName();
 						int lastDot = cuName.lastIndexOf('.');
 						if (lastDot != topLevelTypeName.length() || !topLevelTypeName.regionMatches(0, cuName, 0, lastDot))
 							continue;
+
+						// https://bugs.eclipse.org/bugs/show_bug.cgi?id=351697
+						// If we are looking at source location, just ignore binary types
+						if (!(cu instanceof ICompilationUnit))
+							continue;
 						IType type = ((ICompilationUnit) cu).getType(topLevelTypeName);
 						type = getMemberType(type, name, firstDot);
 						if (acceptType(type, acceptFlags, true/*a source type*/)) { // accept type checks for existence
 							requestor.acceptType(type);
 							break;  // since an exact match was requested, no other matching type can exist
 						}
 					}
 				} catch (JavaModelException e) {
 					// package doesn't exist -> ignore
 				}
 			} else {
 				try {
 					String cuPrefix = firstDot == -1 ? name : name.substring(0, firstDot);
 					IJavaElement[] compilationUnits = pkg.getChildren();
 					for (int i = 0, length = compilationUnits.length; i < length; i++) {
 						if (requestor.isCanceled())
 							return;
 						IJavaElement cu = compilationUnits[i];
 						if (!cu.getElementName().toLowerCase().startsWith(cuPrefix))
 							continue;
 						try {
 							IType[] types = ((ICompilationUnit) cu).getTypes();
 							for (int j = 0, typeLength = types.length; j < typeLength; j++)
 								seekTypesInTopLevelType(name, firstDot, types[j], requestor, acceptFlags);
 						} catch (JavaModelException e) {
 							// cu doesn't exist -> ignore
 						}
 					}
 				} catch (JavaModelException e) {
 					// package doesn't exist -> ignore
 				}
 			}
 		} finally {
 			if (VERBOSE)
 				this.timeSpentInSeekTypesInSourcePackage += System.currentTimeMillis()-start;
 		}
 	}
\ No newline at end of file
","master - Fix for bug 351697: ClassCastException while copying a .class file
to wrong source package
",Buggy
eclipseJdt,17605.json,0aa34db9e617bf74b6393bf5508b95dcdaed80af,"@@ -1,10 +1,11 @@
 protected void consumeMethodHeaderName(boolean isAnnotationMethod) {
 	long selectorSourcePositions = this.identifierPositionStack[this.identifierPtr];
 	int selectorSourceEnd = (int) selectorSourcePositions;
 	int currentAstPtr = this.astPtr;
 	super.consumeMethodHeaderName(isAnnotationMethod);
 	if (this.astPtr > currentAstPtr) { // if ast node was pushed on the ast stack
 		this.sourceEnds.put(this.astStack[this.astPtr], selectorSourceEnd);
 		rememberCategories();
 	}
+	flushCommentsDefinedPriorTo(this.scanner.currentPosition);
 }
\ No newline at end of file
","Fix for Bug 443942 Reconciler reports AST with wrong node range (with
comment after return type)",Buggy
eclipseJdt,6321.json,93b912e3753e060958c1b01615e164e0662ca645,"@@ -1,10 +1,10 @@
 MethodBinding findReplacedMethod(MethodBinding specific, MethodBinding general) {
 	MethodBinding generalSubstitute = computeSubstituteMethod(general, specific);
 	if (generalSubstitute != null 
-			&& (!specific.isAbstract() || general.isAbstract())	// if (abstract(specific) => abstract(general)) check if 'specific' overrides 'general' 
+			&& (!specific.isAbstract() || general.isAbstract() || (general.isDefaultMethod() && specific.declaringClass.isClass()))	// if (abstract(specific) => abstract(general)) check if 'specific' overrides 'general' 
 			&& isSubstituteParameterSubsignature(specific, generalSubstitute)) 
 	{
 		return generalSubstitute;
 	} 
 	return null;
 }
\ No newline at end of file
","Fixed Bug 426318 - [1.8][compiler] Bogus name clash error in the
presence of default methods and varargs",Buggy
commons-lang,3021.json,e582456625cc8a7056cc9354d2a75913f4ceb393,"@@ -1,46 +1,48 @@
     private void init() {
         thisYear= Calendar.getInstance(timeZone, locale).get(Calendar.YEAR);
         
         nameValues= new ConcurrentHashMap<Integer, KeyValue[]>();
         
         StringBuilder regex= new StringBuilder();
         List<Strategy> collector = new ArrayList<Strategy>();
         
         Matcher patternMatcher= formatPattern.matcher(pattern);
         if(!patternMatcher.lookingAt()) {
             throw new IllegalArgumentException(""Invalid pattern"");
         }
 
-        String localeName = locale.toString();
         // These locales don't use the Gregorian calendar
         // See http://docs.oracle.com/javase/6/docs/technotes/guides/intl/calendar.doc.html
-        if (localeName.equals(""ja_JP_JP"") || localeName.startsWith(""th_TH"")) {
+        // Also, the getEras() methods don't return the correct era names.
+        // N.B. Not safe to use toString() comparison because that changes between Java versions
+        if (locale.equals(JAPANESE_IMPERIAL)
+        || (locale.getLanguage().equals(""th"") && locale.getCountry().equals(""TH""))) {
             collector.add(new SimpleDateFormatStrategy());
             strategies= collector.toArray(new Strategy[collector.size()]);
             parsePattern= Pattern.compile(""(.*+)"");
             return;
         }
 
         currentFormatField= patternMatcher.group();
         Strategy currentStrategy= getStrategy(currentFormatField);
         for(;;) {
             patternMatcher.region(patternMatcher.end(), patternMatcher.regionEnd());
             if(!patternMatcher.lookingAt()) {
                 nextStrategy = null;
                 break;
             }
             String nextFormatField= patternMatcher.group();
             nextStrategy = getStrategy(nextFormatField);
             if(currentStrategy.addRegex(this, regex)) {
                 collector.add(currentStrategy);                
             }
             currentFormatField= nextFormatField;
             currentStrategy= nextStrategy;
         }
         if(currentStrategy.addRegex(this, regex)) {
             collector.add(currentStrategy);                
         }
         currentFormatField= null;
         strategies= collector.toArray(new Strategy[collector.size()]);
         parsePattern= Pattern.compile(regex.toString());
     }
\ No newline at end of file
","LANG-828 FastDateParser does not handle non-Gregorian calendars properly
Fix bug in Java 7 (Locale.toString() format has changed)

git-svn-id: https://svn.apache.org/repos/asf/commons/proper/lang/trunk@1390189 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
commons-lang,734.json,fbb0f7f88c84001e0a92dae6a71b7e43bda65a56,"@@ -1,54 +1,58 @@
     public static String wrap(final String str, int wrapLength, String newLineStr, final boolean wrapLongWords) {
         if (str == null) {
             return null;
         }
         if (newLineStr == null) {
             newLineStr = SystemUtils.LINE_SEPARATOR;
         }
         if (wrapLength < 1) {
             wrapLength = 1;
         }
         final int inputLineLength = str.length();
         int offset = 0;
         final StringBuilder wrappedLine = new StringBuilder(inputLineLength + 32);
         
-        while (inputLineLength - offset > wrapLength) {
+        while (offset < inputLineLength) {
             if (str.charAt(offset) == ' ') {
                 offset++;
                 continue;
             }
+            // only last line without leading spaces is left
+            if(inputLineLength - offset <= wrapLength) {
+                break;
+            }
             int spaceToWrapAt = str.lastIndexOf(' ', wrapLength + offset);
 
             if (spaceToWrapAt >= offset) {
                 // normal case
                 wrappedLine.append(str.substring(offset, spaceToWrapAt));
                 wrappedLine.append(newLineStr);
                 offset = spaceToWrapAt + 1;
                 
             } else {
                 // really long word or URL
                 if (wrapLongWords) {
                     // wrap really long word one line at a time
                     wrappedLine.append(str.substring(offset, wrapLength + offset));
                     wrappedLine.append(newLineStr);
                     offset += wrapLength;
                 } else {
                     // do not wrap really long word, just extend beyond limit
                     spaceToWrapAt = str.indexOf(' ', wrapLength + offset);
                     if (spaceToWrapAt >= 0) {
                         wrappedLine.append(str.substring(offset, spaceToWrapAt));
                         wrappedLine.append(newLineStr);
                         offset = spaceToWrapAt + 1;
                     } else {
                         wrappedLine.append(str.substring(offset));
                         offset = inputLineLength;
                     }
                 }
             }
         }
 
         // Whatever is left in line is short enough to just pass through
         wrappedLine.append(str.substring(offset));
 
         return wrappedLine.toString();
     }
\ No newline at end of file
","LANG-995: Fix bug with stripping spaces on last line in WordUtils.wrap(). This fixes #18 from github. Thanks to Andrey Khobnya

git-svn-id: https://svn.apache.org/repos/asf/commons/proper/lang/trunk@1586649 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
commons-lang,1056.json,cd9922ef8b2c57ed6aa1390f89f94c1c40cdc67c,"@@ -1,6 +1,6 @@
     protected void setArrayEnd(String arrayEnd) {
-        if (arrayStart == null) {
-            arrayStart = """";
+        if (arrayEnd == null) {
+            arrayEnd = """";
         }
         this.arrayEnd = arrayEnd;
     }
\ No newline at end of file
","ToStringStyle setArrayEnd handled null incorrectly
bug 31933, fix from Masato Tezuka


git-svn-id: https://svn.apache.org/repos/asf/jakarta/commons/proper/lang/trunk@138011 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
commons-lang,816.json,2d17989e282e67c9c37153adc4074082d3a38b1c,"@@ -1,7 +1,7 @@
     public CompareToBuilder appendSuper(int superCompareTo) {
         if (comparison != 0) {
             return this;
         }
-        comparison = superHashCode;
+        comparison = superCompareTo;
         return this;
     }
\ No newline at end of file
","Fix stupid compile error....


git-svn-id: https://svn.apache.org/repos/asf/jakarta/commons/proper/lang/trunk@137489 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
commons-lang,816.json,dbe97c09cad3ba2c7473c15778773fa4d071e7de,"@@ -1,7 +1,7 @@
-    public CompareToBuilder appendSuper(int superHashCode) {
+    public CompareToBuilder appendSuper(int superCompareTo) {
         if (comparison != 0) {
             return this;
         }
         comparison = superHashCode;
         return this;
     }
\ No newline at end of file
","Javadoc fixes
bug 21758, from Pete Gieser


git-svn-id: https://svn.apache.org/repos/asf/jakarta/commons/proper/lang/trunk@137487 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
commons-lang,183.json,8cafd87c83f4197f7e8d14de8cba453c844266c0,"@@ -1,20 +1,20 @@
     public static List<Method> getMethodsListWithAnnotation(final Class<?> cls,
                                                             final Class<? extends Annotation> annotationCls,
                                                             boolean searchSupers, boolean ignoreAccess) {
 
         Validate.isTrue(cls != null, ""The class must not be null"");
         Validate.isTrue(annotationCls != null, ""The annotation class must not be null"");
         List<Class<?>> classes = (searchSupers ? getAllSuperclassesAndInterfaces(cls)
                 : new ArrayList<Class<?>>());
-        classes.add(cls);
+        classes.add(0, cls);
         final List<Method> annotatedMethods = new ArrayList<>();
         for (Class<?> acls : classes) {
             final Method[] methods = (ignoreAccess ? acls.getDeclaredMethods() : acls.getMethods());
             for (final Method method : methods) {
                 if (method.getAnnotation(annotationCls) != null) {
                     annotatedMethods.add(method);
                 }
             }
         }
         return annotatedMethods;
     }
\ No newline at end of file
","LANG-1317: Add MethodUtils#findAnnotation and extend MethodUtils#getMethodsWithAnnotation for non-public, super-class and interface methods

fix bug introduced by last commit
",Buggy
commons-lang,2681.json,82c5dada6f7b369b69c383aa995f45578325e139,"@@ -1,15 +1,15 @@
-    private static void removeCommonFrames(List causeFrames, List wrapperFrames) {
+    public static void removeCommonFrames(List causeFrames, List wrapperFrames) {
         int causeFrameIndex = causeFrames.size() - 1;
         int wrapperFrameIndex = wrapperFrames.size() - 1;
         while (causeFrameIndex >= 0 && wrapperFrameIndex >= 0) {
             // Remove the frame from the cause trace if it is the same
             // as in the wrapper trace
             String causeFrame = (String) causeFrames.get(causeFrameIndex);
             String wrapperFrame = (String) wrapperFrames.get(wrapperFrameIndex);
             if (causeFrame.equals(wrapperFrame)) {
                 causeFrames.remove(causeFrameIndex);
             }
             causeFrameIndex--;
             wrapperFrameIndex--;
         }
     }
\ No newline at end of file
","Bug #14357 fixed. Mohan's patch makes removeCommonFrames public, and adds an
isThrowableNested to ExceptionUtils.

It adds static attributes to decide if the stack trace should be topDown
and if the stack traces should be trimmed on repeat. If running 1.4 or higher,
it uses the default stack trace, and the functionality of NestableError,
NestableException and NestableRuntimeException getMessage()s all change.
Accompanying these changes are numerous tests.

Submitted by:	Mohan Kishore


git-svn-id: https://svn.apache.org/repos/asf/jakarta/commons/proper/lang/trunk@137314 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
commons-lang,2064.json,f1ba9c252d99b3adf2bb3750339b895b2c097bd2,"@@ -1,16 +1,17 @@
         protected Class<?> resolveClass(ObjectStreamClass desc) throws IOException, ClassNotFoundException {
             String name = desc.getName();
             try {
                 return Class.forName(name, false, classLoader);
             } catch (ClassNotFoundException ex) {
                 try {
                     return Class.forName(name, false, Thread.currentThread().getContextClassLoader());
                 } catch (ClassNotFoundException cnfe) {
                     Class<?> cls = primitiveTypes.get(name);
-                    if (cls != null)
+                    if (cls != null) {
                         return cls;
-                    else
+                    } else {
                         throw cnfe;
+                    }
                 }
             }
         }
\ No newline at end of file
","Applying Benedikt Ritter's patch to fix the Checkstyle error in SerializationUtils - LANG-793

git-svn-id: https://svn.apache.org/repos/asf/commons/proper/lang/trunk@1301321 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
elasticsearch,60742.json,f2411253026503954da172ddd0b1bf77789dd476,"@@ -1,3 +1,3 @@
     public boolean snapshot() {
-        return snapshot != null && snapshot;
+        return snapshot;
     }
\ No newline at end of file
","Internal: Change snapshot state for unreleased versions and add
validation tests for constants

Currently the snapshot flag for Version constants is only set to true
for CURRENT.  However, this means that the snapshot state changes from
branch to branch.  Instead, snapshot should be ""is this version
released?"".  This change also adds a validation test checking that
ID -> constant and vice versa are correct, and fixes one bug found there
(for an unreleased version).
",Buggy
elasticsearch,52357.json,1a915446037ab83ae292df8733e7ba7d63bb667e,"@@ -1,15 +1,16 @@
     public RestStatus status() {
         if (shardFailures.length == 0) {
-            // if no successful shards, it means no active shards, so just return SERVICE_UNAVAILABLE
-            return RestStatus.SERVICE_UNAVAILABLE;
+            // if no successful shards, the failure can be due to EsRejectedExecutionException during fetch phase
+            // on coordinator node. so get the status from cause instead of returning SERVICE_UNAVAILABLE blindly
+            return getCause() == null ? RestStatus.SERVICE_UNAVAILABLE : ExceptionsHelper.status(getCause());
         }
         RestStatus status = shardFailures[0].status();
         if (shardFailures.length > 1) {
             for (int i = 1; i < shardFailures.length; i++) {
                 if (shardFailures[i].status().getStatus() >= 500) {
                     status = shardFailures[i].status();
                 }
             }
         }
         return status;
     }
\ No newline at end of file
","Fixing 503 Service Unavailable errors during fetch phase  (#39086)

When ESRejectedExecutionException gets thrown on the coordinating node while trying to fetch hits, the resulting exception will hold no shard failures, hence `503` is used as the response status code. In that case, `429` should be returned instead. Also, the status code should be taken from the cause if available whenever there are no shard failures instead of blindly returning `503` like we currently do.

Closes #38586",Buggy
elasticsearch,47411.json,f0f2b261595e2f5ea48736eac7a4e4121dd20b2c,"@@ -1,21 +1,21 @@
     public static int getRoutingFactor(int sourceNumberOfShards, int targetNumberOfShards) {
         final int factor;
         if (sourceNumberOfShards < targetNumberOfShards) { // split
             factor = targetNumberOfShards / sourceNumberOfShards;
             if (factor * sourceNumberOfShards != targetNumberOfShards || factor <= 1) {
-                throw new IllegalArgumentException(""the number of source shards ["" + sourceNumberOfShards + ""] must be a must be a "" +
+                throw new IllegalArgumentException(""the number of source shards ["" + sourceNumberOfShards + ""] must be a "" +
                     ""factor of [""
                     + targetNumberOfShards + ""]"");
             }
         } else if (sourceNumberOfShards > targetNumberOfShards) { // shrink
             factor = sourceNumberOfShards / targetNumberOfShards;
             if (factor * targetNumberOfShards != sourceNumberOfShards || factor <= 1) {
-                throw new IllegalArgumentException(""the number of source shards ["" + sourceNumberOfShards + ""] must be a must be a "" +
+                throw new IllegalArgumentException(""the number of source shards ["" + sourceNumberOfShards + ""] must be a "" +
                     ""multiple of [""
                     + targetNumberOfShards + ""]"");
             }
         } else {
             factor = 1;
         }
         return factor;
     }
\ No newline at end of file
","Fix duplicate phrase in shrink/split error message (#36734)

This commit removes a duplicate ""must be a"" from the shrink/split error
messages.",Buggy
elasticsearch,8045.json,92f24c967ae2ad22a728ff43de231cf351b92fd2,"@@ -1,39 +1,39 @@
         protected MultiSearchResponse shardOperation(Request request, ShardId shardId) throws IOException {
             final IndexService indexService = indicesService.indexService(shardId.getIndex());
             final IndexShard indexShard = indicesService.getShardOrNull(shardId);
             try (Engine.Searcher searcher = indexShard.acquireSearcher(""enrich_msearch"")) {
                 final FieldsVisitor visitor = new FieldsVisitor(true);
                 final QueryShardContext context = indexService.newQueryShardContext(shardId.id(),
-                    searcher.getIndexReader(), () -> {throw new UnsupportedOperationException();}, null);
+                    searcher, () -> {throw new UnsupportedOperationException();}, null);
                 final MapperService mapperService = context.getMapperService();
                 final Text typeText = mapperService.documentMapper().typeText();
 
                 final MultiSearchResponse.Item[] items = new MultiSearchResponse.Item[request.multiSearchRequest.requests().size()];
                 for (int i = 0; i < request.multiSearchRequest.requests().size(); i++) {
                     final SearchSourceBuilder searchSourceBuilder = request.multiSearchRequest.requests().get(i).source();
 
                     final QueryBuilder queryBuilder = searchSourceBuilder.query();
                     final int from = searchSourceBuilder.from();
                     final int size = searchSourceBuilder.size();
                     final FetchSourceContext fetchSourceContext = searchSourceBuilder.fetchSource();
 
                     final Query luceneQuery = queryBuilder.rewrite(context).toQuery(context);
                     final int n = from + size;
                     final TopDocs topDocs = searcher.search(luceneQuery, n, new Sort(SortField.FIELD_DOC));
 
                     final SearchHit[] hits = new SearchHit[topDocs.scoreDocs.length];
                     for (int j = 0; j < topDocs.scoreDocs.length; j++) {
                         final ScoreDoc scoreDoc = topDocs.scoreDocs[j];
 
                         visitor.reset();
                         searcher.doc(scoreDoc.doc, visitor);
                         visitor.postProcess(mapperService);
                         final SearchHit hit = new SearchHit(scoreDoc.doc, visitor.uid().id(), typeText, Map.of());
                         hit.sourceRef(filterSource(fetchSourceContext, visitor.source()));
                         hits[j] = hit;
                     }
                     items[i] = new MultiSearchResponse.Item(createSearchResponse(topDocs, hits), null);
                 }
                 return new MultiSearchResponse(items, 1L);
             }
         }
\ No newline at end of file
","fixed compile errors after merging
",Buggy
elasticsearch,32648.json,fa3d365ee83a089d461eacf66f2118f68dc1a8ed,"@@ -1,19 +1,25 @@
     public BytesReference slice(int from, int length) {
+        FutureObjects.checkFromIndexSize(from, length, this.length);
+
+        if (length == 0) {
+            return BytesArray.EMPTY;
+        }
+
         // for slices we only need to find the start and the end reference
         // adjust them and pass on the references in between as they are fully contained
         final int to = from + length;
-        final int limit = getOffsetIndex(from + length);
+        final int limit = getOffsetIndex(to - 1);
         final int start = getOffsetIndex(from);
         final BytesReference[] inSlice = new BytesReference[1 + (limit - start)];
         for (int i = 0, j = start; i < inSlice.length; i++) {
             inSlice[i] = references[j++];
         }
         int inSliceOffset = from - offsets[start];
         if (inSlice.length == 1) {
             return inSlice[0].slice(inSliceOffset, length);
         }
         // now adjust slices in front and at the end
         inSlice[0] = inSlice[0].slice(inSliceOffset, inSlice[0].length() - inSliceOffset);
         inSlice[inSlice.length-1] = inSlice[inSlice.length-1].slice(0, to - offsets[limit]);
         return new CompositeBytesReference(inSlice);
     }
\ No newline at end of file
","Fix CompositeBytesReference#slice to not throw AIOOBE with legal offsets. (#35955)

CompositeBytesReference#slice has two bugs:
 - One that makes it fail if the reference is empty and an empty slice is
   created, this is #35950 and is fixed by special-casing empty-slices.
 - One performance bug that makes it always create a composite slice when
   creating a slice that ends on a boundary, this is fixed by computing `limit`
   as the index of the sub reference that holds the last element rather than
   the next element after the slice.

Closes #35950
",Buggy
elasticsearch,53519.json,68c82cd113e0a79916ea9fce6546139de7753731,"@@ -1,15 +1,14 @@
     public static void writeDocumentRequest(StreamOutput out, DocumentWriteRequest request)  throws IOException {
-        assert request != null : ""request must not be null"";
         if (request instanceof IndexRequest) {
             out.writeByte((byte) 0);
         } else if (request instanceof DeleteRequest) {
             out.writeByte((byte) 1);
         } else if (request instanceof UpdateRequest) {
             out.writeByte((byte) 2);
         } else if (request instanceof UpdateReplicaRequest) {
             out.writeByte((byte) 3);
         } else {
             throw new IllegalStateException(""invalid request ["" + request.getClass().getSimpleName() + "" ]"");
         }
         request.writeTo(out);
     }
\ No newline at end of file
","Revert ""fix bug in bulk replication for noop update operation""

This reverts commit 42bc2d15bedb0f3b457bbfe06247311b9667b7c9.
",Buggy
elasticsearch,53519.json,42bc2d15bedb0f3b457bbfe06247311b9667b7c9,"@@ -1,14 +1,15 @@
     public static void writeDocumentRequest(StreamOutput out, DocumentWriteRequest request)  throws IOException {
+        assert request != null : ""request must not be null"";
         if (request instanceof IndexRequest) {
             out.writeByte((byte) 0);
         } else if (request instanceof DeleteRequest) {
             out.writeByte((byte) 1);
         } else if (request instanceof UpdateRequest) {
             out.writeByte((byte) 2);
         } else if (request instanceof UpdateReplicaRequest) {
             out.writeByte((byte) 3);
         } else {
             throw new IllegalStateException(""invalid request ["" + request.getClass().getSimpleName() + "" ]"");
         }
         request.writeTo(out);
     }
\ No newline at end of file
","fix bug in bulk replication for noop update operation
",Buggy
elasticsearch,9986.json,7e12d5a7958eb9f62fdb073863110dbd09b79747,"@@ -1,48 +1,48 @@
     private void buildUserFromClaims(JWTClaimsSet claims, ActionListener<AuthenticationResult> authResultListener) {
         final String principal = principalAttribute.getClaimValue(claims);
         if (Strings.isNullOrEmpty(principal)) {
             authResultListener.onResponse(AuthenticationResult.unsuccessful(
                 principalAttribute + ""not found in "" + claims.toJSONObject(), null));
             return;
         }
 
         final Map<String, Object> tokenMetadata = new HashMap<>();
         tokenMetadata.put(""id_token_hint"", claims.getClaim(""id_token_hint""));
         ActionListener<AuthenticationResult> wrappedAuthResultListener = ActionListener.wrap(auth -> {
             if (auth.isAuthenticated()) {
                 // Add the ID Token as metadata on the authentication, so that it can be used for logout requests
                 Map<String, Object> metadata = new HashMap<>(auth.getMetadata());
                 metadata.put(CONTEXT_TOKEN_DATA, tokenMetadata);
                 auth = AuthenticationResult.success(auth.getUser(), metadata);
             }
             authResultListener.onResponse(auth);
         }, authResultListener::onFailure);
 
         if (delegatedRealms.hasDelegation()) {
             delegatedRealms.resolve(principal, wrappedAuthResultListener);
             return;
         }
 
         final Map<String, Object> userMetadata;
         if (populateUserMetadata) {
             userMetadata = claims.getClaims().entrySet().stream().filter(entry -> {
                 /*
                  * We whitelist the Types that we want to parse as metadata from the Claims, explicitly filtering out {@link Date}s
                  */
                 Object v = entry.getValue();
-                return (v instanceof String || v instanceof Boolean || v instanceof Number || v instanceof Collections);
+                return (v instanceof String || v instanceof Boolean || v instanceof Number || v instanceof Collection);
             }).collect(Collectors.toUnmodifiableMap(entry -> ""oidc("" + entry.getKey() + "")"", Map.Entry::getValue));
         } else {
             userMetadata = Map.of();
         }
         final List<String> groups = groupsAttribute.getClaimValues(claims);
         final String dn = dnAttribute.getClaimValue(claims);
         final String mail = mailAttribute.getClaimValue(claims);
         final String name = nameAttribute.getClaimValue(claims);
         UserRoleMapper.UserData userData = new UserRoleMapper.UserData(principal, dn, groups, userMetadata, config);
         roleMapper.resolveRoles(userData, ActionListener.wrap(roles -> {
             final User user = new User(principal, roles.toArray(Strings.EMPTY_ARRAY), name, mail, userMetadata, true);
             wrappedAuthResultListener.onResponse(AuthenticationResult.success(user));
         }, wrappedAuthResultListener::onFailure));
 
     }
\ No newline at end of file
","Populate OpenIDConnect metadata collections (#50521)

The OpenIdConnectRealm had a bug which would cause it not to populate
User metadata for collections contained in the user JWT claims.

This commit fixes that bug.

Resolves: #50250",Buggy
elasticsearch,31859.json,cea2d21c50c5a680cbbaefba254866601b5b4608,"@@ -1,20 +1,20 @@
     private int findPlaceholderEndIndex(CharSequence buf, int startIndex) {
         int index = startIndex + this.placeholderPrefix.length();
         int withinNestedPlaceholder = 0;
         while (index < buf.length()) {
             if (Strings.substringMatch(buf, index, this.placeholderSuffix)) {
                 if (withinNestedPlaceholder > 0) {
                     withinNestedPlaceholder--;
-                    index = index + this.placeholderPrefix.length() - 1;
+                    index = index + this.placeholderSuffix.length();
                 } else {
                     return index;
                 }
             } else if (Strings.substringMatch(buf, index, this.placeholderPrefix)) {
                 withinNestedPlaceholder++;
                 index = index + this.placeholderPrefix.length();
             } else {
                 index++;
             }
         }
         return -1;
     }
\ No newline at end of file
","Fix bug in PropertyPlaceholder and add unit tests.

Close #6034
",Buggy
elasticsearch,52107.json,267cd65506ab22ceb7606243ef58979bde5dbfe5,"@@ -1,28 +1,28 @@
         public void start() {
             if (shardIt == null) {
                 // just execute it on the local node
                 transportService.sendRequest(clusterService.localNode(), transportShardAction, internalRequest.request(), new BaseTransportResponseHandler<Response>() {
                     @Override
                     public Response newInstance() {
                         return newResponse();
                     }
 
                     @Override
                     public String executor() {
                         return ThreadPool.Names.SAME;
                     }
 
                     @Override
                     public void handleResponse(final Response response) {
                         listener.onResponse(response);
                     }
 
                     @Override
                     public void handleException(TransportException exp) {
-                        perform(exp);
+                        listener.onFailure(exp);
                     }
                 });
             } else {
                 perform(null);
             }
         }
\ No newline at end of file
","Analysis : Fix no response from Analyze API without specified index

Fix error handling in TransportSingleShardAction without shardIt

Closes #15148
",Buggy
elasticsearch,11277.json,3b739b9fd5da2323a84b242708b64c16660113cc,"@@ -1,6 +1,6 @@
         protected ShardsIterator shards(ClusterState state, InternalRequest request) {
-            return state.routingTable()
-                    .index(request.concreteIndex())
-                    .shard(request.request().getShard().id())
+            return state
+                    .routingTable()
+                    .shardRoutingTable(request.concreteIndex(), request.request().getShard().id())
                     .activeInitializingShardsRandomIt();
         }
\ No newline at end of file
","Avoid NPE on shard changes action (#32630)

If a leader index is deleted while there is an active follower, the
follower will send shard changes requests bound for the leader
index. Today this will result in a null pointer exception because there
will not be an index routing table for the index. A null pointer
exception looks like a bug to a user so this commit addresses this by
throwing an index not found exception instead.",Buggy
elasticsearch,50555.json,03e8734b04d841e31724b10cf0d9c41801699411,"@@ -1,24 +1,29 @@
     private void getMultipleReposSnapshotInfo(List<RepositoryMetaData> repos, String[] snapshots, boolean ignoreUnavailable,
                                               boolean verbose, ActionListener<GetSnapshotsResponse> listener) {
+        // short-circuit if there are no repos, because we can not create GroupedActionListener of size 0
+        if (repos.isEmpty()) {
+            listener.onResponse(new GetSnapshotsResponse(Collections.emptyList()));
+            return;
+        }
         final GroupedActionListener<GetSnapshotsResponse.Response> groupedActionListener =
                 new GroupedActionListener<>(
                         ActionListener.map(listener, responses -> {
                             assert repos.size() == responses.size();
                             return new GetSnapshotsResponse(responses);
                         }), repos.size());
 
         // run concurrently for all repos on GENERIC thread pool
         for (final RepositoryMetaData repo : repos) {
             threadPool.executor(ThreadPool.Names.GENERIC).execute(new ActionRunnable<>(groupedActionListener) {
                 @Override
                 protected void doRun() {
                     try {
                         groupedActionListener.onResponse(GetSnapshotsResponse.Response.snapshots(
                                 repo.name(), getSingleRepoSnapshotInfo(repo.name(), snapshots, ignoreUnavailable, verbose)));
                     } catch (ElasticsearchException e) {
                         groupedActionListener.onResponse(GetSnapshotsResponse.Response.error(repo.name(), e));
                     }
                 }
             });
         }
     }
\ No newline at end of file
","Fix GET /_snapshot/_all/_all if there are no repos (#43558)

When there are no repositories, a request to GET /_snapshot/_all/_all
returns a 504 timeout error.
This happens because try to create GroupedActionListener with the
size of zero, which leads to an exception.
This commit short-circuits if there are no repos and adds a test to
verify the fix.

Closes #43547",Buggy
elasticsearch,35892.json,ba8ad9c2b727f9609e16aac6ed2df17f44c6b683,"@@ -1,3 +1,3 @@
     public long getAgeInMillis() {
-        return Math.max(0, (System.nanoTime() - creationDate) / 1000);
+        return TimeUnit.MILLISECONDS.convert(relativeTimeProvider.getAsLong() - creationDate, TimeUnit.NANOSECONDS);
     }
\ No newline at end of file
","Fix calculation of age of pending tasks

This commit addresses a time unit conversion bug in calculating the age
of a PrioritizedRunnable. The issue was an incorrect conversion from
nanoseconds to milliseconds as instead the conversion was to
microseconds. This leads to the timeInQueue metric for pending tasks to
be off by three orders of magnitude.
",Buggy
elasticsearch,55497.json,53f6dcfd375169c9847a6059253a1990fb7c99f5,"@@ -1,11 +1,11 @@
         private SpanQuery newSpanQuery(Term[] terms, boolean isPrefix) {
             if (terms.length == 1) {
                 return isPrefix ? fieldType.spanPrefixQuery(terms[0].text(), spanRewriteMethod, context) : new SpanTermQuery(terms[0]);
             }
             SpanQuery[] spanQueries = new SpanQuery[terms.length];
             for (int i = 0; i < terms.length; i++) {
-                spanQueries[i] = isPrefix ? new SpanTermQuery(terms[i]) :
-                    fieldType.spanPrefixQuery(terms[i].text(), spanRewriteMethod, context);
+                spanQueries[i] = isPrefix ? fieldType.spanPrefixQuery(terms[i].text(), spanRewriteMethod, context) :
+                    new SpanTermQuery(terms[i]);
             }
             return new SpanOrQuery(spanQueries);
         }
\ No newline at end of file
","Fix wrong logic in `match_phrase` query with multi-word synonyms (#43941)

Disjunction over two individual terms in a phrase query with multi-word synonyms
wrongly applies a prefix query to each of these terms. This change fixes this bug
by inversing the logic to use prefixes on `phrase_prefix` queries only.

Closes #43308",Buggy
elasticsearch,58217.json,a46d2f21c6504c8ff8cb98a2180293994b857a03,"@@ -1,10 +1,11 @@
     private static int expandCommonMappers(List<ObjectMapper> parentMappers, String[] nameParts, int i) {
         ObjectMapper last = parentMappers.get(parentMappers.size() - 1);
         while (i < nameParts.length - 1 && last.getMapper(nameParts[i]) != null) {
             Mapper newLast = last.getMapper(nameParts[i]);
             assert newLast instanceof ObjectMapper;
-            parentMappers.add((ObjectMapper)newLast);
+            last = (ObjectMapper) newLast;
+            parentMappers.add(last);
             ++i;
         }
         return i;
     }
\ No newline at end of file
","Fix dynamic mapper bug with deeply nested fields.
",Buggy
elasticsearch,63178.json,c33f894846989694f6d6fdc250ae396a88545c55,"@@ -1,19 +1,4 @@
         public Set<Entry<String, List<String>>> entrySet() {
-            return httpHeaders.names().stream().map(k -> new Entry<String, List<String>>() {
-
-                @Override
-                public String getKey() {
-                    return k;
-                }
-
-                @Override
-                public List<String> getValue() {
-                    return httpHeaders.getAll(k);
-                }
-
-                @Override
-                public List<String> setValue(List<String> value) {
-                    throw new UnsupportedOperationException(""modifications are not supported"");
-                }
-            }).collect(Collectors.toSet());
+            return httpHeaders.names().stream().map(k -> new AbstractMap.SimpleImmutableEntry<>(k, httpHeaders.getAll(k)))
+                    .collect(Collectors.toSet());
         }
\ No newline at end of file
","Fixing compilation problem in Eclipse (#22956)

",Buggy
elasticsearch,10846.json,70d524c979f90759901fd81f70c56172c311bd86,"@@ -1,7 +1,7 @@
     protected boolean shouldCollect() {
-        if (licensee.collectionEnabled()) {
+        if (!licensee.collectionEnabled()) {
             logger.trace(""collector [{}] can not collect data due to invalid license"", name());
             return false;
         }
         return true;
     }
\ No newline at end of file
","Marvel: Fix bug that prevent collectors to collect when license is enabled

Original commit: elastic/x-pack-elasticsearch@9f22baa2ee8f873e4123681d36bcbe759da619f1
",Buggy
elasticsearch,15635.json,00cecac86e03195a28f4bec92ccd8cc182a16132,"@@ -1,13 +1,15 @@
     public List<ExecutorBuilder<?>> getExecutorBuilders(final Settings settings) {
         if (enabled) {
-            final FixedExecutorBuilder builder =
-                    new FixedExecutorBuilder(
-                            settings,
+            final ScalingExecutorBuilder builder =
+                    new ScalingExecutorBuilder(
                             InternalWatchExecutor.THREAD_POOL_NAME,
+                            0,
+                            // watcher threads can block on I/O for a long time, so we let this
+                            // pool be large so that execution of unblocked watches can proceed
                             5 * EsExecutors.boundedNumberOfProcessors(settings),
-                            1000,
+                            TimeValue.timeValueMinutes(5),
                             ""xpack.watcher.thread_pool"");
             return Collections.singletonList(builder);
         }
         return Collections.emptyList();
     }
\ No newline at end of file
","Change Watcher thread pool to be scaling

Watcher uses a custom thread pool. This is because executing watches can
be long-running tasks that often block on I/O and it is best to not
consume the core thread pools with these tasks. Today this thread pool
is fixed, and sized at five times the bounded number of cores (so 160 on
a 32-core box). It makes sense for there to possibly be so many threads,
again because these tasks can block on I/O and having excess capacity
lets unblocked watches execute. It's the fixed size that can cause
problem, all these threads are always consuming resources even when
there are no or not that many watches running. This commit changes this
thread pool to be a scaling thread pool.

Relates elastic/elasticsearch#3660

Original commit: elastic/x-pack-elasticsearch@3cafab6e8360b17ecaf99d37bc1e024a9c7ff256
",Buggy
elasticsearch,11653.json,bca4edcd56fa984b9e712f9298e6f91a19983710,"@@ -1,76 +1,77 @@
     static Tuple<String, String> overrideFormatToGrokAndRegex(String overrideFormat) {
 
         if (overrideFormat.indexOf('\n') >= 0 || overrideFormat.indexOf('\r') >= 0) {
             throw new IllegalArgumentException(""Multi-line timestamp formats ["" + overrideFormat + ""] not supported"");
         }
 
         if (overrideFormat.indexOf(INDETERMINATE_FIELD_PLACEHOLDER) >= 0) {
             throw new IllegalArgumentException(""Timestamp format ["" + overrideFormat + ""] not supported because it contains [""
                 + INDETERMINATE_FIELD_PLACEHOLDER + ""]"");
         }
 
         StringBuilder grokPatternBuilder = new StringBuilder();
         StringBuilder regexBuilder = new StringBuilder();
 
         boolean notQuoted = true;
         char prevChar = '\0';
         String prevLetterGroup = null;
         int pos = 0;
         while (pos < overrideFormat.length()) {
             char curChar = overrideFormat.charAt(pos);
 
             if (curChar == '\'') {
                 notQuoted = !notQuoted;
             } else if (notQuoted && Character.isLetter(curChar)) {
                 int startPos = pos;
                 int endPos = startPos + 1;
                 while (endPos < overrideFormat.length() && overrideFormat.charAt(endPos) == curChar) {
                     ++endPos;
                     ++pos;
                 }
                 String letterGroup = overrideFormat.substring(startPos, endPos);
                 Tuple<String, String> grokPatternAndRegexForGroup = VALID_LETTER_GROUPS.get(letterGroup);
                 if (grokPatternAndRegexForGroup == null) {
                     // Special case of fractional seconds
                     if (curChar != 'S' || FRACTIONAL_SECOND_SEPARATORS.indexOf(prevChar) == -1 ||
                         ""ss"".equals(prevLetterGroup) == false || endPos - startPos > 9) {
                         String msg = ""Letter group ["" + letterGroup + ""] in ["" + overrideFormat + ""] is not supported"";
                         if (curChar == 'S') {
                             msg += "" because it is not preceded by [ss] and a separator from ["" + FRACTIONAL_SECOND_SEPARATORS + ""]"";
                         }
                         throw new IllegalArgumentException(msg);
                     }
-                    // No need to append to the Grok pattern as %{SECOND} already allows for an optional
-                    // fraction, but we need to remove the separator that's included in %{SECOND}
-                    grokPatternBuilder.deleteCharAt(grokPatternBuilder.length() - 1);
+                    // No need to append to the Grok pattern as %{SECOND} already allows for an optional fraction,
+                    // but we need to remove the separator that's included in %{SECOND} (and that might be escaped)
+                    int numCharsToDelete = (PUNCTUATION_THAT_NEEDS_ESCAPING_IN_REGEX.indexOf(prevChar) >= 0) ? 2 : 1;
+                    grokPatternBuilder.delete(grokPatternBuilder.length() - numCharsToDelete, grokPatternBuilder.length());
                     regexBuilder.append(""\\d{"").append(endPos - startPos).append('}');
                 } else {
                     grokPatternBuilder.append(grokPatternAndRegexForGroup.v1());
                     if (regexBuilder.length() == 0) {
                         regexBuilder.append(""\\b"");
                     }
                     regexBuilder.append(grokPatternAndRegexForGroup.v2());
                 }
                 if (pos + 1 == overrideFormat.length()) {
                     regexBuilder.append(""\\b"");
                 }
                 prevLetterGroup = letterGroup;
             } else {
                 if (PUNCTUATION_THAT_NEEDS_ESCAPING_IN_REGEX.indexOf(curChar) >= 0) {
                     grokPatternBuilder.append('\\');
                     regexBuilder.append('\\');
                 }
                 grokPatternBuilder.append(curChar);
                 regexBuilder.append(curChar);
             }
 
             prevChar = curChar;
             ++pos;
         }
 
         if (prevLetterGroup == null) {
             throw new IllegalArgumentException(""No time format letter groups in override format ["" + overrideFormat + ""]"");
         }
 
         return new Tuple<>(grokPatternBuilder.toString(), regexBuilder.toString());
     }
\ No newline at end of file
","[ML] Fix custom timestamp override with dot-separated fractional seconds (#44127)

Custom timestamp overrides provided to the find_file_structure
endpoint produced an invalid Grok pattern if the fractional
seconds separator was a dot rather than a comma or colon.
This commit fixes that problem and adds tests for this sort
of timestamp override.

Fixes #44110",Buggy
elasticsearch,26537.json,61f5c188e0a577555db382dd0fe9a4222da9df1a,"@@ -1,12 +1,12 @@
-    static Request openJob(OpenJobRequest openJobRequest) {
+    static Request openJob(OpenJobRequest openJobRequest) throws IOException {
         String endpoint = new EndpointBuilder()
                 .addPathPartAsIs(""_xpack"")
                 .addPathPartAsIs(""ml"")
                 .addPathPartAsIs(""anomaly_detectors"")
                 .addPathPart(openJobRequest.getJobId())
                 .addPathPartAsIs(""_open"")
                 .build();
         Request request = new Request(HttpPost.METHOD_NAME, endpoint);
         request.setEntity(createEntity(openJobRequest, REQUEST_BODY_CONTENT_TYPE));
         return request;
     }
\ No newline at end of file
","HLRC: Fix Compile Error From Missing Throws (#33083)

* 50441f97ae745814db96c262e99d0f465aca5b2c#diff-53a95fe7ded21313483f1b2f15977395L72 removed the throws breaking compilation here",Buggy
elasticsearch,54800.json,2637e499ac88ce0aa14db62b13be052e7ca78f98,"@@ -1,8 +1,8 @@
     protected final DirectoryReader wrapReader(DirectoryReader reader,
                                                     Function<DirectoryReader, DirectoryReader> readerWrapperFunction) throws IOException {
-        reader = ElasticsearchDirectoryReader.wrap(reader, engineConfig.getShardId());
         if (engineConfig.getIndexSettings().isSoftDeleteEnabled()) {
             reader = new SoftDeletesDirectoryReaderWrapper(reader, Lucene.SOFT_DELETES_FIELD);
         }
-        return readerWrapperFunction.apply(reader);
+        reader = readerWrapperFunction.apply(reader);
+        return ElasticsearchDirectoryReader.wrap(reader, engineConfig.getShardId());
     }
\ No newline at end of file
","Fix assertion error when caching the result of a search in a read-only index (#41900)

The ReadOnlyEngine wraps its reader with a SoftDeletesDirectoryReaderWrapper if soft deletes
are enabled. However the wrapping is done on top of the ElasticsearchDirectoryReader and that
trips assertion later on since the cache key of these directories are different. This commit
changes the order of the wrapping to put the ElasticsearchDirectoryReader first in order to
ensure that it is always retrieved first when we unwrap the directory.

Closes #41795
",Buggy
elasticsearch,31501.json,0f93b7abdf65425344f5cedda3e6b04b31e910d4,"@@ -1,3 +1,3 @@
-    static boolean needsReassignment(final Assignment assignment, final DiscoveryNodes nodes) {
+    public static boolean needsReassignment(final Assignment assignment, final DiscoveryNodes nodes) {
         return (assignment.isAssigned() == false || nodes.nodeExists(assignment.getExecutorNode()) == false);
     }
\ No newline at end of file
","Fix compilation errors in ML integration tests

After elastic/elasticsearch#29109, the `needsReassignment` method has
been moved to the PersistentTasksClusterService. This commit fixes
some compilation in tests I introduced.
",Buggy
elasticsearch,63560.json,63f33e0f1e045f5c345b80bdbc4b6f367e72aaad,"@@ -1,16 +1,18 @@
     public void writeTo(StreamOutput out) throws IOException {
+        // marshall doc count
+        out.writeGenericValue(docCount);
         // marshall fieldSum
         out.writeGenericValue(fieldSum);
         // counts
         out.writeGenericValue(counts);
         // mean
         out.writeGenericValue(means);
         // variances
         out.writeGenericValue(variances);
         // skewness
         out.writeGenericValue(skewness);
         // kurtosis
         out.writeGenericValue(kurtosis);
         // covariances
         out.writeGenericValue(covariances);
     }
\ No newline at end of file
","Serialize doc counts in Matrix-Stats module

This fixes a bug in the RunningStats class for the matrix stats aggregation module. doc counts were not being searlized which means they were only computed the first time the aggregation was computed. This was causing incorrect results when the aggregation was pulled from cache.
",Buggy
elasticsearch,62818.json,e6fb3a5d950c52ccba8cf1f0b0d6e819e70c243c,"@@ -1,15 +1,21 @@
     public void execute(IngestDocument document) {
         String oldVal = document.getFieldValue(field, String.class, ignoreMissing);
 
         if (oldVal == null && ignoreMissing) {
             return;
         } else if (oldVal == null) {
             throw new IllegalArgumentException(""field ["" + field + ""] is null, cannot extract key-value pairs."");
         }
 
         String fieldPathPrefix = (targetField == null) ? """" : targetField + ""."";
         Arrays.stream(oldVal.split(fieldSplit))
-            .map((f) -> f.split(valueSplit, 2))
+            .map((f) -> {
+                String[] kv = f.split(valueSplit, 2);
+                if (kv.length != 2) {
+                    throw new IllegalArgumentException(""field ["" + field + ""] does not contain value_split ["" + valueSplit + ""]"");
+                }
+                return kv;
+            })
             .filter((p) -> includeKeys == null || includeKeys.contains(p[0]))
             .forEach((p) -> append(document, fieldPathPrefix + p[0], p[1]));
     }
\ No newline at end of file
","fix index out of bounds error in KV Processor (#22288)

- checks for index-out-of-bounds
- added unit tests for failed `field_split` and `value_split` scenarios

missed this test in #22272.",Buggy
elasticsearch,31383.json,76cd7b1eb2cf7f87081c24ae6362ae1d9dec6100,"@@ -1,3 +1,3 @@
-        public Params getParams() {
+        public P getParams() {
             return params;
         }
\ No newline at end of file
","Fixes compile errors in Eclipse due to generics

PersistentTasksCustomMetadata was using a generic param named `Params`. This conflicted with the imported interface `ToXContent.Params`. The java compiler was preferring the generic param over the interface so everything was fine but Eclipse apparently prefers the interface int his case which was screwing up the Hierarchy and causing compile errors in Eclipse. This changes fixes it by renaming the Generic param to `P`
",Buggy
elasticsearch,18621.json,6236b3aee4c4ccf9a06ca94af4c4082b7fcf5cde,"@@ -1,32 +1,45 @@
     public ResourcePrivilegesMap checkResourcePrivileges(Set<String> checkForIndexPatterns, boolean allowRestrictedIndices,
                                                          Set<String> checkForPrivileges) {
         final ResourcePrivilegesMap.Builder resourcePrivilegesMapBuilder = ResourcePrivilegesMap.builder();
         final Map<IndicesPermission.Group, Automaton> predicateCache = new HashMap<>();
         for (String forIndexPattern : checkForIndexPatterns) {
-            final Automaton checkIndexAutomaton = IndicesPermission.Group.buildIndexMatcherAutomaton(allowRestrictedIndices,
-                    forIndexPattern);
-            Automaton allowedIndexPrivilegesAutomaton = null;
-            for (Group group : groups) {
-                final Automaton groupIndexAutomaton = predicateCache.computeIfAbsent(group,
-                        g -> IndicesPermission.Group.buildIndexMatcherAutomaton(g.allowRestrictedIndices(), g.indices()));
-                if (Operations.subsetOf(checkIndexAutomaton, groupIndexAutomaton)) {
-                    if (allowedIndexPrivilegesAutomaton != null) {
-                        allowedIndexPrivilegesAutomaton = Automatons
-                                .unionAndMinimize(Arrays.asList(allowedIndexPrivilegesAutomaton, group.privilege().getAutomaton()));
-                    } else {
-                        allowedIndexPrivilegesAutomaton = group.privilege().getAutomaton();
+            Automaton checkIndexAutomaton = Automatons.patterns(forIndexPattern);
+            if (false == allowRestrictedIndices && false == RestrictedIndicesNames.RESTRICTED_NAMES.contains(forIndexPattern)) {
+                checkIndexAutomaton = Automatons.minusAndMinimize(checkIndexAutomaton, RestrictedIndicesNames.NAMES_AUTOMATON);
+            }
+            if (false == Operations.isEmpty(checkIndexAutomaton)) {
+                Automaton allowedIndexPrivilegesAutomaton = null;
+                for (Group group : groups) {
+                    final Automaton groupIndexAutomaton = predicateCache.computeIfAbsent(group,
+                            g -> IndicesPermission.Group.buildIndexMatcherAutomaton(g.allowRestrictedIndices(), g.indices()));
+                    if (Operations.subsetOf(checkIndexAutomaton, groupIndexAutomaton)) {
+                        if (allowedIndexPrivilegesAutomaton != null) {
+                            allowedIndexPrivilegesAutomaton = Automatons
+                                    .unionAndMinimize(Arrays.asList(allowedIndexPrivilegesAutomaton, group.privilege().getAutomaton()));
+                        } else {
+                            allowedIndexPrivilegesAutomaton = group.privilege().getAutomaton();
+                        }
                     }
                 }
-            }
-            for (String privilege : checkForPrivileges) {
-                IndexPrivilege indexPrivilege = IndexPrivilege.get(Collections.singleton(privilege));
-                if (allowedIndexPrivilegesAutomaton != null
-                        && Operations.subsetOf(indexPrivilege.getAutomaton(), allowedIndexPrivilegesAutomaton)) {
-                    resourcePrivilegesMapBuilder.addResourcePrivilege(forIndexPattern, privilege, Boolean.TRUE);
-                } else {
+                for (String privilege : checkForPrivileges) {
+                    IndexPrivilege indexPrivilege = IndexPrivilege.get(Collections.singleton(privilege));
+                    if (allowedIndexPrivilegesAutomaton != null
+                            && Operations.subsetOf(indexPrivilege.getAutomaton(), allowedIndexPrivilegesAutomaton)) {
+                        resourcePrivilegesMapBuilder.addResourcePrivilege(forIndexPattern, privilege, Boolean.TRUE);
+                    } else {
+                        resourcePrivilegesMapBuilder.addResourcePrivilege(forIndexPattern, privilege, Boolean.FALSE);
+                    }
+                }
+            } else {
+                // the index pattern produced the empty automaton, presumably because the requested pattern expands exclusively inside the
+                // restricted indices namespace - a namespace of indices that are normally hidden when granting/checking privileges - and
+                // the pattern was not marked as `allowRestrictedIndices`. We try to anticipate this by considering _explicit_ restricted
+                // indices even if `allowRestrictedIndices` is false.
+                // TODO The `false` result is a _safe_ default but this is actually an error. Make it an error.
+                for (String privilege : checkForPrivileges) {
                     resourcePrivilegesMapBuilder.addResourcePrivilege(forIndexPattern, privilege, Boolean.FALSE);
                 }
             }
         }
         return resourcePrivilegesMapBuilder.build();
     }
\ No newline at end of file
","Fix Has Privilege API check on restricted indices (#41226)

The Has Privileges API allows to tap into the authorization process, to validate
privileges without actually running the operations to be authorized. This commit
fixes a bug, in which the Has Privilege API returned spurious results when checking
for index privileges over restricted indices (currently .security, .security-6,
.security-7). The actual authorization process is not affected by the bug.",Buggy
elasticsearch,52742.json,a36543531b4f547bbb7be8156d4c1e55f0d53cf9,"@@ -1,8 +1,11 @@
     private void onFailedFreedContext(Throwable e, DiscoveryNode node) {
         logger.warn(() -> new ParameterizedMessage(""Clear SC failed on node[{}]"", node), e);
+        /*
+         * We have to set the failure marker before we count down otherwise we can expose the failure marker before we have set it to a
+         * racing thread successfully freeing a context. This would lead to that thread responding that the clear scroll succeeded.
+         */
+        hasFailed.set(true);
         if (expectedOps.countDown()) {
             listener.onResponse(new ClearScrollResponse(false, freedSearchContexts.get()));
-        } else {
-            hasFailed.set(true);
         }
     }
\ No newline at end of file
","Fix race in clear scroll (#31259)

Here is the problem: if two threads are racing and one hits a failure
freeing a context and the other succeeded, we can expose the value of
the has failure marker to the succeeding thread before the failing
thread has had a chance to set the failure marker. This is a problem if
the failing thread counted down the expected number of operations, then
be put to sleep by a gentle lullaby from the OS, and then the other
thread could count down to zero. Since the failing thread did not get to
set the failure marker, the succeeding thread would respond that the
clear scroll succeeded and that makes that thread a liar. This commit
addresses by first setting the failure marker before we potentially
expose its value to another thread.",Buggy
elasticsearch,9348.json,308ae98988fb9d7c5374a5b16dac810a7bd9715c,"@@ -1,20 +1,22 @@
         private List<Realm> getRealmList(String principal) {
             final List<Realm> orderedRealmList = this.defaultOrderedRealmList;
             if (lastSuccessfulAuthCache != null) {
                 final Realm lastSuccess = lastSuccessfulAuthCache.get(principal);
                 if (lastSuccess != null) {
                     final int index = orderedRealmList.indexOf(lastSuccess);
                     if (index > 0) {
                         final List<Realm> smartOrder = new ArrayList<>(orderedRealmList.size());
                         smartOrder.add(lastSuccess);
-                        for (int i = 1; i < orderedRealmList.size(); i++) {
+                        for (int i = 0; i < orderedRealmList.size(); i++) {
                             if (i != index) {
                                 smartOrder.add(orderedRealmList.get(i));
                             }
                         }
+                        assert smartOrder.size() == orderedRealmList.size() && smartOrder.containsAll(orderedRealmList)
+                            : ""Element mismatch between SmartOrder="" + smartOrder + "" and DefaultOrder="" + orderedRealmList;
                         return Collections.unmodifiableList(smartOrder);
                     }
                 }
             }
             return orderedRealmList;
         }
\ No newline at end of file
","Fix iterate-from-1 bug in smart realm order (#49473)

The AuthenticationService has a feature to ""smart order"" the realm
chain so that whicherver realm was the last one to successfully
authenticate a given user will be tried first when that user tries to
authenticate again.

There was a bug where the building of this realm order would
incorrectly drop the first realm from the default chain unless that
realm was the ""last successful"" realm.

In most cases this didn't cause problems because the first realm is
the reserved realm and so it is unusual for a user that authenticated
against a different realm to later need to authenticate against the
resevered realm.

This commit fixes that bug and adds relevant asserts and tests.",Buggy
elasticsearch,38299.json,38085cf90af953cfcaf7807c2dfccc55b742cdff,"@@ -1,5 +1,4 @@
     public AggregationPath subPath(int offset, int length) {
-        PathElement[] subTokens = new PathElement[length];
-        System.arraycopy(pathElements, offset, subTokens, 0, length);
-        return new AggregationPath(pathElements);
+        List<PathElement> subTokens = new ArrayList<>(pathElements.subList(offset, offset + length));
+        return new AggregationPath(subTokens);
     }
\ No newline at end of file
","Aggregation: Fix AggregationPath.subPath() to not throw ArrayStoreException

Aggregation.subPath() always threw an ArrayStoreException because we were trying to pass a List into System.arraycopy(). This change fixes that bug and adds a test to prevent regression
",Buggy
elasticsearch,10639.json,8b201e64ffeffa8dfe8c5849a81decb2a62dbe06,"@@ -1,19 +1,20 @@
     public static String loadWatch(final ClusterService clusterService, final String watchId) {
         final String resource = String.format(Locale.ROOT, WATCH_FILE, watchId);
 
         try {
             final String clusterUuid = clusterService.state().metaData().clusterUUID();
             final String uniqueWatchId = createUniqueWatchId(clusterUuid, watchId);
 
             // load the resource as-is
             String source = loadResource(resource).utf8ToString();
 
             source = CLUSTER_UUID_PROPERTY.matcher(source).replaceAll(clusterUuid);
             source = WATCH_ID_PROPERTY.matcher(source).replaceAll(watchId);
             source = UNIQUE_WATCH_ID_PROPERTY.matcher(source).replaceAll(uniqueWatchId);
+            source = VERSION_CREATED_PROPERTY.matcher(source).replaceAll(Integer.toString(LAST_UPDATED_VERSION));
 
             return source;
         } catch (final IOException e) {
             throw new RuntimeException(""Unable to load Watch ["" + watchId + ""]"", e);
         }
     }
\ No newline at end of file
","Fix cluster alert for watcher/monitoring IndexOutOfBoundsExcep (#45308)

If a cluster sending monitoring data is unhealthy and triggers an
alert, then stops sending data the following exception [1] can occur.

This exception stops the current Watch and the behavior is actually
correct in part due to the exception. Simply fixing the exception
introduces some incorrect behavior. Now that the Watch does not
error in the this case, it will result in an incorrectly ""resolved""
alert.  The fix here is two parts a) fix the exception b) fix the
following incorrect behavior.

a) fixing the exception is as easy as checking the size of the
array before accessing it.

b) fixing the following incorrect behavior is a bit more intrusive

- Note - the UI depends on the success/met state for each condition
to determine an ""OK"" or ""FIRING""

In this scenario, where an unhealthy cluster triggers an alert and
then goes silent, it should keep ""FIRING"" until it hears back that
the cluster is green. To keep the Watch ""FIRING"" either the index
action or the email action needs to fire. Since the Watch is neither
a ""new"" alert or a ""resolved"" alert, we do not want to keep sending
an email (that would be non-passive too). Without completely changing
the logic of how an alert is resolved allowing the index action to
take place would result in the alert being resolved. Since we can
not keep ""FIRING"" either the email or index action (since we don't
want to resolve the alert nor re-write the logic for alert resolution),
we will introduce a 3rd action. A logging action that WILL fire when
the cluster is unhealthy. Specifically will fire when there is an
unresolved alert and it can not find the cluster state.
This logging action is logged at debug, so it should be noticed much.
This logging action serves as an 'anchor' for the UI to keep the state
in an a ""FIRING"" status until the alert is resolved.

This presents a possible scenario where a cluster starts firing,
then goes completely silent forever, the Watch will be ""FIRING""
forever. This is an edge case that already exists in some scenarios
and requires manual intervention to remove that Watch.

This changes changes to use a template-like method to populate the 
version_created for the default monitoring watches. The version is 
set to 7.5 since that is where this is first introduced.

Fixes #43184




",Buggy
elasticsearch,61886.json,aed30d6cc7761d12b929696774591ac0ccb989d0,"@@ -1,32 +1,32 @@
     public void checkInvalidPatterns() throws IOException {
         Pattern allPatterns = Pattern.compile(""("" + String.join("")|("", getPatterns().values()) + "")"");
         List<String> failures = new ArrayList<>();
         for (File f : files()) {
             List<String> lines;
             try(Stream<String> stream = Files.lines(f.toPath(), StandardCharsets.UTF_8)) {
                     lines = stream.collect(Collectors.toList());
             } catch (UncheckedIOException e) {
                 throw new IllegalArgumentException(""Failed to read "" + f + "" as UTF_8"", e);
             }
             List<Integer> invalidLines = IntStream.range(0, lines.size())
                 .filter(i -> allPatterns.matcher(lines.get(i)).find())
                 .boxed()
                 .collect(Collectors.toList());
 
             String path = getProject().getRootProject().getProjectDir().toURI().relativize(f.toURI()).toString();
-            failures = invalidLines.stream()
+            failures.addAll(invalidLines.stream()
                 .map(l -> new AbstractMap.SimpleEntry<>(l+1, lines.get(l)))
                 .flatMap(kv -> patterns.entrySet().stream()
                     .filter(p -> Pattern.compile(p.getValue()).matcher(kv.getValue()).find())
                     .map(p -> ""- "" + p.getKey() + "" on line "" + kv.getKey() + "" of "" + path)
                 )
-                .collect(Collectors.toList());
+                .collect(Collectors.toList()));
         }
         if (failures.isEmpty() == false) {
             throw new GradleException(""Found invalid patterns:\n"" + String.join(""\n"", failures));
         }
 
         File outputMarker = getOutputMarker();
         outputMarker.getParentFile().mkdirs();
         Files.write(outputMarker.toPath(), ""done"".getBytes(StandardCharsets.UTF_8));
     }
\ No newline at end of file
","Don't replace forbidden pattern failures when found (#40710)

This commit fixes a bug in forbidden patterns where the failures for a
file replace the failures from the previous files instead of extending
them.
",Buggy
elasticsearch,39934.json,8260138e5975ebcb588933d792d22374168c48cf,"@@ -1,21 +1,21 @@
         void toXContent(XContentBuilder builder, Params params, boolean keyed, @Nullable ValueFormatter formatter) throws IOException {
-            if (formatter != null) {
+            if (formatter != null && formatter != ValueFormatter.RAW) {
                 Text keyTxt = new StringText(formatter.format(key));
                 if (keyed) {
                     builder.startObject(keyTxt.string());
                 } else {
                     builder.startObject();
                 }
                 builder.field(CommonFields.KEY_AS_STRING, keyTxt);
             } else {
                 if (keyed) {
                     builder.startObject(String.valueOf(getKeyAsNumber()));
                 } else {
                     builder.startObject();
                 }
             }
             builder.field(CommonFields.KEY, key);
             builder.field(CommonFields.DOC_COUNT, docCount);
             aggregations.toXContentInternal(builder, params);
             builder.endObject();
         }
\ No newline at end of file
","Aggregations: Fixed Histogram key_as_string bug

The key as string field in the response for the histogram aggregation will now only show if format is specified on the request.

Closes #6655
",Buggy
elasticsearch,8075.json,ae4bfe99ecd6e298c56236c7abf9a53c6b490ab2,"@@ -1,30 +1,31 @@
     protected void masterOperation(Task task, DeleteEnrichPolicyAction.Request request, ClusterState state,
                                    ActionListener<AcknowledgedResponse> listener) throws Exception {
         List<PipelineConfiguration> pipelines = IngestService.getPipelines(state);
         EnrichPolicy policy = EnrichStore.getPolicy(request.getName(), state);
         List<String> pipelinesWithProcessors = new ArrayList<>();
 
         for (PipelineConfiguration pipelineConfiguration : pipelines) {
             List<AbstractEnrichProcessor> enrichProcessors =
                 ingestService.getProcessorsInPipeline(pipelineConfiguration.getId(), AbstractEnrichProcessor.class);
             for (AbstractEnrichProcessor processor: enrichProcessors) {
                 if (processor.getPolicyName().equals(request.getName())) {
                     pipelinesWithProcessors.add(pipelineConfiguration.getId());
                 }
             }
         }
 
         if (pipelinesWithProcessors.isEmpty() == false) {
             listener.onFailure(
                 new ElasticsearchStatusException(""Could not delete policy [{}] because a pipeline is referencing it {}"",
                     RestStatus.CONFLICT, request.getName(), pipelinesWithProcessors));
+            return;
         }
 
         EnrichStore.deletePolicy(request.getName(), clusterService, e -> {
            if (e == null) {
                listener.onResponse(new AcknowledgedResponse(true));
            } else {
                listener.onFailure(e);
            }
         });
     }
\ No newline at end of file
","Fix policy removal bug in delete policy (#45573)

The delete policy had a subtle bug in that it would still delete the
policy if pipelines were accessing it, after giving the client back an
error. This commit fixes that and ensures it does not happen by adding
verification in the test.",Buggy
elasticsearch,51449.json,63fe3c6ed604d2aee3ae5266b35e87f35ff09bee,"@@ -1,40 +1,44 @@
     private void verifyThenSubmitUpdate(ClusterRerouteRequest request, ActionListener<ClusterRerouteResponse> listener,
         Map<String, List<AbstractAllocateAllocationCommand>> stalePrimaryAllocations) {
         transportService.sendRequest(transportService.getLocalNode(), IndicesShardStoresAction.NAME,
             new IndicesShardStoresRequest().indices(stalePrimaryAllocations.keySet().toArray(Strings.EMPTY_ARRAY)),
             new ActionListenerResponseHandler<>(
                 ActionListener.wrap(
                     response -> {
                         ImmutableOpenMap<String, ImmutableOpenIntMap<List<IndicesShardStoresResponse.StoreStatus>>> status =
                             response.getStoreStatuses();
                         Exception e = null;
                         for (Map.Entry<String, List<AbstractAllocateAllocationCommand>> entry : stalePrimaryAllocations.entrySet()) {
                             final String index = entry.getKey();
                             final ImmutableOpenIntMap<List<IndicesShardStoresResponse.StoreStatus>> indexStatus = status.get(index);
-                            assert indexStatus != null;
+                            if (indexStatus == null) {
+                                // The index in the stale primary allocation request was green and hence filtered out by the store status
+                                // request. We ignore it here since the relevant exception will be thrown by the reroute action later on.
+                                continue;
+                            }
                             for (AbstractAllocateAllocationCommand command : entry.getValue()) {
                                 final List<IndicesShardStoresResponse.StoreStatus> shardStatus =
                                     indexStatus.get(command.shardId());
                                 if (shardStatus == null || shardStatus.isEmpty()) {
                                     e = ExceptionsHelper.useOrSuppress(e, new IllegalArgumentException(
                                         ""No data for shard ["" + command.shardId() + ""] of index ["" + index + ""] found on any node"")
                                     );
                                 } else if (shardStatus.stream().noneMatch(storeStatus -> {
                                     final DiscoveryNode node = storeStatus.getNode();
                                     final String nodeInCommand = command.node();
                                     return nodeInCommand.equals(node.getName()) || nodeInCommand.equals(node.getId());
                                 })) {
                                     e = ExceptionsHelper.useOrSuppress(e, new IllegalArgumentException(
                                         ""No data for shard ["" + command.shardId() + ""] of index ["" + index + ""] found on node [""
                                             + command.node() + ']'));
                                 }
                             }
                         }
                         if (e == null) {
                             submitStateUpdate(request, listener);
                         } else {
                             listener.onFailure(e);
                         }
                     }, listener::onFailure
                 ), IndicesShardStoresResponse::new));
     }
\ No newline at end of file
","Fix PrimaryAllocationIT Race Condition (#37355)

* Fix PrimaryAllocationIT Race Condition

* Forcing a stale primary allocation on a green index was tripping the assertion that was removed
   * Added a test that this case still errors out correctly
* Made the ability to wipe stopped datanode's data public on the internal test cluster and used it to ensure correct behaviour on the fixed test
   * Previously it simply passed because the test finished before the index went green and would NPE when the index was green at the time of the shard store status request, that would then come up empty
* Closes #37345
",Buggy
elasticsearch,47709.json,049e122e8f653fb54f12e0f0aa1eb86c5a1a629d,"@@ -1,18 +1,18 @@
     public static Map<Integer, List<String>> getAutoExpandReplicaChanges(MetaData metaData, DiscoveryNodes discoveryNodes) {
         // used for translating ""all"" to a number
         final int dataNodeCount = discoveryNodes.getDataNodes().size();
 
         Map<Integer, List<String>> nrReplicasChanged = new HashMap<>();
 
         for (final IndexMetaData indexMetaData : metaData) {
-            if (indexMetaData.getState() != IndexMetaData.State.CLOSE) {
+            if (indexMetaData.getState() == IndexMetaData.State.OPEN || isIndexVerifiedBeforeClosed(indexMetaData)) {
                 AutoExpandReplicas autoExpandReplicas = SETTING.get(indexMetaData.getSettings());
                 autoExpandReplicas.getDesiredNumberOfReplicas(dataNodeCount).ifPresent(numberOfReplicas -> {
                     if (numberOfReplicas != indexMetaData.getNumberOfReplicas()) {
                         nrReplicasChanged.computeIfAbsent(numberOfReplicas, ArrayList::new).add(indexMetaData.getIndex().getName());
                     }
                 });
             }
         }
         return nrReplicasChanged;
     }
\ No newline at end of file
","Auto-expand replicated closed indices (#48973)

Fixes a bug where replicated closed indices were not being auto-expanded.",Buggy
elasticsearch,46897.json,cdb482eaae0517f202efdfaf445e8847917182f1,"@@ -1,9 +1,13 @@
     boolean cancelCommittedPublication() {
         synchronized (mutex) {
-            if (currentPublication.isPresent() && currentPublication.get().isCommitted()) {
-                currentPublication.get().cancel(""cancelCommittedPublication"");
-                return true;
+            if (currentPublication.isPresent()) {
+                final CoordinatorPublication publication = currentPublication.get();
+                if (publication.isCommitted()) {
+                    publication.cancel(""cancelCommittedPublication"");
+                    logger.debug(""Cancelled publication of [{}]."", publication);
+                    return true;
+                }
             }
             return false;
         }
     }
\ No newline at end of file
","Fix RareClusterStateIT (#42430)

* It looks like we might be cancelling a previous publication instead of
the one triggered by the given request with a very low likelihood.
   * Fixed by adding a wait for no in-progress publications
   * Also added debug logging that would've identified this problem
* Closes #36813",Buggy
elasticsearch,19038.json,7597b7ce2bd280401fcbfbeb281dfbb205830d75,"@@ -1,34 +1,38 @@
     public ActionRequestValidationException validate() {
         ActionRequestValidationException validationException = null;
-        for (ApplicationPrivilegeDescriptor privilege : privileges) {
-            try {
-                ApplicationPrivilege.validateApplicationName(privilege.getApplication());
-            } catch (IllegalArgumentException e) {
-                validationException = addValidationError(e.getMessage(), validationException);
-            }
-            try {
-                ApplicationPrivilege.validatePrivilegeName(privilege.getName());
-            } catch (IllegalArgumentException e) {
-                validationException = addValidationError(e.getMessage(), validationException);
-            }
-            if (privilege.getActions().isEmpty()) {
-                validationException = addValidationError(""Application privileges must have at least one action"", validationException);
-            }
-            for (String action : privilege.getActions()) {
-                if (action.indexOf('/') == -1 && action.indexOf('*') == -1 && action.indexOf(':') == -1) {
-                    validationException = addValidationError(""action ["" + action + ""] must contain one of [ '/' , '*' , ':' ]"",
-                        validationException);
-                }
+        if (privileges.isEmpty()) {
+            validationException = addValidationError(""At least one application privilege must be provided"", validationException);
+        } else {
+            for (ApplicationPrivilegeDescriptor privilege : privileges) {
                 try {
-                    ApplicationPrivilege.validatePrivilegeOrActionName(action);
+                    ApplicationPrivilege.validateApplicationName(privilege.getApplication());
                 } catch (IllegalArgumentException e) {
                     validationException = addValidationError(e.getMessage(), validationException);
                 }
-            }
-            if (MetadataUtils.containsReservedMetadata(privilege.getMetadata())) {
-                validationException = addValidationError(""metadata keys may not start with ["" + MetadataUtils.RESERVED_PREFIX
-                    + ""] (in privilege "" + privilege.getApplication() + ' ' + privilege.getName() + "")"", validationException);
+                try {
+                    ApplicationPrivilege.validatePrivilegeName(privilege.getName());
+                } catch (IllegalArgumentException e) {
+                    validationException = addValidationError(e.getMessage(), validationException);
+                }
+                if (privilege.getActions().isEmpty()) {
+                    validationException = addValidationError(""Application privileges must have at least one action"", validationException);
+                }
+                for (String action : privilege.getActions()) {
+                    if (action.indexOf('/') == -1 && action.indexOf('*') == -1 && action.indexOf(':') == -1) {
+                        validationException = addValidationError(""action ["" + action + ""] must contain one of [ '/' , '*' , ':' ]"",
+                            validationException);
+                    }
+                    try {
+                        ApplicationPrivilege.validatePrivilegeOrActionName(action);
+                    } catch (IllegalArgumentException e) {
+                        validationException = addValidationError(e.getMessage(), validationException);
+                    }
+                }
+                if (MetadataUtils.containsReservedMetadata(privilege.getMetadata())) {
+                    validationException = addValidationError(""metadata keys may not start with ["" + MetadataUtils.RESERVED_PREFIX
+                        + ""] (in privilege "" + privilege.getApplication() + ' ' + privilege.getName() + "")"", validationException);
+                }
             }
         }
         return validationException;
     }
\ No newline at end of file
","Add validation for empty PutPrivilegeRequest (#37569)

Return an error to the user if the put privilege api is called with
an empty body (no privileges)

Resolves: #37561",Buggy
elasticsearch,49943.json,adc195e30c4e237372f168086f7a57b0c3b5e7f1,"@@ -1,10 +1,10 @@
     public ActionRequestValidationException validate() {
         ActionRequestValidationException validationException = null;
         if (name == null) {
             validationException = addValidationError(""name is missing"", validationException);
         }
         if (indexPatterns == null || indexPatterns.size() == 0) {
-            validationException = addValidationError(""pattern is missing"", validationException);
+            validationException = addValidationError(""index patterns are missing"", validationException);
         }
         return validationException;
     }
\ No newline at end of file
","Fix error message for a put index template request without index_patterns (#27102)

Just correct the error message from ""Validation Failed: 1: pattern is
missing;"" to ""Validation Failed: 1: index_patterns is missing;"".

Closes #27100",Buggy
elasticsearch,53233.json,a8bfa466b2f2a68c2384bc730a0b8c7c9ce7ea87,"@@ -1,12 +1,12 @@
     public void markAsCompleted(BulkItemResponse translatedResponse) {
         assertInvariants(ItemProcessingState.EXECUTED);
-        assert executionResult == null || translatedResponse.getItemId() == executionResult.getItemId();
+        assert executionResult != null && translatedResponse.getItemId() == executionResult.getItemId();
         assert translatedResponse.getItemId() == getCurrentItem().id();
 
-        if (translatedResponse.isFailed() == false && requestToExecute != getCurrent())  {
+        if (translatedResponse.isFailed() == false && requestToExecute != null && requestToExecute != getCurrent())  {
             request.items()[currentIndex] = new BulkItemRequest(request.items()[currentIndex].id(), requestToExecute);
         }
         getCurrentItem().setPrimaryResponse(translatedResponse);
         currentItemState = ItemProcessingState.COMPLETED;
         advance();
     }
\ No newline at end of file
","Fix NOOP bulk updates (#32819)

#31821 introduced an unreleased bug where NOOP updates were incorrectly mutating the bulk
shard request, inserting null item to be replicated, which would result in NullPointerExceptions when
serializing the request to be shipped to the replicas.

Closes #32808",Buggy
elasticsearch,265.json,c9dc55c3322b631f708867fdfd650e5ca27a30d0,"@@ -1,18 +1,20 @@
     static Tuple<Set<String>, Set<String>> findTasksWithoutConfig(ClusterState state, String transformId) {
         PersistentTasksCustomMetaData tasks = state.metaData().custom(PersistentTasksCustomMetaData.TYPE);
 
         Set<String> taskIds = new HashSet<>();
         Set<String> executorNodes = new HashSet<>();
 
-        Predicate<PersistentTask<?>> taskMatcher = Strings.isAllOrWildcard(new String[] { transformId }) ? t -> true : t -> {
-            TransformTaskParams transformParams = (TransformTaskParams) t.getParams();
-            return Regex.simpleMatch(transformId, transformParams.getId());
-        };
+        if (tasks != null) {
+            Predicate<PersistentTask<?>> taskMatcher = Strings.isAllOrWildcard(new String[] { transformId }) ? t -> true : t -> {
+                TransformTaskParams transformParams = (TransformTaskParams) t.getParams();
+                return Regex.simpleMatch(transformId, transformParams.getId());
+            };
 
-        for (PersistentTasksCustomMetaData.PersistentTask<?> pTask : tasks.findTasks(TransformField.TASK_NAME, taskMatcher)) {
-            executorNodes.add(pTask.getExecutorNode());
-            taskIds.add(pTask.getId());
+            for (PersistentTasksCustomMetaData.PersistentTask<?> pTask : tasks.findTasks(TransformField.TASK_NAME, taskMatcher)) {
+                executorNodes.add(pTask.getExecutorNode());
+                taskIds.add(pTask.getId());
+            }
         }
 
         return new Tuple<>(taskIds, executorNodes);
     }
\ No newline at end of file
","check custom meta data to avoid NPE (#51163)

check custom meta data to avoid NPE, fixes a problem introduced in #51072

fixes #51153",Buggy
elasticsearch,7551.json,341006e9913e831408f5bbc7f8ad8c453a7f630e,"@@ -1,91 +1,91 @@
     private static List<EsIndex> buildIndices(String[] indexNames, String javaRegex, Map<String, Map<String, FieldCapabilities>> fieldCaps,
             Function<String, String> indexNameProcessor,
             BiFunction<String, Map<String, FieldCapabilities>, InvalidMappedField> validityVerifier) {
 
         if (indexNames == null || indexNames.length == 0) {
             return emptyList();
         }
 
         final List<String> resolvedIndices = asList(indexNames);
         Map<String, Fields> indices = new LinkedHashMap<>(resolvedIndices.size());
         Pattern pattern = javaRegex != null ? Pattern.compile(javaRegex) : null;
 
         // sort fields in reverse order to build the field hierarchy
         Set<Entry<String, Map<String, FieldCapabilities>>> sortedFields = new TreeSet<>(
                 Collections.reverseOrder(Comparator.comparing(Entry::getKey)));
 
         sortedFields.addAll(fieldCaps.entrySet());
 
         for (Entry<String, Map<String, FieldCapabilities>> entry : sortedFields) {
             String fieldName = entry.getKey();
             Map<String, FieldCapabilities> types = entry.getValue();
 
             // ignore size added by the mapper plugin
             if (FIELD_NAMES_BLACKLIST.contains(fieldName)) {
                 continue;
             }
 
             // apply verification
             final InvalidMappedField invalidField = validityVerifier.apply(fieldName, types);
 
             // filter meta fields and unmapped
             FieldCapabilities unmapped = types.get(UNMAPPED);
             Set<String> unmappedIndices = unmapped != null ? new HashSet<>(asList(unmapped.indices())) : emptySet();
 
             // check each type
             for (Entry<String, FieldCapabilities> typeEntry : types.entrySet()) {
                 FieldCapabilities typeCap = typeEntry.getValue();
                 String[] capIndices = typeCap.indices();
 
                 // Skip internal fields (name starting with underscore and its type reported by field_caps starts
                 // with underscore as well). A meta field named ""_version"", for example, has the type named ""_version"".
                 if (typeEntry.getKey().startsWith(""_"") && typeCap.getType().startsWith(""_"")) {
                     continue;
                 }
 
                 // compute the actual indices - if any are specified, take into account the unmapped indices
                 List<String> concreteIndices = null;
                 if (capIndices != null) {
                     if (unmappedIndices.isEmpty() == true) {
                         concreteIndices = asList(capIndices);
                     } else {
-                        concreteIndices = new ArrayList<>(capIndices.length - unmappedIndices.size() + 1);
+                        concreteIndices = new ArrayList<>(capIndices.length);
                         for (String capIndex : capIndices) {
                             // add only indices that have a mapping
                             if (unmappedIndices.contains(capIndex) == false) {
                                 concreteIndices.add(capIndex);
                             }
                         }
                     }
                 } else {
                     concreteIndices = resolvedIndices;
                 }
 
                 // put the field in their respective mappings
                 for (String index : concreteIndices) {
                     if (pattern == null || pattern.matcher(index).matches()) {
                         String indexName = indexNameProcessor.apply(index);
                         Fields indexFields = indices.get(indexName);
                         if (indexFields == null) {
                             indexFields = new Fields();
                             indices.put(indexName, indexFields);
                         }
                         EsField field = indexFields.flattedMapping.get(fieldName);
                         if (field == null || (invalidField != null && (field instanceof InvalidMappedField) == false)) {
                             createField(fieldName, fieldCaps, indexFields.hierarchicalMapping, indexFields.flattedMapping,
                                     s -> invalidField != null ? invalidField : createField(s, typeCap.getType(), emptyMap(),
                                             typeCap.isAggregatable()));
                         }
                     }
                 }
             }
         }
 
         // return indices in ascending order
         List<EsIndex> foundIndices = new ArrayList<>(indices.size());
         for (Entry<String, Fields> entry : indices.entrySet()) {
             foundIndices.add(new EsIndex(entry.getKey(), entry.getValue().hierarchicalMapping));
         }
         foundIndices.sort(Comparator.comparing(EsIndex::name));
         return foundIndices;
     }
\ No newline at end of file
","SQL: concrete indices array size bug fix (#43878)

* The created array didn't have the correct initial size while attempting to resolve multiple indices
",Buggy
elasticsearch,41046.json,0354825914ba79d7e3ec500aa9eab0532e43850f,"@@ -1,24 +1,22 @@
     private FieldLookup loadFieldData(String name) {
         FieldLookup data = cachedFieldData.get(name);
         if (data == null) {
             FieldMapper mapper = mapperService.smartNameFieldMapper(name, types);
             if (mapper == null) {
                 throw new ElasticSearchIllegalArgumentException(""No field found for ["" + name + ""] in mapping with types "" + Arrays.toString(types) + """");
             }
             data = new FieldLookup(mapper);
             cachedFieldData.put(name, data);
         }
         if (data.doc() == null) {
             fieldVisitor.name(data.mapper().names().indexName());
             try {
                 reader.document(docId, fieldVisitor);
                 // LUCENE 4 UPGRADE: Only one field we don't need document
                 data.doc(fieldVisitor.createDocument());
             } catch (IOException e) {
                 throw new ElasticSearchParseException(""failed to load field ["" + name + ""]"", e);
-            } finally {
-                fieldVisitor.reset();
             }
         }
         return data;
     }
\ No newline at end of file
","lucene 4: Fixed compile error
",Buggy
elasticsearch,11747.json,22415fa2de1d7d07cea7dd5e7263eb1ed4270503,"@@ -1,82 +1,88 @@
     CharsetMatch findCharset(List<String> explanation, InputStream inputStream) throws Exception {
 
         // We need an input stream that supports mark and reset, so wrap the argument
         // in a BufferedInputStream if it doesn't already support this feature
         if (inputStream.markSupported() == false) {
             inputStream = new BufferedInputStream(inputStream, BUFFER_SIZE);
         }
 
         // This is from ICU4J
         CharsetDetector charsetDetector = new CharsetDetector().setText(inputStream);
         CharsetMatch[] charsetMatches = charsetDetector.detectAll();
 
         // Determine some extra characteristics of the input to compensate for some deficiencies of ICU4J
         boolean pureAscii = true;
         boolean containsZeroBytes = false;
         inputStream.mark(BUFFER_SIZE);
         byte[] workspace = new byte[BUFFER_SIZE];
         int remainingLength = BUFFER_SIZE;
         do {
             int bytesRead = inputStream.read(workspace, 0, remainingLength);
             if (bytesRead <= 0) {
                 break;
             }
             for (int i = 0; i < bytesRead && containsZeroBytes == false; ++i) {
                 if (workspace[i] == 0) {
                     containsZeroBytes = true;
                     pureAscii = false;
                 } else {
                     pureAscii = pureAscii && workspace[i] > 0 && workspace[i] < 128;
                 }
             }
             remainingLength -= bytesRead;
         } while (containsZeroBytes == false && remainingLength > 0);
         inputStream.reset();
 
         if (pureAscii) {
             // If the input is pure ASCII then many single byte character sets will match.  We want to favour
             // UTF-8 in this case, as it avoids putting a bold declaration of a dubious character set choice
             // in the config files.
             Optional<CharsetMatch> utf8CharsetMatch = Arrays.stream(charsetMatches)
                 .filter(charsetMatch -> StandardCharsets.UTF_8.name().equals(charsetMatch.getName())).findFirst();
             if (utf8CharsetMatch.isPresent()) {
                 explanation.add(""Using character encoding ["" + StandardCharsets.UTF_8.name() +
                     ""], which matched the input with ["" + utf8CharsetMatch.get().getConfidence() + ""%] confidence - first ["" +
                     (BUFFER_SIZE / 1024) + ""kB] of input was pure ASCII"");
                 return utf8CharsetMatch.get();
             }
         }
 
         // Input wasn't pure ASCII, so use the best matching character set that's supported by both Java and Go.
         // Additionally, if the input contains zero bytes then avoid single byte character sets, as ICU4J will
         // suggest these for binary files but then
         for (CharsetMatch charsetMatch : charsetMatches) {
             String name = charsetMatch.getName();
             if (Charset.isSupported(name) && FILEBEAT_SUPPORTED_ENCODINGS.contains(name.toLowerCase(Locale.ROOT))) {
 
                 // This extra test is to avoid trying to read binary files as text.  Running the log config
                 // deduction algorithms on binary files is very slow as the binary files generally appear to
                 // have very long lines.
                 boolean spaceEncodingContainsZeroByte = false;
-                byte[] spaceBytes = "" "".getBytes(name);
-                for (int i = 0; i < spaceBytes.length && spaceEncodingContainsZeroByte == false; ++i) {
-                    spaceEncodingContainsZeroByte = (spaceBytes[i] == 0);
+                Charset charset = Charset.forName(name);
+                // Some character sets cannot be encoded.  These are extremely rare so it's likely that
+                // they've been chosen based on incorrectly provided binary data.  Therefore, err on
+                // the side of rejecting binary data.
+                if (charset.canEncode()) {
+                    byte[] spaceBytes = "" "".getBytes(charset);
+                    for (int i = 0; i < spaceBytes.length && spaceEncodingContainsZeroByte == false; ++i) {
+                        spaceEncodingContainsZeroByte = (spaceBytes[i] == 0);
+                    }
                 }
                 if (containsZeroBytes && spaceEncodingContainsZeroByte == false) {
                     explanation.add(""Character encoding ["" + name + ""] matched the input with ["" + charsetMatch.getConfidence() +
                         ""%] confidence but was rejected as the input contains zero bytes and the ["" + name + ""] encoding does not"");
                 } else {
                     explanation.add(""Using character encoding ["" + name + ""], which matched the input with ["" +
                         charsetMatch.getConfidence() + ""%] confidence"");
                     return charsetMatch;
                 }
             } else {
                 explanation.add(""Character encoding ["" + name + ""] matched the input with ["" + charsetMatch.getConfidence() +
                     ""%] confidence but was rejected as it is not supported by ["" +
                     (Charset.isSupported(name) ? ""Filebeat"" : ""the JVM"") + ""]"");
             }
         }
 
         throw new IllegalArgumentException(""Could not determine a usable character encoding for the input"" +
             (containsZeroBytes ? "" - could it be binary data?"" : """"));
     }
\ No newline at end of file
","[ML] Fix character set finder bug with unencodable charsets (#33234)

Some character sets cannot be encoded and this was tripping
up the binary data check in the ML log structure character
set finder.

The fix is to assume that if ICU4J identifies that some bytes
correspond to a character set that cannot be encoded and those
bytes contain zeroes then the data is binary rather than text.

Fixes #33227",Buggy
elasticsearch,54093.json,b3341da0779673c106db526ec58c4449bda59dc2,"@@ -1,9 +1,13 @@
     private static boolean usingBundledJdk() {
         /*
          * We are using the bundled JDK if java.home is the jdk sub-directory of our working directory. This is because we always set
          * the working directory of Elasticsearch to home, and the bundled JDK is in the jdk sub-directory there.
          */
         final String javaHome = System.getProperty(""java.home"");
         final String userDir = System.getProperty(""user.dir"");
-        return PathUtils.get(javaHome).equals(PathUtils.get(userDir).resolve(""jdk"").toAbsolutePath());
+        if (Constants.MAC_OS_X) {
+            return PathUtils.get(javaHome).equals(PathUtils.get(userDir).resolve(""jdk/Contents/Home"").toAbsolutePath());
+        } else {
+            return PathUtils.get(javaHome).equals(PathUtils.get(userDir).resolve(""jdk"").toAbsolutePath());
+        }
     }
\ No newline at end of file
","Fix bug in detecting use of bundled JDK on macOS

This commit fixes a bug in detecting the use of the bundled JDK on
macOS. This bug arose because the path of Java home is different on
macOS.
",Buggy
elasticsearch,12667.json,7ae57d6e226bfc314ce31acc1a622fb0d111fa46,"@@ -1,36 +1,47 @@
     void refresh(PersistentTasksCustomMetaData persistentTasks, ActionListener<Void> onCompletion) {
 
         synchronized (fullRefreshCompletionListeners) {
             fullRefreshCompletionListeners.add(onCompletion);
             if (fullRefreshCompletionListeners.size() > 1) {
                 // A refresh is already in progress, so don't do another
                 return;
             }
         }
 
         ActionListener<Void> refreshComplete = ActionListener.wrap(aVoid -> {
             lastUpdateTime = Instant.now();
             synchronized (fullRefreshCompletionListeners) {
                 assert fullRefreshCompletionListeners.isEmpty() == false;
                 for (ActionListener<Void> listener : fullRefreshCompletionListeners) {
                     listener.onResponse(null);
                 }
                 fullRefreshCompletionListeners.clear();
             }
-        }, onCompletion::onFailure);
+        },
+        e -> {
+            synchronized (fullRefreshCompletionListeners) {
+                assert fullRefreshCompletionListeners.isEmpty() == false;
+                for (ActionListener<Void> listener : fullRefreshCompletionListeners) {
+                    listener.onFailure(e);
+                }
+                // It's critical that we empty out the current listener list on
+                // error otherwise subsequent retries to refresh will be ignored
+                fullRefreshCompletionListeners.clear();
+            }
+        });
 
         // persistentTasks will be null if there's never been a persistent task created in this cluster
         if (persistentTasks == null) {
             refreshComplete.onResponse(null);
         } else {
             List<PersistentTasksCustomMetaData.PersistentTask<?>> mlDataFrameAnalyticsJobTasks = persistentTasks.tasks().stream()
                 .filter(task -> MlTasks.DATA_FRAME_ANALYTICS_TASK_NAME.equals(task.getTaskName())).collect(Collectors.toList());
             ActionListener<Void> refreshDataFrameAnalyticsJobs =
                 ActionListener.wrap(aVoid -> refreshAllDataFrameAnalyticsJobTasks(mlDataFrameAnalyticsJobTasks, refreshComplete),
                     refreshComplete::onFailure);
 
             List<PersistentTasksCustomMetaData.PersistentTask<?>> mlAnomalyDetectorJobTasks = persistentTasks.tasks().stream()
                 .filter(task -> MlTasks.JOB_TASK_NAME.equals(task.getTaskName())).collect(Collectors.toList());
             iterateAnomalyDetectorJobTasks(mlAnomalyDetectorJobTasks.iterator(), refreshDataFrameAnalyticsJobs);
         }
     }
\ No newline at end of file
","[ML] Fix ML memory tracker lockup when inner step fails (#44158)

When the ML memory tracker is refreshed and a refresh is
already in progress the idea is that the second and
subsequent refresh requests receive the same response as
the currently in progress refresh.

There was a bug that if a refresh failed then the ML
memory tracker's view of whether a refresh was in progress
was not reset, leading to every subsequent request being
registered to receive a response that would never come.

This change makes the ML memory tracker pass on failures
as well as successes to all interested parties and reset
the list of interested parties so that further refresh
attempts are possible after either a success or failure.

This fixes problem 1 of #44156",Buggy
elasticsearch,39911.json,4735e0a9d3c7c89f34100e4fd47f3de25e56e1ed,"@@ -1,11 +1,14 @@
     public HistogramAggregationBuilder extendedBounds(double minBound, double maxBound) {
-        if (minBound == Double.NEGATIVE_INFINITY) {
-            throw new IllegalArgumentException(""minBound must not be -Infinity, got: "" + minBound);
+        if (Double.isFinite(minBound) == false) {
+            throw new IllegalArgumentException(""minBound must be finite, got: "" + minBound);
         }
-        if (maxBound == Double.POSITIVE_INFINITY) {
-            throw new IllegalArgumentException(""maxBound must not be +Infinity, got: "" + maxBound);
+        if (Double.isFinite(maxBound) == false) {
+            throw new IllegalArgumentException(""maxBound must be finite, got: "" + maxBound);
+        }
+        if (maxBound < minBound) {
+            throw new IllegalArgumentException(""maxBound ["" + maxBound + ""] must be greater than minBound ["" + minBound + ""]"");
         }
         this.minBound = minBound;
         this.maxBound = maxBound;
         return this;
     }
\ No newline at end of file
","Throw exception when maxBounds greater than minBounds

The recent changes to the Histogram Aggregator introduced a bug where
an exception would not be thrown if the maxBound of the extended bounds
is less that the minBound. This change fixes that bug.

Closes #19833
",Buggy
elasticsearch,45276.json,c5b6f52eccb2a663770e0eb9fee496432e1a8d5c,"@@ -1,21 +1,22 @@
-        private ImmutableOpenMap<String, List<ShardId>> findWaitingIndices(ImmutableOpenMap<ShardId, ShardSnapshotStatus> shards) {
+        ImmutableOpenMap<String, List<ShardId>> findWaitingIndices(ImmutableOpenMap<ShardId, ShardSnapshotStatus> shards) {
             Map<String, List<ShardId>> waitingIndicesMap = new HashMap<>();
             for (ObjectObjectCursor<ShardId, ShardSnapshotStatus> entry : shards) {
                 if (entry.value.state() == State.WAITING) {
-                    List<ShardId> waitingShards = waitingIndicesMap.get(entry.key.getIndex());
+                    final String indexName = entry.key.getIndexName();
+                    List<ShardId> waitingShards = waitingIndicesMap.get(indexName);
                     if (waitingShards == null) {
                         waitingShards = new ArrayList<>();
-                        waitingIndicesMap.put(entry.key.getIndexName(), waitingShards);
+                        waitingIndicesMap.put(indexName, waitingShards);
                     }
                     waitingShards.add(entry.key);
                 }
             }
             if (waitingIndicesMap.isEmpty()) {
                 return ImmutableOpenMap.of();
             }
             ImmutableOpenMap.Builder<String, List<ShardId>> waitingIndicesBuilder = ImmutableOpenMap.builder();
             for (Map.Entry<String, List<ShardId>> entry : waitingIndicesMap.entrySet()) {
                 waitingIndicesBuilder.put(entry.getKey(), Collections.unmodifiableList(entry.getValue()));
             }
             return waitingIndicesBuilder.build();
         }
\ No newline at end of file
","Fixes maintaining the shards a snapshot is waiting on (#24289)

There was a bug in the calculation of the shards that a snapshot must
wait on, due to their relocating or initializing, before the snapshot
can proceed safely to snapshot the shard data.  In this bug, an
incorrect key was used to look up the index of the waiting shards,
resulting in the fact that each index would have at most one shard in
the waiting state causing the snapshot to pause.  This could be
problematic if there are more than one shard in the relocating or
initializing state, which would result in a snapshot prematurely
starting because it thinks its only waiting on one relocating or
initializing shard (when in fact there could be more than one).  While
not a common case and likely rare in practice, it is still problematic.

This commit fixes the issue by ensuring the correct key is used to look
up the waiting indices map as it is being built up, so the list of
waiting shards for each index (those shards that are relocating or
initializing) are aggregated for a given index instead of overwritten.
",Buggy
elasticsearch,60460.json,953a99c75cde29a18db58abde3fdee720fcddc4f,"@@ -1,6 +1,6 @@
     public boolean isSame(StoreFileMetaData other) {
-        if (checksum != null && other.checksum != null) {
-            return checksum.equals(other.checksum);
+        if (checksum == null || other.checksum == null) {
+            return false;
         }
-        return length == other.length;
+        return length == other.length && checksum.equals(other.checksum);
     }
\ No newline at end of file
","fix a bug in new checksum mechanism that caused for replicas not to retain the _checksums file. Also, now that checksums are widely used, consider files without checksums as ones that need to be recovered
",Buggy
elasticsearch,52327.json,fe5af6f34d1204b6238c46c3aff7ea2a056eeb7a,"@@ -1,3 +1,3 @@
     public String toString() {
-        return ""shard ["" + (shardTarget == null ? ""_na"" : shardTarget) + ""], reason ["" + reason + ""]"";
+        return ""shard ["" + (shardTarget == null ? ""_na"" : shardTarget) + ""], reason ["" + reason + ""], cause ["" + (cause == null ? ""_na"" : ExceptionsHelper.stackTrace(cause)) + ""]"";
     }
\ No newline at end of file
","Tests: fix test bug (foo -> bar)
",Buggy
elasticsearch,15357.json,368e5a1194c2d2f762c117dd84397bb65f835dec,"@@ -1,5 +1,6 @@
     public static boolean validate(ClusterState state) {
-        return state.getMetaData().getTemplates().containsKey(WatcherIndexTemplateRegistryField.HISTORY_TEMPLATE_NAME) &&
+        return (state.getMetaData().getTemplates().containsKey(WatcherIndexTemplateRegistryField.HISTORY_TEMPLATE_NAME) ||
+            state.getMetaData().getTemplates().containsKey(WatcherIndexTemplateRegistryField.HISTORY_TEMPLATE_NAME_NO_ILM)) &&
             state.getMetaData().getTemplates().containsKey(WatcherIndexTemplateRegistryField.TRIGGERED_TEMPLATE_NAME) &&
             state.getMetaData().getTemplates().containsKey(WatcherIndexTemplateRegistryField.WATCHES_TEMPLATE_NAME);
     }
\ No newline at end of file
","fix unlikely bug that can prevent Watcher from restarting (#42030)

The bug fixed here is unlikely to happen. It requires ES to be started with
ILM disabled, Watcher enabled, and Watcher explicitly stopped and restarted.
Due to template validation Watcher does not fully start and can result in a
partially started state. This is an unlikely scenerio outside of the testing
framework.

Note - this bug was introduced while the test that would have caught it was
muted. The test remains muted since the underlying cuase of the random failures
has not been identified. When this test is un-muted it will now work.",Buggy
elasticsearch,53154.json,b7314c87211d99c45569ae0cdd8797636220b980,"@@ -1,11 +1,11 @@
     public String toString() {
         StringBuilder builder = new StringBuilder();
         builder.append(""IndexResponse["");
         builder.append(""index="").append(getIndex());
         builder.append("",type="").append(getType());
         builder.append("",id="").append(getId());
         builder.append("",version="").append(getVersion());
         builder.append("",result="").append(getResult().getLowercase());
-        builder.append("",shards="").append(getShardInfo());
+        builder.append("",shards="").append(Strings.toString(getShardInfo(), true));
         return builder.append(""]"").toString();
     }
\ No newline at end of file
","fix IndexResponse#toString to print out shards info (#20562)

IndexResponse#toString method outputs an error caused by the shards object needing to be wrapped into another object. It is fixed by calling a different variant of Strings.toString(XContent) which accepts a second boolean argument that makes sure that a new object is created before outputting ShardInfo. I didn't change ShardInfo#toString directly as whether it needs a new object or not very much depends on where it is printed out. IndexResponse seemed a specific case as the rest of the info were not json, hence the shards object was the first one, but it is usually not the case.",Buggy
elasticsearch,45221.json,5c59b1206762df8461b7f827ce3922231250c49e,"@@ -1,33 +1,35 @@
         public void writeTo(StreamOutput out) throws IOException {
             out.writeVInt(deletes.size());
             for (K delete : deletes) {
                 keySerializer.writeKey(delete, out);
             }
             Version version = out.getVersion();
             // filter out custom states not supported by the other node
             int diffCount = 0;
             for (Diff<T> diff : diffs.values()) {
                 if(valueSerializer.supportsVersion(diff, version)) {
                     diffCount++;
                 }
             }
             out.writeVInt(diffCount);
             for (Map.Entry<K, Diff<T>> entry : diffs.entrySet()) {
                 if(valueSerializer.supportsVersion(entry.getValue(), version)) {
                     keySerializer.writeKey(entry.getKey(), out);
                     valueSerializer.writeDiff(entry.getValue(), out);
                 }
             }
             // filter out custom states not supported by the other node
             int upsertsCount = 0;
             for (T upsert : upserts.values()) {
                 if(valueSerializer.supportsVersion(upsert, version)) {
                     upsertsCount++;
                 }
             }
             out.writeVInt(upsertsCount);
             for (Map.Entry<K, T> entry : upserts.entrySet()) {
-                keySerializer.writeKey(entry.getKey(), out);
-                valueSerializer.write(entry.getValue(), out);
+                if(valueSerializer.supportsVersion(entry.getValue(), version)) {
+                    keySerializer.writeKey(entry.getKey(), out);
+                    valueSerializer.write(entry.getValue(), out);
+                }
             }
         }
\ No newline at end of file
","Fixing the custom object serialization bug in diffable utils. (#39544)

While serializing custom objects, the length of the list is computed after
filtering out the unsupported objects but while writing objects the filter
is not applied thus resulting in writing unsupported objects which will fail
to deserialize by the receiever. Adding the condition to filter out unsupported
custom objects.",Buggy
elasticsearch,56477.json,1792bd6b160993aae2d925ad4b7c0663d14a9e82,"@@ -1,14 +1,6 @@
     public static IndexShardState fromId(byte id) throws ElasticSearchIllegalArgumentException {
-        if (id == 0) {
-            return CREATED;
-        } else if (id == 1) {
-            return RECOVERING;
-        } else if (id == 2) {
-            return STARTED;
-        } else if (id == 3) {
-            return RELOCATED;
-        } else if (id == 4) {
-            return CLOSED;
+        if (id < ORDS[0].id && id > ORDS[ORDS.length - 1].id) {
+            throw new ElasticSearchIllegalArgumentException(""No mapping for id ["" + id + ""]"");
         }
-        throw new ElasticSearchIllegalArgumentException(""No mapping for id ["" + id + ""]"");
+        return ORDS[id];
     }
\ No newline at end of file
","Fixed serialization error. POST_RECOVERY is now also serialized
",Buggy
checkstyle,1499.json,ca8fcd42047b2637e0027ff6aec79edd3656ba56,"@@ -1,3 +1,4 @@
-    public void setIgnoreEqualsIgnoreCase(boolean newValue) {
-        mIgnoreEqualsIgnoreCase = newValue;
+    public void setIgnoreEqualsIgnoreCase(boolean aNewValue)
+    {
+        mIgnoreEqualsIgnoreCase = aNewValue;
     }
\ No newline at end of file
","fix up checkstyle errors.
",Buggy
checkstyle,1058.json,9d41bddb46e5fbe291be4cdb347dee18ea4424fe,"@@ -1,4 +1,8 @@
     public int[] getRequiredTokens()
     {
-        return getDefaultTokens();
+        return new int[] {
+            TokenTypes.CTOR_DEF,
+            TokenTypes.METHOD_DEF,
+            TokenTypes.EXPR,
+        };
     }
\ No newline at end of file
","Fixed bug #1579227: Fixed docs, added unit tests and changed the check implementation to allow turning off the | and & operators
",Buggy
lombok,2739.json,aa40323ae8dde889f4bcf21304e5cffdc0003b4c,"@@ -1,21 +1,26 @@
 	public static TypeParameter[] copyTypeParams(TypeParameter[] params) {
 		if ( params == null ) return null;
 		TypeParameter[] out = new TypeParameter[params.length];
 		int idx = 0;
 		for ( TypeParameter param : params ) {
 			TypeParameter o = new TypeParameter();
 			o.annotations = param.annotations;
 			o.bits = param.bits;
 			o.modifiers = param.modifiers;
 			o.name = param.name;
 			o.type = copyType(param.type);
+			o.sourceStart = param.sourceStart;
+			o.sourceEnd = param.sourceEnd;
+			o.declarationEnd = param.declarationEnd;
+			o.declarationSourceStart = param.declarationSourceStart;
+			o.declarationSourceEnd = param.declarationSourceEnd;
 			if ( param.bounds != null ) {
 				TypeReference[] b = new TypeReference[param.bounds.length];
 				int idx2 = 0;
 				for ( TypeReference ref : param.bounds ) b[idx2++] = copyType(ref);
 				o.bounds = b;
 			}
 			out[idx++] = o;
 		}
 		return out;
 	}
\ No newline at end of file
","Fixed a problem where @Data with a static constructor and generics params on the class would generate errors regarding IllegalArgumentException in setSourcePosition in ASTNode.
",Buggy
lombok,3095.json,6fce13a8db45629a76e31c2a1c676ab9dac021dc,"@@ -1,7 +1,7 @@
-	private static int getReplacementOffset(IJavaCompletionProposal proposal) {
+	private static int getReplacementOffset(Object proposal) {
 		try {
 			return Reflection.replacementOffsetField.getInt(proposal);
 		} catch (Exception ignore) {
 			return 0;
 		}
 	}
\ No newline at end of file
","Somehow in eclipse mars wanted us to pull in more ecj deps, fixed that problem with a trivial code tweak.
",Buggy
lombok,1236.json,e4b61e1263eb0eb832eb6cfbd97ad92e869ca27e,"@@ -1,11 +1,11 @@
 	public static boolean typeMatches(String type, JavacNode node, JCTree typeNode) {
 		String typeName = typeNode == null ? null : typeNode.toString();
 		if (typeName == null || typeName.length() == 0) return false;
 		int lastIndexA = typeName.lastIndexOf('.') + 1;
-		int lastIndexB = type.lastIndexOf('.') + 1;
+		int lastIndexB = Math.max(type.lastIndexOf('.'), type.lastIndexOf('$')) + 1;
 		int len = typeName.length() - lastIndexA;
 		if (len != type.length() - lastIndexB) return false;
 		for (int i = 0; i < len; i++) if (typeName.charAt(i + lastIndexA) != type.charAt(i + lastIndexB)) return false;
 		TypeResolver resolver = node.getImportListAsTypeResolver();
 		return resolver.typeMatches(node, type, typeName);
 	}
\ No newline at end of file
",[performance] fixing bug in earlier performance commit on optimizing lookups of typeMatches.,Buggy
lombok,314.json,9ac86c8a234f2ecd280f27f0dbda15440b1bf155,"@@ -1,9 +1,12 @@
 	public static LombokOptions getDelombokOptions(Context context) {
+		Options rawOptions = Options.instance(context);
+		if (rawOptions instanceof LombokOptions) return (LombokOptions) rawOptions;
+		
 		LombokOptions options;
 		if (Javac.getJavaCompilerVersion() < 8) {
 			options = LombokOptionCompilerVersion.JDK7_AND_LOWER.createAndRegisterOptions(context);
 		} else {
 			options = LombokOptionCompilerVersion.JDK8.createAndRegisterOptions(context);
 		}
 		return options;
 	}
\ No newline at end of file
","fixed a bug where called LombokOptionsFactory.getLombokOptions() would actually cause the old options to be wrapped continuously, thus wrapping LombokOptions into itself infinitely. Now it just wraps if needed, other wise returns what's already been done.
",Buggy
hibernate-search,6397.json,58ae33f9813b56aa60ffb2d301bc1aca8f023f6c,"@@ -1,27 +1,41 @@
 	private void indexAllQueue(Session session) {
 		final InstanceInitializer sessionInitializer = new HibernateSessionLoadingInitializer(
-				(SessionImplementor) session );
+				(SessionImplementor) session
+		);
 		try {
 			ConversionContext contextualBridge = new ContextualExceptionBridgeHelper();
 			while ( true ) {
 				List<?> takeList = source.take();
 				if ( takeList == null ) {
 					break;
 				}
 				else {
 					log.tracef( ""received a list of objects to index: %s"", takeList );
-					for ( Object take : takeList ) {
+					for ( Object object : takeList ) {
 						//trick to attach the objects to session:
-						session.buildLockRequest( LockOptions.NONE ).lock( take );
-						index( take, session, sessionInitializer, contextualBridge );
-						monitor.documentsBuilt( 1 );
+						session.buildLockRequest( LockOptions.NONE ).lock( object );
+						try {
+							index( object, session, sessionInitializer, contextualBridge );
+							monitor.documentsBuilt( 1 );
+						}
+						catch (InterruptedException ie) {
+							// rethrowing the interrupted exception
+							throw ie;
+						}
+						catch (RuntimeException e) {
+							String errorMsg = log.massIndexerUnableToIndexInstance(
+									object.getClass().getName(),
+									object.toString()
+							);
+							errorHandler.handleException( errorMsg, e );
+						}
 						session.clear();
 					}
 				}
 			}
 		}
 		catch (InterruptedException e) {
 			// just quit
 			Thread.currentThread().interrupt();
 		}
 	}
\ No newline at end of file
","HSEARCH-1354 Fixing error handling during indexing for mass indexer and adding test case
",Buggy
hibernate-search,1888.json,835d01200cf073c05220f435d7ec47dc2593dddb,"@@ -1,13 +1,13 @@
-	public Query filterOrPassthrough(Query filteredQuery) {
+	public Query filterOrPassthrough(Query queryToFilter) {
 		if ( isEmpty() ) {
-			return filteredQuery;
+			return queryToFilter;
 		}
 		else {
 			BooleanQuery.Builder boolQueryBuilder = new BooleanQuery.Builder();
-			boolQueryBuilder.add( filteredQuery, Occur.MUST );
+			boolQueryBuilder.add( queryToFilter, Occur.MUST );
 			for ( Query bc : filterQueries ) {
 				boolQueryBuilder.add( bc, BooleanClause.Occur.FILTER );
 			}
 			return boolQueryBuilder.build();
 		}
 	}
\ No newline at end of file
","HSEARCH-2698 Fix incomplete javadoc for some methods

This does not address all the problems, I intentionally didn't address
the more controversial ones (like the useless @return in fluent APIs).
",Buggy
wildfly,13142.json,77807f20fe0a38e6b867210ebf1b305edc14cf6a,"@@ -1,55 +1,59 @@
     private Method getTimeoutMethod(TimeoutMethod timeoutMethodInfo) {
 
         String declaringClass = timeoutMethodInfo.getDeclaringClass();
         Class<?> timeoutMethodDeclaringClass = null;
         try {
             timeoutMethodDeclaringClass = Class.forName(declaringClass, false, timedObjectInvoker.getClassLoader());
         } catch (ClassNotFoundException cnfe) {
-            throw new RuntimeException(""Could not load declaring class: "" + declaringClass + "" of timeout method"");
+            throw new RuntimeException(""Could not load declaring class: "" + declaringClass + "" of timeout method"", cnfe);
         }
 
         String timeoutMethodName = timeoutMethodInfo.getMethodName();
         String[] timeoutMethodParams = timeoutMethodInfo.getMethodParams();
         // load the method param classes
         Class<?>[] timeoutMethodParamTypes = new Class<?>[]
                 {};
         if (timeoutMethodParams != null) {
             timeoutMethodParamTypes = new Class<?>[timeoutMethodParams.length];
             int i = 0;
             for (String paramClassName : timeoutMethodParams) {
                 Class<?> methodParamClass = null;
                 try {
                     methodParamClass = Class.forName(paramClassName, false, timedObjectInvoker.getClassLoader());
                 } catch (ClassNotFoundException cnfe) {
-                    throw new RuntimeException(""Could not load method param class: "" + paramClassName + "" of timeout method"");
+                    throw new RuntimeException(""Could not load method param class: "" + paramClassName + "" of timeout method"", cnfe);
                 }
                 timeoutMethodParamTypes[i++] = methodParamClass;
             }
         }
         // now start looking for the method
         Class<?> klass = timeoutMethodDeclaringClass;
         while (klass != null) {
             Method[] methods = klass.getDeclaredMethods();
             for (Method method : methods) {
                 if (method.getName().equals(timeoutMethodName)) {
                     Class<?>[] methodParamTypes = method.getParameterTypes();
                     // param length doesn't match
                     if (timeoutMethodParamTypes.length != methodParamTypes.length) {
                         continue;
                     }
+                    boolean match = true;
                     for (int i = 0; i < methodParamTypes.length; i++) {
                         // param type doesn't match
                         if (!timeoutMethodParamTypes[i].equals(methodParamTypes[i])) {
-                            continue;
+                            match = false;
+                            break;
                         }
                     }
-                    // match found
-                    return method;
+                    if (match) {
+                        // match found
+                        return method;
+                    }
                 }
             }
             klass = klass.getSuperclass();
 
         }
         // no match found
         return null;
     }
\ No newline at end of file
","Fix minor timer service bug
",Buggy
wildfly,15035.json,162a90c311abfe554f09dc4b9c080098bd27ad89,"@@ -1,18 +1,18 @@
         public final T visit(final ContextNode contextNode) throws NamingException {
             if (isEmpty(currentName)) {
                 return found(contextNode);
             }
             final String childName = currentName.get(0);
             traversedName.add(childName);
             currentName = currentName.getSuffix(1);
             final TreeNode node = contextNode.children.get(childName);
             if (node == null) {
                 if (createIfMissing) {
-                    final NamingContext subContext = new NamingContext(traversedName, InMemoryNamingStore.this, new Hashtable<String, Object>());
-                    return contextNode.addOrGetChild(childName, new ContextNode(contextNode, childName, traversedName, subContext)).accept(this);
+                    final NamingContext subContext = new NamingContext((Name)traversedName.clone(), InMemoryNamingStore.this, new Hashtable<String, Object>());
+                    return contextNode.addOrGetChild(childName, new ContextNode(contextNode, childName, (Name)traversedName.clone(), subContext)).accept(this);
                 } else {
                     throw nameNotFoundException(childName, contextNode.fullName);
                 }
             }
             return node.accept(this);
         }
\ No newline at end of file
","AS7-1407 - Fix bug in nested context binding
",Buggy
wildfly,11562.json,1af2b154ec4daa8436ba6f946ef54fe201062c6a,"@@ -1,6 +1,8 @@
     private synchronized void destroySingletonInstance() {
         if (this.singletonComponentInstance != null) {
-            this.destroyInstance(this.singletonComponentInstance);
+            // TODO: Implement destroying an instance
+            logger.warn(""Destorying of singleton instance not yet implemented"");
+            //this.destroyInstance(this.singletonComponentInstance);
             this.singletonComponentInstance = null;
         }
     }
\ No newline at end of file
","Fix compilation errors in EJB3 module to start refactoring the EJB3 component
",Buggy
wildfly,9528.json,3b47b9b23bf3f10d124f26f37dff3245fe09ec56,"@@ -1,52 +1,52 @@
         public void execute(final OperationContext context, final ModelNode operation) throws OperationFailedException {
             final ModelNode model = context.readResource(PathAddress.EMPTY_ADDRESS).getModel();
 
             final ModelNode coreThreads;
             final ModelNode maxThreads;
             final ModelNode queueLength;
 
             if (isRuntimeStage) {
                 coreThreads = CORE_THREADS_AD.resolveModelAttribute(context, model);
                 maxThreads = MAX_THREADS_AD.resolveModelAttribute(context, model);
                 queueLength = QUEUE_LENGTH_AD.resolveModelAttribute(context, model);
             } else {
                 coreThreads = model.get(CORE_THREADS);
                 maxThreads = model.get(MAX_THREADS);
                 queueLength = model.get(QUEUE_LENGTH);
             }
 
             if (coreThreads.getType() == ModelType.EXPRESSION || maxThreads.getType() == ModelType.EXPRESSION ||
                     queueLength.getType() == ModelType.EXPRESSION) {
                 context.addStep(new ExecutorQueueValidationStepHandler(true), OperationContext.Stage.RUNTIME, true);
                 return;
             }
 
             // Validate an unbounded queue
             if (!queueLength.isDefined() || queueLength.asInt() == Integer.MAX_VALUE) {
                 if (coreThreads.isDefined() && coreThreads.asInt() <= 0) {
-                    throw EeLogger.ROOT_LOGGER.invalidCoreThreadsSize(coreThreads.asString());
+                    throw EeLogger.ROOT_LOGGER.invalidCoreThreadsSize(queueLength.asString());
                 }
 
             }
 
             // Validate a hand-off queue
             if (queueLength.isDefined() && queueLength.asInt() == 0) {
                 if (coreThreads.isDefined() && coreThreads.asInt() <= 0) {
-                    throw EeLogger.ROOT_LOGGER.invalidCoreThreadsSize(coreThreads.asString());
+                    throw EeLogger.ROOT_LOGGER.invalidCoreThreadsSize(queueLength.asString());
                 }
             }
 
             // max-threads must be defined and greater than 0 if core-threads is 0
             if (coreThreads.isDefined() && coreThreads.asInt() == 0) {
                 if (!maxThreads.isDefined() || maxThreads.asInt() <= 0) {
                     throw EeLogger.ROOT_LOGGER.invalidMaxThreads(maxThreads.isDefined() ? maxThreads.asInt() : 0, coreThreads.asInt());
                 }
             }
 
             // max-threads must be greater than or equal to core-threads
             if (coreThreads.isDefined() && maxThreads.isDefined()) {
                 if (maxThreads.asInt() < coreThreads.asInt()) {
                     throw EeLogger.ROOT_LOGGER.invalidMaxThreads(maxThreads.asInt(), coreThreads.asInt());
                 }
             }
         }
\ No newline at end of file
","[WFLY-8516] Update schema documentation and fix error messages for the managed-executor-service.
",Buggy
wildfly,10266.json,2bb205f62a00e2d69781f4b468c299316f855764,"@@ -1,5 +1,5 @@
     public void start(StartContext context) throws StartException {
         this.value.setDefaultBootstrapContext(defaultBootstrapContext.getValue());
-        ROOT_LOGGER.startingSubsystem(""JCS"", Version.FULL_VERSION);
+        ROOT_LOGGER.startingSubsystem(""JCA"", Version.FULL_VERSION);
         ROOT_LOGGER.tracef(""config=%s"", value);
     }
\ No newline at end of file
","Fix spelling error in a JCA subsystem log message.
",Buggy
wildfly,18502.json,a10bd882e880725b709e6745e140931720629a95,"@@ -1,17 +1,20 @@
     public InputStream sanitize(InputStream in) throws Exception {
+        byte [] content = IOUtils.toByteArray(in);
         try {
-            Document doc = builder.parse(in);
+            // storing the entire file in memory in case we need to bail.
+            Document doc = builder.parse(new ByteArrayInputStream(content));
             Object result = expression.evaluate(doc, XPathConstants.NODESET);
             NodeList nodes = (NodeList) result;
             for (int i = 0; i < nodes.getLength(); i++) {
                 nodes.item(i).setTextContent("""");
             }
             DOMSource source = new DOMSource(doc);
             ByteArrayOutputStream output = new ByteArrayOutputStream();
             StreamResult outStream = new StreamResult(output);
             transformer.transform(source, outStream);
             return new ByteArrayInputStream(output.toByteArray());
         } catch (Exception e) {
-            return in;
+            ROOT_LOGGER.debug(""Error while sanitizing an xml document"", e);
+            return new ByteArrayInputStream(content);
         }
     }
\ No newline at end of file
","Addressing AS7-6731 [bz920113]

Module dependency on xalan now uses services=import
Adding javadoc to various bits of the code
Fixes an issue where an error during sanitation causes
0 length files to be stored in the archive.
",Buggy
wildfly,6365.json,7f64913774a8043da0b0cc545f4e1b2a8af1a082,"@@ -1,7 +1,13 @@
     public boolean isTransactionActive() {
         try {
-            return (injectedTransaction.getValue().getStatus() & Status.STATUS_ACTIVE) != 0;
+            final int status = injectedTransaction.getValue().getStatus();
+            return status == Status.STATUS_ACTIVE ||
+                    status == Status.STATUS_COMMITTING ||
+                    status == Status.STATUS_MARKED_ROLLBACK ||
+                    status == Status.STATUS_PREPARED ||
+                    status == Status.STATUS_PREPARING ||
+                    status == Status.STATUS_ROLLING_BACK;
         } catch (SystemException e) {
             throw new RuntimeException(""SystemException while getting transaction status"", e);
         }
     }
\ No newline at end of file
","Fix bug in WeldTransactionServices
",Buggy
wildfly,14704.json,59232bbc1b3a2808f2cbc125e1aca2647fa5abd5,"@@ -1,16 +1,11 @@
     public static void initializeNamingManager() {
         // Setup naming environment
         System.setProperty(Context.URL_PKG_PREFIXES, PACKAGE_PREFIXES);
         try {
             //If we are reusing the JVM. e.g. in tests we should not set this again
             if (!NamingManager.hasInitialContextFactoryBuilder())
                 NamingManager.setInitialContextFactoryBuilder(new InitialContextFactoryBuilder());
         } catch (NamingException e) {
             log.warn(""Failed to set InitialContextFactoryBuilder"", e);
         }
-        try {
-            NamingManager.setObjectFactoryBuilder(ObjectFactoryBuilder.INSTANCE);
-        } catch(Throwable t) {
-            log.warn(""Failed to set ObjectFactoryBuilder"", t);
-        }
     }
\ No newline at end of file
","Fix problem where object factory builder can only be set once
",Buggy
wildfly,14735.json,603f475d6af9bc7abc7bcee74a897d4577977d27,"@@ -1,3 +1,3 @@
     public void close() throws NamingException {
-        namingStore.close();
+        // NO-OP
     }
\ No newline at end of file
","Fix bug in naming context with Context.close removing entries from the naming store
",Buggy
wildfly,5832.json,8c3680a316585b462638de3f031affc527f5c723,"@@ -1,7 +1,7 @@
     public static <T> Class<T> loadClass(String className, ClassLoader classLoader) {
         try {
             return cast(classLoader.loadClass(className));
-        } catch (Exception e) {
+        } catch (Throwable e) {
             return null;
         }
     }
\ No newline at end of file
","Capture RuntimeExceptions in dinamic class loading

Since 9.x, if you deploy an war with two (or more wars) with different libraries, deployment crash since it's trying to load classes from one WAR with the classloader from the other WAR. This cross load is intended (see BeanDeploymentArchiveImpl, method isAccesible, line 246, WFLY-4250), but it's waiting for a null load, not a RuntimeException.

With this fix, a warn is registered in log but application can be loaded without major problems.
",Buggy
wildfly,10236.json,efb61994477cc0e8f0f1eca6da690a78c9c33699,"@@ -1,21 +1,21 @@
         private void writeWorkManagers(XMLExtendedStreamWriter writer, ModelNode parentNode) throws XMLStreamException {
             if (parentNode.hasDefined(WORKMANAGER) && parentNode.get(WORKMANAGER).asList().size() != 0) {
                 for (Property property : parentNode.get(WORKMANAGER).asPropertyList()) {
                     if (""default"".equals(property.getValue().get(NAME).asString())) {
                         writer.writeStartElement(Element.DEFAULT_WORKMANAGER.getLocalName());
                     } else {
                         writer.writeStartElement(Element.WORKMANAGER.getLocalName());
                         WorkManagerAdd.WmParameters.NAME.getAttribute().marshallAsAttribute(property.getValue(), writer);
                     }
-                    for (Property prop : property.getValue().asPropertyList()) {
+                    for (Property prop : property.getValue().asPropertyList() ) {
                         if (WORKMANAGER_LONG_RUNNING.equals(prop.getName()) && prop.getValue().isDefined() && prop.getValue().asPropertyList().size() != 0) {
                             ThreadsParser.getInstance().writeBoundedQueueThreadPool(writer, prop.getValue().asProperty().getValue(), Element.LONG_RUNNING_THREADS.getLocalName(), false);
                         }
-                        if (WORKMANAGER_SHORT_RUNNING.equals(prop.getName())) {
+                        if (WORKMANAGER_SHORT_RUNNING.equals(prop.getName()) && prop.getValue().isDefined() && prop.getValue().asPropertyList().size() != 0) {
                             ThreadsParser.getInstance().writeBoundedQueueThreadPool(writer, prop.getValue().asProperty().getValue(), Element.SHORT_RUNNING_THREADS.getLocalName(), false);
                         }
                     }
                     writer.writeEndElement();
                 }
             }
         }
\ No newline at end of file
","Fixing persistemce problem when all thread executor config has been removed
",Buggy
wildfly,10893.json,e8dd2b36ea6a8dd25b8cffc37791e862fb08aa45,"@@ -1,12 +1,12 @@
         public ResourceAdapter doDeploy(URL url, String deploymentName, File root, ClassLoader cl, Connector cmd,
                 IronJacamar ijmd) throws Throwable {
             // TODO
             this.setConfiguration(getConfig().getValue());
 
             this.start();
 
-            CommonDeployment dep = this.createObjectsAndInjectValue(url, deploymentName, root, null, cl, cmd, ijmd, null);
+            CommonDeployment dep = this.createObjectsAndInjectValue(url, deploymentName, root, cl, cmd, ijmd);
 
             return dep.getResourceAdapter();
 
         }
\ No newline at end of file
","fixing problem with latests ironjacamar snapshots
",Buggy
javaparser,3383.json,85b5cf5a98bc7fc59b3481d802bdff3b736ae8a1,"@@ -1,62 +1,65 @@
     public void accept(VarType node, ProblemReporter reporter) {
         // All allowed locations are within a VariableDeclaration inside a VariableDeclarationExpr inside something else.
         Optional<VariableDeclarator> variableDeclarator = node.findAncestor(VariableDeclarator.class);
         if (!variableDeclarator.isPresent()) {
             // Java 11's var in lambda's
             if (varAllowedInLambdaParameters) {
                 boolean valid = node
                         .findAncestor(Parameter.class)
                         .flatMap(Node::getParentNode)
                         .map((Node p) -> p instanceof LambdaExpr).orElse(false);
                 if (valid) {
                     return;
                 }
             }
             reportIllegalPosition(node, reporter);
             return;
         }
         variableDeclarator.ifPresent(vd -> {
+            if(vd.getType().isArrayType()){
+                reporter.report(vd, ""\""var\"" cannot have extra array brackets."");
+            }
             Optional<Node> variableDeclarationExpr = vd.getParentNode();
             if (!variableDeclarationExpr.isPresent()) {
                 reportIllegalPosition(node, reporter);
                 return;
             }
             variableDeclarationExpr.ifPresent(vdeNode -> {
                 if (!(vdeNode instanceof VariableDeclarationExpr)) {
                     reportIllegalPosition(node, reporter);
                     return;
                 }
                 VariableDeclarationExpr vde = (VariableDeclarationExpr) vdeNode;
                 if (vde.getVariables().size() > 1) {
                     reporter.report(vde, ""\""var\"" only takes a single variable."");
                 }
                 Optional<Node> container = vdeNode.getParentNode();
                 if (!container.isPresent()) {
                     reportIllegalPosition(node, reporter);
                     return;
                 }
                 container.ifPresent(c -> {
                     boolean positionIsFine = c instanceof ForStmt || c instanceof ForeachStmt || c instanceof ExpressionStmt;
                     if (!positionIsFine) {
                         reportIllegalPosition(node, reporter);
                     }
                     // A local variable declaration ends up inside an ExpressionStmt.
                     if (c instanceof ExpressionStmt) {
                         if (!vd.getInitializer().isPresent()) {
                             reporter.report(node, ""\""var\"" needs an initializer."");
                         }
                         vd.getInitializer().ifPresent(initializer -> {
                             if (initializer instanceof NullLiteralExpr) {
                                 reporter.report(node, ""\""var\"" cannot infer type from just null."");
                             }
-                            if (initializer instanceof ArrayCreationExpr) {
+                            if (initializer instanceof ArrayInitializerExpr) {
                                 reporter.report(node, ""\""var\"" cannot infer array types."");
                             }
                         });
 
                     }
                 });
             });
         });
 
     }
\ No newline at end of file
","Fix mistake with var and array initializers.
",Buggy
javaparser,6722.json,c620101966295e302b9ff94a73a0e2ab29c7ec6d,"@@ -1,3 +1,3 @@
     public boolean isWildcard() {
-        return getType().isArray();
+        return getType().isWildcard();
     }
\ No newline at end of file
","Fix bug in LazyType
",Buggy
javaparser,6689.json,a795de5cf63b37147e9efcd9ed89e486a613fd3c,"@@ -1,3 +1,3 @@
     public String getName() {
-        return constructor.getName();
+        return constructor.getDeclaringClass().getSimpleName();
     }
\ No newline at end of file
","Fixed a bug in ReflectionConstructorDeclaration that caused the constructor's signature to be calculated incorrectly.
",Buggy
javaparser,6349.json,dc99432270600b2bb2a445c86b329a77601005e6,"@@ -1,10 +1,10 @@
     public SymbolReference<ResolvedAnnotationDeclaration> solve(AnnotationExpr annotationExpr) {
         Context context = JavaParserFactory.getContext(annotationExpr, typeSolver);
         SymbolReference<ResolvedTypeDeclaration> typeDeclarationSymbolReference = context.solveType(annotationExpr.getNameAsString(), typeSolver);
-        ResolvedAnnotationDeclaration annotationDeclaration = (ResolvedAnnotationDeclaration) typeDeclarationSymbolReference.getCorrespondingDeclaration();
         if (typeDeclarationSymbolReference.isSolved()) {
+            ResolvedAnnotationDeclaration annotationDeclaration = (ResolvedAnnotationDeclaration) typeDeclarationSymbolReference.getCorrespondingDeclaration();
             return SymbolReference.solved(annotationDeclaration);
         } else {
             return SymbolReference.unsolved(ResolvedAnnotationDeclaration.class);
         }
     }
\ No newline at end of file
","Fixed minor bug: a corresponding declaration of a SymbolReference is only available if the SymbolReference is solved, and one should not try to retrieve it otherwise, lest a NullPointerException be thrown.
",Buggy
intellij-community,15168.json,8983e75f816afa5ca0d149e488a252e54d16f50f,"@@ -1,22 +1,22 @@
   private static void showWhatsNewNotification(@NotNull Project project) {
     PropertiesComponent properties = PropertiesComponent.getInstance();
     String updateHtmlMessage = properties.getValue(UPDATE_WHATS_NEW_MESSAGE);
     if (updateHtmlMessage == null) {
       LOG.warn(""Cannot show what's new notification: no content found."");
       return;
     }
 
     String title = IdeBundle.message(""update.whats.new.notification.title"", ApplicationNamesInfo.getInstance().getFullProductName());
     UpdateChecker.getNotificationGroup().createNotification(title, null, null, NotificationType.INFORMATION, null)
       .addAction(new NotificationAction(IdeBundle.message(""update.whats.new.notification.action"")) {
         @Override
         public void actionPerformed(@NotNull AnActionEvent e, @NotNull Notification notification) {
           LightVirtualFile file = new LightVirtualFile(IdeBundle.message(""update.whats.new.file.name"", ApplicationInfo.getInstance().getFullVersion()), updateHtmlMessage);
           file.putUserData(HTMLEditorProvider.Companion.getHTML_CONTENT_TYPE(), true);
           FileEditorManager.getInstance(project).openFile(file, true);
           IdeUpdateUsageTriggerCollector.trigger(""update.whats.new"");
           notification.expire();
         }
-      });
+      }).notify(project);
     properties.setValue(UPDATE_WHATS_NEW_MESSAGE, null);
   }
\ No newline at end of file
","Fix stupid mistake: lost call notify()

GitOrigin-RevId: 954900084aa113c881590d721b66974c560d9d9f",Buggy
intellij-community,24434.json,358dddc2d98464d660a801e43e3671cbd5b340ed,"@@ -1,5 +1,5 @@
   public static Icon loadApplicationIconImage(@NotNull ScaleContext ctx, int size) {
     String url = ApplicationInfoImpl.getShadowInstance().getApplicationSvgIconUrl();
     Image image = loadApplicationIconImage(url, ctx, size, null);
-    return image != null ? new JBImageIcon(ImageUtil.ensureHiDPI(image, ctx)) : null;
+    return image != null ? new JBImageIcon(image) : null;
   }
\ No newline at end of file
","IDEA-217767 License dialog polishing

* App icon problems fixed

GitOrigin-RevId: babcb9bce8c091934088cc24bc7ce335170096a6",Buggy
intellij-community,8042.json,08de853c05b9eb1944f79c1ea7df05ae1f103aa7,"@@ -1,3 +1,3 @@
   protected static String getUserHome() {
-    return SystemProperties.getUserHome();
+    return StringUtil.trimEnd(SystemProperties.getUserHome(), ""/"");
   }
\ No newline at end of file
","save all paths in .iml relatively except for the ones under USER_HOME (IDEA-60906)
reason: fixes the issue and I don't see any problems it could cause
",Buggy
intellij-community,32648.json,0922a97944f2ca7d388ba2807e0e64afb02fe427,"@@ -1,3 +1,3 @@
   public void load(Element element) {
-    setVagrantFolder(element.getAttributeValue(VAGRANT_FOLDER));
+    setVagrantFolder(StringUtil.notNullize(element.getAttributeValue(VAGRANT_FOLDER)));
   }
\ No newline at end of file
","Vagrant error messaging fixed.
",Buggy
intellij-community,23329.json,bcb3520ffa862b37e8147a7dac6cddb7d67c82b8,"@@ -1,29 +1,29 @@
     public void doExecute(Editor editor, @Nullable Caret caret, DataContext dataContext) {
       int endOffset = editor.getDocument().getTextLength();
       List<Caret> carets = editor.getCaretModel().getAllCarets();
       if (editor.isColumnMode() && editor.getCaretModel().supportsMultipleCarets()) {
         if (caret == null) { // normally we're always called with null caret
           caret = carets.get(0) == editor.getCaretModel().getPrimaryCaret() ? carets.get(carets.size() - 1) : carets.get(0);
         }
         LogicalPosition leadSelectionPosition = editor.visualToLogicalPosition(caret.getLeadSelectionPosition());
         LogicalPosition targetPosition = editor.offsetToLogicalPosition(endOffset).leanForward(true);
         editor.getSelectionModel().setBlockSelection(leadSelectionPosition, targetPosition);
       }
       else {
         if (caret == null) { // normally we're always called with null caret
           caret = carets.get(0);
         }
         int selectionStart = caret.getLeadSelectionOffset();
         if (editor instanceof EditorImpl && ((EditorImpl)editor).myUseNewRendering) {
-          editor.getCaretModel().moveToLogicalPosition(editor.offsetToLogicalPosition(endOffset).leanForward(true));
+          caret.moveToLogicalPosition(editor.offsetToLogicalPosition(endOffset).leanForward(true));
         }
         else {
           caret.moveToOffset(endOffset);
         }
         caret.setSelection(selectionStart, endOffset);
       }
       ScrollingModel scrollingModel = editor.getScrollingModel();
       scrollingModel.disableAnimation();
       scrollingModel.scrollToCaret(ScrollType.CENTER);
       scrollingModel.enableAnimation();
     }
\ No newline at end of file
","editor.new.rendering: fix a mistake in TextEndWithSelectionAction
",Buggy
intellij-community,11452.json,8a97673aeb2e23f7a0bafdb1907b513cd3514810,"@@ -1,3 +1,3 @@
-  protected boolean atToken(final IElementType tokenType) {
+  protected boolean atToken(@Nullable final IElementType tokenType) {
     return myBuilder.getTokenType() == tokenType;
   }
\ No newline at end of file
","better recovery for syntax errors in parameter list (PY-3635); fix old bug with tuple parameters parsing
",Buggy
intellij-community,28989.json,ac607f3f6a68a2dbccca5581d55264e5ecad1181,"@@ -1,4 +1,4 @@
     public void addNotify() {
       super.addNotify();
-      addMouseListenerToHierarchy(this, myEntranceListener);
+      ListenerUtil.addMouseListener(this, myEntranceListener);
     }
\ No newline at end of file
","links in IDE Fatal errors fix
",Buggy
intellij-community,10790.json,e3fc0ee66ac0e1b3cff41e6cf7cf90b5c16318f5,"@@ -1,26 +1,29 @@
   private static int getExpressionPriority(PyElement expr) {
     int priority = 0;
-    if (expr instanceof PySubscriptionExpression || expr instanceof PySliceExpression || expr instanceof PyCallExpression) priority = 1;
+    if (expr instanceof PyReferenceExpression ||
+        expr instanceof PySubscriptionExpression ||
+        expr instanceof PySliceExpression ||
+        expr instanceof PyCallExpression) priority = 1;
     else if (expr instanceof PyPrefixExpression) {
       final IElementType opType = getOperationType(expr);
       if (opType == PLUS || opType == MINUS || opType == TILDE) priority = 2;
       if (opType == NOT_KEYWORD) priority = 11;
     }
     else if (expr instanceof PyBinaryExpression) {
       final IElementType opType = getOperationType(expr);
       if (opType == EXP) priority =  3;
       if (opType == MULT || opType == DIV || opType == PERC || opType == FLOORDIV) priority =  4;
       if (opType == PLUS || opType == MINUS) priority =  5;
       if (opType == LTLT || opType == GTGT) priority = 6;
       if (opType == AND) priority = 7;
       if (opType == XOR) priority = 8;
       if (opType == OR) priority = 9;
       if (COMPARISON_OPERATIONS.contains(opType)) priority = 10;
       if (opType == AND_KEYWORD) priority = 12;
       if (opType == OR_KEYWORD) priority = 13;
     }
     else if (expr instanceof PyConditionalExpression) priority = 14;
     else if (expr instanceof PyLambdaExpression) priority = 15;
 
     return -priority;
   }
\ No newline at end of file
","PY-13114 Inlining of method call does not add extra parenthesis

Fix prioritization problem: reference expressions should have the same
priority as indexing, slicing and function calls.
",Buggy
intellij-community,11366.json,aa7434f6b1f2853d50f940681697db30743e0f2e,"@@ -1,12 +1,13 @@
   static void deleteAdjacentComma(ASTDelegatePsiElement pyImportStatement, ASTNode child, final PyElement[] elements) {
     if (ArrayUtil.contains(child.getPsi(), elements)) {
       ASTNode next = getNextComma(child);
       if (next == null) {
         next = getPrevComma(child);
       }
       if (next != null) {
-        removeSlash(pyImportStatement, next);
+        final ASTNode prev = next.getTreePrev();
         pyImportStatement.deleteChildInternal(next);
+        removeSlash(pyImportStatement, prev);
       }
     }
   }
\ No newline at end of file
","fixed PY-5489 Refactor/Move: leads to syntax error with multi-line imports
",Buggy
intellij-community,11366.json,319662174c861f6c1472a6d644db4513907f4c74,"@@ -1,11 +1,12 @@
   static void deleteAdjacentComma(ASTDelegatePsiElement pyImportStatement, ASTNode child, final PyElement[] elements) {
     if (ArrayUtil.contains(child.getPsi(), elements)) {
       ASTNode next = getNextComma(child);
       if (next == null) {
         next = getPrevComma(child);
       }
       if (next != null) {
+        removeSlash(pyImportStatement, next);
         pyImportStatement.deleteChildInternal(next);
       }
     }
   }
\ No newline at end of file
","fixed PY-5489 Refactor/Move: leads to syntax error with multi-line imports
",Buggy
intellij-community,36036.json,84dd250e37af6f1a98d160eaae6a59022d24c7dd,"@@ -1,8 +1,11 @@
   public void revalidate(@NotNull PositionTracker<Balloon> tracker) {
+    if (ApplicationManager.getApplication().isDisposeInProgress()) {
+      return;
+    }
     RelativePoint newPosition = tracker.recalculateLocation(this);
 
     if (newPosition != null) {
       myTargetPoint = myPosition.getShiftedPoint(newPosition.getPoint(myLayeredPane), myCalloutShift);
       myPosition.updateBounds(this);
     }
   }
\ No newline at end of file
","Fix for ""Application being disposed"" error
",Buggy
intellij-community,29938.json,d5022fa9bef92fcb2e21a87b4a03cb0938a1f961,"@@ -1,12 +1,20 @@
   private void doCloseCommunication() {
     if (myPydevConsoleCommunication != null) {
-      try {
-        myPydevConsoleCommunication.close();
-        // waiting for REPL communication before destroying process handler
-        Thread.sleep(300);
-      }
-      catch (Exception e1) {
-        // Ignore
-      }
+
+      UIUtil.invokeAndWaitIfNeeded(new Runnable() {
+        @Override
+        public void run() {
+          try {
+            myPydevConsoleCommunication.close();
+            Thread.sleep(300);
+          }
+          catch (Exception e1) {
+            // Ignore
+          }
+        }
+      });
+
+      // waiting for REPL communication before destroying process handler
+
     }
   }
\ No newline at end of file
","Fixed EDT bug (PY-3434).
",Buggy
intellij-community,12571.json,d9a69b15763b0da7a03c07d0f9c8e5a8f7e3d7f7,"@@ -1,25 +1,25 @@
     private static void appendDescriptors(ASTNode node,
                                           List<FoldingDescriptor> descriptors) {
         if (node.getElementType() == PyElementTypes.STATEMENT_LIST) {
             IElementType elType = node.getTreeParent().getElementType();
             if (elType == PyElementTypes.FUNCTION_DECLARATION || elType == PyElementTypes.CLASS_DECLARATION) {
                 ASTNode colon = node.getTreeParent().findChildByType(PyTokenTypes.COLON);
-                if (colon != null && colon.getStartOffset() + 1 < node.getStartOffset() + node.getTextLength()) {
+                if (colon != null && colon.getStartOffset() + 1 < colon.getTextRange().getEndOffset()) {
                     descriptors.add(new FoldingDescriptor(node,
                             new TextRange(colon.getStartOffset() + 1, node.getStartOffset() + node.getTextLength())));
                 }
                 else {
                     TextRange range = node.getTextRange();
                     if (range.getStartOffset() < range.getEndOffset()-1) { // only for ranges at leas 1 char wide
                         descriptors.add(new FoldingDescriptor(node, range));
                     }
                 }
             }
         }
 
         ASTNode child = node.getFirstChildNode();
         while (child != null) {
             appendDescriptors(child, descriptors);
             child = child.getTreeNext();
         }
     }
\ No newline at end of file
","Fixed an assertion error when indentation is wrong. (This whole thing begs to be rewritten.)
",Buggy
intellij-community,12571.json,df6834a4b25a87ff95c28760a761cae01c53874f,"@@ -1,25 +1,25 @@
     private static void appendDescriptors(ASTNode node,
                                           List<FoldingDescriptor> descriptors) {
         if (node.getElementType() == PyElementTypes.STATEMENT_LIST) {
             IElementType elType = node.getTreeParent().getElementType();
             if (elType == PyElementTypes.FUNCTION_DECLARATION || elType == PyElementTypes.CLASS_DECLARATION) {
                 ASTNode colon = node.getTreeParent().findChildByType(PyTokenTypes.COLON);
-                if (colon != null) {
+                if (colon != null && colon.getStartOffset() + 1 < node.getStartOffset() + node.getTextLength()) {
                     descriptors.add(new FoldingDescriptor(node,
                             new TextRange(colon.getStartOffset() + 1, node.getStartOffset() + node.getTextLength())));
                 }
                 else {
                     TextRange range = node.getTextRange();
                     if (range.getStartOffset() < range.getEndOffset()-1) { // only for ranges at leas 1 char wide
                         descriptors.add(new FoldingDescriptor(node, range));
                     }
                 }
             }
         }
 
         ASTNode child = node.getFirstChildNode();
         while (child != null) {
             appendDescriptors(child, descriptors);
             child = child.getTreeNext();
         }
     }
\ No newline at end of file
","Fixed an assertion error when a function is being defined and a colon is not yet typed in.
",Buggy
intellij-community,679.json,5dc1df3c0d442dd294ec203a212d97f07a9fb175,"@@ -1,80 +1,80 @@
   private static void compileCythonExtension(@NotNull Project project) {
     try {
       final RunManager runManager = RunManager.getInstance(project);
       final RunnerAndConfigurationSettings selectedConfiguration = runManager.getSelectedConfiguration();
       if (selectedConfiguration == null) {
         throw new ExecutionException(""Python Run Configuration should be selected"");
       }
       final RunConfiguration configuration = selectedConfiguration.getConfiguration();
       if (!(configuration instanceof AbstractPythonRunConfiguration)) {
         throw new ExecutionException(""Python Run Configuration should be selected"");
       }
       AbstractPythonRunConfiguration runConfiguration = (AbstractPythonRunConfiguration)configuration;
-      final String sdkPath = runConfiguration.getSdkHome();
+      final String interpreterPath = runConfiguration.getInterpreterPath();
       final String helpersPath = PythonHelpersLocator.getHelpersRoot().getPath();
 
       final String cythonExtensionsDir = PyDebugRunner.CYTHON_EXTENSIONS_DIR;
       final String[] cythonArgs =
         {""build_ext"", ""--build-lib"", cythonExtensionsDir, ""--build-temp"", String.format(""%s%sbuild"", cythonExtensionsDir, File.separator)};
 
       final List<String> cmdline = new ArrayList<>();
-      cmdline.add(sdkPath);
+      cmdline.add(interpreterPath);
       cmdline.add(FileUtil.join(helpersPath, FileUtil.toSystemDependentName(SETUP_CYTHON_PATH)));
       cmdline.addAll(Arrays.asList(cythonArgs));
       LOG.info(""Compile Cython Extensions "" + StringUtil.join(cmdline, "" ""));
 
       final Map<String, String> environment = new HashMap<>(System.getenv());
       PythonEnvUtil.addToPythonPath(environment, cythonExtensionsDir);
       PythonEnvUtil.setPythonUnbuffered(environment);
       PythonEnvUtil.setPythonDontWriteBytecode(environment);
-      if (sdkPath != null) {
-        PythonEnvUtil.resetHomePathChanges(sdkPath, environment);
+      if (interpreterPath != null) {
+        PythonEnvUtil.resetHomePathChanges(interpreterPath, environment);
       }
       GeneralCommandLine commandLine = new GeneralCommandLine(cmdline).withEnvironment(environment);
 
       final boolean canCreate = FileUtil.ensureCanCreateFile(new File(helpersPath));
       final boolean useSudo = !canCreate && !SystemInfo.isWindows;
       Process process;
       if (useSudo) {
         process = ExecUtil.sudo(commandLine, ""Please enter your password to compile cython extensions: "");
       }
       else {
         process = commandLine.createProcess();
       }
 
       ProgressManager.getInstance().run(new Task.Backgroundable(project, ""Compile Cython Extensions"") {
         @Override
         public void run(@NotNull ProgressIndicator indicator) {
           final CapturingProcessHandler handler =
             new CapturingProcessHandler(process, commandLine.getCharset(), commandLine.getCommandLineString());
           handler.addProcessListener(new ProcessAdapter() {
             @Override
             public void onTextAvailable(@NotNull ProcessEvent event, @NotNull Key outputType) {
               if (outputType == ProcessOutputTypes.STDOUT || outputType == ProcessOutputTypes.STDERR) {
                 for (String line : StringUtil.splitByLines(event.getText())) {
                   if (isSignificantOutput(line)) {
                     indicator.setText2(line.trim());
                   }
                 }
               }
             }
 
             private boolean isSignificantOutput(String line) {
               return line.trim().length() > 3;
             }
           });
           final ProcessOutput result = handler.runProcessWithProgressIndicator(indicator);
           final int exitCode = result.getExitCode();
           if (exitCode != 0) {
             final String message = StringUtil.isEmptyOrSpaces(result.getStdout()) && StringUtil.isEmptyOrSpaces(result.getStderr())
                                    ? ""Permission denied""
                                    : ""Non-zero exit code ("" + exitCode + ""): \n"" + result.getStderr();
             UIUtil.invokeLaterIfNeeded(() -> showErrorDialog(project, message));
           }
         }
       });
     }
     catch (IOException | ExecutionException e) {
       showErrorDialog(project, e.getMessage());
     }
   }
\ No newline at end of file
","Fixes after review (PY-26101)

Fix stepping after error jump, fix tests, move code modification to an appropriate function and make it more general
",Buggy
intellij-community,6419.json,39a18a8cfd9b96c783c9a408ad36fee10452c418,"@@ -1,24 +1,30 @@
-  private static String quoteItemsInFragments(@NotNull PyNewStyleStringFormatParser.Field field, char hostStringQuote) {
+  private static String quoteItemsInFragments(@NotNull PyNewStyleStringFormatParser.Field field, @NotNull StringNodeInfo hostStringInfo) {
     List<String> escaped = new ArrayList<>();
     for (String part : field.getAttributesAndLookups()) {
       if (part.startsWith(""."")) {
         escaped.add(part);
       }
       else if (part.startsWith(""["")) {
         if (part.contains(""\\"")) {
           return null;
         }
         final String indexText = part.substring(1, part.length() - 1);
         if (indexText.matches(""\\d+"")) {
           escaped.add(part);
           continue;
         }
-        final char quote = flipQuote(hostStringQuote);
-        if (indexText.indexOf(hostStringQuote) >= 0 || indexText.indexOf(quote) >= 0) {
-          return null;
+        final char originalQuote = hostStringInfo.getSingleQuote();
+        char targetQuote = flipQuote(originalQuote);
+        // there are no escapes inside the fragment, so the lookup key cannot contain 
+        // the host string quote unless it's a multiline string literal
+        if (indexText.indexOf(targetQuote) >= 0) {
+          if (!hostStringInfo.isTripleQuoted() || indexText.indexOf(originalQuote) >= 0) {
+            return null;
+          }
+          targetQuote = originalQuote;
         }
-        escaped.add(""["" + quote + indexText + quote + ""]"");
+        escaped.add(""["" + targetQuote + indexText + targetQuote + ""]"");
       }
     }
     return StringUtil.join(escaped, """");
   }
\ No newline at end of file
","PY-21245 Handle quotes in lookup items inside multiline string literals better

Namely, allow lookup items that contain quotes in some cases if the
containing string literal is multiline, hence there is still a suitable
type of quotes to wrap injected string literal into.

The orignal error described in the issue has been fixed earlier as
part of other changes for PY-21161.
",Buggy
intellij-community,3353.json,234eea4ef406b48f114d35e7385b2ebfeece9e6d,"@@ -1,10 +1,3 @@
-  private static AndroidFacet getFacet(@NotNull Module module) {
-    AndroidFacet androidFacet = null;
-
-    for (Facet facet : module.getFacets().values()) {
-      if (facet instanceof AndroidFacet) {
-        androidFacet = (AndroidFacet)facet;
-      }
-    }
-    return androidFacet;
-  }
\ No newline at end of file
+    public AndroidFacet getFacet() {
+      return myFacet;
+    }
\ No newline at end of file
","android-jps: fix some bugs, support aapt and dex compilation
",Buggy
intellij-community,23124.json,295d3d1dd1470e62a6748a0baeded3ad4ca1d508,"@@ -1,13 +1,14 @@
-  public void beginObject() {
+  public JsonReaderEx beginObject() {
     int p = peeked;
     if (p == PEEKED_NONE) {
       p = doPeek();
     }
     if (p == PEEKED_BEGIN_OBJECT) {
       push(JsonScope.EMPTY_OBJECT);
       peeked = PEEKED_NONE;
     }
     else {
       throw createParseError(""Expected BEGIN_OBJECT but was "" + peek());
     }
+    return this;
   }
\ No newline at end of file
","cleanup, fix WEB-14597 Breakpoints being ignored if functions called from live console

AsynPromise  don't ignore error if no rejected handler
",Buggy
intellij-community,35717.json,ac323a030f4b82bc3a41f4bb970f770de5a10462,"@@ -1,10 +1,10 @@
     private void updateFile(final VirtualFile file) {
-      myQueue.queue(new Update(""ProblemUpdate"") {
+      myQueue.queue(new Update(file) {
         public void run() {
           if (isFileOpen(file)) {
             updateFileIcon(file);
             updateFileColor(file);
           }
         }
       });
     }
\ No newline at end of file
","fixed bug with file staying red underwaved in editor tab
",Buggy
intellij-community,26650.json,aca5c269d7a12badc8892d6a204c4496583cd882,"@@ -1,4 +1,4 @@
   protected void buildPayload(Payload payload) {
     super.buildPayload(payload);
-    payload.add(myThreadId).add(myFrameId).add(""FRAME"").add(myExpression);
+    payload.add(""FRAME"").add(myExpression);
   }
\ No newline at end of file
","fixed bug after refactoring
",Buggy
intellij-community,15806.json,1a1325592a39001a011e5c0ece3664a582fc1fff,"@@ -1,9 +1,12 @@
-  public EditorWithProviderComposite findFileComposite(final VirtualFile file) {
+  public EditorWithProviderComposite findFileComposite(VirtualFile file) {
+    if (file instanceof BackedVirtualFile)
+      file = ((BackedVirtualFile)file).getOriginFile();
+
     for (int i = 0; i != getTabCount(); ++i) {
       final EditorWithProviderComposite editor = getEditorAt(i);
       if (editor.getFile().equals(file)) {
         return editor;
       }
     }
     return null;
   }
\ No newline at end of file
","Add check of BackedVirtualFile in findFileComposite in EditorWindow.java
to fix problem with openedEditorWindow resolving.

Now if you try go to Usage of variables in Jupyter, Zeppelin Notebooks (BackedVirtualFile)
new window will be opened. We need to get original file for correct search of File Composite

GitOrigin-RevId: 5a3577cb3964fc0a7fa0c7fa91a4fed137fe2ebf",Buggy
intellij-community,6447.json,f96c4ad9fa786eb5990bebe12f45dbbe4f698642,"@@ -1,16 +1,17 @@
   public void beforeCharDeleted(char c, PsiFile file, Editor editor) {
     isTripleQuote = false;
     if (c == '""' || c == '\'' && CodeInsightSettings.getInstance().AUTOINSERT_PAIR_QUOTE) {
       final QuoteHandler quoteHandler = TypedHandler.getQuoteHandler(file, editor);
       if (quoteHandler == null || !(quoteHandler instanceof BaseQuoteHandler)) return;
 
       final int offset = editor.getCaretModel().getCurrentCaret().getOffset();
       String text = editor.getDocument().getText();
       boolean mayBeTripleQuote = offset >= 3 && offset + 2 < text.length();
       if (mayBeTripleQuote) {
         HighlighterIterator iterator = ((EditorEx)editor).getHighlighter().createIterator(offset);
-        boolean hasTripleQuoteAfter = text.charAt(offset - 1) == c && text.charAt(offset - 2) == c && text.charAt(offset - 3) == c;
+        boolean hasTripleQuoteAfter = offset + 2 < text.length() &&
+                                      text.charAt(offset) == c && text.charAt(offset + 1) == c && text.charAt(offset + 2) == c;
         isTripleQuote = quoteHandler.isOpeningQuote(iterator, offset - 1) && hasTripleQuoteAfter;
       }
     }
   }
\ No newline at end of file
","PY-1779 Fix problem with removing pair of triple quotes

Check if there is triple quote to the right of the cursor
",Buggy
intellij-community,11190.json,bf7f424b6599b6b662a69c63d5028263dcbee88b,"@@ -1,10 +1,10 @@
   public static String constructPythonPathCommand(Collection<String> pythonPath) {
     final String path = Joiner.on("", "").join(Collections2.transform(pythonPath, new Function<String, String>() {
       @Override
       public String apply(String input) {
-        return ""'"" + input.replace(""\\"", ""\\\\"") + ""'"";
+        return ""'"" + input.replace(""\\"", ""\\\\"").replace(""'"", ""\\'"") + ""'"";
       }
     }));
 
     return ""sys.path.extend(["" + path + ""])"";
   }
\ No newline at end of file
","fix problem with single quote in project path
http://youtrack.jetbrains.com/issue/PY-10179
",Buggy
intellij-community,7728.json,9421b80596d7526f1637a84fb4bf457977dd635e,"@@ -1,16 +1,16 @@
     public boolean accept(File file) {
       final JavaSourceRootDescriptor rd = myBuildRootIndex.findJavaRootDescriptor(myContext, file);
       if (rd == null) {
         return true;
       }
-      final JpsModule moduleOfFile = rd.target.getModule();
-      if (myChunkModules.contains(moduleOfFile)) {
+      final ModuleBuildTarget targetOfFile = rd.target;
+      if (myChunkTargets.contains(targetOfFile)) {
         return true;
       }
-      Set<JpsModule> moduleOfFileWithDependencies = myCache.get(moduleOfFile);
-      if (moduleOfFileWithDependencies == null) {
-        moduleOfFileWithDependencies = ProjectPaths.getModulesWithDependentsRecursively(moduleOfFile, true);
-        myCache.put(moduleOfFile, moduleOfFileWithDependencies);
+      Set<BuildTarget<?>> targetOfFileWithDependencies = myCache.get(targetOfFile);
+      if (targetOfFileWithDependencies == null) {
+        targetOfFileWithDependencies = myBuildTargetIndex.getDependenciesRecursively(targetOfFile, myContext);
+        myCache.put(targetOfFile, targetOfFileWithDependencies);
       }
-      return Utils.intersects(moduleOfFileWithDependencies, myChunkModules);
+      return ContainerUtil.intersects(targetOfFileWithDependencies, myChunkTargets);
     }
\ No newline at end of file
","external build: fixed problem with files remaining dirty after 'Make Project'
",Buggy
intellij-community,10628.json,cfedbcc1be3a6aec0e05d57995ce6945e112168c,"@@ -1,15 +1,21 @@
   protected JPanel createAdvancedSettings() {
     JComponent advancedSettings = null;
     if (myProjectGenerator instanceof PythonProjectGenerator)
       advancedSettings = ((PythonProjectGenerator)myProjectGenerator).getSettingsPanel(myProjectDirectory);
     else if (myProjectGenerator instanceof WebProjectTemplate) {
       advancedSettings = ((WebProjectTemplate)myProjectGenerator).getPeer().getComponent();
     }
     if (advancedSettings != null) {
       final JPanel jPanel = new JPanel(new VerticalFlowLayout());
       final HideableDecorator deco = new HideableDecorator(jPanel, ""Mor&e Settings"", false);
+      boolean isValid = checkValid();
+      deco.setOn(!isValid);
+      if (myProjectGenerator instanceof PythonProjectGenerator && !deco.isExpanded()) {
+        final ValidationResult result = ((PythonProjectGenerator)myProjectGenerator).warningValidation(getSdk());
+        deco.setOn(!result.isOk());
+      }
       deco.setContentComponent(advancedSettings);
       return jPanel;
     }
     return null;
   }
\ No newline at end of file
","fixed PY-13503 Create New Project: Expand more setting by default if there is an error in configuration
",Buggy
intellij-community,35455.json,04eb55fb65bb931432ac5b51786825882d53027a,"@@ -1,21 +1,26 @@
     private boolean runNextEvent() {
       long startedAt = System.currentTimeMillis();
       final RunnableInfo lastInfo = getNextEvent(true);
       myLastInfo = lastInfo;
 
       if (lastInfo != null) {
         try {
           doRun(lastInfo);
           lastInfo.markDone();
         }
-        catch (ProcessCanceledException ignored) { }
+        catch (ProcessCanceledException ignored) {
+
+        }
         catch (Throwable t) {
+          if (ApplicationManager.getApplication().isUnitTestMode()) {
+            ExceptionUtil.rethrow(t);
+          }
           LOG.error(t);
         }
         finally {
           if (!DEBUG) myLastInfo = null;
           TransactionGuardImpl.logTimeMillis(startedAt, lastInfo.runnable);
         }
       }
       return lastInfo != null;
     }
\ No newline at end of file
","make exceptions thrown in invokeLater() and friends visible in tests to help fix errors in abandoned futures

GitOrigin-RevId: aec5c2221220e3567f67c9a35d050a61f06a3a2e",Buggy
intellij-community,18837.json,7e6fe7d6c4d89fc902a471879c0244f8b19597db,"@@ -1,6 +1,8 @@
   public boolean isDumb() {
-    if (!ApplicationManager.getApplication().isReadAccessAllowed() && REPORTED_EXECUTIONS.add(ExceptionUtil.currentStackTrace())) {
+    if (!ApplicationManager.getApplication().isReadAccessAllowed() &&
+        Registry.is(""ide.check.is.dumb.contract"") &&
+        REPORTED_EXECUTIONS.add(ExceptionUtil.currentStackTrace())) {
       LOG.error(""To avoid race conditions isDumb method should be used only under read action or in EDT thread."");
     }
     return myState.get() != State.SMART;
   }
\ No newline at end of file
","IDEA-CR-47405: IDEA-214525 Disable isDumb check by default

Need to fix found frequent problems and switch on it back

GitOrigin-RevId: 2a916fbfe43bb077042adf0e0515253c3aa7ce55
",Buggy
intellij-community,2087.json,90a381b2f133397b7cbbfac2a4966e528b3e91cf,"@@ -1,10 +1,10 @@
   public boolean isAsyncAllowed() {
     final LanguageLevel languageLevel = LanguageLevel.forElement(this);
     final String functionName = getName();
 
     return languageLevel.isAtLeast(LanguageLevel.PYTHON35) && (
       functionName == null ||
-      ArrayUtil.contains(functionName, PyNames.AITER, PyNames.ANEXT, PyNames.AENTER, PyNames.AEXIT) ||
+      ArrayUtil.contains(functionName, PyNames.AITER, PyNames.ANEXT, PyNames.AENTER, PyNames.AEXIT, PyNames.CALL) ||
       !PyNames.getBuiltinMethods(languageLevel).containsKey(functionName)
     );
   }
\ No newline at end of file
","PY-20662 Fixed: Making any magic method async displays an error, even though it is sometimes legal

Mark __call__ builtin as allowed to be async
",Buggy
intellij-community,10885.json,2b57b19667f12b0967107bbb6dd4052825fed484,"@@ -1,4 +1,7 @@
   public String getValue() {
+    if (myListPopUp == null || !myListPopUp.isVisible()) {
+      return null; // Nothing is selected if list is invisible
+    }
     final Object value = myList.getSelectedValue();
     return ((value == null) ? """" : getElement(value).mySuggestion.getText());
   }
\ No newline at end of file
","PY-11855 Run manage.py task improvements

Tests enabled, completion bug fixed
",Buggy
intellij-community,38709.json,1e53ffa3e0e7fe08387b61f9aba2b48275685b41,"@@ -1,6 +1,8 @@
   public void setCancelButtonText(String text){
-    if (myDialog != null)
+    if (myDialog != null) {
       myDialog.changeCancelButtonText(text);
-    else
+    }
+    else {
       myCancelText = text;
+    }
   }
\ No newline at end of file
","Fixing problem of progress window appearing over modal dialogs shown during runProcessWithProgressSynchronously().
",Buggy
intellij-community,18404.json,87fa91dd700f6b1cfc0885f0857cf501df46649f,"@@ -1,6 +1,7 @@
     private JComponent createErrorsLink() {
       IdeMessagePanel panel = new IdeMessagePanel(null, MessagePool.getInstance());
       panel.setBorder(JBUI.Borders.emptyRight(13));
+      panel.setOpaque(false);
       Disposer.register(this, panel);
       return panel;
     }
\ No newline at end of file
","Fix error icon background on welcome screen

GitOrigin-RevId: 6412c1adb4627ebdd5895f3319a3878f7a68a44d
",Buggy
intellij-community,17737.json,29ea6cca1f95c474adfc2715fe7d091e26d043d7,"@@ -1,104 +1,109 @@
     private void processModules(final DiffState state, File fileName) {
       final Difference.Specifier<ModuleRepr, ModuleRepr.Diff> modulesDiff = state.myModulesDiff;
       if (modulesDiff.unchanged()) {
         return;
       }
+
+      for (ModuleRepr moduleRepr : modulesDiff.added()) {
+        myDelta.addChangedClass(moduleRepr.name); // need this for integrate
+      }
+      
       for (ModuleRepr removedModule : modulesDiff.removed()) {
-        myDelta.addDeletedClass(removedModule, fileName);
+        myDelta.addDeletedClass(removedModule, fileName); // need this for integrate
         myPresent.affectDependentModules(state, removedModule.name, null, true);
       }
 
       for (Pair<ModuleRepr, ModuleRepr.Diff> pair : modulesDiff.changed()) {
         final ModuleRepr moduleRepr = pair.first;
         final ModuleRepr.Diff d = pair.second;
         boolean affectSelf = false;
         boolean affectDeps = false;
         UsageConstraint constraint = null;
 
-        myDelta.addChangedClass(moduleRepr.name);
+        myDelta.addChangedClass(moduleRepr.name); // need this for integrate
 
         if (d.versionChanged()) {
           final int version = moduleRepr.getVersion();
           myPresent.affectDependentModules(state, moduleRepr.name, new UsageConstraint() {
             public boolean checkResidence(int dep) {
               final ModuleRepr depModule = myPresent.moduleReprByName(dep);
               if (depModule != null) {
                 for (ModuleRequiresRepr requires : depModule.getRequires()) {
                   if (requires.name == moduleRepr.name && requires.getVersion() == version) {
                     return true;
                   }
                 }
               }
               return false;
             }
           }, false);
         }
 
         final Difference.Specifier<ModuleRequiresRepr, ModuleRequiresRepr.Diff> requiresDiff = d.requires();
         for (ModuleRequiresRepr removed : requiresDiff.removed()) {
           affectSelf = true;
           if (removed.isTransitive()) {
             affectDeps = true;
             constraint = UsageConstraint.ANY;
             break;
           }
         }
         for (Pair<ModuleRequiresRepr, ModuleRequiresRepr.Diff> changed : requiresDiff.changed()) {
           affectSelf |= changed.second.versionChanged();
           if (changed.second.becameNonTransitive()) {
             affectDeps = true;
             // we could have created more precise constraint here: analyze if required module (recursively)
             // has only qualified exports that include given module's name. But this seems to be excessive since
             // in most cases module's exports are unqualified, so that any other module can access the exported API.
             constraint = UsageConstraint.ANY;
           }
         }
 
         final Difference.Specifier<ModulePackageRepr, ModulePackageRepr.Diff> exportsDiff = d.exports();
 
         if (!affectDeps) {
           for (ModulePackageRepr removedPackage : exportsDiff.removed()) {
             affectDeps = true;
             if (!removedPackage.isQualified()) {
               constraint = UsageConstraint.ANY;
               break;
             }
             for (Integer name : removedPackage.getModuleNames()) {
               final UsageConstraint matchName = UsageConstraint.exactMatch(name);
               if (constraint == null) {
                 constraint = matchName;
               }
               else {
                 constraint = constraint.or(matchName);
               }
             }
           }
         }
 
         if (!affectDeps || constraint != UsageConstraint.ANY) {
           for (Pair<ModulePackageRepr, ModulePackageRepr.Diff> p : exportsDiff.changed()) {
             final Collection<Integer> removedModuleNames = p.second.targetModules().removed();
             affectDeps |= !removedModuleNames.isEmpty();
             if (!removedModuleNames.isEmpty()) {
               affectDeps = true;
               for (Integer name : removedModuleNames) {
                 final UsageConstraint matchName = UsageConstraint.exactMatch(name);
                 if (constraint == null) {
                   constraint = matchName;
                 }
                 else {
                   constraint = constraint.or(matchName);
                 }
               }
             }
           }
         }
 
         if (affectSelf) {
           myPresent.affectModule(moduleRepr, myAffectedFiles);
         }
         if (affectDeps) {
           myPresent.affectDependentModules(state, moduleRepr.name, constraint, true);
         }
       }
     }
\ No newline at end of file
","fix module-info integrate after errors (IDEA-181208)
",Buggy
intellij-community,29881.json,89451925c29655bb8771859c792c18d6b28c9e55,"@@ -1,19 +1,19 @@
     public void visitPyFunction(final PyFunction node) {
       PyDecoratorList decolist = node.getDecoratorList();
       if (decolist != null) {
         PyDecorator[] decos = decolist.getDecorators();
         if (decos.length > 1) {
           for (int i = decos.length - 1; i >= 1; i -= 1) {
             PyDecorator deco = decos[i];
             String deconame = deco.getName();
             if ((PyNames.CLASSMETHOD.equals(deconame) || PyNames.STATICMETHOD.equals(deconame)) && deco.isBuiltin()) {
               registerProblem(
                 decos[i-1],
                 PyBundle.message(""INSP.decorator.receives.unexpected.builtin""),
-                ProblemHighlightType.GENERIC_ERROR_OR_WARNING
+                ProblemHighlightType.GENERIC_ERROR_OR_WARNING, null, new RemoveDecoratorQuickFix()
               );
             }
           }
         }
       }
     }
\ No newline at end of file
","added Remove decorator quick fix to the Problematic nesting of decorators inspection
",Buggy
intellij-community,27903.json,0b9404bccbc274086537d9c49bf8a31a26ba4d7a,"@@ -1,9 +1,11 @@
   private static boolean distinctTokens(@Nullable IElementType token1, @Nullable IElementType token2) {
     if (token1 == token2) return false;
     if (token1 == null || token2 == null) return true;
     if (StringEscapesTokenTypes.STRING_LITERAL_ESCAPES.contains(token1) ||
         StringEscapesTokenTypes.STRING_LITERAL_ESCAPES.contains(token2)) return false;
-    if (!token1.getLanguage().is(token2.getLanguage())) return true;
-    BidiRegionsSeparator separator = LanguageBidiRegionsSeparator.INSTANCE.forLanguage(token1.getLanguage());
+    if (token1 != TokenType.WHITE_SPACE && token2 != TokenType.WHITE_SPACE && !token1.getLanguage().is(token2.getLanguage())) return true;
+    Language language = token1.getLanguage();
+    if (language == Language.ANY) language = token2.getLanguage();
+    BidiRegionsSeparator separator = LanguageBidiRegionsSeparator.INSTANCE.forLanguage(language);
     return separator.createBorderBetweenTokens(token1, token2);
   }
\ No newline at end of file
","IDEA-169157 Right-to-left bug - fix for JSX files
",Buggy
intellij-community,35807.json,6555125d8e28088da575e0b10ca50780c50642d0,"@@ -1,22 +1,23 @@
   public static ScriptOutput executeScriptInConsoleWithFullOutput(String exePathString,
                                                                   @Nullable VirtualFile scriptFile,
                                                                   @Nullable String workingDirectory,
                                                                   long timeout,
                                                                   ScriptOutputType scriptOutputType,
                                                                   @NonNls String... parameters)
     throws ExecutionException {
     final OSProcessHandler processHandler = execute(exePathString, workingDirectory, scriptFile, parameters);
 
     final StringBuilder standardOutput = scriptOutputType.readStandardOutput() ? new StringBuilder() : null;
     final StringBuilder errorOutput = scriptOutputType.readErrorOutput() ? new StringBuilder() : null;
     final StringBuilder mergedOutput =
       (scriptOutputType.readStandardOutput() && scriptOutputType.readErrorOutput()) ? new StringBuilder() : null;
     addReadingProcessListener(scriptOutputType, processHandler, standardOutput, errorOutput, mergedOutput);
+    processHandler.startNotify();
 
     if (!processHandler.waitFor(timeout)) {
       LOG.warn(""Process did not complete in "" + timeout / 1000 + ""s"");
       throw new ExecutionException(ExecutionBundle.message(""script.execution.timeout"", String.valueOf(timeout / 1000)));
     }
     LOG.debug(""script output: "" + standardOutput);
     return new ScriptOutput(scriptOutputType, standardOutput, errorOutput, mergedOutput);
   }
\ No newline at end of file
","WI-6566 Empty output in command line toolwindow:
fixed bug with too early processHandler.startNotify() in ScriptRunnerUtil; removed command execution ""cmd \c"" wrapping.
",Buggy
intellij-community,18229.json,6ee5fbcfe50c4e017eff321c5ebe208dd89d6945,"@@ -1,9 +1,10 @@
   public ExternalSystemTaskExecutionSettings clone() {
     ExternalSystemTaskExecutionSettings result = new ExternalSystemTaskExecutionSettings();
     result.setExternalSystemIdString(getExternalSystemIdString());
     result.setExternalProjectPath(getExternalProjectPath());
     result.setVmOptions(getVmOptions());
+    result.setScriptParameters(getScriptParameters());
     result.setTaskNames(ContainerUtilRt.newArrayList(getTaskNames()));
     result.setTaskDescriptions(ContainerUtilRt.newArrayList(getTaskDescriptions()));
     return result;
   }
\ No newline at end of file
","IDEA-117792 Gradle Run/Debug Configuration: support adding Gradle specific parameters. Fix after review.
+ fix bug - http://youtrack.jetbrains.com/issue/IDEA-118470
",Buggy
hector,2566.json,4e038b0c1c911e81c2ce68123f3ecdb588c0e090,"@@ -1,3 +1,3 @@
   public K getKey() {
-    return keySerializer.fromByteBuffer(entry.getKey()); 
+    return keySerializer.fromByteBuffer(entry.getKey().duplicate());
   }
\ No newline at end of file
","#345: fix bug with multiple bytebuffer readings
",Buggy
hector,1056.json,77b7e5e1215b64a40f87488849cead5aa67e6ac4,"@@ -1,27 +1,30 @@
   public static void main(String[] args) throws HectorException {
     CassandraClientPool pool = CassandraClientPoolFactory.INSTANCE.get();
     CassandraClient client = pool.borrowClient(""tush"", 9160);
     // A load balanced version would look like this:
     // CassandraClient client = pool.borrowClient(new String[] {""cas1:9160"", ""cas2:9160"", ""cas3:9160""});
 
+    Keyspace keyspace = null;
     try {
-      Keyspace keyspace = client.getKeyspace(""Keyspace1"");
+      keyspace = client.getKeyspace(""Keyspace1"");
       ColumnPath columnPath = new ColumnPath(""Standard1"");
       columnPath.setColumn(bytes(""column-name""));
 
       // insert
       keyspace.insert(""key"", columnPath, bytes(""value""));
 
       // read
       Column col = keyspace.getColumn(""key"", columnPath);
 
       System.out.println(""Read from cassandra: "" + string(col.getValue()));
 
+    } finally {
       // This line makes sure that even if the client had failures and recovered, a correct
       // releaseClient is called, on the up to date client.
-      client = keyspace.getClient();
-    } finally {
-      // return client to pool. do it in a finally block to make sure it's executed
-      pool.releaseClient(client);
+      if (keyspace != null) {
+        client = keyspace.getClient();
+        // return client to pool. do it in a finally block to make sure it's executed
+        pool.releaseClient(client);
+      }
     }
   }
\ No newline at end of file
","Fix a bug when releasing a client in the ExampleClient
",Buggy
hector,1056.json,7e7fd435503f29b0bfbc6ec8a997e28ecf323a22,"@@ -1,25 +1,28 @@
   public static void main(String[] args) throws IllegalStateException, PoolExhaustedException,
       Exception {
     CassandraClientPool pool = CassandraClientPoolFactory.INSTANCE.get();
     CassandraClient client = pool.borrowClient(""tush"", 9160);
     // A load balanced version would look like this:
     // CassandraClient client = pool.borrowClient(new String[] {""cas1:9160"", ""cas2:9160"", ""cas3:9160""});
 
     try {
       Keyspace keyspace = client.getKeyspace(""Keyspace1"");
       ColumnPath columnPath = new ColumnPath(""Standard1"");
       columnPath.setColumn(bytes(""column-name""));
 
       // insert
       keyspace.insert(""key"", columnPath, bytes(""value""));
 
       // read
       Column col = keyspace.getColumn(""key"", columnPath);
 
       System.out.println(""Read from cassandra: "" + string(col.getValue()));
 
+      // This line makes sure that even if the client had failures and recovered, a correct
+      // releaseClient is called, on the up to date client.
+      client = keyspace.getClient();
     } finally {
       // return client to pool. do it in a finally block to make sure it's executed
       pool.releaseClient(client);
     }
   }
\ No newline at end of file
","Fix ExampleClient to release the correct client even when there's possible errors and failover
(cherry picked from commit 184b6460812c21e7fde77821245848f9ed2f3e6e)
",Buggy
hector,1991.json,4be28e7d287b02b6f1036b415c5e732ec804065f,"@@ -1,14 +1,17 @@
   private String getContextPath() {
-    URL url = getClass().getClassLoader().getResource(""/"");
+    ClassLoader loader = getClass().getClassLoader();
+    if(loader == null)
+     return null;
+    URL url = loader.getResource(""/"");
     if (url != null) {
       String[] elements = url.toString().split(""/"");
       for (int i = elements.length - 1; i > 0; --i) {
         // URLs look like this: file:/.../ImageServer/WEB-INF/classes/
         // And we want that part that's just before WEB-INF
         if (""WEB-INF"".equals(elements[i])) {
           return elements[i - 1];
         }
       }
     }
     return null;
   }
\ No newline at end of file
","fixed a bug which causes NullPointerException in JmxMonitor on some platforms.
",Buggy
hector,115.json,872da019f266973c0bf570d927371e33d838b4e8,"@@ -1,28 +1,28 @@
   public boolean addColumnToCollection(CFMappingDef<?> cfMapDef, Object obj, String colName,
       byte[] colValue) {
     // if can parse, then at least adheres to formatting
     CollectionItemColName collColumnName;
     try {
       collColumnName = parseCollectionItemColName(colName);
     } catch (HectorObjectMapperException e) {
       return false;
     }
 
     // get property from mapping def - if not there, then isn't a collection
     // (but probably a problem elsewhere)
-    PropertyMappingDefinition md = cfMapDef.getPropMapByPropName(collColumnName.getPropertyName());
+    PropertyMappingDefinition md = cfMapDef.getPropMapByColumnName(collColumnName.getPropertyName());
     if (null == md) {
       return false;
     }
 
     Collection<Object> coll;
     try {
       coll = (Collection<Object>) reflectionHelper.invokeGetter(obj, md);
     } catch (HectorObjectMapperException e) {
       return false;
     }
 
     Object value = deserializeCollectionValue(colValue);
     coll.add(value);
     return true;
   }
\ No newline at end of file
","fix bug: when mapping java collections, if property name different from column name, would not map correctly
",Buggy
hector,2740.json,bf6efaeda600325fdeed53aad52e1700a0556cfd,"@@ -1,28 +1,28 @@
   public long createClock() {
     switch (this) {
 	    case MICROSECONDS:
 	    	return System.currentTimeMillis() * ONE_THOUSAND;
 	    case MICROSECONDS_SYNC:
 	      // The following simulates a microseconds resolution by advancing a static counter
 	      // every time a client calls the createClock method, simulating a tick.
 	      long us = System.currentTimeMillis() * ONE_THOUSAND;
 	      // Synchronized to guarantee unique time within and across threads.
 	      synchronized (ClockResolution.class) {
 	         if (us > lastTime) {
 	        	 lastTime = us;
 	         } else {
 	        	 // the time i got from the system is equals or less
 	        	 // (hope not - clock going backwards)
 	        	 // One more ""microsecond""
-	        	 us = lastTime++;
+	        	 us = ++lastTime;
 	         }
 	      }
 	      return us;
 	    case MILLISECONDS:
 	      return System.currentTimeMillis();
 	    case SECONDS:
 	      return System.currentTimeMillis() / 1000;
 	}
 
     return System.currentTimeMillis();
   }
\ No newline at end of file
","Fix bug. Increment lastTime first and later assign

The lastTime was getting incremented right after assigning it to us.
",Buggy
hector,52.json,d0401ba77a823d118c98a74db02678c948cf33bc,"@@ -1,16 +1,26 @@
   private byte[] generateColumnFamilyKeyFromPkObj(CFMappingDef<?> cfMapDef, Object pkObj) {
     List<byte[]> segmentList = new ArrayList<byte[]>(cfMapDef.getKeyDef().getIdPropertyMap().size());
-
+    
+    List<String> rm1 = new ArrayList<String>();
+    List<String> rm2 = new ArrayList<String>();
+    
     if (cfMapDef.getKeyDef().isComplexKey()) {
-      for (PropertyDescriptor pd : cfMapDef.getKeyDef().getPropertyDescriptorMap().values()) {
-        segmentList.add(callMethodAndConvertToCassandraType(pkObj, pd.getReadMethod(),
-            new DefaultConverter()));
+    	
+      Map<String, PropertyDescriptor> propertyDescriptorMap = cfMapDef.getKeyDef().getPropertyDescriptorMap(); 	
+      Map<String, PropertyMappingDefinition> idPropertyMap =  cfMapDef.getKeyDef().getIdPropertyMap();
+    	
+      for (String key : cfMapDef.getKeyDef().getIdPropertyMap().keySet()) {
+    	  PropertyDescriptor pd = propertyDescriptorMap.get(key);
+    	  segmentList.add(callMethodAndConvertToCassandraType(pkObj, pd.getReadMethod(),
+    	            new DefaultConverter()));
       }
+     
+    	 
     } else {
       PropertyMappingDefinition md = cfMapDef.getKeyDef().getIdPropertyMap().values().iterator()
                                              .next();
       segmentList.add(md.getConverter().convertObjTypeToCassType(pkObj));
     }
 
     return keyConcatStrategy.concat(segmentList);
   }
\ No newline at end of file
","Fix for unordered Composite Key when finding values by key

A problem occurred when you attempted to find an object by composite
key.  The composite would be persisted in order by the order of the
composite fields in the class.  When attempting to find the object the
objectMapper would use the natural ordering of the field names instead.
",Buggy
hector,2393.json,befd460c79a1d16c64a1a9857678621106e4a111,"@@ -1,13 +1,16 @@
-        public boolean hasNext()
-        {
-            boolean retval = false;
-            if (isStart)
-            {
-                retval = res.hasResults();
-            }
-            else
-            {
-                retval = res.hasNext();
-            }
-            return retval;
-        }
\ No newline at end of file
+		public boolean hasNext() 
+		{
+			boolean retval = false;
+			if (isStart) 
+			{
+				if(res.hasResults() || res.hasNext()) 
+				{
+					retval = true; 
+				}
+			} 
+			else 
+			{
+				retval = res.hasNext();
+			}
+			return retval;
+		}
\ No newline at end of file
","Fix bug in hasNext when no result for a key is returned
",Buggy
cucumber-jvm,1443.json,5f8f31b3d2b34050a93e27990ed25ce9274f49ac,"@@ -1,22 +1,23 @@
     public void newWorld() {
+        stepDefinitions.clear();
         MutablePicoContainer pico = new DefaultPicoContainer();
         for(Class stepsClass : stepsClasses) {
             pico.addComponent(stepsClass);
         }
 
         for(Object stepObject : pico.getComponents()) {
             for (Method method : stepObject.getClass().getMethods()) {
                 String regexpString = null;
                 if (method.isAnnotationPresent(Given.class)) {
                     regexpString = method.getAnnotation(Given.class).value();
                 } else if (method.isAnnotationPresent(When.class)) {
                     regexpString = method.getAnnotation(When.class).value();
                 } else if (method.isAnnotationPresent(Then.class)) {
                     regexpString = method.getAnnotation(Then.class).value();
                 }
                 if(regexpString != null) {
                     stepDefinitions.add(new StepDefinition(regexpString, stepObject, method));
                 }
             }
         }
     }
\ No newline at end of file
","Fix Ambiguous problem for Cucumber Java
",Buggy
cucumber-jvm,1018.json,d8406dd1cbd14b82a79ccf5205f4367c9883a768,"@@ -1,10 +1,10 @@
         private String calculateElementName(cucumber.api.TestCase testCase) {
             String testCaseName = testCase.getName();
             if (testCaseName.equals(previousTestCaseName)) {
-                return testCaseName + (includesBlank(testCaseName) ? "" "" : ""_"") + ++exampleNumber;
+                return Utils.getUniqueTestNameForScenarioExample(testCaseName, ++exampleNumber);
             } else {
                 previousTestCaseName = testCase.getName();
                 exampleNumber = 1;
                 return testCaseName;
             }
         }
\ No newline at end of file
","Android: Fix Cucumber execution on Gradle (#1094)

* Fix AndroidInstrumentationReporter for Gradle builds

* the connected check tasks of the Android/Gradle build system do not like non-unique test names
* we add a unique index to the test names if they are non-unique (e.g. on scenario outlines with multiple examples)
* for this bug fix, we provide a unit test

* Fix AndroidInstrumentationReporter for Gradle builds

* the connected check tasks of the Android/Gradle build system do not like non-unique test names
* we add a unique index to the test names if they are non-unique (e.g. on scenario outlines with multiple examples)
* for this bug fix, we provide a unit test

This is a re-integration of PR-1094. The original pull request code was performed on 1.2.6-SNAPSHOT base. This code bases on version 2.3.2-SNAPSHOT.

* Update Cukeulator example project to work with newest Android build tools

- Update to Android Studio 3.0.1, SDK 26+ and Gradle 4.1
- Replace Instrumentation class by CucumberRunner
- CucumberRunner uses AndroidJUnitRunner (JUnit 4+)
- CalculationSteps class uses ActivityTestRule instead of deprecated ActivityInstrumentationTestCase2
- Fix permissions to write reports on internal storage

* Improve Cukeulator example project

* Update README.md
* Enable local Maven dependencies for better development experience
* Describe, how to use Cukeulator example project with locally built Cucumber-JVM

* Rename duplicated test case names in AndroidInstrumentationReporter like JUnitFormatter in cucumber-core

* Fix typo

* Improve readability of AndroidInstrumentationReporterTest

* Share common logic for test case name between JUnitFormatter and AndroidInstrumentationReporter

* Improve code quality

- Create merged method calculateUniqueTestName from getUniqueTestName and ensureUniqueTestName and make it private
- Use better test method name: test_case_names_are_unique_on_equal_scenario_names (instead of scenario_outline_all_test_names_unique)
- Refactor test code: now it should be readable

* Change misleading variable names

* [Android] Split up test of making test names unique.

To provide better documentation of the functionality, that is:
* test names within feature are made unique by appending blank and
  number
* test names within are made unique by appending underscore and number
  when no blank in name
* test names in different features can be the same
* test names are made unique also when not consecutive
",Buggy
hazelcast,11513.json,7a17eba9e37e1ce2953f5320c56c13c92620953d,"@@ -1,12 +1,11 @@
     public boolean shouldWait() {
         WriteBehindQueue<DelayedEntry> writeBehindQueue = store.getWriteBehindQueue();
-        int size = writeBehindQueue.size();
-        if (size == 0) {
+        DelayedEntry entry = writeBehindQueue.peek();
+        if (entry == null) {
             return false;
         }
 
-        DelayedEntry entry = writeBehindQueue.peek();
         long currentSequence = entry.getSequence();
-        return entry != null && currentSequence <= this.sequence
-                && size + currentSequence - 1 >= this.sequence;
+        return currentSequence <= this.sequence
+                && writeBehindQueue.size() + currentSequence - 1 >= this.sequence;
     }
\ No newline at end of file
","Fixes findbugs problem
",Buggy
hazelcast,27666.json,515671c5314975716054e45c0866ffd8be64f4c2,"@@ -1,17 +1,17 @@
     private void updateConfig(AliasedDiscoveryConfig config, Node node) {
         NamedNodeMap attributes = node.getAttributes();
         for (int a = 0; a < attributes.getLength(); a++) {
             Node att = attributes.item(a);
             String value = getTextContent(att).trim();
             if (""enabled"".equals(lowerCaseInternal(att.getNodeName()))) {
                 config.setEnabled(getBooleanValue(value));
             } else if (att.getNodeName().equals(""connection-timeout-seconds"")) {
                 config.setProperty(""connection-timeout-seconds"", value);
             }
         }
         for (Node n : childElements(node)) {            
-            String key = cleanNodeName(n, ""eureka"".equals(n.getParentNode().getLocalName()));
+            String key = cleanNodeName(n, !""eureka"".equals(n.getParentNode().getLocalName()));
             String value = getTextContent(n).trim();
             config.setProperty(key, value);
         }
     }
\ No newline at end of file
",eureka lowercase bug fix,Buggy
hazelcast,16541.json,6ce43d4090fe4924dfc7dc45583a328e25bb1e9f,"@@ -1,14 +1,15 @@
     public void run() throws Exception {
         CollectionWrapper wrapper = getCollectionWrapper();
-        if (wrapper == null || wrapper.getVersion() == version){
+        if (wrapper == null || wrapper.getVersion() != version){
             notify = false;
             return;
         }
+        wrapper.incrementAndGetVersion();
         for (Operation op: opList){
             op.setNodeEngine(getNodeEngine()).setServiceName(getServiceName()).setPartitionId(getPartitionId());
             op.beforeRun();
             op.run();
             op.afterRun();
         }
         getOrCreateContainer().unlock(dataKey, getCallerUuid(), threadId);
     }
\ No newline at end of file
","Multimap commit txn version bug fixed
",Buggy
hazelcast,28391.json,8a5e458780154dfd44ef41dd02770456c19c7dbf,"@@ -1,4 +1,13 @@
     public final void sendResponse(Object value) {
         OperationResponseHandler responseHandler = getOperationResponseHandler();
-        responseHandler.sendResponse(this, value);
+        if (responseHandler == null) {
+            if (value instanceof Throwable) {
+                // in case of a throwable, we want the stacktrace.
+                getLogger().warning(""Missing responseHandler for "" + toString(), (Throwable) value);
+            } else {
+                getLogger().warning(""Missing responseHandler for "" + toString() + "" value["" + value + ""]"");
+            }
+        } else {
+            responseHandler.sendResponse(this, value);
+        }
     }
\ No newline at end of file
","NPE on operation sendResponse if no response handler is set

The problem is fixed by adding a check if the response handler is set.

If it isn't set a warning is printed so we don't loose the exception. It is better
that a response handler is always set to prevent loosing any track of problematic flows.
",Buggy
hazelcast,21845.json,7ab1db9edc8409f599bf01054636a1643e3cf2d3,"@@ -1,3 +1,11 @@
     public double getRatio() {
-        return ((double) hits / misses) * 100.0;
+        if (misses == 0) {
+            if (hits == 0) {
+                return Double.NaN;
+            } else {
+                return Double.POSITIVE_INFINITY;
+            }
+        } else {
+            return ((double) hits / misses) * PERCENTAGE;
+        }
     }
\ No newline at end of file
","Fixed checkstyle issue and divide by zero problem for ratio in ""NearCacheStatsImpl""",Buggy
hazelcast,22872.json,0fd3a71c944b64d8b3a3ad75361015fb289be227,"@@ -1,4 +1,4 @@
     protected DiagnosticsLogWriter write(String s) {
-        printWriter.write(s);
+        printWriter.write(s == null ? ""null"" : s);
         return this;
     }
\ No newline at end of file
","Fixed NPE in Diagnostics

Fix #9085

The problem was that the printWriter was called with a print(null). So the fix is to do a simple null check and write
""null"" in case of null.
",Buggy
hazelcast,10446.json,cd1d3e928d20e4ec4cc22d0cc91d93c2b6600c9e,"@@ -1,3 +1,3 @@
     public Object getKey() {
-        return key;
+        return new MapKey(name, key);
     }
\ No newline at end of file
","map txn bug fix: same key overrides txn op with same key but different map name
",Buggy
hazelcast,6968.json,0ae63554413e19520e136b5a35fec3c05d801866,"@@ -1,4 +1,6 @@
     private void createCachesOnCluster() {
         ClientCacheProxyFactory proxyFactory = (ClientCacheProxyFactory) getClientProxyFactory(ICacheService.SERVICE_NAME);
-        proxyFactory.recreateCachesOnCluster();
+        if (proxyFactory != null) {
+            proxyFactory.recreateCachesOnCluster();
+        }
     }
\ No newline at end of file
","Fix NPE when jcache not in classpath

fixing a bug recently introduced in #13810

fixes #13851
",Buggy
hazelcast,29434.json,f701a369208b2acf3066ba1b306d68688a765a56,"@@ -1,7 +1,9 @@
     public void populate(LiveOperations liveOperations) {
         for (Queue<ParkedOperation> parkQueue : parkQueueMap.values()) {
-            for (ParkedOperation op : parkQueue) {
-                liveOperations.add(op.getCallerAddress(), op.getCallId());
+            for (ParkedOperation parkedOperation : parkQueue) {
+                // we need to read out the data from the BlockedOperation; not from the ParkerOperation-container.
+                Operation operation = parkedOperation.getOperation();
+                liveOperations.add(operation.getCallerAddress(), operation.getCallId());
             }
         }
     }
\ No newline at end of file
","Fix heartbeat problem for BlockingOperations

The problem is that the ParkedOperation; the container around the BlockingOperation; is
asked for callid/calleraddress. But this container object doesn't have any sensible
information, so the heartbeat is not constructed correctly for a blocked Operation.
",Buggy
hazelcast,17124.json,fc8ec0a85ea7e388794baf5c7710ec824b6cb10c,"@@ -1,20 +1,27 @@
     public void close() throws IOException {
         if (!CLOSED.compareAndSet(this, FALSE, TRUE)) {
             return;
         }
 
+        // we execute this in its own try/catch block because we don't want to skip closing the socketChannel in case
+        // of problems.
+        try {
+            onClose();
+        } catch (Exception e) {
+            getLogger().severe(format(""Failed to call 'onClose' on channel [%s]"", this), e);
+        }
+
         try {
             socketChannel.close();
         } finally {
             for (ChannelCloseListener closeListener : closeListeners) {
                 // it is important we catch exceptions so that other listeners aren't obstructed when
                 // one of the listeners is throwing an exception.
                 try {
                     closeListener.onClose(this);
                 } catch (Exception e) {
-                    ILogger logger = Logger.getLogger(getClass());
-                    logger.severe(format(""Failed to process closeListener [%s] on channel [%s]"", closeListener, this), e);
+                    getLogger().severe(format(""Failed to process closeListener [%s] on channel [%s]"", closeListener, this), e);
                 }
             }
         }
     }
\ No newline at end of file
","Fix AbstractChannel.close forwarding to reader/writer

A bug was introduced by me in the 3.9 io changes where the forwarding of
the close to the underlying channel reader/writer is skipped.

This pr restores these closes by adding a template method to the AbstractChannel
which is implemented by the NioChannel.
",Buggy
hazelcast,12126.json,8bbe3fbfaa5e85b1e504100aa7d4c425970dee3d,"@@ -1,3 +1,5 @@
     public boolean eval(Object arg) {
-        return (key == null || key.equals(arg)) && predicate.apply((Map.Entry)arg);
+        final QueryEntry entry = (QueryEntry) arg;
+        final Data keyData = entry.getKeyData();
+        return (key == null || key.equals(keyData)) && predicate.apply((Map.Entry)arg);
     }
\ No newline at end of file
","MapAddListenerRequest serialization bug fix and related to that  QueryEventFilter bug fix
",Buggy
hazelcast,12000.json,777bd5c28ac36f1b948f94a68b21328e3743e877,"@@ -1,11 +1,10 @@
     public static int getMaxSizePerNode(MaxSizeConfig maxSizeConfig) {
-
-        int maxSizePerNode = getApproximateMaxSize(maxSizeConfig, MaxSizePolicy.PER_NODE);
+        double maxSizePerNode = getApproximateMaxSize(maxSizeConfig, MaxSizePolicy.PER_NODE);
 
         if (maxSizePerNode == MaxSizeConfig.DEFAULT_MAX_SIZE) {
             // unlimited
             return -1;
         }
 
-        return maxSizePerNode;
+        return (int) maxSizePerNode;
     }
\ No newline at end of file
","Fixed getApproximateMaxSize calculation bug
",Buggy
jetty,11444.json,93b6877d724cbec52cc427e168144d539ea8e38b,"@@ -1,9 +1,9 @@
     protected void doStart() throws Exception
     {
         Objects.requireNonNull(httpClient, ""Provided HttpClient is null"");
 
+        super.doStart();
+
         if (!httpClient.isRunning())
             throw new IllegalStateException(""HttpClient is not running (did you forget to start it?): "" + httpClient);
-
-        super.doStart();
     }
\ No newline at end of file
","Issue #2210 - fixing flaw in safety checks with JSR356 ClientContainer
",Buggy
jetty,3568.json,6c81941142b9efe2b5b80198268ae75687dc6374,"@@ -1,61 +1,66 @@
     public void validate(Certificate[] certChain) throws CertificateException
     {
         try
         {
             ArrayList<X509Certificate> certList = new ArrayList<X509Certificate>();
             for (Certificate item : certChain)
             {
                 if (item == null)
                     continue;
                 
                 if (!(item instanceof X509Certificate))
                 {
                     throw new IllegalStateException(""Invalid certificate type in chain"");
                 }
                 
                 certList.add((X509Certificate)item);
             }
     
             if (certList.isEmpty())
             {
                 throw new IllegalStateException(""Invalid certificate chain"");
                 
             }
     
             X509CertSelector certSelect = new X509CertSelector();
             certSelect.setCertificate(certList.get(0));
             
             // Configure certification path builder parameters
             PKIXBuilderParameters pbParams = new PKIXBuilderParameters(_trustStore, certSelect);
             pbParams.addCertStore(CertStore.getInstance(""Collection"", new CollectionCertStoreParameters(certList)));
     
             // Set maximum certification path length
             pbParams.setMaxPathLength(_maxCertPathLength);
     
             // Enable revocation checking
             pbParams.setRevocationEnabled(true);
     
             // Set static Certificate Revocation List
             if (_crls != null && !_crls.isEmpty())
             {
                 pbParams.addCertStore(CertStore.getInstance(""Collection"", new CollectionCertStoreParameters(_crls)));
             }
     
             // Enable On-Line Certificate Status Protocol (OCSP) support
-            Security.setProperty(""ocsp.enable"",""true"");
-    
+            if (_enableOCSP)
+            {
+                Security.setProperty(""ocsp.enable"",""true"");
+            }
             // Enable Certificate Revocation List Distribution Points (CRLDP) support
-            System.setProperty(""com.sun.security.enableCRLDP"",""true"");
+            if (_enableCRLDP)
+            {
+                System.setProperty(""com.sun.security.enableCRLDP"",""true"");
+            }
     
             // Build certification path
             CertPathBuilderResult buildResult = CertPathBuilder.getInstance(""PKIX"").build(pbParams);               
             
             // Validate certification path
             CertPathValidator.getInstance(""PKIX"").validate(buildResult.getCertPath(),pbParams);
         }
         catch (GeneralSecurityException gse)
         {
             LOG.debug(gse);
             throw new CertificateException(""Unable to validate certificate: "" + gse.getMessage(), gse);
         }
     }
\ No newline at end of file
","[Bug 373567] cert validation issue with ocsp and crldp always being enabled when validating turned on fixed
",Buggy
jetty,12794.json,c6d86122dbd737f2247b01653da0af938075370d,"@@ -1,45 +1,46 @@
     public Authentication validateRequest(ServletRequest request, ServletResponse response, boolean mandatory) throws ServerAuthException
     {
         HttpServletRequest req = (HttpServletRequest)request;
         HttpServletResponse res = (HttpServletResponse)response;
 
         String header = req.getHeader(HttpHeader.AUTHORIZATION.asString());
+        String authScheme = getAuthSchemeFromHeader(header);
 
         if (!mandatory)
         {
             return new DeferredAuthentication(this);
         }
 
         // The client has responded to the challenge we sent previously
-        if (header != null && header.startsWith(HttpHeader.NEGOTIATE.asString().toLowerCase()))
+        if (header != null && isAuthSchemeNegotiate(authScheme))
         {
             String spnegoToken = header.substring(10);
 
             UserIdentity user = login(null,spnegoToken, request);
 
             if ( user != null )
             {
                 return new UserAuthentication(getAuthMethod(),user);
             }
         }
 
         // A challenge should be sent if any of the following cases are true:
         //   1. There was no Authorization header provided
         //   2. There was an Authorization header for a type other than Negotiate
         try
         {
              if (DeferredAuthentication.isDeferred(res))
              {
                  return Authentication.UNAUTHENTICATED;
              }
 
             LOG.debug(""SpengoAuthenticator: sending challenge"");
             res.setHeader(HttpHeader.WWW_AUTHENTICATE.asString(), HttpHeader.NEGOTIATE.asString());
             res.sendError(HttpServletResponse.SC_UNAUTHORIZED);
             return Authentication.SEND_CONTINUE;
         }
         catch (IOException ioe)
         {
             throw new ServerAuthException(ioe);
         }
     }
\ No newline at end of file
","Fix a bug around handling ""Negotiate"" case-insensitively in SpnegoAut (#1710)

* Fix a bug around handling ""Negotiate"" case-insensitively in SpnegoAuthenticator

Closes #1709

Signed-off-by: Josh Elser <elserj@apache.org>

* Clean up isAuthSchemeNegotiate(String) since we don't need to use startsWith()

Signed-off-by: Josh Elser <elserj@apache.org>
",Buggy
jetty,12794.json,1fd3e4ad1b8903bc9033dd24c86a0207996097b1,"@@ -1,46 +1,45 @@
     public Authentication validateRequest(ServletRequest request, ServletResponse response, boolean mandatory) throws ServerAuthException
     {
         HttpServletRequest req = (HttpServletRequest)request;
         HttpServletResponse res = (HttpServletResponse)response;
 
         String header = req.getHeader(HttpHeader.AUTHORIZATION.asString());
 
         if (!mandatory)
         {
             return new DeferredAuthentication(this);
         }
 
-        // check to see if we have authorization headers required to continue
-        if ( header == null )
-        {
-            try
-            {
-                 if (DeferredAuthentication.isDeferred(res))
-                 {
-                     return Authentication.UNAUTHENTICATED;
-                 }
-
-                LOG.debug(""SpengoAuthenticator: sending challenge"");
-                res.setHeader(HttpHeader.WWW_AUTHENTICATE.asString(), HttpHeader.NEGOTIATE.asString());
-                res.sendError(HttpServletResponse.SC_UNAUTHORIZED);
-                return Authentication.SEND_CONTINUE;
-            }
-            catch (IOException ioe)
-            {
-                throw new ServerAuthException(ioe);
-            }
-        }
-        else if (header != null && header.startsWith(HttpHeader.NEGOTIATE.asString()))
+        // The client has responded to the challenge we sent previously
+        if (header != null && header.startsWith(HttpHeader.NEGOTIATE.asString().toLowerCase()))
         {
             String spnegoToken = header.substring(10);
 
             UserIdentity user = login(null,spnegoToken, request);
 
             if ( user != null )
             {
                 return new UserAuthentication(getAuthMethod(),user);
             }
         }
 
-        return Authentication.UNAUTHENTICATED;
+        // A challenge should be sent if any of the following cases are true:
+        //   1. There was no Authorization header provided
+        //   2. There was an Authorization header for a type other than Negotiate
+        try
+        {
+             if (DeferredAuthentication.isDeferred(res))
+             {
+                 return Authentication.UNAUTHENTICATED;
+             }
+
+            LOG.debug(""SpengoAuthenticator: sending challenge"");
+            res.setHeader(HttpHeader.WWW_AUTHENTICATE.asString(), HttpHeader.NEGOTIATE.asString());
+            res.sendError(HttpServletResponse.SC_UNAUTHORIZED);
+            return Authentication.SEND_CONTINUE;
+        }
+        catch (IOException ioe)
+        {
+            throw new ServerAuthException(ioe);
+        }
     }
\ No newline at end of file
","Sends the WWW-Authenticate header if a non-Negotiate authorization he (#1700)

* Sends the WWW-Authenticate header if a non-Negotiate authorization header was given

Fixes #1698

Signed-off-by: Josh Elser <elserj@apache.org>

* Dumb compilation error

Signed-off-by: Josh Elser <elserj@apache.org>

* Adds a test to show the challenge is sent.

Signed-off-by: Josh Elser <elserj@apache.org>

* Refactor the conditionals per Greg's suggestion

Signed-off-by: Josh Elser <elserj@apache.org>

* Add the expected license header

Signed-off-by: Josh Elser <elserj@apache.org>
",Buggy
jetty,6485.json,c170801600f37d831007e6f496e7fc7d86e71dd1,"@@ -1,27 +1,27 @@
     protected void doStop() throws Exception
     {
         super.doStop();
 
         try
         {
             for (int i=_configurations.length;i-->0;)
                 _configurations[i].deconfigure(this);
             
             _configurations=null;
             
             // restore security handler
-            if (_securityHandler.getHandler()==null)
+            if (_securityHandler != null && _securityHandler.getHandler()==null)
             {
                 _sessionHandler.setHandler(_securityHandler);
                 _securityHandler.setHandler(_servletHandler);
             }
         }
         finally
         {
             if (_ownClassLoader)
                 setClassLoader(null);
 
             setAvailable(true);
             _unavailableException=null;
         }
     }
\ No newline at end of file
","Bug 277027 Fix NPE if no security handler installed

git-svn-id: svn+ssh://dev.eclipse.org/svnroot/rt/org.eclipse.jetty/jetty/trunk@239 7e9141cc-0065-0410-87d8-b60c137991c4
",Buggy
jetty,1562.json,4236f14955e828946c33f447fed3e65dfa8bfc1e,"@@ -1,15 +1,15 @@
         public void run()
         {
             try
             {
                 if (handle)
                     handleWithContext();
-                else
+                else if (getHttpConfiguration().isNotifyRemoteAsyncErrors())
                     getState().asyncError(failure);
                 callback.succeeded();
             }
             catch (Throwable x)
             {
                 callback.failed(x);
             }
         }
\ No newline at end of file
","Fixes #1891 - Make HTTP/2 async error notifications configurable.

Introduced HttpConfiguration.notifyRemoteAsyncErrors, true by default.
",Buggy
jetty,6487.json,0b13e6cddd8b8056311176389024fdb187305749,"@@ -1,12 +1,12 @@
     private void dumpUrl()
     {
         Connector[] connectors = getServer().getConnectors();
         for (int i=0;i<connectors.length;i++)
         {
             String displayName = getDisplayName();
             if (displayName == null)
-                displayName = ""WebApp@""+connectors.hashCode();
+                displayName = ""WebApp@""+Arrays.hashCode(connectors);
 
             LOG.info(displayName + "" at http://"" + connectors[i].toString() + getContextPath());
         }
     }
\ No newline at end of file
","fix error prone error

Signed-off-by: olivier lamy <olamy@webtide.com>
",Buggy
jetty,5128.json,8ec4e56681231a2370715cde72d46262aba65294,"@@ -1,17 +1,17 @@
     private static MultiMap<String> parseQueryString(String url)
     {
         MultiMap<String> res = new MultiMap<String>();
         int questionMarkIndex = url.indexOf('?');
         if (questionMarkIndex == -1)
         {
             return res;
         }
         int poundIndex = url.indexOf('#');
         if (poundIndex == -1)
         {
             poundIndex = url.length();
         }
-        UrlEncoded.decodeUtf8To(url.getBytes(), questionMarkIndex+1,
+        UrlEncoded.decodeUtf8To(url, questionMarkIndex+1,
                     poundIndex - questionMarkIndex - 1, res);
         return res;
     }
\ No newline at end of file
","Fixing compile error
",Buggy
jclouds,26844.json,c0e6a2c51cd131bcef2ee051cfe200b41afda528,"@@ -1,57 +1,57 @@
       public T read(JsonReader in) throws IOException {
          if (in.peek() == JsonToken.NULL) {
             in.nextNull();
             return null;
          }
 
          List<Parameter> params = parameterizedCtor.getParameters();
          Object[] values = new Object[params.size()];
          boolean empty = true;
 
          // Set all primitive constructor params to defaults
          for (Parameter param : params) {
             if (param.getType().getRawType() == boolean.class) {
                values[param.hashCode()] = Boolean.FALSE;
             } else if (param.getType().getRawType().isPrimitive()) {
                values[param.hashCode()] = 0;
             }
          }
 
          try {
             in.beginObject();
             while (in.hasNext()) {
                empty = false;
                String name = in.nextName();
                ParameterReader<?> parameter = parameterReaders.get(name);
-               if (parameter == null) {
+               if (parameter == null || in.peek() == JsonToken.NULL) {
                   in.skipValue();
                } else {
                   Object value = parameter.read(in);
                   if (value != null)
                      values[parameter.position] = value;
                }
             }
          } catch (IllegalStateException e) {
             throw new JsonSyntaxException(e);
          }
 
          for (Parameter param : params) {
             if (param.getType().getRawType().isPrimitive()) {
                checkArgument(values[param.hashCode()] != null,
                   ""Primitive param[%s] in constructor %s cannot be absent!"", param.hashCode(), parameterizedCtor);
             } else if (param.getType().getRawType() == Optional.class && values[param.hashCode()] == null) {
                values[param.hashCode()] = Optional.absent();
             }
          }
          in.endObject();
 
          try {
             return newInstance(values);
          } catch (NullPointerException ex) {
             // If {} was found and constructor threw NPE, we treat the field as null
             if (empty && values.length > 0) {
                return null;
             }
             throw ex;
          }
       }
\ No newline at end of file
","Fixed bug found in docker provider where deserialization constructors don't handle json null.
",Buggy
jclouds,27517.json,b59457a405f1741cebfa14775b397ae225dd714b,"@@ -1,4 +1,4 @@
    public <C extends Context> C unwrap(TypeToken<C> type) {
-      checkArgument(checkNotNull(type, ""type"").isAssignableFrom(backendType), ""backend type: %s not assignable from %s"", backendType, type);
+      checkArgument(checkNotNull(type, ""type"").isAssignableFrom(backendType), ""backend type: %s not assignable to %s"", backendType, type);
       return (C) backend;
    }
\ No newline at end of file
","Fixing an error message about an unassignable backend
",Buggy
jclouds,25412.json,d41101df5932043c3a8614552f25ab91194595ba,"@@ -1,19 +1,19 @@
    private ImmutableMap<String, String> getContentMetadataForManifest(ContentMetadata contentMetadata) {
       Builder<String, String> mapBuilder = ImmutableMap.builder();
       if (contentMetadata.getContentType() != null) {
          mapBuilder.put(""content-type"", contentMetadata.getContentType());
       }
       /**
-       * Do not set content-length. Set automatically to manifest json string length by BindManifestToJsonPayload
+       * Do not set content-length. Set automatically to manifest json string length by BindToJsonPayload
        */
       if (contentMetadata.getContentDisposition() != null) {
          mapBuilder.put(""content-disposition"", contentMetadata.getContentDisposition());
       }
       if (contentMetadata.getContentEncoding() != null) {
          mapBuilder.put(""content-encoding"", contentMetadata.getContentEncoding());
       }
       if (contentMetadata.getContentLanguage() != null) {
          mapBuilder.put(""content-language"", contentMetadata.getContentLanguage());
       }
       return mapBuilder.build();
    }
\ No newline at end of file
","JCLOUDS-1264: Swift Unicode multipart manifests

This fixes a bug where previously BindManifestToJsonPayload used the
character length as the ContentLength, instead of the byte length,
which caused issues if the JSON contained multi-byte Unicode
characters.
",Buggy
jclouds,18000.json,9965fbcadb0913889f19d4f29e9f66f20e3f4f08,"@@ -1,24 +1,24 @@
    public Instance getWorkingInstance(String zone, String name, String flavorId, int size) {
       InstanceApi instanceApi = api.getInstanceApiForZone(zone);
       for (int retries = 0; retries < 10; retries++) {
          Instance instance = null;
          try {
             instance = instanceApi.create(flavorId, size, name);
          } catch (Exception e) {
 
             Uninterruptibles.sleepUninterruptibly(15, TimeUnit.SECONDS);
 
-            logger.error(e.getStackTrace().toString());
+            logger.error(Arrays.toString(e.getStackTrace()));
             continue;
          }
 
          Instance updatedInstance = awaitAvailable(instance, instanceApi);
          if (updatedInstance != null) {
             return updatedInstance;
          }
          instanceApi.delete(instance.getId());
          InstancePredicates.awaitDeleted(instanceApi).apply(instance);
          
       }
       return null;
    }
\ No newline at end of file
","Address error-prone warning
",Buggy
jclouds,1113.json,347926543ee72a14f8587bc83f72e1064cef8784,"@@ -1,4 +1,8 @@
    @Override protected void configure() {
       super.configure();
       bindHttpApi(binder(), UseApiToResolveProjectName.GetProject.class);
+      bind(OAuthScopes.class).toInstance(ReadOrWriteScopes.create( //
+            ""https://www.googleapis.com/auth/compute.readonly"", //
+            ""https://www.googleapis.com/auth/compute"" //
+      ));
    }
\ No newline at end of file
"," * Change OAuthScopes into an interface as opposed to boilerplating annotations.
 * Fixed errors because of boilerplating annotations.
",Buggy
jclouds,25772.json,f851271ae3d56d1549e62cd3723ad6207ced97f1,"@@ -1,3 +1,3 @@
-      public static NodeAttributes condition(String condition) {
-         return new NodeAttributes().condition(condition);
+      public static NodeAttributes condition(Condition condition) {
+         return new NodeAttributes().condition(condition.name());
       }
\ No newline at end of file
","minor bug fixes plus wiring up
",Buggy
jclouds,14356.json,6d657b1c90d590d38a6110f18f4683592932336d,"@@ -1,3 +1,3 @@
    public float getCpuUsed() {
-      return cpuUsed != null ? Float.parseFloat(cpuUsed.substring(9, cpuUsed.length() - 1)) : 0.0f;
+      return cpuUsed != null ? Float.parseFloat(cpuUsed.substring(0, cpuUsed.length() - 1)) : 0.0f;
    }
\ No newline at end of file
","Fix bug in parsing VirtualMachine.cpuUsed
",Buggy
okhttp,1134.json,aed222454743ebe5724d6ad438fafed37956521e,"@@ -1,15 +1,25 @@
   @Override public void connectSocket(Socket socket, InetSocketAddress address,
       int connectTimeout) throws IOException {
     try {
       socket.connect(address, connectTimeout);
     } catch (AssertionError e) {
       if (Util.isAndroidGetsocknameError(e)) throw new IOException(e);
       throw e;
     } catch (SecurityException e) {
       // Before android 4.3, socket.connect could throw a SecurityException
       // if opening a socket resulted in an EACCES error.
       IOException ioException = new IOException(""Exception in connect"");
       ioException.initCause(e);
       throw ioException;
+    } catch (ClassCastException e) {
+      // On android 8.0, socket.connect throws a ClassCastException due to a bug
+      // see https://issuetracker.google.com/issues/63649622
+      if (Build.VERSION.SDK_INT == 26) {
+        IOException ioException = new IOException(""Exception in connect"");
+        ioException.initCause(e);
+        throw ioException;
+      } else {
+        throw e;
+      }
     }
   }
\ No newline at end of file
","Add workaround for https://issuetracker.google.com/issues/63649622 (#3624)

* Add workaround for https://issuetracker.google.com/issues/63649622

This fixes #3438

* Rethrowing the Android O bug CCE as IOException
",Buggy
okhttp,55.json,8bce6897f9f7e0b16508c462665e4f9d26d92e39,"@@ -1,34 +1,34 @@
   private static Request transformRequest(HttpRequest request) {
     Request.Builder builder = new Request.Builder();
 
     RequestLine requestLine = request.getRequestLine();
     String method = requestLine.getMethod();
     builder.url(requestLine.getUri());
 
     String contentType = null;
     for (Header header : request.getAllHeaders()) {
       String name = header.getName();
-      if (""Content-Type"".equals(name)) {
+      if (""Content-Type"".equalsIgnoreCase(name)) {
         contentType = header.getValue();
       } else {
         builder.header(name, header.getValue());
       }
     }
 
     RequestBody body = null;
     if (request instanceof HttpEntityEnclosingRequest) {
       HttpEntity entity = ((HttpEntityEnclosingRequest) request).getEntity();
       if (entity != null) {
         // Wrap the entity in a custom Body which takes care of the content, length, and type.
         body = new HttpEntityBody(entity, contentType);
 
         Header encoding = entity.getContentEncoding();
         if (encoding != null) {
           builder.header(encoding.getName(), encoding.getValue());
         }
       }
     }
     builder.method(method, body);
 
     return builder.build();
   }
\ No newline at end of file
","fixed a bug that content type is compared by case sensitive
",Buggy
okhttp,1015.json,8b17ab4e65b21c6480a38c383a16899f9ffabbcc,"@@ -1,39 +1,42 @@
   public void streamFailed(IOException e) {
     Socket socket;
     Connection releasedConnection;
     boolean noNewStreams = false;
 
     synchronized (connectionPool) {
       if (e instanceof StreamResetException) {
-        StreamResetException streamResetException = (StreamResetException) e;
-        if (streamResetException.errorCode == ErrorCode.REFUSED_STREAM) {
+        ErrorCode errorCode = ((StreamResetException) e).errorCode;
+        if (errorCode == ErrorCode.REFUSED_STREAM) {
+          // Retry REFUSED_STREAM errors once on the same connection.
           refusedStreamCount++;
-        }
-        // On HTTP/2 stream errors, retry REFUSED_STREAM errors once on the same connection. All
-        // other errors must be retried on a new connection.
-        if (streamResetException.errorCode != ErrorCode.REFUSED_STREAM || refusedStreamCount > 1) {
+          if (refusedStreamCount > 1) {
+            noNewStreams = true;
+            route = null;
+          }
+        } else if (errorCode != ErrorCode.CANCEL) {
+          // Keep the connection for CANCEL errors. Everything else wants a fresh connection.
           noNewStreams = true;
           route = null;
         }
       } else if (connection != null
           && (!connection.isMultiplexed() || e instanceof ConnectionShutdownException)) {
         noNewStreams = true;
 
         // If this route hasn't completed a call, avoid it for new connections.
         if (connection.successCount == 0) {
           if (route != null && e != null) {
             routeSelector.connectFailed(route, e);
           }
           route = null;
         }
       }
       releasedConnection = connection;
       socket = deallocate(noNewStreams, false, true);
       if (connection != null || !reportedAcquired) releasedConnection = null;
     }
 
     closeQuietly(socket);
     if (releasedConnection != null) {
       eventListener.connectionReleased(call, releasedConnection);
     }
   }
\ No newline at end of file
","Fix stream cancel error stopping reused connection
",Buggy
okhttp,2062.json,a87147e65424df05b7d7829555eef1220dbf4633,"@@ -1,18 +1,18 @@
     public Response response(Request request, DiskLruCache.Snapshot snapshot) {
       String contentType = responseHeaders.get(""Content-Type"");
       String contentLength = responseHeaders.get(""Content-Length"");
       Request cacheRequest = new Request.Builder()
           .url(url)
-          .method(message, null)
+          .method(requestMethod, null)
           .headers(varyHeaders)
           .build();
       return new Response.Builder()
           .request(cacheRequest)
           .protocol(protocol)
           .code(code)
           .message(message)
           .headers(responseHeaders)
           .body(new CacheResponseBody(snapshot, contentType, contentLength))
           .handshake(handshake)
           .build();
     }
\ No newline at end of file
","Fix a bug where the cacheResponse's request method was wrong.

We were returning the message (like 'OK') rather than the method
(like 'GET'). Ugh.
",Buggy
openmrs-core,30.json,35fbc63bd8566c1b7800fcfdd1e34a6640ef0bd4,"@@ -1,30 +1,36 @@
 	protected File getFile(HttpServletRequest request) {
 		
 		String path = request.getPathInfo();
 		
 		Module module = ModuleUtil.getModuleForPath(path);
 		if (module == null) {
 			log.warn(""No module handles the path: "" + path);
 			return null;
 		}
 		
 		String relativePath = ModuleUtil.getPathForResource(module, path);
 		String realPath = getServletContext().getRealPath("""") + MODULE_PATH + module.getModuleIdAsPath() + ""/resources""
 		        + relativePath;
 		
 		//if in dev mode, load resources from the development directory
 		File devDir = ModuleUtil.getDevelopmentDirectory(module.getModuleId());
 		if (devDir != null) {
 			realPath = devDir.getAbsolutePath() + ""/omod/target/classes/web/module/resources"" + relativePath;
 		}
 		
 		realPath = realPath.replace(""/"", File.separator);
 		
 		File f = new File(realPath);
 		if (!f.exists()) {
+			if (isJstlFile(path)) {
+				f =  new File(realPath + "".withjstl"");
+				if (f.exists()) {
+					return f;
+				}
+			}
 			log.warn(""No file with path '"" + realPath + ""' exists for module '"" + module.getModuleId() + ""'"");
 			return null;
 		}
 		
 		return f;
 	}
\ No newline at end of file
",Fixing jslt file load error,Buggy
openmrs-core,6620.json,6c5b1205526a53e2327f802adf31e1f4e340d93f,"@@ -1,20 +1,20 @@
 	public PatientIdentifier savePatientIdentifier(PatientIdentifier patientIdentifier) throws APIException {
 		//if the argument or the following required fields are not specified
 		PatientIdentifierType.LocationBehavior locationBehavior = null;
 		if (patientIdentifier != null) {
-			patientIdentifier.getIdentifierType().getLocationBehavior();
+			locationBehavior = patientIdentifier.getIdentifierType().getLocationBehavior();
 		}
 		
 		if (patientIdentifier == null
 		        || patientIdentifier.getPatient() == null
 		        || patientIdentifier.getIdentifierType() == null
 		        || StringUtils.isBlank(patientIdentifier.getIdentifier())
 		        || (locationBehavior == PatientIdentifierType.LocationBehavior.REQUIRED && patientIdentifier.getLocation() == null))
 			throw new APIException(""PatientIdentifier argument or one of its required fields is null or invalid"");
 		if (patientIdentifier.getPatientIdentifierId() == null) {
 			Context.requirePrivilege(PrivilegeConstants.ADD_PATIENT_IDENTIFIERS);
 		} else
 			Context.requirePrivilege(PrivilegeConstants.EDIT_PATIENT_IDENTIFIERS);
 		
 		return dao.savePatientIdentifier(patientIdentifier);
 	}
\ No newline at end of file
","Fixing forgotten assignment bug for:
PatientService.savePatientIdentifier still requires location -
TRUNK-4056",Buggy
openmrs-core,4909.json,837c70069a4bfca920ed92a7e73da0dbead6aff0,"@@ -1,6 +1,3 @@
 	public void purgeConceptClass(ConceptClass cc) throws DAOException  {
-		sessionFactory.getCurrentSession().createQuery(""delete from ConceptClass where concept_class_id = :c"")
-					.setInteger(""c"", cc.getConceptClassId())
-					.executeUpdate();			
 		sessionFactory.getCurrentSession().delete(cc);
 	}
\ No newline at end of file
","Fixing conceptClass deletion error and fieldAnswer errors found by cmack

git-svn-id: http://svn.openmrs.org/openmrs/trunk@4553 5bac5841-c719-aa4e-b3fe-cce5062f897a
",Buggy
openmrs-core,7646.json,f6e02ac804e140765a89e0f983c794be1b3ffa14,"@@ -1,127 +1,127 @@
 	public void execute(Database database) throws CustomChangeException {
 		JdbcConnection connection = (JdbcConnection) database.getConnection();
 		Map<String, HashSet<Integer>> duplicates = new HashMap<String, HashSet<Integer>>();
 		Statement stmt = null;
 		PreparedStatement pStmt = null;
 		ResultSet rs = null;
 		boolean autoCommit = true;
 		try {
 			// set auto commit mode to false for UPDATE action
 			autoCommit = connection.getAutoCommit();
 			connection.setAutoCommit(false);
 			stmt = connection.createStatement();
-			rs = stmt.executeQuery(""SELECT * FROM location_attribute_type""
+			rs = stmt.executeQuery(""SELECT * FROM location_attribute_type ""
 			        + ""INNER JOIN (SELECT name FROM location_attribute_type GROUP BY name HAVING count(name) > 1) ""
 			        + ""dup ON location_attribute_type.name = dup.name"");
 			Integer id = null;
 			String name = null;
 			
 			while (rs.next()) {
 				id = rs.getInt(""location_attribute_type_id"");
 				name = rs.getString(""name"");
 				if (duplicates.get(name) == null) {
 					HashSet<Integer> results = new HashSet<Integer>();
 					results.add(id);
 					duplicates.put(name, results);
 				} else {
 					HashSet<Integer> results = duplicates.get(name);
 					results.add(id);
 				}
 			}
 			
 			Iterator it2 = duplicates.entrySet().iterator();
 			while (it2.hasNext()) {
 				Map.Entry pairs = (Map.Entry) it2.next();
 				HashSet values = (HashSet) pairs.getValue();
 				List<Integer> duplicateNames = new ArrayList<Integer>(values);
 				int duplicateNameId = 1;
 				for (int i = 1; i < duplicateNames.size(); i++) {
 					String newName = pairs.getKey() + ""_"" + duplicateNameId;
 					List<List<Object>> duplicateResult = null;
 					boolean duplicateName = false;
 					Connection con = DatabaseUpdater.getConnection();
 					do {
 						String sqlValidatorString = ""select * from location_attribute_type where name = '"" + newName + ""'"";
 						duplicateResult = DatabaseUtil.executeSQL(con, sqlValidatorString, true);
 						if (!duplicateResult.isEmpty()) {
 							duplicateNameId += 1;
 							newName = pairs.getKey() + ""_"" + duplicateNameId;
 							duplicateName = true;
 						} else {
 							duplicateName = false;
 						}
 					} while (duplicateName);
 					pStmt = connection
 					        .prepareStatement(""update location_attribute_type set name = ?, changed_by = ?, date_changed = ? where location_attribute_type_id = ?"");
 					if (!duplicateResult.isEmpty()) {
 						pStmt.setString(1, newName);
 					}
 					pStmt.setString(1, newName);
 					pStmt.setInt(2, DatabaseUpdater.getAuthenticatedUserId());
 					
 					Calendar cal = Calendar.getInstance();
 					Date date = new Date(cal.getTimeInMillis());
 					
 					pStmt.setDate(3, date);
 					pStmt.setInt(4, duplicateNames.get(i));
 					duplicateNameId += 1;
 					
 					pStmt.executeUpdate();
 				}
 			}
 		}
 		catch (BatchUpdateException e) {
 			log.warn(""Error generated while processsing batch insert"", e);
 			try {
 				log.debug(""Rolling back batch"", e);
 				connection.rollback();
 			}
 			catch (Exception rbe) {
 				log.warn(""Error generated while rolling back batch insert"", e);
 			}
 			// marks the changeset as a failed one
 			throw new CustomChangeException(""Failed to update one or more duplicate LocationAttributeType names"", e);
 		}
 		catch (Exception e) {
 			throw new CustomChangeException(""Error while updating duplicate LocationAttributeType object names"", e);
 		}
 		finally {
 			// reset to auto commit mode
 			try {
 				connection.commit();
 				connection.setAutoCommit(autoCommit);
 			}
 			catch (DatabaseException e) {
 				log.warn(""Failed to reset auto commit back to true"", e);
 			}
 			
 			if (rs != null) {
 				try {
 					rs.close();
 				}
 				catch (SQLException e) {
 					log.warn(""Failed to close the resultset object"");
 				}
 			}
 			
 			if (stmt != null) {
 				try {
 					stmt.close();
 				}
 				catch (SQLException e) {
 					log
 					        .warn(""Failed to close the select statement used to identify duplicate LocationAttributeType object names"");
 				}
 			}
 			
 			if (pStmt != null) {
 				try {
 					pStmt.close();
 				}
 				catch (SQLException e) {
 					log
 					        .warn(""Failed to close the prepared statement used to update duplicate LocationAttributeType object names"");
 				}
 			}
 		}
 	}
\ No newline at end of file
",Fixing liquibase upgrade error for: TRUNK-4334,Buggy
openmrs-core,6353.json,95b3ab3de2d8ec488d0ca0fcbcb1e8969d491313,"@@ -1,21 +1,28 @@
 	private Class datatypeClassHandled(Type t) {
 		if (t instanceof ParameterizedType) {
 			ParameterizedType pt = (ParameterizedType) t;
 			Type first = pt.getActualTypeArguments()[0];
 			if (first instanceof Class && CustomDatatype.class.isAssignableFrom((Class) first)) {
 				return (Class) first;
 			} else {
 				return datatypeClassHandled(pt.getRawType());
 			}
 			
 		} else if (t instanceof Class) {
+			Type genericSuperclass = ((Class) t).getGenericSuperclass();
+			if (genericSuperclass != null) {
+				Class ret = datatypeClassHandled(genericSuperclass);
+				if (ret != null) {
+					return ret;
+				}
+			}
 			for (Type candidate : ((Class) t).getGenericInterfaces()) {
 				Class ret = datatypeClassHandled(candidate);
 				if (ret != null) {
 					return ret;
 				}
 			}
 		}
 		
 		return null;
 	}
\ No newline at end of file
","Fixed bug where a custom datatype handler that extends a generic abstract class can't be found  -TRUNK-3499
",Buggy
openmrs-core,7456.json,4fff45254e5332a1b608a88d6daa83e7a330daf7,"@@ -1,9 +1,9 @@
 	public static byte[] getSavedSecretKey() {
-		String keyText = Context.getRuntimeProperties().getProperty(OpenmrsConstants.ENCRYPTION_VECTOR_RUNTIME_PROPERTY,
-		    OpenmrsConstants.ENCRYPTION_VECTOR_DEFAULT);
+		String keyText = Context.getRuntimeProperties().getProperty(OpenmrsConstants.ENCRYPTION_KEY_RUNTIME_PROPERTY,
+		    OpenmrsConstants.ENCRYPTION_KEY_DEFAULT);
 		
 		if (StringUtils.hasText(keyText))
 			return Base64.decode(keyText);
 		
 		throw new APIException(""no encryption secret key found"");
 	}
\ No newline at end of file
","TRUNK-1919 - fixed glaring flaw where I pulled in the encryption.vector runtime property instead of encryption.key

git-svn-id: http://svn.openmrs.org/openmrs/trunk@18684 5bac5841-c719-aa4e-b3fe-cce5062f897a
",Buggy
openmrs-core,6446.json,119e3fa6338f5401f0a75873e5a6526b8b23cd80,"@@ -1,10 +1,10 @@
 	private void checkPrivileges(Role role) {
-		Collection<Privilege> privileges = role.getPrivileges();
-		
 		Optional.ofNullable(role.getPrivileges())
 		.map(p -> p.stream().filter(pr -> !Context.hasPrivilege(pr.getPrivilege())).map(Privilege::getPrivilege)
 			.distinct().collect(Collectors.joining("", "")))
 		.ifPresent(missing -> {
-			throw new APIException(""Role.you.must.have.privileges: "", new Object[] { missing });
+			if (StringUtils.isNotBlank(missing)) {
+				throw new APIException(""Role.you.must.have.privileges"", new Object[] { missing });
+			}
 		});
     }
\ No newline at end of file
","Fix for TRUNK-5726

* Only throws exception if actually missing permissions are found
* Correct error string
* Adds unit tests
",Buggy
openmrs-core,2762.json,29eae1d038bc6036af4903c9b43f42a157b10a1a,"@@ -1,49 +1,49 @@
 	private Provider getProvider(PV1 pv1) throws HL7Exception {
 		XCN hl7Provider = pv1.getAttendingDoctor(0);
 		Provider provider = null;
 		String id = hl7Provider.getIDNumber().getValue();
 		String assignAuth = hl7Provider.getAssigningAuthority().getUniversalID().getValue();
 		String type = hl7Provider.getAssigningAuthority().getUniversalIDType().getValue();
 		String errorMessage = """";
 		if (StringUtils.hasText(id)) {
 			String specificErrorMsg = """";
 			if (OpenmrsUtil.nullSafeEquals(""L"", type)) {
 				if (HL7Constants.PROVIDER_ASSIGNING_AUTH_PROV_ID.equalsIgnoreCase(assignAuth)) {
 					try {
 						provider = Context.getProviderService().getProvider(Integer.valueOf(id));
 					}
 					catch (NumberFormatException e) {
 						// ignore
 					}
 					specificErrorMsg = ""with provider Id"";
 				} else if (HL7Constants.PROVIDER_ASSIGNING_AUTH_IDENTIFIER.equalsIgnoreCase(assignAuth)) {
 					provider = Context.getProviderService().getProviderByIdentifier(id);
-					specificErrorMsg = ""with provider identifier:"" + id;
+					specificErrorMsg = ""with provider identifier"";
 				} else if (HL7Constants.PROVIDER_ASSIGNING_AUTH_PROV_UUID.equalsIgnoreCase(assignAuth)) {
 					provider = Context.getProviderService().getProviderByUuid(id);
 					specificErrorMsg = ""with provider uuid"";
 				}
 			} else {
 				try {
 					Person person = Context.getPersonService().getPerson(Integer.valueOf(id));
 					Collection<Provider> providers = Context.getProviderService().getProvidersByPerson(person);
 					if (!providers.isEmpty())
 						provider = providers.iterator().next();
 				}
 				catch (NumberFormatException e) {
 					// ignore
 				}
 				specificErrorMsg = ""associated to a person with person id"";
 			}
 			
 			errorMessage = ""Could not resolve provider "" + specificErrorMsg + "":"" + id;
 		} else {
 			errorMessage = ""No unique identifier was found for the provider"";
 		}
 		
 		if (provider == null) {
 			throw new HL7Exception(errorMessage);
 		}
 		
 		return provider;
 	}
\ No newline at end of file
","Follow up to ,Fixed the error messages to be more helpful when the provider can't be resolved - TRUNK-3108

git-svn-id: http://svn.openmrs.org/openmrs/trunk@26248 5bac5841-c719-aa4e-b3fe-cce5062f897a
",Buggy
openmrs-core,2762.json,dc4c547246dcf46aa2ff0dcb5e43caee7cd5f1d7,"@@ -1,38 +1,49 @@
 	private Provider getProvider(PV1 pv1) throws HL7Exception {
 		XCN hl7Provider = pv1.getAttendingDoctor(0);
 		Provider provider = null;
 		String id = hl7Provider.getIDNumber().getValue();
 		String assignAuth = hl7Provider.getAssigningAuthority().getUniversalID().getValue();
 		String type = hl7Provider.getAssigningAuthority().getUniversalIDType().getValue();
+		String errorMessage = """";
 		if (StringUtils.hasText(id)) {
+			String specificErrorMsg = """";
 			if (OpenmrsUtil.nullSafeEquals(""L"", type)) {
 				if (HL7Constants.PROVIDER_ASSIGNING_AUTH_PROV_ID.equalsIgnoreCase(assignAuth)) {
 					try {
 						provider = Context.getProviderService().getProvider(Integer.valueOf(id));
 					}
 					catch (NumberFormatException e) {
 						// ignore
 					}
+					specificErrorMsg = ""with provider Id"";
 				} else if (HL7Constants.PROVIDER_ASSIGNING_AUTH_IDENTIFIER.equalsIgnoreCase(assignAuth)) {
 					provider = Context.getProviderService().getProviderByIdentifier(id);
+					specificErrorMsg = ""with provider identifier:"" + id;
 				} else if (HL7Constants.PROVIDER_ASSIGNING_AUTH_PROV_UUID.equalsIgnoreCase(assignAuth)) {
 					provider = Context.getProviderService().getProviderByUuid(id);
+					specificErrorMsg = ""with provider uuid"";
 				}
 			} else {
 				try {
 					Person person = Context.getPersonService().getPerson(Integer.valueOf(id));
 					Collection<Provider> providers = Context.getProviderService().getProvidersByPerson(person);
 					if (!providers.isEmpty())
 						provider = providers.iterator().next();
 				}
 				catch (NumberFormatException e) {
 					// ignore
 				}
+				specificErrorMsg = ""associated to a person with person id"";
 			}
+			
+			errorMessage = ""Could not resolve provider "" + specificErrorMsg + "":"" + id;
+		} else {
+			errorMessage = ""No unique identifier was found for the provider"";
 		}
 		
-		if (provider == null)
-			throw new HL7Exception(""Could not resolve provider"");
+		if (provider == null) {
+			throw new HL7Exception(errorMessage);
+		}
 		
 		return provider;
 	}
\ No newline at end of file
","Improved the error messages to be more helpful when the provider can't be resolved - TRUNK-3108

git-svn-id: http://svn.openmrs.org/openmrs/trunk@26246 5bac5841-c719-aa4e-b3fe-cce5062f897a
",Buggy
openmrs-core,2762.json,7932358da8194ef18be1ce23e0b72b0c4f51a63a,"@@ -1,39 +1,39 @@
 	private Provider getProvider(PV1 pv1) throws HL7Exception {
 		XCN hl7Provider = pv1.getAttendingDoctor(0);
 		Provider provider = null;
 		String id = hl7Provider.getIDNumber().getValue();
 		String assignAuth = ((HD) hl7Provider.getComponent(8)).getNamespaceID().getValue();
 		String nameTypeCode = ((ID) hl7Provider.getComponent(9)).getValue();
 		
 		if (StringUtils.hasText(id)) {
 			if (OpenmrsUtil.nullSafeEquals(""L"", nameTypeCode)) {
 				if (HL7Constants.PROVIDER_ASSIGNING_AUTH_PROV_ID.equalsIgnoreCase(assignAuth)) {
 					try {
 						provider = Context.getProviderService().getProvider(Integer.valueOf(id));
 					}
 					catch (NumberFormatException e) {
 						// ignore
 					}
 				} else if (HL7Constants.PROVIDER_ASSIGNING_AUTH_IDENTIFIER.equalsIgnoreCase(assignAuth)) {
 					provider = Context.getProviderService().getProviderByIdentifier(id);
 				} else if (HL7Constants.PROVIDER_ASSIGNING_AUTH_PROV_UUID.equalsIgnoreCase(assignAuth)) {
 					provider = Context.getProviderService().getProviderByUuid(id);
 				}
 			} else {
 				try {
 					Person person = Context.getPersonService().getPerson(Integer.valueOf(id));
 					Collection<Provider> providers = Context.getProviderService().getProvidersByPerson(person);
 					if (!providers.isEmpty())
 						provider = providers.iterator().next();
 				}
 				catch (NumberFormatException e) {
 					// ignore
 				}
 			}
 		}
 		
 		if (provider == null)
-			throw new HL7Exception(""Could not resolve provider with personId or identifier as '"" + id + ""'"");
+			throw new HL7Exception(""Could not resolve provider"");
 		
 		return provider;
 	}
\ No newline at end of file
","Rephrased the error message when the provider can't be resolved when processing an HL7 message

git-svn-id: http://svn.openmrs.org/openmrs/trunk@26240 5bac5841-c719-aa4e-b3fe-cce5062f897a
",Buggy
openmrs-core,6970.json,6f7de13f5e4d0b9e4d8ea553bfd92842cd0c161a,"@@ -1,19 +1,24 @@
 	public FormResource saveFormResource(FormResource formResource) throws APIException {
-		if (formResource == null) {
+	    	if (formResource == null) {
 			return null;
 		}
-		
 		// If a form resource with same name exists, replace it with current value
 		FormResource toPersist = formResource;
 		FormResource original = Context.getFormService().getFormResource(formResource.getForm(), formResource.getName());
 		if (original != null) {
 			original.setName(formResource.getName());
 			original.setValue(formResource.getValue());
 			original.setDatatypeClassname(formResource.getDatatypeClassname());
 			original.setDatatypeConfig(formResource.getDatatypeConfig());
 			original.setPreferredHandlerClassname(formResource.getPreferredHandlerClassname());
 			toPersist = original;
 		}
-		CustomDatatypeUtil.saveIfDirty(toPersist);
+		try {
+		    CustomDatatypeUtil.saveIfDirty(toPersist);
+		}
+		catch (ConstraintViolationException ex) {
+		    throw new InvalidFileTypeException(ex.getMessage(), ex);
+		}
+		
 		return dao.saveFormResource(toPersist);
 	}
\ No newline at end of file
","TRUNK-4473: Fixed error occuring when user tries to upload binary files with form resource
",Buggy
openmrs-core,105.json,f2d3fdd76e95f7783e530e4c3e7b4f0b7d48a852,"@@ -1,9 +1,10 @@
 	public static String escapeQuotesAndNewlines(String s) {
 		if (s == null)
 			return """";
 		
 		s = s.replace(""\"""", ""\\\"""");
+		s = s.replace(""\r\n"", ""\\r\\n"");
 		s = s.replace(""\n"", ""\\n"");
 		
 		return s;
 	}
\ No newline at end of file
","Fixed javascript error on form schema designer when field descriptions had multiple lines - #594

git-svn-id: http://svn.openmrs.org/openmrs/trunk@11807 5bac5841-c719-aa4e-b3fe-cce5062f897a
",Buggy
hadoop,10762.json,d3949058b84c393413ffea11de5c81ab8ad2ae3c,"@@ -1,40 +1,40 @@
   void doRollback(StorageDirectory bpSd, NamespaceInfo nsInfo)
       throws IOException {
     File prevDir = bpSd.getPreviousDir();
     // regular startup if previous dir does not exist
     if (!prevDir.exists())
       return;
     // read attributes out of the VERSION file of previous directory
-    DataStorage prevInfo = new DataStorage();
+    BlockPoolSliceStorage prevInfo = new BlockPoolSliceStorage();
     prevInfo.readPreviousVersionProperties(bpSd);
 
     // We allow rollback to a state, which is either consistent with
     // the namespace state or can be further upgraded to it.
     // In another word, we can only roll back when ( storedLV >= software LV)
     // && ( DN.previousCTime <= NN.ctime)
     if (!(prevInfo.getLayoutVersion() >= HdfsConstants.LAYOUT_VERSION && 
         prevInfo.getCTime() <= nsInfo.getCTime())) { // cannot rollback
       throw new InconsistentFSStateException(bpSd.getRoot(),
           ""Cannot rollback to a newer state.\nDatanode previous state: LV = ""
               + prevInfo.getLayoutVersion() + "" CTime = "" + prevInfo.getCTime()
               + "" is newer than the namespace state: LV = ""
               + nsInfo.getLayoutVersion() + "" CTime = "" + nsInfo.getCTime());
     }
     
     LOG.info(""Rolling back storage directory "" + bpSd.getRoot()
         + "".\n   target LV = "" + nsInfo.getLayoutVersion()
         + ""; target CTime = "" + nsInfo.getCTime());
     File tmpDir = bpSd.getRemovedTmp();
     assert !tmpDir.exists() : ""removed.tmp directory must not exist."";
     // 1. rename current to tmp
     File curDir = bpSd.getCurrentDir();
     assert curDir.exists() : ""Current directory must exist."";
     rename(curDir, tmpDir);
     
     // 2. rename previous to current
     rename(prevDir, curDir);
     
     // 3. delete removed.tmp dir
     deleteDir(tmpDir);
     LOG.info(""Rollback of "" + bpSd.getRoot() + "" is complete"");
   }
\ No newline at end of file
","HDFS-3970. Fix bug causing rollback of HDFS upgrade to result in bad VERSION file. Contributed by Vinay and Andrew Wang.


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1430037 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
hadoop,78812.json,64f537da0a216055d5b6eae49a2a9129189cacbf,"@@ -1,18 +1,26 @@
-    public FileStatus[] globStatus(Path pathPattern, PathFilter filter)
+    public FileStatus[] globStatus(final Path pathPattern, final PathFilter filter)
       throws IOException {
+      
       String filename = pathPattern.toUri().getPath();
+      
       List<String> filePatterns = GlobExpander.expand(filename);
       if (filePatterns.size() == 1) {
-        return globStatusInternal(pathPattern, filter);
+        Path p = fixRelativePart(pathPattern);
+        FileSystem fs = getFSofPath(p);
+        URI uri = fs.getUri();
+        return globStatusInternal(uri, p, filter);
       } else {
         List<FileStatus> results = new ArrayList<FileStatus>();
         for (String filePattern : filePatterns) {
-          FileStatus[] files = 
-                      globStatusInternal(new Path(filePattern), filter);
+          Path p = new Path(filePattern);
+          p = fixRelativePart(p);
+          FileSystem fs = getFSofPath(p);
+          URI uri = fs.getUri();
+          FileStatus[] files = globStatusInternal(uri, p, filter);
           for (FileStatus file : files) {
             results.add(file);
           }
         }
         return results.toArray(new FileStatus[results.size()]);
       }
     }
\ No newline at end of file
","HADOOP-6286. Fix bugs in related to URI handling in glob methods in FileContext. Contributed by Boris Shkolnik.


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@822805 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
hadoop,37278.json,3a154f75ed85d864b3ffd35818992418f2b6aa59,"@@ -1,21 +1,25 @@
   public RLESparseResourceAllocation getRangeOverlapping(long start, long end) {
     readLock.lock();
     try {
       NavigableMap<Long, Resource> a = this.getCumulative();
 
       if (a != null && !a.isEmpty()) {
         // include the portion of previous entry that overlaps start
         if (start > a.firstKey()) {
           long previous = a.floorKey(start);
           a = a.tailMap(previous, true);
         }
-        a = a.headMap(end, true);
+
+        if (end < a.lastKey()) {
+          a = a.headMap(end, true);
+        }
+
       }
       RLESparseResourceAllocation ret =
           new RLESparseResourceAllocation(a, resourceCalculator);
       return ret;
     } finally {
       readLock.unlock();
     }
 
   }
\ No newline at end of file
","YARN-4525. Fix bug in RLESparseResourceAllocation.getRangeOverlapping(). (Ishai Menache and Carlo Curino via asuresh)
",Buggy
hadoop,3337.json,46cbce9af1272ce0eb6e300f96a1a8d4b08e23e3,"@@ -1,18 +1,18 @@
   private static LocatedBlock toLocatedBlock(final Map<?, ?> m) throws IOException {
     if (m == null) {
       return null;
     }
 
     final ExtendedBlock b = toExtendedBlock((Map<?, ?>)m.get(""block""));
     final DatanodeInfo[] locations = toDatanodeInfoArray(
         (Object[])m.get(""locations""));
     final long startOffset = (Long)m.get(""startOffset"");
     final boolean isCorrupt = (Boolean)m.get(""isCorrupt"");
     final DatanodeInfo[] cachedLocations = toDatanodeInfoArray(
         (Object[])m.get(""cachedLocations""));
 
     final LocatedBlock locatedblock = new LocatedBlock(b, locations,
-        startOffset, isCorrupt, cachedLocations);
+        null, null, startOffset, isCorrupt, cachedLocations);
     locatedblock.setBlockToken(toBlockToken((Map<?, ?>)m.get(""blockToken"")));
     return locatedblock;
   }
\ No newline at end of file
","HDFS-5508. Fix compilation error after merge. (Contributed by szetszwo)

git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/branches/HDFS-2832@1541352 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
hadoop,33132.json,c6ea28c480940d1f95cabe3af452dce197c6669d,"@@ -1,23 +1,24 @@
   public List<PrivilegedOperation> bootstrap(Configuration configuration)
       throws ResourceHandlerException {
     Set<Device> availableDevices = null;
     try {
       availableDevices = devicePlugin.getDevices();
     } catch (Exception e) {
       throw new ResourceHandlerException(""Exception thrown from""
           + "" plugin's \""getDevices\"""" + e.getMessage());
     }
     /**
      * We won't fail the NM if plugin returns invalid value here.
      * */
     if (availableDevices == null) {
       LOG.error(""Bootstrap "" + resourceName
           + "" failed. Null value got from plugin's getDevices method"");
       return null;
     }
     // Add device set. Here we trust the plugin's return value
     deviceMappingManager.addDeviceSet(resourceName, availableDevices);
-    // TODO: Init cgroups
-
+    // Init cgroups
+    this.cGroupsHandler.initializeCGroupController(
+        CGroupsHandler.CGroupController.DEVICES);
     return null;
   }
\ No newline at end of file
","YARN-9331. [YARN-8851] Fix a bug that lacking cgroup initialization when bootstrap DeviceResourceHandlerImpl. Contributed by Zhankun Tang.
",Buggy
hadoop,22809.json,b524501d4f4b48edeb02901114087f3b5f57691f,"@@ -1,3 +1,3 @@
     public URI[] getCacheFiles() throws IOException {
-      return reduceContext.getCacheArchives();
+      return reduceContext.getCacheFiles();
     }
\ No newline at end of file
","MAPREDUCE-5685. Fixed a bug with JobContext getCacheFiles API inside the WrappedReducer class. Contributed by Yi Song.


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1554320 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
hadoop,12133.json,68d5dfdc78d121e89eeae4e577d670028a14a955,"@@ -1,90 +1,90 @@
   void startDataNode(List<StorageLocation> dataDirectories,
                      SecureResources resources
                      ) throws IOException {
 
     // settings global for all BPs in the Data Node
     this.secureResources = resources;
     synchronized (this) {
       this.dataDirs = dataDirectories;
     }
     this.dnConf = new DNConf(this);
     checkSecureConfig(dnConf, getConf(), resources);
 
     if (dnConf.maxLockedMemory > 0) {
       if (!NativeIO.POSIX.getCacheManipulator().verifyCanMlock()) {
         throw new RuntimeException(String.format(
             ""Cannot start datanode because the configured max locked memory"" +
             "" size (%s) is greater than zero and native code is not available."",
             DFS_DATANODE_MAX_LOCKED_MEMORY_KEY));
       }
       if (Path.WINDOWS) {
         NativeIO.Windows.extendWorkingSetSize(dnConf.maxLockedMemory);
       } else {
         long ulimit = NativeIO.POSIX.getCacheManipulator().getMemlockLimit();
         if (dnConf.maxLockedMemory > ulimit) {
           throw new RuntimeException(String.format(
             ""Cannot start datanode because the configured max locked memory"" +
             "" size (%s) of %d bytes is more than the datanode's available"" +
             "" RLIMIT_MEMLOCK ulimit of %d bytes."",
             DFS_DATANODE_MAX_LOCKED_MEMORY_KEY,
             dnConf.maxLockedMemory,
             ulimit));
         }
       }
     }
     LOG.info(""Starting DataNode with maxLockedMemory = {}"",
         dnConf.maxLockedMemory);
 
     int volFailuresTolerated = dnConf.getVolFailuresTolerated();
     int volsConfigured = dnConf.getVolsConfigured();
     if (volFailuresTolerated < MAX_VOLUME_FAILURE_TOLERATED_LIMIT
         || volFailuresTolerated >= volsConfigured) {
       throw new DiskErrorException(""Invalid value configured for ""
           + ""dfs.datanode.failed.volumes.tolerated - "" + volFailuresTolerated
-          + "". Value configured is either greater than -1 or >= ""
+          + "". Value configured is either less than -1 or >= ""
           + ""to the number of configured volumes ("" + volsConfigured + "")."");
     }
 
     storage = new DataStorage();
     
     // global DN settings
     registerMXBean();
     initDataXceiver();
     startInfoServer();
     pauseMonitor = new JvmPauseMonitor();
     pauseMonitor.init(getConf());
     pauseMonitor.start();
   
     // BlockPoolTokenSecretManager is required to create ipc server.
     this.blockPoolTokenSecretManager = new BlockPoolTokenSecretManager();
 
     // Login is done by now. Set the DN user name.
     dnUserName = UserGroupInformation.getCurrentUser().getUserName();
     LOG.info(""dnUserName = {}"", dnUserName);
     LOG.info(""supergroup = {}"", supergroup);
     initIpcServer();
 
     metrics = DataNodeMetrics.create(getConf(), getDisplayName());
     peerMetrics = dnConf.peerStatsEnabled ?
         DataNodePeerMetrics.create(getDisplayName()) : null;
     metrics.getJvmMetrics().setPauseMonitor(pauseMonitor);
 
     ecWorker = new ErasureCodingWorker(getConf(), this);
     blockRecoveryWorker = new BlockRecoveryWorker(this);
 
     blockPoolManager = new BlockPoolManager(this);
     blockPoolManager.refreshNamenodes(getConf());
 
     // Create the ReadaheadPool from the DataNode context so we can
     // exit without having to explicitly shutdown its thread pool.
     readaheadPool = ReadaheadPool.getInstance();
     saslClient = new SaslDataTransferClient(dnConf.getConf(),
         dnConf.saslPropsResolver, dnConf.trustedChannelResolver);
     saslServer = new SaslDataTransferServer(dnConf, blockPoolTokenSecretManager);
     startMetricsLogger();
 
     if (dnConf.diskStatsEnabled) {
       diskMetrics = new DataNodeDiskMetrics(this,
           dnConf.outliersReportIntervalMs);
     }
   }
\ No newline at end of file
","HDFS-14056. Fix error messages in HDFS-12716. Contributed by Ayush Saxena.
",Buggy
hadoop,33173.json,a457a8951a1b35f06811c40443ca44bb9c698c30,"@@ -1,46 +1,48 @@
   public boolean initPlugin(Configuration conf) {
     this.aliasMap = new HashMap<>();
     if (this.initialized) {
       return true;
     }
     // Find the proper toolchain, mainly aocl
     String pluginDefaultBinaryName = getDefaultBinaryName();
     String pathToExecutable = conf.get(YarnConfiguration.NM_FPGA_PATH_TO_EXEC,
         """");
     if (pathToExecutable.isEmpty()) {
       pathToExecutable = pluginDefaultBinaryName;
     }
     // Validate file existence
     File binaryPath = new File(pathToExecutable);
     if (!binaryPath.exists()) {
       // When binary not exist, fail
       LOG.warn(""Failed to find FPGA discoverer executable configured in "" +
           YarnConfiguration.NM_FPGA_PATH_TO_EXEC +
           "", please check! Try default path"");
       pathToExecutable = pluginDefaultBinaryName;
       // Try to find in plugin's preferred path
       String pluginDefaultPreferredPath = getDefaultPathToExecutable();
       if (null == pluginDefaultPreferredPath) {
         LOG.warn(""Failed to find FPGA discoverer executable from system environment "" +
             getDefaultPathEnvName()+
             "", please check your environment!"");
       } else {
         binaryPath = new File(pluginDefaultPreferredPath + ""/bin"", pluginDefaultBinaryName);
         if (binaryPath.exists()) {
-          pathToExecutable = pluginDefaultPreferredPath;
+          pathToExecutable = binaryPath.getAbsolutePath();
+          LOG.info(""Succeed in finding FPGA discoverer executable: "" +
+              pathToExecutable);
         } else {
           pathToExecutable = pluginDefaultBinaryName;
           LOG.warn(""Failed to find FPGA discoverer executable in "" +
               pluginDefaultPreferredPath + "", file doesn't exists! Use default binary"" + pathToExecutable);
         }
       }
     }
     setPathToExecutable(pathToExecutable);
     if (!diagnose(10*1000)) {
       LOG.warn(""Intel FPGA for OpenCL diagnose failed!"");
       this.initialized = false;
     } else {
       this.initialized = true;
     }
     return this.initialized;
   }
\ No newline at end of file
","YARN-8456. Fix a configuration handling bug when user leave FPGA discover executable path configuration default but set OpenCL SDK path environment variable. (Zhankun Tang via wangda)

Change-Id: Iff150ea98ba0c60d448474fd940eb121afce6965
",Buggy
hadoop,16528.json,c3ca348b81bdf6aa0857a1d4d140c6c9d64be490,"@@ -1,29 +1,29 @@
   public void checkSuperuserPrivilege() throws  AccessControlException {
 
     // Try to get the ugi in the RPC call.
     UserGroupInformation ugi = null;
     try {
       ugi = NameNode.getRemoteUser();
     } catch (IOException e) {
       // Ignore as we catch it afterwards
     }
     if (ugi == null) {
       LOG.error(""Cannot get the remote user name"");
       throw new AccessControlException(""Cannot get the remote user name"");
     }
 
     // Is this by the Router user itself?
-    if (ugi.getUserName().equals(superUser)) {
+    if (ugi.getShortUserName().equals(superUser)) {
       return;
     }
 
     // Is the user a member of the super group?
     List<String> groups = Arrays.asList(ugi.getGroupNames());
     if (groups.contains(superGroup)) {
       return;
     }
 
     // Not a superuser
     throw new AccessControlException(
         ugi.getUserName() + "" is not a super user"");
   }
\ No newline at end of file
","HDFS-14620. RBF: Fix 'not a super user' error when disabling a namespace in kerberos with superuser principal. Contributed by luhuachao.
",Buggy
hadoop,75002.json,c8abf5f20a7ca802e3e7c93c8c5d260902cb4052,"@@ -1,37 +1,44 @@
-  private int init(String[] args) throws IOException {
+  protected int init(String[] args) throws IOException {
+    // no args should print the help message
+    if (0 == args.length) {
+      printCredShellUsage();
+      ToolRunner.printGenericCommandUsage(System.err);
+      return 1;
+    }
+
     for (int i = 0; i < args.length; i++) { // parse command line
       if (args[i].equals(""create"")) {
         String alias = args[++i];
         command = new CreateCommand(alias);
         if (alias.equals(""-help"")) {
           printCredShellUsage();
-          return -1;
+          return 0;
         }
       } else if (args[i].equals(""delete"")) {
         String alias = args[++i];
         command = new DeleteCommand(alias);
         if (alias.equals(""-help"")) {
           printCredShellUsage();
-          return -1;
+          return 0;
         }
       } else if (args[i].equals(""list"")) {
         command = new ListCommand();
       } else if (args[i].equals(""-provider"")) {
         userSuppliedProvider = true;
         getConf().set(CredentialProviderFactory.CREDENTIAL_PROVIDER_PATH, 
             args[++i]);
       } else if (args[i].equals(""-i"") || (args[i].equals(""-interactive""))) {
         interactive = true;
       } else if (args[i].equals(""-v"") || (args[i].equals(""-value""))) {
         value = args[++i];
       } else if (args[i].equals(""-help"")) {
         printCredShellUsage();
-        return -1;
+        return 0;
       } else {
         printCredShellUsage();
         ToolRunner.printGenericCommandUsage(System.err);
-        return -1;
+        return 1;
       }
     }
     return 0;
   }
\ No newline at end of file
","HADOOP-10927. Fix CredentialShell help behavior and error codes. Contributed by Josh Elser.

git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1615827 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
hadoop,22351.json,1d915238a6a06d09e1789532994f00f496bd969c,"@@ -1,3 +1,3 @@
     public URI[] getCacheFiles() throws IOException {
-      return mapContext.getCacheArchives();
+      return mapContext.getCacheFiles();
     }
\ No newline at end of file
","MAPREDUCE-5385. Fixed a bug with JobContext getCacheFiles API. Contributed by Omkar Vinit Joshi.


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1508595 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
hadoop,8777.json,3b5ea8750202ad9ed0e297d92a90d6dc772ce12a,"@@ -1,45 +1,45 @@
   FSImageStorageInspector readAndInspectDirs()
       throws IOException {
     Integer layoutVersion = null;
     boolean multipleLV = false;
     StringBuilder layoutVersions = new StringBuilder();
 
     // First determine what range of layout versions we're going to inspect
     for (Iterator<StorageDirectory> it = dirIterator();
          it.hasNext();) {
       StorageDirectory sd = it.next();
       if (!sd.getVersionFile().exists()) {
         FSImage.LOG.warn(""Storage directory "" + sd + "" contains no VERSION file. Skipping..."");
         continue;
       }
       readProperties(sd); // sets layoutVersion
       int lv = getLayoutVersion();
       if (layoutVersion == null) {
         layoutVersion = Integer.valueOf(lv);
       } else if (!layoutVersion.equals(lv)) {
         multipleLV = true;
       }
       layoutVersions.append(""("").append(sd.getRoot()).append("", "").append(lv).append("") "");
     }
     
     if (layoutVersion == null) {
       throw new IOException(""No storage directories contained VERSION information"");
     }
     if (multipleLV) {            
       throw new IOException(
-          ""Storage directories containe multiple layout versions: ""
+          ""Storage directories contain multiple layout versions: ""
               + layoutVersions);
     }
     // If the storage directories are with the new layout version
     // (ie edits_<txnid>) then use the new inspector, which will ignore
     // the old format dirs.
     FSImageStorageInspector inspector;
     if (LayoutVersion.supports(Feature.TXID_BASED_LAYOUT, getLayoutVersion())) {
       inspector = new FSImageTransactionalStorageInspector();
     } else {
       inspector = new FSImagePreTransactionalStorageInspector();
     }
     
     inspectStorageDirs(inspector);
     return inspector;
   }
\ No newline at end of file
","HDFS-3629. Fix the typo in the error message about inconsistent storage layout version. Contributed by Brandon Li. (harsh)


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1359905 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
hadoop,35650.json,c4d7bbda5cb3ceaf54a022f3cf97109e8e190d71,"@@ -1,8 +1,8 @@
-  protected void serviceStart() throws Exception {
-    super.serviceStart();
+  protected void serviceInit(Configuration conf) throws Exception {
+    super.serviceInit(conf);
+    getDispatcher().register(SystemMetricsEventType.class,
+        new TimelineV2EventHandler());
     publishContainerMetrics = getConfig().getBoolean(
         YarnConfiguration.RM_PUBLISH_CONTAINER_METRICS_ENABLED,
         YarnConfiguration.DEFAULT_RM_PUBLISH_CONTAINER_METRICS_ENABLED);
-    getDispatcher().register(SystemMetricsEventType.class,
-        new TimelineV2EventHandler());
   }
\ No newline at end of file
","YARN-4460. [Bug fix] RM fails to start when SMP is enabled. (Li Lu via Varun Saxena)
",Buggy
hadoop,34713.json,3d00c8f3942da931150de79f42cd4913bf751123,"@@ -1,3 +1,3 @@
   public Service[] getServices() {
-    return nodeManagerServices;
+    return NODE_MANAGER_SERVICES;
   }
\ No newline at end of file
","Made fixes for whitespace errors and checstyle warnings before merge.
",Buggy
hadoop,71639.json,9591765040b85927ac69179ab46383eef9560a28,"@@ -1,25 +1,44 @@
   private byte remoteLookup(Message response, Name name, int type,
       int iterations) {
+    // If retrieving the root zone, query for NS record type
+    if (name.toString().equals(""."")) {
+      type = Type.NS;
+    }
+
+    // Always add any CNAMEs to the response first
+    if (type != Type.CNAME) {
+      Record[] cnameAnswers = getRecords(name, Type.CNAME);
+      if (cnameAnswers != null) {
+        for (Record cnameR : cnameAnswers) {
+          if (!response.findRecord(cnameR)) {
+            response.addRecord(cnameR, Section.ANSWER);
+          }
+        }
+      }
+    }
+
     // Forward lookup to primary DNS servers
     Record[] answers = getRecords(name, type);
     try {
       for (Record r : answers) {
-        if (r.getType() == Type.SOA) {
-          response.addRecord(r, Section.AUTHORITY);
-        } else {
-          response.addRecord(r, Section.ANSWER);
+        if (!response.findRecord(r)) {
+          if (r.getType() == Type.SOA) {
+            response.addRecord(r, Section.AUTHORITY);
+          } else {
+            response.addRecord(r, Section.ANSWER);
+          }
         }
         if (r.getType() == Type.CNAME) {
           Name cname = ((CNAMERecord) r).getAlias();
           if (iterations < 6) {
-            remoteLookup(response, cname, Type.CNAME, iterations + 1);
+            remoteLookup(response, cname, type, iterations + 1);
           }
         }
       }
     } catch (NullPointerException e) {
       return Rcode.NXDOMAIN;
     } catch (Throwable e) {
       return Rcode.SERVFAIL;
     }
     return Rcode.NOERROR;
   }
\ No newline at end of file
","YARN-8410.  Fixed a bug in A record lookup by CNAME record.
            Contributed by Shane Kumpf
",Buggy
hadoop,4984.json,076ecf79ca38cbb908f54ea58d985d24486ceefc,"@@ -1,4 +1,4 @@
   public String toString() {
-    return getClass().getSimpleName() + "": "" + snapshotId + "" (post=""
-        + (posteriorDiff == null? null: posteriorDiff.snapshotId) + "")"";
+    return getClass().getSimpleName() + "": "" + this.getSnapshotId() + "" (post=""
+        + (posteriorDiff == null? null: posteriorDiff.getSnapshotId()) + "")"";
   }
\ No newline at end of file
","HDFS-5726. Fix compilation error in AbstractINodeDiff for JDK7. Contributed by Jing Zhao.

git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1556433 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
hadoop,43166.json,23f394240e1568a38025e63e9dc0842e8c5235f7,"@@ -1,61 +1,61 @@
   public int initiateUpgrade(Service service) throws YarnException,
       IOException {
     boolean upgradeEnabled = getConfig().getBoolean(
         YARN_SERVICE_UPGRADE_ENABLED,
         YARN_SERVICE_UPGRADE_ENABLED_DEFAULT);
     if (!upgradeEnabled) {
       throw new YarnException(ErrorStrings.SERVICE_UPGRADE_DISABLED);
     }
     Service persistedService =
         ServiceApiUtil.loadService(fs, service.getName());
     if (!StringUtils.isEmpty(persistedService.getId())) {
       cachedAppInfo.put(persistedService.getName(), new AppInfo(
           ApplicationId.fromString(persistedService.getId()),
           persistedService.getKerberosPrincipal().getPrincipalName()));
     }
 
     if (persistedService.getVersion().equals(service.getVersion())) {
       String message =
           service.getName() + "" is already at version "" + service.getVersion()
               + "". There is nothing to upgrade."";
       LOG.error(message);
       throw new YarnException(message);
     }
 
     Service liveService = getStatus(service.getName());
     if (!liveService.getState().equals(ServiceState.STABLE)) {
       String message = service.getName() + "" is at "" +
           liveService.getState()
-          + "" state, upgrade can not be invoked when service is STABLE."";
+          + "" state and upgrade can only be initiated when service is STABLE."";
       LOG.error(message);
       throw new YarnException(message);
     }
 
     Path serviceUpgradeDir = checkAppNotExistOnHdfs(service, true);
     ServiceApiUtil.validateAndResolveService(service, fs, getConfig());
     ServiceApiUtil.createDirAndPersistApp(fs, serviceUpgradeDir, service);
 
     ApplicationReport appReport =
         yarnClient.getApplicationReport(getAppId(service.getName()));
     if (StringUtils.isEmpty(appReport.getHost())) {
       throw new YarnException(service.getName() + "" AM hostname is empty"");
     }
     ClientAMProtocol proxy = createAMProxy(service.getName(), appReport);
 
     UpgradeServiceRequestProto.Builder requestBuilder =
         UpgradeServiceRequestProto.newBuilder();
     requestBuilder.setVersion(service.getVersion());
     if (service.getState().equals(ServiceState.UPGRADING_AUTO_FINALIZE)) {
       requestBuilder.setAutoFinalize(true);
     }
     UpgradeServiceResponseProto responseProto = proxy.upgrade(
         requestBuilder.build());
     if (responseProto.hasError()) {
       LOG.error(""Service {} upgrade to version {} failed because {}"",
           service.getName(), service.getVersion(), responseProto.getError());
       throw new YarnException(""Failed to upgrade service "" + service.getName()
           + "" to version "" + service.getVersion() + "" because "" +
           responseProto.getError());
     }
     return EXIT_SUCCESS;
   }
\ No newline at end of file
","YARN-8610.  Fixed initiate upgrade error message.
            Contributed by Chandni Singh
",Buggy
hadoop,81000.json,1ddb48872f6a4985f4d0baadbb183899226cff68,"@@ -1,9 +1,9 @@
   public long getTimeDuration(String name, long defaultValue,
       TimeUnit defaultUnit, TimeUnit returnUnit) {
     String vStr = get(name);
     if (null == vStr) {
-      return defaultValue;
+      return returnUnit.convert(defaultValue, defaultUnit);
     } else {
       return getTimeDurationHelper(name, vStr, defaultUnit, returnUnit);
     }
   }
\ No newline at end of file
","HADOOP-16265. Fix bug causing Configuration#getTimeDuration to use incorrect units when the default value is used. Contributed by starphin.
",Buggy
hadoop,10220.json,3335e502446b1542fc99c0c831e0542e53eac6f1,"@@ -1,11 +1,11 @@
-  void shutDownAll() throws InterruptedException {
-    BPOfferService[] bposArray = this.getAllNamenodeThreads();
-    
-    for (BPOfferService bpos : bposArray) {
-      bpos.stop(); //interrupts the threads
-    }
-    //now join
-    for (BPOfferService bpos : bposArray) {
-      bpos.join();
+  void shutDownAll(BPOfferService[] bposArray) throws InterruptedException {
+    if (bposArray != null) {
+      for (BPOfferService bpos : bposArray) {
+        bpos.stop(); //interrupts the threads
+      }
+      //now join
+      for (BPOfferService bpos : bposArray) {
+        bpos.join();
+      }
     }
   }
\ No newline at end of file
","HDFS-3616. Fix a ConcurrentModificationException bug that BP actor threads may not be shutdown properly in DataNode.  Contributed by Jing Zhao 


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1402608 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
hadoop,26655.json,977d7cc5b947682478ad7b38bd442f0efa1cd204,"@@ -1,45 +1,38 @@
     protected void setup(JobImpl job) throws IOException {
 
       String oldJobIDString = job.oldJobId.toString();
       String user = 
         UserGroupInformation.getCurrentUser().getShortUserName();
       Path path = MRApps.getStagingAreaDir(job.conf, user);
       if(LOG.isDebugEnabled()) {
         LOG.debug(""startJobs: parent="" + path + "" child="" + oldJobIDString);
       }
 
       job.remoteJobSubmitDir =
           FileSystem.get(job.conf).makeQualified(
               new Path(path, oldJobIDString));
       job.remoteJobConfFile =
           new Path(job.remoteJobSubmitDir, MRJobConfig.JOB_CONF_FILE);
 
       // Prepare the TaskAttemptListener server for authentication of Containers
       // TaskAttemptListener gets the information via jobTokenSecretManager.
       JobTokenIdentifier identifier =
           new JobTokenIdentifier(new Text(oldJobIDString));
       job.jobToken =
           new Token<JobTokenIdentifier>(identifier, job.jobTokenSecretManager);
       job.jobToken.setService(identifier.getJobId());
       // Add it to the jobTokenSecretManager so that TaskAttemptListener server
       // can authenticate containers(tasks)
       job.jobTokenSecretManager.addTokenForJob(oldJobIDString, job.jobToken);
       LOG.info(""Adding job token for "" + oldJobIDString
           + "" to jobTokenSecretManager"");
 
       // Upload the jobTokens onto the remote FS so that ContainerManager can
       // localize it to be used by the Containers(tasks)
       Credentials tokenStorage = new Credentials();
       TokenCache.setJobToken(job.jobToken, tokenStorage);
 
       if (UserGroupInformation.isSecurityEnabled()) {
         tokenStorage.addAll(job.fsTokens);
       }
-
-      Path remoteJobTokenFile =
-          new Path(job.remoteJobSubmitDir,
-              MRJobConfig.APPLICATION_TOKENS_FILE);
-      tokenStorage.writeTokenStorageFile(remoteJobTokenFile, job.conf);
-      LOG.info(""Writing back the job-token file on the remote file system:""
-          + remoteJobTokenFile.toString());
     }
\ No newline at end of file
","MAPREDUCE-3233. Fixed a bug in MR Job so as to be able to restart the application on AM crash. Contributed by Mahadev Konar.


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1187669 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
hadoop,10300.json,eb7fe1d588de903be2ff6e20384c25c184881532,"@@ -1,24 +1,26 @@
   private void breakHardlinks(File file, Block b) throws IOException {
     final FileIoProvider fileIoProvider = getFileIoProvider();
     final File tmpFile = DatanodeUtil.createFileWithExistsCheck(
         getVolume(), b, DatanodeUtil.getUnlinkTmpFile(file), fileIoProvider);
-    try (FileInputStream in = fileIoProvider.getFileInputStream(
-        getVolume(), file)) {
-      try (FileOutputStream out = fileIoProvider.getFileOutputStream(
-          getVolume(), tmpFile)) {
-        IOUtils.copyBytes(in, out, 16 * 1024);
+    try {
+      try (FileInputStream in = fileIoProvider.getFileInputStream(
+          getVolume(), file)) {
+        try (FileOutputStream out = fileIoProvider.getFileOutputStream(
+            getVolume(), tmpFile)) {
+          IOUtils.copyBytes(in, out, 16 * 1024);
+        }
       }
       if (file.length() != tmpFile.length()) {
-        throw new IOException(""Copy of file "" + file + "" size "" + file.length()+
-                              "" into file "" + tmpFile +
-                              "" resulted in a size of "" + tmpFile.length());
+        throw new IOException(""Copy of file "" + file + "" size "" + file.length()
+            + "" into file "" + tmpFile + "" resulted in a size of ""
+            + tmpFile.length());
       }
       fileIoProvider.replaceFile(getVolume(), tmpFile, file);
     } catch (IOException e) {
       if (!fileIoProvider.delete(getVolume(), tmpFile)) {
         DataNode.LOG.info(""detachFile failed to delete temporary file "" +
                           tmpFile);
       }
       throw e;
     }
   }
\ No newline at end of file
","HDFS-13509. Bug fix for breakHardlinks() of ReplicaInfo/LocalReplica, and fix TestFileAppend failures on Windows. Contributed by Xiao Liang.
",Buggy
hadoop,62895.json,2e61ed306f1d525096a800f28546601ef585a832,"@@ -1,14 +1,14 @@
   public boolean equals(Object obj) {
     if (this == obj)
       return true;
-    if (!super.equals(obj))
+    if (obj == null)
       return false;
     if (getClass() != obj.getClass())
       return false;
     NodeId other = (NodeId) obj;
     if (!this.getHost().equals(other.getHost()))
       return false;
     if (this.getPort() != other.getPort())
       return false;
     return true;
   }
\ No newline at end of file
","MAPREDUCE-3030. Fixed a bug in NodeId.equals() that was causing RM to reject all NMs. Contributed by Devaraj K.


git-svn-id: https://svn.apache.org/repos/asf/hadoop/common/trunk@1172638 13f79535-47bb-0310-9956-ffa450edef68
",Buggy
facebook-android-sdk,2616.json,e3a111ea10f0646633777dd8cf5ed06838bf2a62,"@@ -1,13 +1,14 @@
     static float[] maxPool1D(float[] x, int rows, int cols, int pool_size) {
         int len = rows - pool_size + 1;
         float[] res = new float[len * cols];
 
         for (int c = 0; c < cols; c++) {
             for (int i = 0; i < len; i++) {
-                for (int r = i; r < i + pool_size; r++) {
+                res[i * cols + c] = x[i * cols + c];
+                for (int r = i + 1; r < i + pool_size; r++) {
                     res[i * cols + c] = Math.max(res[i * cols + c], x[r * cols + c]);
                 }
             }
         }
         return res;
     }
\ No newline at end of file
","Fix the bug of MaxPool1D

Summary:
Previously, for code:
```
for (int r = i; r < i + pool_size; r++) {
    res[i * cols + c] = Math.max(res[i * cols + c], x[r * cols + c]);
```
will get 0 if all the number in x is smaller than 0, which would make the prediction not accurate if there is no relu() after maxpooling.

Reviewed By: ninanina0815

Differential Revision: D20881716

fbshipit-source-id: a8a50f1fb584a35780683377a10548f19ab4fede
",Buggy
facebook-android-sdk,2859.json,6b275f68c69db30100c542919db3325837938c25,"@@ -1,5 +1,6 @@
     public void onReceive(Context context, Intent intent) {
-        if (AccessTokenManager.ACTION_CURRENT_ACCESS_TOKEN_CHANGED.equals(intent.getAction())) {
+        if (AccessTokenManager.ACTION_CURRENT_ACCESS_TOKEN_CHANGED.equals(intent.getAction())
+                && FacebookSdk.isInitialized()) {
             AccessTokenManager.getInstance().currentAccessTokenChanged();
         }
     }
\ No newline at end of file
","Fixes bug with SDK Initialize on broadcast

Summary: [android sdk] Fixes bug with SDK Initialize on broadcast

Reviewed By: ct2mak

Differential Revision: D15450566

fbshipit-source-id: 7ec5a7f8f55a658959a5ac7143bd8577c57a2a74
",Buggy
facebook-android-sdk,1309.json,39a0d134e7f137fc0b7d727eb0d0f229d43f1db0,"@@ -1,20 +1,20 @@
     private String getChromePackage() {
         if (currentPackage != null) {
             return currentPackage;
         }
         Context context = loginClient.getActivity();
-        Intent serviceIntent = new Intent(CUSTOM_TABS_SERVICE_ACTION);
+        Intent serviceIntent = new Intent(CustomTabsService.ACTION_CUSTOM_TABS_CONNECTION);
         List<ResolveInfo> resolveInfos =
                 context.getPackageManager().queryIntentServices(serviceIntent, 0);
         if (resolveInfos != null) {
             Set<String> chromePackages = new HashSet<>(Arrays.asList(CHROME_PACKAGES));
             for (ResolveInfo resolveInfo : resolveInfos) {
                 ServiceInfo serviceInfo = resolveInfo.serviceInfo;
                 if (serviceInfo != null && chromePackages.contains(serviceInfo.packageName)) {
                     currentPackage = serviceInfo.packageName;
                     return currentPackage;
                 }
             }
         }
         return null;
     }
\ No newline at end of file
","AndroidX Custom Tab Issue Fix (#670)

Summary:
Thanks for proposing a pull request!

To help us review the request, please complete the following:

- [ ] sign [contributor license agreement](https://developers.facebook.com/opensource/cla)
- [ ] I've ensured that all existing tests pass and added tests (when/where necessary)
- [ ] I've updated the documentation (when/where necessary) and [Changelog](CHANGELOG.md) (when/where necessary)
- [ ] I've added the proper label to this pull request (e.g. `bug` for bug fixes)

## Pull Request Details
Custom Tab has to be working for AndroidX enabled projects

## Expected Results
What do you expect to happen?
If the Facebook app is not installed, then on click of the Facebook login button in App, Custom Chrome Tab has to be open.

## Actual Results
What actually happened? Can you provide a stack trace?
If the Facebook app is not installed, then on click of Facebook login button in App, by default WebView is opening instead of Custom Chrome Tab even I have enabled the Custom Tab for my project.

## Steps to Reproduce
What are the steps necessary to reproduce this issue?
Integrate Facebook Login Button in App
Uninstall Facebook App from the Device
Make sure your project is migrated to AndroidX.
Click on the ""Login With Facebook"" button, WebView is opening instead of Custom Chrome Tab

Please merge the Pull Requests, so that we can use the Custom Chrome Tab in Facebook SDK for AndroidX Projects
Pull Request resolved: https://github.com/facebook/facebook-android-sdk/pull/670

Test Plan:
Built Hackbook with Gradle and buck and chrome custom tabs works for both
Buck: buck install hb4a. This uses Android X and is not working without this fix
Gradle: On Android studio

Went to Login > Login with custom tab to test the feature

Reviewed By: Mxiim

Differential Revision: D19603133

Pulled By: ct2mak

fbshipit-source-id: 44d2f463d2fbd3a50646dc8caf3e4f7cb02c026b
",Buggy
facebook-android-sdk,2911.json,4c16e0ff5234b07ad26111a74cade26f1fecfcb0,"@@ -1,78 +1,80 @@
     public static void setAppEventExtendedDeviceInfoParameters(
             JSONObject params,
             Context appContext
     ) throws JSONException {
         JSONArray extraInfoArray = new JSONArray();
         extraInfoArray.put(EXTRA_APP_EVENTS_INFO_FORMAT_VERSION);
 
         Utility.refreshPeriodicExtendedDeviceInfo(appContext);
 
         // Application Manifest info:
         String pkgName = appContext.getPackageName();
         int versionCode = -1;
         String versionName = """";
 
         try {
             PackageInfo pi = appContext.getPackageManager().getPackageInfo(pkgName, 0);
             versionCode = pi.versionCode;
             versionName = pi.versionName;
         } catch (PackageManager.NameNotFoundException e) {
             // Swallow
         }
 
         // Application Manifest info:
         extraInfoArray.put(pkgName);
         extraInfoArray.put(versionCode);
         extraInfoArray.put(versionName);
 
         // OS/Device info
         extraInfoArray.put(Build.VERSION.RELEASE);
         extraInfoArray.put(Build.MODEL);
 
         // Locale
         Locale locale;
         try {
             locale = appContext.getResources().getConfiguration().locale;
         } catch (Exception e) {
             locale = Locale.getDefault();
         }
         extraInfoArray.put(locale.getLanguage() + ""_"" + locale.getCountry());
 
         // Time zone
         extraInfoArray.put(deviceTimezoneAbbreviation);
 
         // Carrier
         extraInfoArray.put(carrierName);
 
         // Screen dimensions
         int width = 0;
         int height = 0;
         double density = 0;
         try {
             WindowManager wm = (WindowManager) appContext.getSystemService(Context.WINDOW_SERVICE);
             if (wm != null) {
                 Display display = wm.getDefaultDisplay();
                 DisplayMetrics displayMetrics = new DisplayMetrics();
                 display.getMetrics(displayMetrics);
                 width = displayMetrics.widthPixels;
                 height = displayMetrics.heightPixels;
                 density = displayMetrics.density;
             }
         } catch (Exception e) {
             // Swallow
         }
         extraInfoArray.put(width);
         extraInfoArray.put(height);
-        extraInfoArray.put(String.format(""%.2f"", density));
+
+        final DecimalFormat df = new DecimalFormat(""#.##"");
+        extraInfoArray.put(df.format(density));
 
         // CPU Cores
         extraInfoArray.put(refreshBestGuessNumberOfCPUCores());
 
         // External Storage
         extraInfoArray.put(totalExternalStorageGB);
         extraInfoArray.put(availableExternalStorageGB);
 
         extraInfoArray.put(deviceTimeZoneName);
 
         params.put(""extinfo"", extraInfoArray.toString());
     }
\ No newline at end of file
","Resolve Issue with String Format

Summary:
Should fix a problem where `String.format` crashes with:

```
Fatal Exception: java.lang.NullPointerException
Attempt to get length of null array
```

For more context, view the [bug report](https://developers.internmc.facebook.com/bugs/406495719925086/)

Reviewed By: KylinChang

Differential Revision: D14219986

fbshipit-source-id: 7d2a4ec0720deb48661fabcbcb39d861ff5b70a7
",Buggy
facebook-android-sdk,3863.json,1583b645976fdcdbe41d34020b13fb6939c5bf8a,"@@ -1,5 +1,5 @@
     public final String getAccessToken() {
         synchronized (this.lock) {
-            return this.tokenInfo.getToken();
+            return (this.tokenInfo == null) ? null : this.tokenInfo.getToken();
         }
     }
\ No newline at end of file
","[android-sdk] Don't add access_token parameters from a closed Session.

Summary:
Request would try to append an access_token if it could get one from a supplied Session, even if the Session
was closed. This is incorrect; it should act as if no Session was provided and let the server return an error if
appropriate.

Test Plan:
- Modified HelloFacebook to always enable the ""Pick Some Friends"" button
- Logged in
- Picked friends
- Logged out
- Picked friends, observed an error message indicating no access token was provided, as expected
- Added unit tests (and fixed one broken one), verified they ran

Revert Plan:

Reviewers: mmarucheck, mingfli, karthiks, gregschechte

Reviewed By: mmarucheck

Differential Revision: https://phabricator.fb.com/D616959

Task ID: 1852996
",Buggy
titan,920.json,74166f9174459bcbd8b7b8d7812d6b14c90faba5,"@@ -1,15 +1,34 @@
-    public void unlock(KeyColumn kc, ConsistentKeyLockTransaction requestor) {
+    public boolean unlock(KeyColumn kc, ConsistentKeyLockTransaction requestor) {
 
-        assert locks.containsKey(kc);
-
-        AuditRecord audit = new AuditRecord(requestor, 0);
-
-        assert locks.get(kc).equals(audit);
-
-        locks.remove(kc, audit);
-
-        if (log.isTraceEnabled()) {
-            log.trace(""Local unlock succeeded: {} namespace={} txn={}"",
-                    new Object[]{kc, name, requestor});
+        if (!locks.containsKey(kc)) {
+            log.error(""Local unlock failed: no locks found for {}"", kc);
+            return false;
         }
+
+        AuditRecord unlocker = new AuditRecord(requestor, 0);
+
+        AuditRecord holder = locks.get(kc);
+
+        if (!holder.equals(unlocker)) {
+            log.error(""Local unlock of {} by {} failed: it is held by {}"",
+                    new Object[] { kc, unlocker, holder });
+            return false;
+        }
+
+        boolean removed = locks.remove(kc, unlocker);
+
+        if (removed) {
+            if (log.isTraceEnabled()) {
+                log.trace(""Local unlock succeeded: {} namespace={} txn={}"",
+                        new Object[] { kc, name, requestor });
+            }
+        } else {
+            log.warn(""Local unlock warning: lock record for {} disappeared ""
+                    + ""during removal; this suggests the lock either expired ""
+                    + ""while we were removing it, or that it was erroneously ""
+                    + ""unlocked multiple times."", kc);
+        }
+
+        // Even if !removed, we're finished unlocking, so return true
+        return true;
     }
\ No newline at end of file
","Locking logging tweaks and renewal fix

* Added new logging statements and reworded existing statements in
  ConsistentKeyLockTransaction and LocalLockMediator

* LocalLockMediator#unlock() now logs errors and returns false instead
  of generating assertion failures when called on an expired or
  nonexistent lock; call sites updated accordingly

* Replaced broken unit test in LockKeyColumnValueStoreTest named
  relockExtendsLocalExpiration with a new test method called
  repeatLockingDoesNotExtendExpiration (closes #264)
",Buggy
titan,316.json,9b77325b51d00dd5c81ddce7b8cf312b04d7057c,"@@ -1,4 +1,9 @@
     public <O> void set(String key, O value) {
-        if (value==null) config.clearProperty(key);
-        else config.setProperty(key,value);
+        if (value==null) {
+            config.clearProperty(key);
+        } else if (Duration.class.isAssignableFrom(value.getClass())) {
+            config.setProperty(key,((Duration)value).getLength(TimeUnit.MILLISECONDS));
+        } else {
+            config.setProperty(key,value);
+        }
     }
\ No newline at end of file
","Make CommonsConfiguration write Durations as ms

CommonsConfiguration read Durations as unitless positive milliseconds
expressed as a bare integer, but would serialize through the toString
behavior used for the general case.  The toString was something like
""Duration [60 ms]"", so it was asymmetrical.  Special-casing Duration
on the write path to make it symmetrical.  This fixes an error when
copying the graph's local configuration into a Hadoop configuration
object prior to launching a MapReduce-based index management job.
",Buggy
titan,3867.json,a457c6bc3a440d72e045436f8be7a93948568f2e,"@@ -1,21 +1,21 @@
     public List<SliceQuery> getQueries() {
         if (isGlobalGraphIndex()) {
             //Everything
-            return ImmutableList.of(new SliceQuery(BufferUtil.zeroBuffer(128), BufferUtil.oneBuffer(128)));
+            return ImmutableList.of(new SliceQuery(BufferUtil.zeroBuffer(1), BufferUtil.oneBuffer(128)));
         } else {
             RelationTypeIndexWrapper wrapper = (RelationTypeIndexWrapper)index;
             InternalRelationType wrappedType = wrapper.getWrappedType();
             Direction direction=null;
             for (Direction dir : Direction.values()) if (wrappedType.isUnidirected(dir)) direction=dir;
             assert direction!=null;
 
             StandardTitanTx tx = (StandardTitanTx)graph.get().buildTransaction().readOnly().start();
             try {
                 QueryContainer qc = new QueryContainer(tx);
                 qc.addQuery().type(wrappedType).direction(direction).relations();
                 return qc.getSliceQueries();
             } finally {
                 tx.rollback();
             }
         }
     }
\ No newline at end of file
","Fixed bug in IndexRemoveJob. The issue was that a slicequery starting with 128 0s was used as the start slice in an attempt to get all columns. However, if the contents of the buffer are identical it compares the lengths. Hence, a staticbuffer with just a single 0 in it will be considered smaller and hence such index records werent' returned.
",Buggy
