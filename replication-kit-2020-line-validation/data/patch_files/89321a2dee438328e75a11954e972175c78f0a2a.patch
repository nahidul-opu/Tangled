From 89321a2dee438328e75a11954e972175c78f0a2a Mon Sep 17 00:00:00 2001
From: Nezih Yigitbasi <nyigitbasi@netflix.com>
Date: Mon, 22 Jun 2015 14:28:42 -0700
Subject: [PATCH] PARQUET-311: Fix NPE when debug logging metadata

Fixes the issue reported at https://issues.apache.org/jira/browse/PARQUET-311

Author: Nezih Yigitbasi <nyigitbasi@netflix.com>

Closes #221 from nezihyigitbasi/debug-log-fix and squashes the following commits:

59129ed [Nezih Yigitbasi] PARQUET-311: Fix NPE when debug logging metadata
---
 .../column/statistics/BinaryStatistics.java   |  4 +--
 .../TestParquetMetadataConverter.java         | 31 +++++++++++++++++++
 2 files changed, 33 insertions(+), 2 deletions(-)

diff --git a/parquet-column/src/main/java/org/apache/parquet/column/statistics/BinaryStatistics.java b/parquet-column/src/main/java/org/apache/parquet/column/statistics/BinaryStatistics.java
index b2d9b5579a..6341f96a36 100644
--- a/parquet-column/src/main/java/org/apache/parquet/column/statistics/BinaryStatistics.java
+++ b/parquet-column/src/main/java/org/apache/parquet/column/statistics/BinaryStatistics.java
@@ -53,12 +53,12 @@ public void setMinMaxFromBytes(byte[] minBytes, byte[] maxBytes) {
 
   @Override
   public byte[] getMaxBytes() {
-    return max.getBytes();
+    return max == null ? null : max.getBytes();
   }
 
   @Override
   public byte[] getMinBytes() {
-    return min.getBytes();
+    return min == null ? null : min.getBytes();
   }
 
   @Override
diff --git a/parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java b/parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java
index b4f56fa92c..1a740fe852 100644
--- a/parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java
+++ b/parquet-hadoop/src/test/java/org/apache/parquet/format/converter/TestParquetMetadataConverter.java
@@ -19,6 +19,7 @@
 package org.apache.parquet.format.converter;
 
 import static java.util.Collections.emptyList;
+import static org.apache.parquet.schema.MessageTypeParser.parseMessageType;
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.fail;
 import static org.apache.parquet.format.CompressionCodec.UNCOMPRESSED;
@@ -34,11 +35,19 @@
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.Collections;
+import java.util.HashMap;
+import java.util.HashSet;
 import java.util.List;
 import java.util.Random;
 import java.util.Set;
 import java.util.TreeSet;
 
+import org.apache.parquet.column.statistics.BinaryStatistics;
+import org.apache.parquet.hadoop.metadata.BlockMetaData;
+import org.apache.parquet.hadoop.metadata.ColumnChunkMetaData;
+import org.apache.parquet.hadoop.metadata.ColumnPath;
+import org.apache.parquet.hadoop.metadata.CompressionCodecName;
+import org.apache.parquet.hadoop.metadata.ParquetMetadata;
 import org.junit.Assert;
 import org.junit.Test;
 
@@ -252,4 +261,26 @@ public void randomTestFilterMetaData() {
     }
   }
 
+  @Test
+  public void testNullFieldMetadataDebugLogging() throws NoSuchFieldException, IllegalAccessException, IOException {
+    MessageType schema = parseMessageType("message test { optional binary some_null_field; }");
+    org.apache.parquet.hadoop.metadata.FileMetaData fileMetaData = new org.apache.parquet.hadoop.metadata.FileMetaData(schema, new HashMap<String, String>(), null);
+    List<BlockMetaData> blockMetaDataList = new ArrayList<BlockMetaData>();
+    BlockMetaData blockMetaData = new BlockMetaData();
+    blockMetaData.addColumn(createColumnChunkMetaData());
+    blockMetaDataList.add(blockMetaData);
+    ParquetMetadata metadata = new ParquetMetadata(fileMetaData, blockMetaDataList);
+    ParquetMetadata.toJSON(metadata);
+  }
+
+  private ColumnChunkMetaData createColumnChunkMetaData() {
+    Set<Encoding> e = new HashSet<Encoding>();
+    PrimitiveTypeName t = PrimitiveTypeName.BINARY;
+    ColumnPath p = ColumnPath.get("foo");
+    CompressionCodecName c = CompressionCodecName.GZIP;
+    BinaryStatistics s = new BinaryStatistics();
+    ColumnChunkMetaData md = ColumnChunkMetaData.get(p, t, c, e, s,
+            0, 0, 0, 0, 0);
+    return md;
+  }
 }
