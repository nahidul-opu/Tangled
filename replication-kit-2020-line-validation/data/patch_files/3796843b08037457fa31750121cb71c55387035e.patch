From ac6c42b37385fd05fa9776e53d6de41320a202c4 Mon Sep 17 00:00:00 2001
From: Kevin <djkevincr@yahoo.com>
Date: Sun, 18 Sep 2016 22:01:12 +0530
Subject: [PATCH 1/3] adding fix for GORA-401

---
 .../org/apache/gora/mapreduce/PersistentDeserializer.java   | 6 +++++-
 .../org/apache/gora/mapreduce/PersistentSerializer.java     | 2 +-
 .../src/test/java/org/apache/gora/util/TestIOUtils.java     | 5 +++++
 3 files changed, 11 insertions(+), 2 deletions(-)

diff --git a/gora-core/src/main/java/org/apache/gora/mapreduce/PersistentDeserializer.java b/gora-core/src/main/java/org/apache/gora/mapreduce/PersistentDeserializer.java
index 79eee4291..8a957b91d 100644
--- a/gora-core/src/main/java/org/apache/gora/mapreduce/PersistentDeserializer.java
+++ b/gora-core/src/main/java/org/apache/gora/mapreduce/PersistentDeserializer.java
@@ -68,6 +68,10 @@ public void close() throws IOException { }
 
   @Override
   public PersistentBase deserialize(PersistentBase persistent) throws IOException {
-    return datumReader.read(reuseObjects ? persistent : null, decoder);
+    persistent = datumReader.read(reuseObjects ? persistent : null, decoder);
+    byte[] __g__dirty = new byte[persistent.getFieldsCount()];
+    decoder.readFixed(__g__dirty);
+    persistent.setDirtyBytes(java.nio.ByteBuffer.wrap(__g__dirty));
+    return persistent;
   }
 }
diff --git a/gora-core/src/main/java/org/apache/gora/mapreduce/PersistentSerializer.java b/gora-core/src/main/java/org/apache/gora/mapreduce/PersistentSerializer.java
index b75d1dd75..1851ff51b 100644
--- a/gora-core/src/main/java/org/apache/gora/mapreduce/PersistentSerializer.java
+++ b/gora-core/src/main/java/org/apache/gora/mapreduce/PersistentSerializer.java
@@ -63,7 +63,7 @@ public void open(OutputStream out) throws IOException {
   @Override
   public void serialize(PersistentBase persistent) throws IOException {
     datumWriter.setSchema(persistent.getSchema());
-        
     datumWriter.write(persistent, encoder);
+    encoder.writeFixed(persistent.getDirtyBytes().array());
   }
 }
diff --git a/gora-core/src/test/java/org/apache/gora/util/TestIOUtils.java b/gora-core/src/test/java/org/apache/gora/util/TestIOUtils.java
index d0f3e1c92..ec2a791cb 100644
--- a/gora-core/src/test/java/org/apache/gora/util/TestIOUtils.java
+++ b/gora-core/src/test/java/org/apache/gora/util/TestIOUtils.java
@@ -30,6 +30,7 @@
 import org.apache.avro.util.ByteBufferInputStream;
 import org.apache.avro.util.ByteBufferOutputStream;
 import org.apache.gora.mapreduce.GoraMapReduceUtils;
+import org.apache.gora.persistency.impl.PersistentBase;
 import org.apache.gora.util.IOUtils;
 import org.apache.hadoop.conf.Configuration;
 import org.apache.hadoop.io.DataInputBuffer;
@@ -135,6 +136,10 @@ public static <T> void testSerializeDeserialize(T... objects) throws Exception {
           log.info("After : " + before);
         }
         assertEquals(before, after);
+        if ((before instanceof PersistentBase) && (after instanceof PersistentBase)) {
+          assertEquals(Arrays.equals(((PersistentBase) before).getDirtyBytes().array(),
+                  ((PersistentBase) after).getDirtyBytes().array()), true);
+        }
       }
       
       //assert that the end of input is reached

From 70637707188c30111862d716b9af94cf7c742d1a Mon Sep 17 00:00:00 2001
From: Kevin <djkevincr@yahoo.com>
Date: Mon, 19 Sep 2016 12:06:08 +0530
Subject: [PATCH 2/3] adding Alfonso Nishikawa reviews and test cases

---
 .../mapreduce/MapReduceSerialization.java     | 159 ++++++++++++++++++
 .../TestHBaseStoreMapReduceSerialization.java |  56 ++++++
 2 files changed, 215 insertions(+)
 create mode 100644 gora-core/src/examples/java/org/apache/gora/examples/mapreduce/MapReduceSerialization.java
 create mode 100644 gora-hbase/src/test/java/org/apache/gora/hbase/mapreduce/TestHBaseStoreMapReduceSerialization.java

diff --git a/gora-core/src/examples/java/org/apache/gora/examples/mapreduce/MapReduceSerialization.java b/gora-core/src/examples/java/org/apache/gora/examples/mapreduce/MapReduceSerialization.java
new file mode 100644
index 000000000..fd5c062d6
--- /dev/null
+++ b/gora-core/src/examples/java/org/apache/gora/examples/mapreduce/MapReduceSerialization.java
@@ -0,0 +1,159 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.gora.examples.mapreduce;
+
+import java.io.IOException;
+
+import org.apache.gora.examples.generated.WebPage;
+import org.apache.gora.mapreduce.GoraMapper;
+import org.apache.gora.mapreduce.GoraReducer;
+import org.apache.gora.query.Query;
+import org.apache.gora.store.DataStore;
+import org.apache.gora.store.DataStoreFactory;
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.conf.Configured;
+import org.apache.hadoop.io.Text;
+import org.apache.hadoop.mapreduce.Job;
+import org.apache.hadoop.util.Tool;
+import org.apache.hadoop.util.ToolRunner;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * Test that serializing from Map to Reduce holds the dirty state
+ */
+public class MapReduceSerialization extends Configured implements Tool {
+
+  private static final Logger LOG = LoggerFactory.getLogger(MapReduceSerialization.class);
+
+  public MapReduceSerialization() {
+
+  }
+
+  public MapReduceSerialization(Configuration conf) {
+    setConf(conf);
+  }
+
+  /**
+   * {@link CheckDirtyBitsSerializationMapper} gets a WebPage, sets
+   * the URL to the string "hola" and emits it with the same key.
+   */
+  public static class CheckDirtyBitsSerializationMapper
+          extends GoraMapper<String, WebPage, Text, WebPage> {
+
+    @Override
+    protected void map(String key, WebPage page, Context context)
+            throws IOException ,InterruptedException {
+      page.setUrl("hola") ;
+      context.write(new Text(key), page) ;
+    };
+  }
+
+  /**
+   * {@link CheckDirtyBytesSerializationReducer} just take vales and emits
+   * them as is.
+   */
+  public static class CheckDirtyBytesSerializationReducer extends GoraReducer<Text, WebPage,
+          String, WebPage> {
+
+    @Override
+    protected void reduce(Text key, Iterable<WebPage> values, Context context)
+            throws IOException ,InterruptedException {
+      for (WebPage val : values) {
+        LOG.info(key.toString()) ;
+        LOG.info(val.toString()) ;
+        LOG.info(String.valueOf(val.isDirty())) ;
+        context.write(key.toString(), val);
+      }
+    };
+
+  }
+
+  /**
+   * Creates and returns the {@link Job} for submitting to Hadoop mapreduce.
+   * @param inStore
+   * @param query
+   * @return
+   * @throws IOException
+   */
+  public Job createJob(DataStore<String,WebPage> inStore, Query<String,WebPage> query
+          , DataStore<String,WebPage> outStore) throws IOException {
+    Job job = new Job(getConf());
+
+    job.setJobName("Check serialization of dirty bits");
+
+    job.setNumReduceTasks(1);
+    job.setJarByClass(getClass());
+    
+    /* Mappers are initialized with GoraMapper#initMapper().
+     * Instead of the TokenizerMapper defined here, if the input is not 
+     * obtained via Gora, any other mapper can be used, such as 
+     * Hadoop-MapReduce's WordCount.TokenizerMapper.
+     */
+    GoraMapper.initMapperJob(job, query, Text.class
+            , WebPage.class, CheckDirtyBitsSerializationMapper.class, true);
+    
+    /* Reducers are initialized with GoraReducer#initReducer().
+     * If the output is not to be persisted via Gora, any reducer 
+     * can be used instead.
+     */
+    GoraReducer.initReducerJob(job, outStore, CheckDirtyBytesSerializationReducer.class);
+
+    return job;
+  }
+
+  public int mapReduceSerialization(DataStore<String,WebPage> inStore,
+                                    DataStore<String, WebPage> outStore) throws IOException, InterruptedException, ClassNotFoundException {
+    Query<String,WebPage> query = inStore.newQuery();
+    query.setFields("url") ;
+
+    Job job = createJob(inStore, query, outStore);
+    return job.waitForCompletion(true) ? 0 : 1;
+  }
+
+  @Override
+  public int run(String[] args) throws Exception {
+
+    DataStore<String,WebPage> inStore;
+    DataStore<String,WebPage> outStore;
+    Configuration conf = new Configuration();
+    if(args.length > 0) {
+      String dataStoreClass = args[0];
+      inStore = DataStoreFactory.getDataStore(dataStoreClass,
+              String.class, WebPage.class, conf);
+      if(args.length > 1) {
+        dataStoreClass = args[1];
+      }
+      outStore = DataStoreFactory.getDataStore(dataStoreClass,
+              String.class, WebPage.class, conf);
+    } else {
+      inStore = DataStoreFactory.getDataStore(String.class, WebPage.class, conf);
+      outStore = DataStoreFactory.getDataStore(String.class, WebPage.class, conf);
+    }
+
+    return mapReduceSerialization(inStore, outStore);
+  }
+
+  // Usage WordCount [<input datastore class> [output datastore class]]
+  public static void main(String[] args) throws Exception {
+    int ret = ToolRunner.run(new MapReduceSerialization(), args);
+    System.exit(ret);
+  }
+
+}
\ No newline at end of file
diff --git a/gora-hbase/src/test/java/org/apache/gora/hbase/mapreduce/TestHBaseStoreMapReduceSerialization.java b/gora-hbase/src/test/java/org/apache/gora/hbase/mapreduce/TestHBaseStoreMapReduceSerialization.java
new file mode 100644
index 000000000..f73c77b6a
--- /dev/null
+++ b/gora-hbase/src/test/java/org/apache/gora/hbase/mapreduce/TestHBaseStoreMapReduceSerialization.java
@@ -0,0 +1,56 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.gora.hbase.mapreduce;
+
+import org.apache.gora.examples.generated.WebPage;
+import org.apache.gora.hbase.store.HBaseStore;
+import org.apache.gora.hbase.util.HBaseClusterSingleton;
+import org.apache.gora.mapreduce.MapReduceTestUtils;
+import org.apache.gora.store.DataStoreFactory;
+import org.junit.After;
+import org.junit.Before;
+import org.junit.Test;
+
+/**
+ * Tests related to {@link HBaseStore} using mapreduce.
+ */
+public class TestHBaseStoreMapReduceSerialization {
+  private static final HBaseClusterSingleton cluster = HBaseClusterSingleton.build(1);
+
+  private HBaseStore<String, WebPage> webPageStore;
+
+  @SuppressWarnings("unchecked")
+  @Before
+  public void setUp() throws Exception {
+    cluster.deleteAllTables();
+    webPageStore = DataStoreFactory.getDataStore(
+            HBaseStore.class, String.class, WebPage.class, cluster.getConf());
+  }
+
+  @After
+  public void tearDown() throws Exception {
+    webPageStore.close();
+  }
+
+  @Test
+  public void testMapReduceSerialization() throws Exception {
+    MapReduceTestUtils.testMapReduceSerialization(cluster.getConf(), webPageStore, webPageStore);
+  }
+
+}
\ No newline at end of file

From 28e1011120468f183d7f1fb6371285946420a34b Mon Sep 17 00:00:00 2001
From: Kevin <djkevincr@yahoo.com>
Date: Mon, 19 Sep 2016 12:07:02 +0530
Subject: [PATCH 3/3] adding Alfonso Nishikawa reviews and test cases

---
 .../mapreduce/MapReduceSerialization.java     | 51 +++++++++----------
 .../gora/mapreduce/MapReduceTestUtils.java    | 44 ++++++++++++++++
 2 files changed, 69 insertions(+), 26 deletions(-)

diff --git a/gora-core/src/examples/java/org/apache/gora/examples/mapreduce/MapReduceSerialization.java b/gora-core/src/examples/java/org/apache/gora/examples/mapreduce/MapReduceSerialization.java
index fd5c062d6..a8dcf9e4b 100644
--- a/gora-core/src/examples/java/org/apache/gora/examples/mapreduce/MapReduceSerialization.java
+++ b/gora-core/src/examples/java/org/apache/gora/examples/mapreduce/MapReduceSerialization.java
@@ -43,7 +43,6 @@ public class MapReduceSerialization extends Configured implements Tool {
   private static final Logger LOG = LoggerFactory.getLogger(MapReduceSerialization.class);
 
   public MapReduceSerialization() {
-
   }
 
   public MapReduceSerialization(Configuration conf) {
@@ -56,13 +55,12 @@ public MapReduceSerialization(Configuration conf) {
    */
   public static class CheckDirtyBitsSerializationMapper
           extends GoraMapper<String, WebPage, Text, WebPage> {
-
     @Override
     protected void map(String key, WebPage page, Context context)
-            throws IOException ,InterruptedException {
-      page.setUrl("hola") ;
-      context.write(new Text(key), page) ;
-    };
+            throws IOException, InterruptedException {
+      page.setUrl("hola");
+      context.write(new Text(key), page);
+    }
   }
 
   /**
@@ -71,29 +69,29 @@ protected void map(String key, WebPage page, Context context)
    */
   public static class CheckDirtyBytesSerializationReducer extends GoraReducer<Text, WebPage,
           String, WebPage> {
-
     @Override
     protected void reduce(Text key, Iterable<WebPage> values, Context context)
-            throws IOException ,InterruptedException {
+            throws IOException, InterruptedException {
       for (WebPage val : values) {
-        LOG.info(key.toString()) ;
-        LOG.info(val.toString()) ;
-        LOG.info(String.valueOf(val.isDirty())) ;
+        LOG.info(key.toString());
+        LOG.info(val.toString());
+        LOG.info(String.valueOf(val.isDirty()));
         context.write(key.toString(), val);
       }
-    };
-
+    }
   }
 
   /**
    * Creates and returns the {@link Job} for submitting to Hadoop mapreduce.
-   * @param inStore
-   * @param query
-   * @return
+   *
+   * @param inStore  input store on MR jobs runs on
+   * @param query    query to select input set run MR
+   * @param outStore output store which stores results of MR jobs
+   * @return job MR job definition
    * @throws IOException
    */
-  public Job createJob(DataStore<String,WebPage> inStore, Query<String,WebPage> query
-          , DataStore<String,WebPage> outStore) throws IOException {
+  public Job createJob(DataStore<String, WebPage> inStore, Query<String, WebPage> query
+          , DataStore<String, WebPage> outStore) throws IOException {
     Job job = new Job(getConf());
 
     job.setJobName("Check serialization of dirty bits");
@@ -118,10 +116,11 @@ public Job createJob(DataStore<String,WebPage> inStore, Query<String,WebPage> qu
     return job;
   }
 
-  public int mapReduceSerialization(DataStore<String,WebPage> inStore,
-                                    DataStore<String, WebPage> outStore) throws IOException, InterruptedException, ClassNotFoundException {
-    Query<String,WebPage> query = inStore.newQuery();
-    query.setFields("url") ;
+  public int mapReduceSerialization(DataStore<String, WebPage> inStore,
+                                    DataStore<String, WebPage> outStore)
+          throws IOException, InterruptedException, ClassNotFoundException {
+    Query<String, WebPage> query = inStore.newQuery();
+    query.setFields("url");
 
     Job job = createJob(inStore, query, outStore);
     return job.waitForCompletion(true) ? 0 : 1;
@@ -130,14 +129,14 @@ public int mapReduceSerialization(DataStore<String,WebPage> inStore,
   @Override
   public int run(String[] args) throws Exception {
 
-    DataStore<String,WebPage> inStore;
-    DataStore<String,WebPage> outStore;
+    DataStore<String, WebPage> inStore;
+    DataStore<String, WebPage> outStore;
     Configuration conf = new Configuration();
-    if(args.length > 0) {
+    if (args.length > 0) {
       String dataStoreClass = args[0];
       inStore = DataStoreFactory.getDataStore(dataStoreClass,
               String.class, WebPage.class, conf);
-      if(args.length > 1) {
+      if (args.length > 1) {
         dataStoreClass = args[1];
       }
       outStore = DataStoreFactory.getDataStore(dataStoreClass,
diff --git a/gora-core/src/test/java/org/apache/gora/mapreduce/MapReduceTestUtils.java b/gora-core/src/test/java/org/apache/gora/mapreduce/MapReduceTestUtils.java
index f7a44f0f6..91ae1bc8d 100644
--- a/gora-core/src/test/java/org/apache/gora/mapreduce/MapReduceTestUtils.java
+++ b/gora-core/src/test/java/org/apache/gora/mapreduce/MapReduceTestUtils.java
@@ -18,6 +18,9 @@
 
 package org.apache.gora.mapreduce;
 
+import java.nio.ByteBuffer;
+import java.nio.charset.Charset;
+import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
@@ -26,10 +29,12 @@
 import org.apache.gora.examples.WebPageDataCreator;
 import org.apache.gora.examples.generated.TokenDatum;
 import org.apache.gora.examples.generated.WebPage;
+import org.apache.gora.examples.mapreduce.MapReduceSerialization;
 import org.apache.gora.examples.mapreduce.QueryCounter;
 import org.apache.gora.examples.mapreduce.WordCount;
 import org.apache.gora.examples.spark.SparkWordCount;
 import org.apache.gora.query.Query;
+import org.apache.gora.query.Result;
 import org.apache.gora.store.DataStore;
 import org.apache.gora.store.impl.DataStoreBase;
 import org.apache.hadoop.conf.Configuration;
@@ -141,4 +146,43 @@ private static void assertTokenCount(DataStore<String, TokenDatum> outStore,
     assertNotNull("token:" + token + " cannot be found in datastore", datum);
     assertEquals("count for token:" + token + " is wrong", count, datum.getCount().intValue());
   }
+
+  public static void testMapReduceSerialization(Configuration conf, DataStore<String, WebPage> inStore, DataStore<String,
+          WebPage> outStore) throws Exception {
+    //Datastore now has to be a Hadoop based datastore
+    ((DataStoreBase<String, WebPage>) inStore).setConf(conf);
+    ((DataStoreBase<String, WebPage>) outStore).setConf(conf);
+
+    //create input
+    WebPage page = WebPage.newBuilder().build();
+    page.setUrl("TestURL");
+    List<CharSequence> content = new ArrayList<CharSequence>();
+    content.add("parsed1");
+    content.add("parsed2");
+    page.setParsedContent(content);
+    page.setContent(ByteBuffer.wrap("content".getBytes(Charset.defaultCharset())));
+    inStore.put("key1", page);
+    inStore.flush();
+
+    // expected
+    WebPage expectedPage = WebPage.newBuilder().build();
+    expectedPage.setUrl("hola");
+    List<CharSequence> expectedContent = new ArrayList<CharSequence>();
+    expectedContent.add("parsed1");
+    expectedContent.add("parsed2");
+    expectedPage.setParsedContent(expectedContent);
+    expectedPage.setContent(ByteBuffer.wrap("content".getBytes(Charset.defaultCharset())));
+
+    //run the job
+    MapReduceSerialization mapReduceSerialization = new MapReduceSerialization(conf);
+    mapReduceSerialization.mapReduceSerialization(inStore, outStore);
+
+    Query<String, WebPage> outputQuery = outStore.newQuery();
+    Result<String, WebPage> serializationResult = outStore.execute(outputQuery);
+
+    while (serializationResult.next()) {
+      assertEquals(expectedPage, serializationResult.get());
+    }
+  }
+
 }
