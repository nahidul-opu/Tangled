From 59c58d0b829aa156f038cc900b803508f8849765 Mon Sep 17 00:00:00 2001
From: Ryan Blue <rblue@cloudera.com>
Date: Tue, 23 Sep 2014 12:14:17 -0700
Subject: [PATCH] PARQUET-82: Check page size is valid when writing.

Author: Ryan Blue <rblue@cloudera.com>

Closes #48 from rdblue/PARQUET-82-check-page-size and squashes the following commits:

9f31402 [Ryan Blue] PARQUET-82: Check page size is valid when writing.
---
 .../hadoop/ColumnChunkPageWriteStore.java     | 20 +++++++++++++++++++
 1 file changed, 20 insertions(+)

diff --git a/parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java b/parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java
index 279eb5640b..6d7f685a63 100644
--- a/parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java
+++ b/parquet-hadoop/src/main/java/parquet/hadoop/ColumnChunkPageWriteStore.java
@@ -77,8 +77,18 @@ public void writePage(BytesInput bytes,
                           Encoding dlEncoding,
                           Encoding valuesEncoding) throws IOException {
       long uncompressedSize = bytes.size();
+      if (uncompressedSize > Integer.MAX_VALUE) {
+        throw new ParquetEncodingException(
+            "Cannot write page larger than Integer.MAX_VALUE bytes: " +
+                uncompressedSize);
+      }
       BytesInput compressedBytes = compressor.compress(bytes);
       long compressedSize = compressedBytes.size();
+      if (compressedSize > Integer.MAX_VALUE) {
+        throw new ParquetEncodingException(
+            "Cannot write compressed page larger than Integer.MAX_VALUE bytes: "
+                + compressedSize);
+      }
       BooleanStatistics statistics = new BooleanStatistics(); // dummy stats object
       parquetMetadataConverter.writeDataPageHeader(
           (int)uncompressedSize,
@@ -107,8 +117,18 @@ public void writePage(BytesInput bytes,
                           Encoding dlEncoding,
                           Encoding valuesEncoding) throws IOException {
       long uncompressedSize = bytes.size();
+      if (uncompressedSize > Integer.MAX_VALUE) {
+        throw new ParquetEncodingException(
+            "Cannot write page larger than Integer.MAX_VALUE bytes: " +
+            uncompressedSize);
+      }
       BytesInput compressedBytes = compressor.compress(bytes);
       long compressedSize = compressedBytes.size();
+      if (compressedSize > Integer.MAX_VALUE) {
+        throw new ParquetEncodingException(
+            "Cannot write compressed page larger than Integer.MAX_VALUE bytes: "
+            + compressedSize);
+      }
       parquetMetadataConverter.writeDataPageHeader(
           (int)uncompressedSize,
           (int)compressedSize,
