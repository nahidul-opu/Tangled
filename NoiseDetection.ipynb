{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "from modules.Untangler import Untangler, UntanglerOpenAI\n",
    "random_seed = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"./data/GoldSet.csv\")\n",
    "df1[\"Diff\"] = df1[\"Diff\"].apply(lambda x: x.replace(\"\\\\ No newline at end of file\",\"\").strip())\n",
    "\n",
    "df2 = pd.read_csv(\"./data/GoldSet_TrueBuggyMethods.csv\")\n",
    "df2[\"Diff\"] = df2[\"Diff\"].apply(lambda x: x.replace(\"\\\\ No newline at end of file\",\"\").strip())\n",
    "\n",
    "df3 = pd.read_csv(\"./data/GoldSet_TrueNotBuggyMethods.csv\")\n",
    "df3[\"Diff\"] = df3[\"Diff\"].apply(lambda x: x.replace(\"\\\\ No newline at end of file\",\"\").strip())\n",
    "\n",
    "df = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "df.to_csv(\"./data/Complete_GoldSet.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/Complete_GoldSet.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gpt-4o-mini 2 shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1776it [00:00, 21403.08it/s]\n",
      "1776it [43:36,  1.47s/it]\n"
     ]
    }
   ],
   "source": [
    "untangler = Untangler(model_name=\"openai\")\n",
    "result = untangler.batch_detect(df, iteratively=False)\n",
    "result.to_csv(\"./Results/openai-4o-mini_2shot_result.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Buggy       0.86      0.85      0.86       900\n",
      "    NotBuggy       0.85      0.86      0.85       876\n",
      "\n",
      "    accuracy                           0.85      1776\n",
      "   macro avg       0.85      0.85      0.85      1776\n",
      "weighted avg       0.85      0.85      0.85      1776\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = pd.read_csv(\"./Results/openai-4o-mini_2shot_result.csv\")\n",
    "print(classification_report(result[\"Decision\"], result[\"Detection\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gpt-4o-mini 2 shot cot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untangler = Untangler(model_name=\"openai\", enable_cot=True)\n",
    "res = untangler.batch_detect(df)\n",
    "result.to_csv(\"./Results/openai-4o-mini_2shot_cot_result.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Buggy       0.78      0.90      0.84       900\n",
      "    NotBuggy       0.88      0.75      0.81       876\n",
      "\n",
      "    accuracy                           0.82      1776\n",
      "   macro avg       0.83      0.82      0.82      1776\n",
      "weighted avg       0.83      0.82      0.82      1776\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = pd.read_csv(\"./Results/openai-4o-mini_2shot_cot_result.csv\")\n",
    "print(classification_report(result[\"Decision\"], result[\"Detection\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gpt-4o-mini 6 shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untangler = Untangler(model_name=\"openai\")\n",
    "result = untangler.batch_detect(df, iteratively=False)\n",
    "result.to_csv(\"./Results/openai_4o-mini_result.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Buggy       0.77      0.91      0.84       901\n",
      "    NotBuggy       0.89      0.73      0.80       877\n",
      "\n",
      "    accuracy                           0.82      1778\n",
      "   macro avg       0.83      0.82      0.82      1778\n",
      "weighted avg       0.83      0.82      0.82      1778\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = pd.read_csv(\"./Results/openai_4o-mini_result.csv\")\n",
    "print(classification_report(result[\"Decision\"], result[\"Detection\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gemini-2.0-flash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untangler = Untangler(model_name=\"gemini\")\n",
    "result = untangler.batch_detect(df)\n",
    "result.to_csv(\"./Results/gemini_result.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Buggy       0.83      0.94      0.88       900\n",
      "    NotBuggy       0.93      0.80      0.86       876\n",
      "\n",
      "    accuracy                           0.87      1776\n",
      "   macro avg       0.88      0.87      0.87      1776\n",
      "weighted avg       0.88      0.87      0.87      1776\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = pd.read_csv(\"./Results/gemini_result.csv\")\n",
    "result[\"Detection\"] = result[\"Detection\"].apply(lambda x: x.strip())\n",
    "result = result[result[\"Detection\"].isin(['Buggy', 'NotBuggy'])]\n",
    "result[\"Detection\"].unique()\n",
    "print(classification_report(result[\"Decision\"], result[\"Detection\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gemini-2.0 2 shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1776it [22:44:36, 46.10s/it]   \n"
     ]
    }
   ],
   "source": [
    "untangler = Untangler(model_name=\"gemini\")\n",
    "result = untangler.batch_detect(df)\n",
    "result.to_csv(\"./Results/gemini_2shot_result.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Buggy       0.74      0.98      0.84       900\n",
      "    NotBuggy       0.97      0.65      0.78       876\n",
      "\n",
      "    accuracy                           0.82      1776\n",
      "   macro avg       0.85      0.81      0.81      1776\n",
      "weighted avg       0.85      0.82      0.81      1776\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = pd.read_csv(\"./Results/gemini_2shot_result.csv\")\n",
    "result[\"Detection\"] = result[\"Detection\"].apply(lambda x: x.strip())\n",
    "result = result[result[\"Detection\"].isin(['Buggy', 'NotBuggy'])]\n",
    "result[\"Detection\"].unique()\n",
    "print(classification_report(result[\"Decision\"], result[\"Detection\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# o3-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "untangler = UntanglerOpenAI(model_name=\"o3-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1778it [5:11:40, 10.52s/it]\n"
     ]
    }
   ],
   "source": [
    "result = untangler.batch_detect(df, iteratively=True)\n",
    "result.to_csv(\"./Results/openai_o3-mini_result.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Buggy       0.63      0.98      0.77       901\n",
      "    NotBuggy       0.95      0.42      0.58       877\n",
      "\n",
      "    accuracy                           0.70      1778\n",
      "   macro avg       0.79      0.70      0.68      1778\n",
      "weighted avg       0.79      0.70      0.68      1778\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = pd.read_csv(\"./Results/openai_o3-mini_result.csv\")\n",
    "print(classification_report(result[\"Decision\"], result[\"Detection\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1718it [1:50:58,  3.88s/it]\n"
     ]
    }
   ],
   "source": [
    "untangler = Untangler(model_name=\"openai\")\n",
    "untangler.change_model(\"gpt-4o\")\n",
    "result = untangler.batch_detect(df, iteratively=True)\n",
    "result.to_csv(\"./Results/openai_gpt-4o_result.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Buggy       0.89      0.85      0.87       901\n",
      "    NotBuggy       0.85      0.89      0.87       877\n",
      "\n",
      "    accuracy                           0.87      1778\n",
      "   macro avg       0.87      0.87      0.87      1778\n",
      "weighted avg       0.87      0.87      0.87      1778\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = pd.read_csv(\"./Results/openai_gpt-4o_result.csv\")\n",
    "print(classification_report(result[\"Decision\"], result[\"Detection\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4o 2 shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1444it [1:40:13,  3.55s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error - Error code: 500 - {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID req_b935c4e4cde17eaab10d2770a5415b67 in your email.)', 'type': 'server_error', 'param': None, 'code': None}}.\n",
      "Retrying in 1 minute\n",
      "Error - Error code: 500 - {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID req_b8d008da8a14f8f8d25856886a5da74a in your email.)', 'type': 'server_error', 'param': None, 'code': None}}.\n",
      "Retrying in 1 minute\n",
      "Error - Error code: 500 - {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID req_da7271c9a7fbca4a4c8a9f1a4dffa172 in your email.)', 'type': 'server_error', 'param': None, 'code': None}}.\n",
      "Retrying in 1 minute\n",
      "Error - Error code: 500 - {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID req_199935bfe82d0bf0ea1ecd8ae2996d24 in your email.)', 'type': 'server_error', 'param': None, 'code': None}}.\n",
      "Retrying in 1 minute\n",
      "Error - Error code: 500 - {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID req_c82fe33d00e6fbc35ff555806a58417c in your email.)', 'type': 'server_error', 'param': None, 'code': None}}.\n",
      "Retrying in 1 minute\n",
      "Error - Error code: 500 - {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID req_eef629ab972688bcb283bb766da058df in your email.)', 'type': 'server_error', 'param': None, 'code': None}}.\n",
      "Retrying in 1 minute\n",
      "Error - Error code: 500 - {'error': {'message': 'The server had an error processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if you keep seeing this error. (Please include the request ID req_39f9e256c3cc2cf6f29d9e2309b227bc in your email.)', 'type': 'server_error', 'param': None, 'code': None}}.\n",
      "Retrying in 1 minute\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1776it [2:28:54,  5.03s/it] \n"
     ]
    }
   ],
   "source": [
    "untangler = Untangler(model_name=\"openai\")\n",
    "untangler.change_model(\"gpt-4o\")\n",
    "result = untangler.batch_detect(df, iteratively=True)\n",
    "result.to_csv(\"./Results/openai_gpt-4o_2shot_result.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Buggy       0.89      0.87      0.88       900\n",
      "    NotBuggy       0.87      0.89      0.88       876\n",
      "\n",
      "    accuracy                           0.88      1776\n",
      "   macro avg       0.88      0.88      0.88      1776\n",
      "weighted avg       0.88      0.88      0.88      1776\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = pd.read_csv(\"./Results/openai_gpt-4o_2shot_result.csv\")\n",
    "print(classification_report(result[\"Decision\"], result[\"Detection\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4o 2 shot cot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1776it [2:33:50,  5.20s/it]\n"
     ]
    }
   ],
   "source": [
    "untangler = Untangler(model_name=\"openai\", enable_cot=True)\n",
    "untangler.change_model(\"gpt-4o\")\n",
    "result = untangler.batch_detect(df, iteratively=True)\n",
    "result.to_csv(\"./Results/openai_gpt-4o_2shot_cot_result.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Buggy       0.83      0.93      0.88       900\n",
      "    NotBuggy       0.92      0.81      0.86       876\n",
      "\n",
      "    accuracy                           0.87      1776\n",
      "   macro avg       0.88      0.87      0.87      1776\n",
      "weighted avg       0.87      0.87      0.87      1776\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = pd.read_csv(\"./Results/openai_gpt-4o_2shot_cot_result.csv\")\n",
    "print(classification_report(result[\"Decision\"], result[\"Detection\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
