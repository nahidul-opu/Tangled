{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "\n",
    "from modules.Untangler import Untangler, UntanglerOpenAI\n",
    "random_seed = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"./data/GoldSet.csv\")\n",
    "df1[\"Diff\"] = df1[\"Diff\"].apply(lambda x: x.replace(\"\\\\ No newline at end of file\",\"\").strip())\n",
    "\n",
    "df2 = pd.read_csv(\"./data/GoldSet_TrueBuggyMethods.csv\")\n",
    "df2[\"Diff\"] = df2[\"Diff\"].apply(lambda x: x.replace(\"\\\\ No newline at end of file\",\"\").strip())\n",
    "\n",
    "df3 = pd.read_csv(\"./data/GoldSet_TrueNotBuggyMethods.csv\")\n",
    "df3[\"Diff\"] = df3[\"Diff\"].apply(lambda x: x.replace(\"\\\\ No newline at end of file\",\"\").strip())\n",
    "\n",
    "df = pd.concat([df1, df2, df3], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/Complete_GoldSet.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gpt-4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1778it [1:45:10,  3.55s/it]\n"
     ]
    }
   ],
   "source": [
    "untangler = Untangler(model_name=\"openai\")\n",
    "result = untangler.batch_detect(df, iteratively=True)\n",
    "result.to_csv(\"./Results/openai_result.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Buggy       0.77      0.91      0.84       901\n",
      "    NotBuggy       0.89      0.73      0.80       877\n",
      "\n",
      "    accuracy                           0.82      1778\n",
      "   macro avg       0.83      0.82      0.82      1778\n",
      "weighted avg       0.83      0.82      0.82      1778\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = pd.read_csv(\"./Results/openai_result.csv\")\n",
    "print(classification_report(result[\"Decision\"], result[\"Detection\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gemini-2.0-flash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untangler = Untangler(model_name=\"gemini\")\n",
    "result = untangler.batch_detect(df)\n",
    "result.to_csv(\"./Results/gemini_result.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Buggy       0.83      0.94      0.88       900\n",
      "    NotBuggy       0.93      0.80      0.86       876\n",
      "\n",
      "    accuracy                           0.87      1776\n",
      "   macro avg       0.88      0.87      0.87      1776\n",
      "weighted avg       0.88      0.87      0.87      1776\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = pd.read_csv(\"./Results/gemini_result.csv\")\n",
    "result[\"Detection\"] = result[\"Detection\"].apply(lambda x: x.strip())\n",
    "result = result[result[\"Detection\"].isin(['Buggy', 'NotBuggy'])]\n",
    "result[\"Detection\"].unique()\n",
    "print(classification_report(result[\"Decision\"], result[\"Detection\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# o3-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "untangler = UntanglerOpenAI(model_name=\"o3-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1778it [5:11:40, 10.52s/it]\n"
     ]
    }
   ],
   "source": [
    "result = untangler.batch_detect(df, iteratively=True)\n",
    "result.to_csv(\"./Results/openai_o3-mini_result.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Buggy       0.63      0.98      0.77       901\n",
      "    NotBuggy       0.95      0.42      0.58       877\n",
      "\n",
      "    accuracy                           0.70      1778\n",
      "   macro avg       0.79      0.70      0.68      1778\n",
      "weighted avg       0.79      0.70      0.68      1778\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = pd.read_csv(\"./Results/openai_o3-mini_result.csv\")\n",
    "print(classification_report(result[\"Decision\"], result[\"Detection\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:00, 22306.57it/s]\n",
      "0it [00:05, ?it/s]\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Errors(data=[BatchError(code='token_limit_exceeded', line=None, message='Enqueued token limit reached for gpt-4o in organization org-RusRbI31Ti1GmBfluMMBQII7. Limit: 90,000 enqueued tokens. Please try again once some in_progress batches have been completed.', param=None)], object='list')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m untangler \u001b[38;5;241m=\u001b[39m Untangler(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m untangler\u001b[38;5;241m.\u001b[39mchange_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43muntangler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_detect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteratively\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m result\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./Results/openai_gpt-4o_result-part1.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32md:\\Winter 2025\\COMP 7890 - Data-driven Software Engineering\\Project\\Tangled\\modules\\Untangler.py:290\u001b[0m, in \u001b[0;36mUntangler.batch_detect\u001b[1;34m(self, df, iteratively)\u001b[0m\n\u001b[0;32m    283\u001b[0m         batch_input_file_id \u001b[38;5;241m=\u001b[39m batch_input_file\u001b[38;5;241m.\u001b[39mid\n\u001b[0;32m    284\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__current_openai_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__client\u001b[38;5;241m.\u001b[39mbatches\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m    285\u001b[0m             input_file_id\u001b[38;5;241m=\u001b[39mbatch_input_file_id,\n\u001b[0;32m    286\u001b[0m             endpoint\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/v1/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    287\u001b[0m             completion_window\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m24h\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    288\u001b[0m         )\n\u001b[1;32m--> 290\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__current_openai_batch, df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_batch_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m()\n",
      "File \u001b[1;32md:\\Winter 2025\\COMP 7890 - Data-driven Software Engineering\\Project\\Tangled\\modules\\Untangler.py:309\u001b[0m, in \u001b[0;36mUntangler.get_batch_result\u001b[1;34m(self, batch_id, df)\u001b[0m\n\u001b[0;32m    307\u001b[0m         pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, batch\u001b[38;5;241m.\u001b[39mrequest_counts\u001b[38;5;241m.\u001b[39mcompleted \u001b[38;5;241m-\u001b[39m pbar\u001b[38;5;241m.\u001b[39mn))\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfailed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpired\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 309\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(batch\u001b[38;5;241m.\u001b[39merrors)\n\u001b[0;32m    311\u001b[0m explanations \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    312\u001b[0m answers \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mException\u001b[0m: Errors(data=[BatchError(code='token_limit_exceeded', line=None, message='Enqueued token limit reached for gpt-4o in organization org-RusRbI31Ti1GmBfluMMBQII7. Limit: 90,000 enqueued tokens. Please try again once some in_progress batches have been completed.', param=None)], object='list')"
     ]
    }
   ],
   "source": [
    "untangler = Untangler(model_name=\"openai\")\n",
    "untangler.change_model(\"gpt-4o\")\n",
    "result = untangler.batch_detect(df[:200], iteratively=False)\n",
    "result.to_csv(\"./Results/openai_gpt-4o_result-part1.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untangler = Untangler(model_name=\"openai\")\n",
    "untangler.change_model(\"gpt-4o\")\n",
    "result = untangler.batch_detect(df[850:], iteratively=False)\n",
    "result.to_csv(\"./Results/openai_gpt-4o_result-part2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, result = untangler.get_batch_result(\"batch_67c9dba2e8e481909e2bef8ae01070cd\", df)\n",
    "result.to_csv(\"./Results/openai_gpt-4o_result.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_csv(\"./Results/openai_gpt-4o_resul.csv\")\n",
    "print(classification_report(result[\"Decision\"], result[\"Detection\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
