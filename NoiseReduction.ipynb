{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.set_autosave_interval(120000)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 120 seconds\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%autosave 120\n",
    "import sys\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from modules.utilities import are_bugs_from_tangled, has_bug, is_same_history, parse_hash_delimited_string\n",
    "from modules.Untangler import Untangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9781it [06:28, 25.18it/s]:00<?, ?it/s]\n",
      "12755it [24:45,  8.59it/s]28<5:11:01, 388.78s/it]\n",
      "2659it [01:51, 23.95it/s]:14<13:29:59, 1034.03s/it]\n",
      "15953it [05:47, 45.89it/s]05<7:49:39, 612.60s/it]  \n",
      "3340it [08:45,  6.36it/s]:53<6:21:06, 508.14s/it]\n",
      "1145it [00:38, 29.38it/s]:39<6:17:15, 514.44s/it]\n",
      "2948it [02:37, 18.74it/s]:18<4:12:50, 352.79s/it]\n",
      "1146it [00:55, 20.61it/s]:55<3:22:14, 288.91s/it]\n",
      "36514it [02:11, 277.92it/s]1<2:26:40, 214.65s/it]\n",
      "22124it [57:15,  6.44it/s]03<2:05:56, 188.92s/it]\n",
      "62190it [16:05, 64.39it/s]51:19<12:54:27, 1191.47s/it]\n",
      "2390it [01:02, 38.05it/s]:07:27<11:51:07, 1122.84s/it]\n",
      "3759it [00:33, 112.18it/s]08:30<8:13:34, 800.40s/it]  \n",
      "38081it [08:53, 71.34it/s]09:03<5:40:51, 568.11s/it]\n",
      "20757it [04:25, 78.09it/s]17:58<5:25:27, 557.92s/it]\n",
      "70081it [03:56, 296.23it/s]2:24<4:26:19, 469.99s/it]\n",
      "35265it [12:54, 45.53it/s] 6:22<3:40:04, 400.14s/it]\n",
      "36274it [10:38, 56.82it/s]39:17<4:33:35, 512.98s/it]\n",
      "1958it [00:03, 637.27it/s]49:56<4:44:39, 550.96s/it]\n",
      "24800it [00:42, 587.70it/s]0:00<3:13:12, 386.43s/it]\n",
      "5345it [00:10, 532.78it/s] 0:42<2:16:54, 283.24s/it]\n",
      "35950it [06:12, 96.62it/s]50:53<1:33:55, 201.27s/it]\n",
      "5862it [00:46, 126.35it/s]57:05<1:53:45, 252.79s/it]\n",
      "20358it [03:25, 99.08it/s] 7:52<1:22:43, 190.91s/it]\n",
      "10645it [03:37, 48.86it/s]01:18<1:21:25, 195.40s/it]\n",
      "9548it [02:38, 60.35it/s]:04:56<1:20:53, 202.22s/it]\n",
      "2636it [01:00, 43.93it/s]:07:34<1:12:28, 189.08s/it]\n",
      "874it [00:12, 69.83it/s]3:08:35<55:08, 150.37s/it]  \n",
      "2085it [00:19, 107.80it/s]08:47<38:09, 109.03s/it]\n",
      "2684it [01:46, 25.27it/s]:09:06<27:22, 82.14s/it] \n",
      "37133it [05:02, 122.85it/s]0:53<28:18, 89.38s/it]\n",
      "1498it [00:24, 61.08it/s]:15:56<46:02, 153.46s/it]\n",
      "9467it [02:31, 62.66it/s]:16:20<32:31, 114.81s/it]\n",
      "16908it [08:01, 35.09it/s]18:52<33:32, 125.76s/it]\n",
      "1953it [01:03, 30.56it/s]:26:54<58:10, 232.71s/it]\n",
      "6066it [01:30, 67.14it/s]:27:58<42:29, 182.09s/it]\n",
      "8992it [03:38, 41.15it/s]:29:28<33:29, 154.61s/it]\n",
      "36715it [03:01, 202.53it/s]3:07<34:46, 173.85s/it]\n",
      "8145it [07:13, 18.81it/s]:36:09<32:19, 176.29s/it]\n",
      "20627it [11:57, 28.77it/s]43:22<42:14, 253.40s/it]\n",
      "10374it [00:47, 220.34it/s]5:20<58:53, 392.65s/it]\n",
      "26634it [01:22, 322.52it/s]6:07<38:32, 289.06s/it]\n",
      " 86%|████████▌ | 42/49 [3:57:31<26:31, 227.31s/it]"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "untangler = Untangler(model_name=\"openai\")\n",
    "untangler.change_model(\"gpt-4o\")\n",
    "\n",
    "csv_files = glob.glob(\"./data/Processed/*.csv\")\n",
    "for csv_file in tqdm(csv_files):\n",
    "    df = pd.read_csv(csv_file,delimiter=\"\\t\")\n",
    "    project_name = os.path.basename(csv_file).replace(\".csv\",\"\")\n",
    "\n",
    "    rows = []\n",
    "    for _, row in tqdm(df.iterrows()):\n",
    "        row = row.to_dict()\n",
    "        history = parse_hash_delimited_string(row[\"Buggycommiit\"])\n",
    "        change_list = parse_hash_delimited_string(row[\"TangledWMoveandFileRename\"])\n",
    "        if row[\"Age\"] < (365*2):\n",
    "            continue\n",
    "        if sum(history) >= 1 and any(t > 1 for t in [a * b for a, b in zip(change_list, history)]):\n",
    "            row[\"Decision\"] = \"Buggy\"\n",
    "            change_list.reverse()\n",
    "            history.reverse()\n",
    "            \n",
    "            json_path = os.path.join(\"./data/source-methods/\", project_name, row[\"file\"])\n",
    "            data = json.load(open(json_path, encoding=\"utf8\"))\n",
    "\n",
    "            buggy = False\n",
    "\n",
    "            for index, (change_count, is_buggy) in enumerate(zip(change_list, history)):\n",
    "                if is_buggy == 1 and change_count > 1:\n",
    "                    hash = data[\"changeHistory\"][index]\n",
    "                    \n",
    "                    commit_data = data[\"changeHistoryDetails\"][hash]\n",
    "                    change_data = commit_data[\"subchanges\"][0] if \"subchanges\" in commit_data.keys() else commit_data\n",
    "\n",
    "                    untangler.prepare_prompt(change_data[\"commitMessage\"], change_data[\"diff\"])\n",
    "\n",
    "                    error = True\n",
    "                    while error:\n",
    "                        try:\n",
    "                            result = untangler.detect()\n",
    "                            error = False\n",
    "                        except Exception as e:\n",
    "                            error = True\n",
    "                            print(f\"Error - {e}.\\nRetrying in 10s\")\n",
    "                            time.sleep(10)\n",
    "                    if result == \"Buggy\":\n",
    "                        buggy = True\n",
    "                        break\n",
    "                elif is_buggy == 1 and change_count == 1:\n",
    "                    buggy = True\n",
    "                    break\n",
    "                    \n",
    "            if buggy:\n",
    "                row[\"Detection\"] = \"Buggy\"\n",
    "            else:\n",
    "                row[\"Detection\"] = \"NotBuggy\"\n",
    "            row[\"result\"] = result\n",
    "        elif sum(history) >= 1:\n",
    "            row[\"Decision\"] = \"Buggy\"\n",
    "            row[\"Detection\"] = \"Buggy\"\n",
    "        else:\n",
    "            row[\"Decision\"] = \"NotBuggy\"\n",
    "            row[\"Detection\"] = \"NotBuggy\"\n",
    "        rows.append(row)\n",
    "    df = pd.DataFrame(rows)\n",
    "    df = df.drop([\"Unnamed: 26\"], axis=1)\n",
    "    df.to_csv(f\"./data/Cleaned/{project_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
