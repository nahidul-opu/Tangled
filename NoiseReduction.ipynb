{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.notebook.set_autosave_interval(120000)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 120 seconds\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%autosave 120\n",
    "import sys\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from modules.utilities import are_bugs_from_tangled, has_bug, is_same_history, parse_hash_delimited_string\n",
    "from modules.Untangler import Untangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9781it [06:28, 25.18it/s]:00<?, ?it/s]\n",
      "12755it [24:45,  8.59it/s]28<5:11:01, 388.78s/it]\n",
      "2659it [01:51, 23.95it/s]:14<13:29:59, 1034.03s/it]\n",
      "15953it [05:47, 45.89it/s]05<7:49:39, 612.60s/it]  \n",
      "3340it [08:45,  6.36it/s]:53<6:21:06, 508.14s/it]\n",
      "1145it [00:38, 29.38it/s]:39<6:17:15, 514.44s/it]\n",
      "2948it [02:37, 18.74it/s]:18<4:12:50, 352.79s/it]\n",
      "1146it [00:55, 20.61it/s]:55<3:22:14, 288.91s/it]\n",
      "36514it [02:11, 277.92it/s]1<2:26:40, 214.65s/it]\n",
      "22124it [57:15,  6.44it/s]03<2:05:56, 188.92s/it]\n",
      " 20%|██        | 10/49 [1:51:19<12:54:27, 1191.47s/it]"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "untangler = Untangler(model_name=\"openai\")\n",
    "untangler.change_model(\"gpt-4o\")\n",
    "\n",
    "csv_files = glob.glob(\"./data/Processed/*.csv\")\n",
    "for csv_file in tqdm(csv_files):\n",
    "    df = pd.read_csv(csv_file,delimiter=\"\\t\")\n",
    "    project_name = os.path.basename(csv_file).replace(\".csv\",\"\")\n",
    "\n",
    "    rows = []\n",
    "    for _, row in tqdm(df.iterrows()):\n",
    "        row = row.to_dict()\n",
    "        history = parse_hash_delimited_string(row[\"Buggycommiit\"])\n",
    "        change_list = parse_hash_delimited_string(row[\"TangledWMoveandFileRename\"])\n",
    "        if row[\"Age\"] < (365*2):\n",
    "            continue\n",
    "        if sum(history) >= 1 and any(t > 1 for t in [a * b for a, b in zip(change_list, history)]):\n",
    "            row[\"Decision\"] = \"Buggy\"\n",
    "            change_list.reverse()\n",
    "            history.reverse()\n",
    "            \n",
    "            json_path = os.path.join(\"./data/source-methods/\", project_name, row[\"file\"])\n",
    "            data = json.load(open(json_path, encoding=\"utf8\"))\n",
    "\n",
    "            buggy = False\n",
    "\n",
    "            for index, (change_count, is_buggy) in enumerate(zip(change_list, history)):\n",
    "                if is_buggy == 1 and change_count > 1:\n",
    "                    hash = data[\"changeHistory\"][index]\n",
    "                    \n",
    "                    commit_data = data[\"changeHistoryDetails\"][hash]\n",
    "                    change_data = commit_data[\"subchanges\"][0] if \"subchanges\" in commit_data.keys() else commit_data\n",
    "\n",
    "                    untangler.prepare_prompt(change_data[\"commitMessage\"], change_data[\"diff\"])\n",
    "\n",
    "                    error = True\n",
    "                    while error:\n",
    "                        try:\n",
    "                            result = untangler.detect()\n",
    "                            error = False\n",
    "                        except Exception as e:\n",
    "                            error = True\n",
    "                            print(f\"Error - {e}.\\nRetrying in 10s\")\n",
    "                            time.sleep(10)\n",
    "                    if result == \"Buggy\":\n",
    "                        buggy = True\n",
    "                        break\n",
    "                elif is_buggy == 1 and change_count == 1:\n",
    "                    buggy = True\n",
    "                    break\n",
    "                    \n",
    "            if buggy:\n",
    "                row[\"Detection\"] = \"Buggy\"\n",
    "            else:\n",
    "                row[\"Detection\"] = \"NotBuggy\"\n",
    "            row[\"result\"] = result\n",
    "        elif sum(history) >= 1:\n",
    "            row[\"Decision\"] = \"Buggy\"\n",
    "            row[\"Detection\"] = \"Buggy\"\n",
    "        else:\n",
    "            row[\"Decision\"] = \"NotBuggy\"\n",
    "            row[\"Detection\"] = \"NotBuggy\"\n",
    "        rows.append(row)\n",
    "    df = pd.DataFrame(rows)\n",
    "    df = df.drop([\"Unnamed: 26\"], axis=1)\n",
    "    df.to_csv(f\"./data/Cleaned/{project_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
